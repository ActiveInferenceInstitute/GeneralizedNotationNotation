{
  "metadata": {
    "model_name": "actinf_pomdp_agent",
    "framework": "pymdp_real_implementation",
    "timestamp": "2025-08-29T12:14:53.662299",
    "num_steps": 10
  },
  "simulation_data": [
    {
      "step": 1,
      "timestamp": "2025-08-29T12:14:53.659842",
      "belief": [
        0.3333333333333333,
        0.3333333333333333,
        0.3333333333333333
      ],
      "true_state": 1,
      "free_energy": 0.760601787666146,
      "expected_utilities": [
        0.39999999999999997,
        0.3457619047619048
      ],
      "action": 1,
      "action_probs": [
        0.704289701138652,
        0.29571029886134814
      ],
      "observation": 1,
      "reward": 0.1,
      "posterior_belief": [
        0.05073149428633816,
        0.9131668971540869,
        0.036101608559574935
      ]
    },
    {
      "step": 2,
      "timestamp": "2025-08-29T12:14:53.660397",
      "belief": [
        0.05073149428633816,
        0.9131668971540869,
        0.036101608559574935
      ],
      "true_state": 1,
      "free_energy": 1.5051154043297676,
      "expected_utilities": [
        0.2408324113836524,
        0.26483256215361906
      ],
      "action": 0,
      "action_probs": [
        0.40516192772691373,
        0.5948380722730863
      ],
      "observation": 0,
      "reward": 0.1,
      "posterior_belief": [
        0.7383277226501225,
        0.223753899571708,
        0.03791837777816945
      ]
    },
    {
      "step": 3,
      "timestamp": "2025-08-29T12:14:53.660681",
      "belief": [
        0.7383277226501225,
        0.223753899571708,
        0.03791837777816945
      ],
      "true_state": 0,
      "free_energy": 1.1761421710065756,
      "expected_utilities": [
        0.24180529130020975,
        0.29530949474895446
      ],
      "action": 0,
      "action_probs": [
        0.2981616630949576,
        0.7018383369050423
      ],
      "observation": 0,
      "reward": 0.1,
      "posterior_belief": [
        0.9666404961217185,
        0.022342460186207527,
        0.011017043692073883
      ]
    },
    {
      "step": 4,
      "timestamp": "2025-08-29T12:14:53.660888",
      "belief": [
        0.9666404961217185,
        0.022342460186207527,
        0.011017043692073883
      ],
      "true_state": 0,
      "free_energy": 1.6918193831136097,
      "expected_utilities": [
        0.2273996268971056,
        0.2990835024822779
      ],
      "action": 0,
      "action_probs": [
        0.24104808070440417,
        0.7589519192955958
      ],
      "observation": 3,
      "reward": 0.0,
      "posterior_belief": [
        0.7766483472852032,
        0.11563972213034526,
        0.10771193058445172
      ]
    },
    {
      "step": 5,
      "timestamp": "2025-08-29T12:14:53.661064",
      "belief": [
        0.7766483472852032,
        0.11563972213034526,
        0.10771193058445172
      ],
      "true_state": 0,
      "free_energy": 1.173421812642505,
      "expected_utilities": [
        0.279179738827974,
        0.313087023166166
      ],
      "action": 0,
      "action_probs": [
        0.3676023631660877,
        0.6323976368339123
      ],
      "observation": 3,
      "reward": 0.0,
      "posterior_belief": [
        0.6436538430996421,
        0.18094780549124168,
        0.1753983514091162
      ]
    },
    {
      "step": 6,
      "timestamp": "2025-08-29T12:14:53.661239",
      "belief": [
        0.6436538430996421,
        0.18094780549124168,
        0.1753983514091162
      ],
      "true_state": 2,
      "free_energy": 0.9609700669005543,
      "expected_utilities": [
        0.31542581717958174,
        0.3228894876448876
      ],
      "action": 0,
      "action_probs": [
        0.47018074699982104,
        0.529819253000179
      ],
      "observation": 2,
      "reward": 1.0,
      "posterior_belief": [
        0.11500523187982567,
        0.047347416416999744,
        0.8376473517031746
      ]
    },
    {
      "step": 7,
      "timestamp": "2025-08-29T12:14:53.661429",
      "belief": [
        0.11500523187982567,
        0.047347416416999744,
        0.8376473517031746
      ],
      "true_state": 2,
      "free_energy": 1.3176662001299135,
      "expected_utilities": [
        0.67006015683705,
        0.4525702962794077
      ],
      "action": 0,
      "action_probs": [
        0.9701086161963499,
        0.029891383803650175
      ],
      "observation": 2,
      "reward": 1.0,
      "posterior_belief": [
        0.014248785337468076,
        0.01051019536320292,
        0.9752410192993289
      ]
    },
    {
      "step": 8,
      "timestamp": "2025-08-29T12:14:53.661607",
      "belief": [
        0.014248785337468076,
        0.01051019536320292,
        0.9752410192993289
      ],
      "true_state": 2,
      "free_energy": 1.7263131388019535,
      "expected_utilities": [
        0.7437415658347907,
        0.47991062492595454
      ],
      "action": 0,
      "action_probs": [
        0.9855327524358952,
        0.014467247564104788
      ],
      "observation": 0,
      "reward": 0.1,
      "posterior_belief": [
        0.689838971456945,
        0.0374123964458614,
        0.27274863209719363
      ]
    },
    {
      "step": 9,
      "timestamp": "2025-08-29T12:14:53.661808",
      "belief": [
        0.689838971456945,
        0.0374123964458614,
        0.27274863209719363
      ],
      "true_state": 0,
      "free_energy": 1.1257946814865374,
      "expected_utilities": [
        0.36755689248804724,
        0.3473685380146847
      ],
      "action": 0,
      "action_probs": [
        0.5800585309147156,
        0.41994146908528446
      ],
      "observation": 2,
      "reward": 1.0,
      "posterior_belief": [
        0.09803495382600005,
        0.021223487966389485,
        0.8807415582076104
      ]
    },
    {
      "step": 10,
      "timestamp": "2025-08-29T12:14:53.662028",
      "belief": [
        0.09803495382600005,
        0.021223487966389485,
        0.8807415582076104
      ],
      "true_state": 2,
      "free_energy": 1.437921746658739,
      "expected_utilities": [
        0.6931371044201754,
        0.4617709017680067
      ],
      "action": 0,
      "action_probs": [
        0.9759167155654062,
        0.02408328443459383
      ],
      "observation": 3,
      "reward": 0.0,
      "posterior_belief": [
        0.16862446767820005,
        0.11485644157647264,
        0.7165190907453273
      ]
    }
  ],
  "traces": {
    "belief_states": [
      [
        0.3333333333333333,
        0.3333333333333333,
        0.3333333333333333
      ],
      [
        0.05073149428633816,
        0.9131668971540869,
        0.036101608559574935
      ],
      [
        0.7383277226501225,
        0.223753899571708,
        0.03791837777816945
      ],
      [
        0.9666404961217185,
        0.022342460186207527,
        0.011017043692073883
      ],
      [
        0.7766483472852032,
        0.11563972213034526,
        0.10771193058445172
      ],
      [
        0.6436538430996421,
        0.18094780549124168,
        0.1753983514091162
      ],
      [
        0.11500523187982567,
        0.047347416416999744,
        0.8376473517031746
      ],
      [
        0.014248785337468076,
        0.01051019536320292,
        0.9752410192993289
      ],
      [
        0.689838971456945,
        0.0374123964458614,
        0.27274863209719363
      ],
      [
        0.09803495382600005,
        0.021223487966389485,
        0.8807415582076104
      ]
    ],
    "actions": [
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "observations": [
      1,
      0,
      0,
      3,
      3,
      2,
      2,
      0,
      2,
      3
    ],
    "rewards": [
      0.1,
      0.1,
      0.1,
      0.0,
      0.0,
      1.0,
      1.0,
      0.1,
      1.0,
      0.0
    ],
    "free_energy": [
      0.760601787666146,
      1.5051154043297676,
      1.1761421710065756,
      1.6918193831136097,
      1.173421812642505,
      0.9609700669005543,
      1.3176662001299135,
      1.7263131388019535,
      1.1257946814865374,
      1.437921746658739
    ]
  },
  "summary": {
    "total_reward": 3.4,
    "average_reward": 0.34,
    "final_free_energy": 1.437921746658739,
    "final_belief_entropy": 0.7875747877601975,
    "final_belief": [
      0.16862446767820005,
      0.11485644157647264,
      0.7165190907453273
    ],
    "steps_completed": 10
  },
  "agent_matrices": {
    "A_shape": [
      4,
      3
    ],
    "B_shape": [
      3,
      3,
      2
    ],
    "C_length": 4,
    "D_length": 3
  }
}