{
  "summary": {
    "final_entropy": 0.08620176665935834,
    "average_reward": 0.52,
    "steps_completed": 10,
    "total_reward": 5.2,
    "final_free_energy": -0.08658386234843458
  },
  "metadata": {
    "num_steps": 10,
    "model_name": "actinf_pomdp_agent",
    "framework": "activeinference_jl_working"
  },
  "traces": {
    "belief_states": [
      [
        0.3333333333333333,
        0.3333333333333333,
        0.3333333333333333
      ],
      [
        0.3333333333333333,
        0.3333333333333333,
        0.3333333333333333
      ],
      [
        0.3333333333333333,
        0.3333333333333333,
        0.3333333333333333
      ],
      [
        0.05,
        0.9,
        0.05
      ],
      [
        0.04795128758087023,
        0.9168707735243317,
        0.03517793889479796
      ],
      [
        0.06641256759897159,
        0.07073166433554308,
        0.8628557680654854
      ],
      [
        0.14648879731928013,
        0.14951216503488016,
        0.7039990376458397
      ],
      [
        0.018283957491843226,
        0.018475006057309656,
        0.9632410364508471
      ],
      [
        0.007964570237967778,
        0.00797401301647199,
        0.9840614167455602
      ],
      [
        0.007326354973914167,
        0.007326813668791993,
        0.9853468313572937
      ]
    ],
    "observations": [
      4,
      4,
      2,
      2,
      3,
      4,
      3,
      3,
      3,
      3
    ],
    "actions": [
      1,
      2,
      1,
      2,
      2,
      1,
      1,
      1,
      1,
      1
    ],
    "rewards": [
      0.0,
      0.0,
      0.1,
      0.1,
      1.0,
      0.0,
      1.0,
      1.0,
      1.0,
      1.0
    ],
    "free_energy": [
      -1.0986122886651097,
      -1.0986122886651097,
      -1.0986122886651097,
      -0.39439769144444276,
      -0.3429818193992625,
      -0.49473849068873854,
      -0.8125945433840565,
      -0.18298236867767995,
      -0.09282866017025386,
      -0.08658386234843458
    ]
  }
}
