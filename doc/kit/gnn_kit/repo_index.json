{
  "file_tree": [
    {
      "path": "SECURITY.md",
      "is_dir": false,
      "name": "SECURITY.md",
      "size": 2762
    },
    {
      "path": ".gitignore",
      "is_dir": false,
      "name": ".gitignore",
      "size": 93
    },
    {
      "path": "LICENSE.md",
      "is_dir": false,
      "name": "LICENSE.md",
      "size": 1099
    },
    {
      "path": "SUPPORT.md",
      "is_dir": false,
      "name": "SUPPORT.md",
      "size": 3391
    },
    {
      "path": "CONTRIBUTING.md",
      "is_dir": false,
      "name": "CONTRIBUTING.md",
      "size": 4034
    },
    {
      "path": "README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 15285
    },
    {
      "path": "CODE_OF_CONDUCT.md",
      "is_dir": false,
      "name": "CODE_OF_CONDUCT.md",
      "size": 5369
    },
    {
      "path": "CITATION.cff",
      "is_dir": false,
      "name": "CITATION.cff",
      "size": 2725
    },
    {
      "path": ".cursorrules",
      "is_dir": false,
      "name": ".cursorrules",
      "size": 7558
    },
    {
      "path": "src",
      "is_dir": true,
      "name": "src",
      "size": 0
    },
    {
      "path": "src/7_mcp.py",
      "is_dir": false,
      "name": "7_mcp.py",
      "size": 29577
    },
    {
      "path": "src/2_setup.py",
      "is_dir": false,
      "name": "2_setup.py",
      "size": 11684
    },
    {
      "path": "src/1_gnn.py",
      "is_dir": false,
      "name": "1_gnn.py",
      "size": 27448
    },
    {
      "path": "src/5_export.py",
      "is_dir": false,
      "name": "5_export.py",
      "size": 19195
    },
    {
      "path": "src/9_render.py",
      "is_dir": false,
      "name": "9_render.py",
      "size": 12021
    },
    {
      "path": "src/requirements.txt",
      "is_dir": false,
      "name": "requirements.txt",
      "size": 149
    },
    {
      "path": "src/main.py",
      "is_dir": false,
      "name": "main.py",
      "size": 36462
    },
    {
      "path": "src/6_visualization.py",
      "is_dir": false,
      "name": "6_visualization.py",
      "size": 10713
    },
    {
      "path": "src/12_site.py",
      "is_dir": false,
      "name": "12_site.py",
      "size": 5112
    },
    {
      "path": "src/3_tests.py",
      "is_dir": false,
      "name": "3_tests.py",
      "size": 9718
    },
    {
      "path": "src/10_execute.py",
      "is_dir": false,
      "name": "10_execute.py",
      "size": 8412
    },
    {
      "path": "src/11_llm.py",
      "is_dir": false,
      "name": "11_llm.py",
      "size": 26836
    },
    {
      "path": "src/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 25402
    },
    {
      "path": "src/4_gnn_type_checker.py",
      "is_dir": false,
      "name": "4_gnn_type_checker.py",
      "size": 12715
    },
    {
      "path": "src/8_ontology.py",
      "is_dir": false,
      "name": "8_ontology.py",
      "size": 16852
    },
    {
      "path": "output",
      "is_dir": true,
      "name": "output",
      "size": 0
    },
    {
      "path": "output/gnn_processing_summary.md",
      "is_dir": false,
      "name": "gnn_processing_summary.md",
      "size": 107
    },
    {
      "path": "doc",
      "is_dir": true,
      "name": "doc",
      "size": 0
    },
    {
      "path": "doc/gnn_llm_neurosymbolic_active_inference.md",
      "is_dir": false,
      "name": "gnn_llm_neurosymbolic_active_inference.md",
      "size": 49124
    },
    {
      "path": "doc/gnn_multiagent.md",
      "is_dir": false,
      "name": "gnn_multiagent.md",
      "size": 14606
    },
    {
      "path": "doc/gnn_dsl_manual.md",
      "is_dir": false,
      "name": "gnn_dsl_manual.md",
      "size": 18341
    },
    {
      "path": "doc/gnn_implementation.md",
      "is_dir": false,
      "name": "gnn_implementation.md",
      "size": 22718
    },
    {
      "path": "doc/gnn_syntax.md",
      "is_dir": false,
      "name": "gnn_syntax.md",
      "size": 9524
    },
    {
      "path": "doc/resource_metrics.md",
      "is_dir": false,
      "name": "resource_metrics.md",
      "size": 5235
    },
    {
      "path": "doc/gnn_examples_doc.md",
      "is_dir": false,
      "name": "gnn_examples_doc.md",
      "size": 12749
    },
    {
      "path": "doc/gnn_paper.md",
      "is_dir": false,
      "name": "gnn_paper.md",
      "size": 15143
    },
    {
      "path": "doc/gnn_file_structure_doc.md",
      "is_dir": false,
      "name": "gnn_file_structure_doc.md",
      "size": 9272
    },
    {
      "path": "doc/gnn_overview.md",
      "is_dir": false,
      "name": "gnn_overview.md",
      "size": 6925
    },
    {
      "path": "doc/about_gnn.md",
      "is_dir": false,
      "name": "about_gnn.md",
      "size": 13771
    },
    {
      "path": "doc/ontology_system.md",
      "is_dir": false,
      "name": "ontology_system.md",
      "size": 3574
    },
    {
      "path": "doc/gnn_tools.md",
      "is_dir": false,
      "name": "gnn_tools.md",
      "size": 19577
    },
    {
      "path": "src/gnn_type_checker",
      "is_dir": true,
      "name": "gnn_type_checker",
      "size": 0
    },
    {
      "path": "src/gnn_type_checker/resource_estimator.py",
      "is_dir": false,
      "name": "resource_estimator.py",
      "size": 76070
    },
    {
      "path": "src/gnn_type_checker/__main__.py",
      "is_dir": false,
      "name": "__main__.py",
      "size": 201
    },
    {
      "path": "src/gnn_type_checker/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 10921
    },
    {
      "path": "src/gnn_type_checker/checker.py",
      "is_dir": false,
      "name": "checker.py",
      "size": 21955
    },
    {
      "path": "src/gnn_type_checker/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 1727
    },
    {
      "path": "src/gnn_type_checker/cli.py",
      "is_dir": false,
      "name": "cli.py",
      "size": 8163
    },
    {
      "path": "src/gnn_type_checker/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 336
    },
    {
      "path": "src/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/__pycache__/2_setup.cpython-312.pyc",
      "is_dir": false,
      "name": "2_setup.cpython-312.pyc",
      "size": 10329
    },
    {
      "path": "src/__pycache__/4_gnn_type_checker.cpython-312.pyc",
      "is_dir": false,
      "name": "4_gnn_type_checker.cpython-312.pyc",
      "size": 10958
    },
    {
      "path": "src/__pycache__/7_mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "7_mcp.cpython-312.pyc",
      "size": 25195
    },
    {
      "path": "src/__pycache__/10_execute.cpython-312.pyc",
      "is_dir": false,
      "name": "10_execute.cpython-312.pyc",
      "size": 5866
    },
    {
      "path": "src/__pycache__/3_tests.cpython-312.pyc",
      "is_dir": false,
      "name": "3_tests.cpython-312.pyc",
      "size": 6904
    },
    {
      "path": "src/__pycache__/6_visualization.cpython-312.pyc",
      "is_dir": false,
      "name": "6_visualization.cpython-312.pyc",
      "size": 7913
    },
    {
      "path": "src/__pycache__/8_ontology.cpython-312.pyc",
      "is_dir": false,
      "name": "8_ontology.cpython-312.pyc",
      "size": 15224
    },
    {
      "path": "src/__pycache__/11_llm.cpython-312.pyc",
      "is_dir": false,
      "name": "11_llm.cpython-312.pyc",
      "size": 24565
    },
    {
      "path": "src/__pycache__/5_export.cpython-312.pyc",
      "is_dir": false,
      "name": "5_export.cpython-312.pyc",
      "size": 20642
    },
    {
      "path": "src/__pycache__/1_gnn.cpython-312.pyc",
      "is_dir": false,
      "name": "1_gnn.cpython-312.pyc",
      "size": 19238
    },
    {
      "path": "src/__pycache__/9_render.cpython-312.pyc",
      "is_dir": false,
      "name": "9_render.cpython-312.pyc",
      "size": 8780
    },
    {
      "path": "src/ontology",
      "is_dir": true,
      "name": "ontology",
      "size": 0
    },
    {
      "path": "src/ontology/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 13473
    },
    {
      "path": "src/ontology/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 4559
    },
    {
      "path": "src/ontology/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 131
    },
    {
      "path": "src/ontology/act_inf_ontology_terms.json",
      "is_dir": false,
      "name": "act_inf_ontology_terms.json",
      "size": 8956
    },
    {
      "path": "src/execute",
      "is_dir": true,
      "name": "execute",
      "size": 0
    },
    {
      "path": "src/execute/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 1882
    },
    {
      "path": "src/execute/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 2074
    },
    {
      "path": "src/execute/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 53
    },
    {
      "path": "src/execute/pymdp_runner.py",
      "is_dir": false,
      "name": "pymdp_runner.py",
      "size": 11435
    },
    {
      "path": "src/site",
      "is_dir": true,
      "name": "site",
      "size": 0
    },
    {
      "path": "src/site/generator.py",
      "is_dir": false,
      "name": "generator.py",
      "size": 30449
    },
    {
      "path": "src/site/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 2953
    },
    {
      "path": "src/site/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 141
    },
    {
      "path": "src/tests",
      "is_dir": true,
      "name": "tests",
      "size": 0
    },
    {
      "path": "src/tests/test_gnn_type_checker.py",
      "is_dir": false,
      "name": "test_gnn_type_checker.py",
      "size": 6284
    },
    {
      "path": "src/tests/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 7083
    },
    {
      "path": "src/tests/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 141
    },
    {
      "path": "src/export",
      "is_dir": true,
      "name": "export",
      "size": 0
    },
    {
      "path": "src/export/structured_data_exporters.py",
      "is_dir": false,
      "name": "structured_data_exporters.py",
      "size": 3846
    },
    {
      "path": "src/export/text_exporters.py",
      "is_dir": false,
      "name": "text_exporters.py",
      "size": 5587
    },
    {
      "path": "src/export/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 7976
    },
    {
      "path": "src/export/format_exporters.py",
      "is_dir": false,
      "name": "format_exporters.py",
      "size": 24864
    },
    {
      "path": "src/export/graph_exporters.py",
      "is_dir": false,
      "name": "graph_exporters.py",
      "size": 4014
    },
    {
      "path": "src/utils",
      "is_dir": true,
      "name": "utils",
      "size": 0
    },
    {
      "path": "src/utils/logging_utils.py",
      "is_dir": false,
      "name": "logging_utils.py",
      "size": 2291
    },
    {
      "path": "src/utils/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 131
    },
    {
      "path": "src/setup",
      "is_dir": true,
      "name": "setup",
      "size": 0
    },
    {
      "path": "src/setup/utils.py",
      "is_dir": false,
      "name": "utils.py",
      "size": 1543
    },
    {
      "path": "src/setup/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 4257
    },
    {
      "path": "src/setup/setup.py",
      "is_dir": false,
      "name": "setup.py",
      "size": 9347
    },
    {
      "path": "src/setup/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 202
    },
    {
      "path": "src/gnn",
      "is_dir": true,
      "name": "gnn",
      "size": 0
    },
    {
      "path": "src/gnn/gnn_file_structure.md",
      "is_dir": false,
      "name": "gnn_file_structure.md",
      "size": 2516
    },
    {
      "path": "src/gnn/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 4122
    },
    {
      "path": "src/gnn/gnn_punctuation.md",
      "is_dir": false,
      "name": "gnn_punctuation.md",
      "size": 1789
    },
    {
      "path": "src/gnn/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 131
    },
    {
      "path": "src/mcp",
      "is_dir": true,
      "name": "mcp",
      "size": 0
    },
    {
      "path": "src/mcp/npx_inspector.py",
      "is_dir": false,
      "name": "npx_inspector.py",
      "size": 15868
    },
    {
      "path": "src/mcp/server_stdio.py",
      "is_dir": false,
      "name": "server_stdio.py",
      "size": 7620
    },
    {
      "path": "src/mcp/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 19286
    },
    {
      "path": "src/mcp/test_mcp.py",
      "is_dir": false,
      "name": "test_mcp.py",
      "size": 15921
    },
    {
      "path": "src/mcp/server_http.py",
      "is_dir": false,
      "name": "server_http.py",
      "size": 7731
    },
    {
      "path": "src/mcp/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 8691
    },
    {
      "path": "src/mcp/meta_mcp.py",
      "is_dir": false,
      "name": "meta_mcp.py",
      "size": 4954
    },
    {
      "path": "src/mcp/cli.py",
      "is_dir": false,
      "name": "cli.py",
      "size": 4644
    },
    {
      "path": "src/mcp/mcp_implementation_spec.md",
      "is_dir": false,
      "name": "mcp_implementation_spec.md",
      "size": 69149
    },
    {
      "path": "src/mcp/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 144
    },
    {
      "path": "src/mcp/model_context_protocol.md",
      "is_dir": false,
      "name": "model_context_protocol.md",
      "size": 16713
    },
    {
      "path": "src/visualization",
      "is_dir": true,
      "name": "visualization",
      "size": 0
    },
    {
      "path": "src/visualization/matrix_visualizer.py",
      "is_dir": false,
      "name": "matrix_visualizer.py",
      "size": 10261
    },
    {
      "path": "src/visualization/__main__.py",
      "is_dir": false,
      "name": "__main__.py",
      "size": 266
    },
    {
      "path": "src/visualization/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 5934
    },
    {
      "path": "src/visualization/visualizer.py",
      "is_dir": false,
      "name": "visualizer.py",
      "size": 22967
    },
    {
      "path": "src/visualization/ontology_visualizer.py",
      "is_dir": false,
      "name": "ontology_visualizer.py",
      "size": 3768
    },
    {
      "path": "src/visualization/run_visualization.py",
      "is_dir": false,
      "name": "run_visualization.py",
      "size": 2727
    },
    {
      "path": "src/visualization/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 2242
    },
    {
      "path": "src/visualization/cli.py",
      "is_dir": false,
      "name": "cli.py",
      "size": 2687
    },
    {
      "path": "src/visualization/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 245
    },
    {
      "path": "src/visualization/parser.py",
      "is_dir": false,
      "name": "parser.py",
      "size": 11203
    },
    {
      "path": "src/render",
      "is_dir": true,
      "name": "render",
      "size": 0
    },
    {
      "path": "src/render/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 9330
    },
    {
      "path": "src/render/pymdp_utils.py",
      "is_dir": false,
      "name": "pymdp_utils.py",
      "size": 8155
    },
    {
      "path": "src/render/rxinfer.py",
      "is_dir": false,
      "name": "rxinfer.py",
      "size": 43706
    },
    {
      "path": "src/render/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 905
    },
    {
      "path": "src/render/render.py",
      "is_dir": false,
      "name": "render.py",
      "size": 9771
    },
    {
      "path": "src/render/pymdp.py",
      "is_dir": false,
      "name": "pymdp.py",
      "size": 84342
    },
    {
      "path": "src/render/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 131
    },
    {
      "path": "src/llm",
      "is_dir": true,
      "name": "llm",
      "size": 0
    },
    {
      "path": "src/llm/llm_operations.py",
      "is_dir": false,
      "name": "llm_operations.py",
      "size": 5079
    },
    {
      "path": "src/llm/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 16468
    },
    {
      "path": "src/llm/.env.example",
      "is_dir": false,
      "name": ".env.example",
      "size": 29
    },
    {
      "path": "src/llm/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 131
    },
    {
      "path": "src/gnn_type_checker/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/gnn_type_checker/__pycache__/checker.cpython-312.pyc",
      "is_dir": false,
      "name": "checker.cpython-312.pyc",
      "size": 26650
    },
    {
      "path": "src/gnn_type_checker/__pycache__/cli.cpython-310.pyc",
      "is_dir": false,
      "name": "cli.cpython-310.pyc",
      "size": 3011
    },
    {
      "path": "src/gnn_type_checker/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 547
    },
    {
      "path": "src/gnn_type_checker/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 11216
    },
    {
      "path": "src/gnn_type_checker/__pycache__/resource_estimator.cpython-312.pyc",
      "is_dir": false,
      "name": "resource_estimator.cpython-312.pyc",
      "size": 73856
    },
    {
      "path": "src/gnn_type_checker/__pycache__/__main__.cpython-310.pyc",
      "is_dir": false,
      "name": "__main__.cpython-310.pyc",
      "size": 417
    },
    {
      "path": "src/gnn_type_checker/__pycache__/resource_estimator.cpython-310.pyc",
      "is_dir": false,
      "name": "resource_estimator.cpython-310.pyc",
      "size": 46847
    },
    {
      "path": "src/gnn_type_checker/__pycache__/checker.cpython-310.pyc",
      "is_dir": false,
      "name": "checker.cpython-310.pyc",
      "size": 15809
    },
    {
      "path": "src/gnn_type_checker/__pycache__/__init__.cpython-310.pyc",
      "is_dir": false,
      "name": "__init__.cpython-310.pyc",
      "size": 460
    },
    {
      "path": "src/gnn_type_checker/__pycache__/cli.cpython-312.pyc",
      "is_dir": false,
      "name": "cli.cpython-312.pyc",
      "size": 9095
    },
    {
      "path": "src/ontology/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/ontology/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 177
    },
    {
      "path": "src/ontology/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 14549
    },
    {
      "path": "src/execute/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/execute/__pycache__/pymdp_runner.cpython-312.pyc",
      "is_dir": false,
      "name": "pymdp_runner.cpython-312.pyc",
      "size": 13036
    },
    {
      "path": "src/execute/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 176
    },
    {
      "path": "src/execute/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 1062
    },
    {
      "path": "src/site/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/site/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 173
    },
    {
      "path": "src/site/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 4158
    },
    {
      "path": "src/site/__pycache__/generator.cpython-312.pyc",
      "is_dir": false,
      "name": "generator.cpython-312.pyc",
      "size": 32516
    },
    {
      "path": "src/tests/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/tests/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 174
    },
    {
      "path": "src/tests/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 9169
    },
    {
      "path": "src/tests/__pycache__/test_gnn_type_checker.cpython-312-pytest-8.3.5.pyc",
      "is_dir": false,
      "name": "test_gnn_type_checker.cpython-312-pytest-8.3.5.pyc",
      "size": 8977
    },
    {
      "path": "src/export/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/export/__pycache__/structured_data_exporters.cpython-312.pyc",
      "is_dir": false,
      "name": "structured_data_exporters.cpython-312.pyc",
      "size": 5722
    },
    {
      "path": "src/export/__pycache__/format_exporters.cpython-312.pyc",
      "is_dir": false,
      "name": "format_exporters.cpython-312.pyc",
      "size": 24797
    },
    {
      "path": "src/export/__pycache__/format_exporters.cpython-310.pyc",
      "is_dir": false,
      "name": "format_exporters.cpython-310.pyc",
      "size": 19653
    },
    {
      "path": "src/export/__pycache__/text_exporters.cpython-312.pyc",
      "is_dir": false,
      "name": "text_exporters.cpython-312.pyc",
      "size": 7560
    },
    {
      "path": "src/export/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 8188
    },
    {
      "path": "src/export/__pycache__/graph_exporters.cpython-312.pyc",
      "is_dir": false,
      "name": "graph_exporters.cpython-312.pyc",
      "size": 5702
    },
    {
      "path": "src/utils/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/utils/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 174
    },
    {
      "path": "src/utils/__pycache__/logging_utils.cpython-312.pyc",
      "is_dir": false,
      "name": "logging_utils.cpython-312.pyc",
      "size": 2133
    },
    {
      "path": "src/setup/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/setup/__pycache__/utils.cpython-312.pyc",
      "is_dir": false,
      "name": "utils.cpython-312.pyc",
      "size": 2131
    },
    {
      "path": "src/setup/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 425
    },
    {
      "path": "src/setup/__pycache__/setup.cpython-312.pyc",
      "is_dir": false,
      "name": "setup.cpython-312.pyc",
      "size": 12098
    },
    {
      "path": "src/setup/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 4950
    },
    {
      "path": "src/gnn/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/gnn/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 172
    },
    {
      "path": "src/gnn/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 4411
    },
    {
      "path": "src/gnn/examples",
      "is_dir": true,
      "name": "examples",
      "size": 0
    },
    {
      "path": "src/gnn/examples/gnn_POMDP_example.md",
      "is_dir": false,
      "name": "gnn_POMDP_example.md",
      "size": 8049
    },
    {
      "path": "src/gnn/examples/gnn_example_pymdp_agent.md",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent.md",
      "size": 6387
    },
    {
      "path": "src/mcp/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/mcp/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 315
    },
    {
      "path": "src/mcp/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 17709
    },
    {
      "path": "src/visualization/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/visualization/__pycache__/ontology_visualizer.cpython-310.pyc",
      "is_dir": false,
      "name": "ontology_visualizer.cpython-310.pyc",
      "size": 3915
    },
    {
      "path": "src/visualization/__pycache__/visualizer.cpython-310.pyc",
      "is_dir": false,
      "name": "visualizer.cpython-310.pyc",
      "size": 13195
    },
    {
      "path": "src/visualization/__pycache__/cli.cpython-310.pyc",
      "is_dir": false,
      "name": "cli.cpython-310.pyc",
      "size": 2009
    },
    {
      "path": "src/visualization/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 453
    },
    {
      "path": "src/visualization/__pycache__/matrix_visualizer.cpython-312.pyc",
      "is_dir": false,
      "name": "matrix_visualizer.cpython-312.pyc",
      "size": 11810
    },
    {
      "path": "src/visualization/__pycache__/parser.cpython-312.pyc",
      "is_dir": false,
      "name": "parser.cpython-312.pyc",
      "size": 11880
    },
    {
      "path": "src/visualization/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 6443
    },
    {
      "path": "src/visualization/__pycache__/parser.cpython-310.pyc",
      "is_dir": false,
      "name": "parser.cpython-310.pyc",
      "size": 6848
    },
    {
      "path": "src/visualization/__pycache__/ontology_visualizer.cpython-312.pyc",
      "is_dir": false,
      "name": "ontology_visualizer.cpython-312.pyc",
      "size": 5056
    },
    {
      "path": "src/visualization/__pycache__/run_visualization.cpython-310.pyc",
      "is_dir": false,
      "name": "run_visualization.cpython-310.pyc",
      "size": 2284
    },
    {
      "path": "src/visualization/__pycache__/__init__.cpython-310.pyc",
      "is_dir": false,
      "name": "__init__.cpython-310.pyc",
      "size": 435
    },
    {
      "path": "src/visualization/__pycache__/matrix_visualizer.cpython-310.pyc",
      "is_dir": false,
      "name": "matrix_visualizer.cpython-310.pyc",
      "size": 7288
    },
    {
      "path": "src/visualization/__pycache__/cli.cpython-312.pyc",
      "is_dir": false,
      "name": "cli.cpython-312.pyc",
      "size": 3300
    },
    {
      "path": "src/visualization/__pycache__/visualizer.cpython-312.pyc",
      "is_dir": false,
      "name": "visualizer.cpython-312.pyc",
      "size": 24082
    },
    {
      "path": "src/render/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/render/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 175
    },
    {
      "path": "src/render/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 9300
    },
    {
      "path": "src/render/__pycache__/render.cpython-312.pyc",
      "is_dir": false,
      "name": "render.cpython-312.pyc",
      "size": 9385
    },
    {
      "path": "src/render/__pycache__/pymdp_utils.cpython-312.pyc",
      "is_dir": false,
      "name": "pymdp_utils.cpython-312.pyc",
      "size": 10881
    },
    {
      "path": "src/render/__pycache__/pymdp.cpython-312.pyc",
      "is_dir": false,
      "name": "pymdp.cpython-312.pyc",
      "size": 80507
    },
    {
      "path": "src/render/__pycache__/rxinfer.cpython-312.pyc",
      "is_dir": false,
      "name": "rxinfer.cpython-312.pyc",
      "size": 42131
    },
    {
      "path": "src/llm/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/llm/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 172
    },
    {
      "path": "src/llm/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 14439
    },
    {
      "path": "src/llm/__pycache__/llm_operations.cpython-312.pyc",
      "is_dir": false,
      "name": "llm_operations.cpython-312.pyc",
      "size": 6450
    },
    {
      "path": "output/mcp_processing_step",
      "is_dir": true,
      "name": "mcp_processing_step",
      "size": 0
    },
    {
      "path": "output/mcp_processing_step/7_mcp_integration_report.md",
      "is_dir": false,
      "name": "7_mcp_integration_report.md",
      "size": 37184
    },
    {
      "path": "output/gnn_exports",
      "is_dir": true,
      "name": "gnn_exports",
      "size": 0
    },
    {
      "path": "output/gnn_exports/5_export_step_report.md",
      "is_dir": false,
      "name": "5_export_step_report.md",
      "size": 421
    },
    {
      "path": "output/logs",
      "is_dir": true,
      "name": "logs",
      "size": 0
    },
    {
      "path": "output/logs/pipeline.log",
      "is_dir": false,
      "name": "pipeline.log",
      "size": 487614
    },
    {
      "path": "output/gnn_processing_step",
      "is_dir": true,
      "name": "gnn_processing_step",
      "size": 0
    },
    {
      "path": "output/gnn_processing_step/1_gnn_discovery_report.md",
      "is_dir": false,
      "name": "1_gnn_discovery_report.md",
      "size": 1528
    },
    {
      "path": "output/test_reports",
      "is_dir": true,
      "name": "test_reports",
      "size": 0
    },
    {
      "path": "output/test_reports/pytest_report.xml",
      "is_dir": false,
      "name": "pytest_report.xml",
      "size": 687
    },
    {
      "path": "output/gnn_type_check",
      "is_dir": true,
      "name": "gnn_type_check",
      "size": 0
    },
    {
      "path": "output/gnn_type_check/type_check_report.md",
      "is_dir": false,
      "name": "type_check_report.md",
      "size": 536
    },
    {
      "path": "output/ontology_processing",
      "is_dir": true,
      "name": "ontology_processing",
      "size": 0
    },
    {
      "path": "output/ontology_processing/ontology_processing_report.md",
      "is_dir": false,
      "name": "ontology_processing_report.md",
      "size": 6284
    },
    {
      "path": "output/gnn_exports/gnn_example_pymdp_agent",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent",
      "size": 0
    },
    {
      "path": "output/gnn_exports/gnn_example_pymdp_agent/gnn_example_pymdp_agent.txt",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent.txt",
      "size": 2763
    },
    {
      "path": "output/gnn_exports/gnn_example_pymdp_agent/gnn_example_pymdp_agent.json",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent.json",
      "size": 15147
    },
    {
      "path": "output/gnn_exports/gnn_example_pymdp_agent/gnn_example_pymdp_agent.xml",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent.xml",
      "size": 16156
    },
    {
      "path": "output/gnn_exports/gnn_example_pymdp_agent/gnn_example_pymdp_agent.gnn",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent.gnn",
      "size": 6108
    },
    {
      "path": "output/gnn_exports/gnn_airplane_trading_pomdp",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp",
      "size": 0
    },
    {
      "path": "output/gnn_exports/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp.gnn",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp.gnn",
      "size": 9946
    },
    {
      "path": "output/gnn_exports/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp.txt",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp.txt",
      "size": 2627
    },
    {
      "path": "output/gnn_exports/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp.json",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp.json",
      "size": 22387
    },
    {
      "path": "output/gnn_exports/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp.xml",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp.xml",
      "size": 23178
    },
    {
      "path": "output/gnn_exports/gnn_poetic_muse_model",
      "is_dir": true,
      "name": "gnn_poetic_muse_model",
      "size": 0
    },
    {
      "path": "output/gnn_exports/gnn_poetic_muse_model/gnn_poetic_muse_model.json",
      "is_dir": false,
      "name": "gnn_poetic_muse_model.json",
      "size": 23143
    },
    {
      "path": "output/gnn_exports/gnn_poetic_muse_model/gnn_poetic_muse_model.txt",
      "is_dir": false,
      "name": "gnn_poetic_muse_model.txt",
      "size": 3388
    },
    {
      "path": "output/gnn_exports/gnn_poetic_muse_model/gnn_poetic_muse_model.xml",
      "is_dir": false,
      "name": "gnn_poetic_muse_model.xml",
      "size": 24543
    },
    {
      "path": "output/gnn_exports/gnn_poetic_muse_model/gnn_poetic_muse_model.gnn",
      "is_dir": false,
      "name": "gnn_poetic_muse_model.gnn",
      "size": 9355
    },
    {
      "path": "output/gnn_exports/gnn_POMDP_example",
      "is_dir": true,
      "name": "gnn_POMDP_example",
      "size": 0
    },
    {
      "path": "output/gnn_exports/gnn_POMDP_example/gnn_POMDP_example.gnn",
      "is_dir": false,
      "name": "gnn_POMDP_example.gnn",
      "size": 7819
    },
    {
      "path": "output/gnn_exports/gnn_POMDP_example/gnn_POMDP_example.json",
      "is_dir": false,
      "name": "gnn_POMDP_example.json",
      "size": 17619
    },
    {
      "path": "output/gnn_exports/gnn_POMDP_example/gnn_POMDP_example.txt",
      "is_dir": false,
      "name": "gnn_POMDP_example.txt",
      "size": 2626
    },
    {
      "path": "output/gnn_exports/gnn_POMDP_example/gnn_POMDP_example.xml",
      "is_dir": false,
      "name": "gnn_POMDP_example.xml",
      "size": 18589
    },
    {
      "path": "output/gnn_exports/gnn_active_inference_language_model",
      "is_dir": true,
      "name": "gnn_active_inference_language_model",
      "size": 0
    },
    {
      "path": "output/gnn_exports/gnn_active_inference_language_model/gnn_active_inference_language_model.json",
      "is_dir": false,
      "name": "gnn_active_inference_language_model.json",
      "size": 28405
    },
    {
      "path": "output/gnn_exports/gnn_active_inference_language_model/gnn_active_inference_language_model.txt",
      "is_dir": false,
      "name": "gnn_active_inference_language_model.txt",
      "size": 5732
    },
    {
      "path": "output/gnn_exports/gnn_active_inference_language_model/gnn_active_inference_language_model.xml",
      "is_dir": false,
      "name": "gnn_active_inference_language_model.xml",
      "size": 30188
    },
    {
      "path": "output/gnn_exports/gnn_active_inference_language_model/gnn_active_inference_language_model.gnn",
      "is_dir": false,
      "name": "gnn_active_inference_language_model.gnn",
      "size": 13517
    },
    {
      "path": "output/gnn_examples_visualization",
      "is_dir": true,
      "name": "gnn_examples_visualization",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Cm1.png",
      "is_dir": false,
      "name": "matrix_Cm1.png",
      "size": 29832
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Am1.png",
      "is_dir": false,
      "name": "matrix_Am1.png",
      "size": 34655
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/model_metadata.json",
      "is_dir": false,
      "name": "model_metadata.json",
      "size": 1427
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/full_model_data.json",
      "is_dir": false,
      "name": "full_model_data.json",
      "size": 6641
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/file_content.md",
      "is_dir": false,
      "name": "file_content.md",
      "size": 13050
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Bf0.png",
      "is_dir": false,
      "name": "matrix_Bf0.png",
      "size": 27677
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Bf1.png",
      "is_dir": false,
      "name": "matrix_Bf1.png",
      "size": 36639
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Am2.png",
      "is_dir": false,
      "name": "matrix_Am2.png",
      "size": 34441
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/ontology_annotations.png",
      "is_dir": false,
      "name": "ontology_annotations.png",
      "size": 155892
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Df0.png",
      "is_dir": false,
      "name": "matrix_Df0.png",
      "size": 27201
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/state_space.png",
      "is_dir": false,
      "name": "state_space.png",
      "size": 205255
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Cm2.png",
      "is_dir": false,
      "name": "matrix_Cm2.png",
      "size": 35738
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Cm0.png",
      "is_dir": false,
      "name": "matrix_Cm0.png",
      "size": 35913
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Am0.png",
      "is_dir": false,
      "name": "matrix_Am0.png",
      "size": 38175
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/connections.png",
      "is_dir": false,
      "name": "connections.png",
      "size": 62403
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/combined_matrices.png",
      "is_dir": false,
      "name": "combined_matrices.png",
      "size": 107750
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/combined_visualization.png",
      "is_dir": false,
      "name": "combined_visualization.png",
      "size": 153622
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Df1.png",
      "is_dir": false,
      "name": "matrix_Df1.png",
      "size": 30886
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Cm1.png",
      "is_dir": false,
      "name": "matrix_Cm1.png",
      "size": 25777
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Am1.png",
      "is_dir": false,
      "name": "matrix_Am1.png",
      "size": 62049
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/model_metadata.json",
      "is_dir": false,
      "name": "model_metadata.json",
      "size": 1576
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/full_model_data.json",
      "is_dir": false,
      "name": "full_model_data.json",
      "size": 10678
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/file_content.md",
      "is_dir": false,
      "name": "file_content.md",
      "size": 20737
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Bf0.png",
      "is_dir": false,
      "name": "matrix_Bf0.png",
      "size": 35468
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Bf1.png",
      "is_dir": false,
      "name": "matrix_Bf1.png",
      "size": 48711
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/ontology_annotations.png",
      "is_dir": false,
      "name": "ontology_annotations.png",
      "size": 117131
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Df0.png",
      "is_dir": false,
      "name": "matrix_Df0.png",
      "size": 34160
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/state_space.png",
      "is_dir": false,
      "name": "state_space.png",
      "size": 186485
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Cm0.png",
      "is_dir": false,
      "name": "matrix_Cm0.png",
      "size": 26327
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Am0.png",
      "is_dir": false,
      "name": "matrix_Am0.png",
      "size": 44947
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/connections.png",
      "is_dir": false,
      "name": "connections.png",
      "size": 60686
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/combined_matrices.png",
      "is_dir": false,
      "name": "combined_matrices.png",
      "size": 96171
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/combined_visualization.png",
      "is_dir": false,
      "name": "combined_visualization.png",
      "size": 134102
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Df1.png",
      "is_dir": false,
      "name": "matrix_Df1.png",
      "size": 34009
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model",
      "is_dir": true,
      "name": "gnn_poetic_muse_model",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/model_metadata.json",
      "is_dir": false,
      "name": "model_metadata.json",
      "size": 1903
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/matrix_Dv2.png",
      "is_dir": false,
      "name": "matrix_Dv2.png",
      "size": 31469
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/full_model_data.json",
      "is_dir": false,
      "name": "full_model_data.json",
      "size": 9849
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/file_content.md",
      "is_dir": false,
      "name": "file_content.md",
      "size": 19414
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/ontology_annotations.png",
      "is_dir": false,
      "name": "ontology_annotations.png",
      "size": 143481
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/matrix_Dv0.png",
      "is_dir": false,
      "name": "matrix_Dv0.png",
      "size": 28607
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/matrix_Dv1.png",
      "is_dir": false,
      "name": "matrix_Dv1.png",
      "size": 28155
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/state_space.png",
      "is_dir": false,
      "name": "state_space.png",
      "size": 243749
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/matrix_Cm0.png",
      "is_dir": false,
      "name": "matrix_Cm0.png",
      "size": 34359
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/matrix_Bv3.png",
      "is_dir": false,
      "name": "matrix_Bv3.png",
      "size": 43976
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/combined_matrices.png",
      "is_dir": false,
      "name": "combined_matrices.png",
      "size": 66473
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example",
      "is_dir": true,
      "name": "gnn_POMDP_example",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Cm1.png",
      "is_dir": false,
      "name": "matrix_Cm1.png",
      "size": 32384
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Am1.png",
      "is_dir": false,
      "name": "matrix_Am1.png",
      "size": 44800
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/model_metadata.json",
      "is_dir": false,
      "name": "model_metadata.json",
      "size": 1475
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/full_model_data.json",
      "is_dir": false,
      "name": "full_model_data.json",
      "size": 8316
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/file_content.md",
      "is_dir": false,
      "name": "file_content.md",
      "size": 16368
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/ontology_annotations.png",
      "is_dir": false,
      "name": "ontology_annotations.png",
      "size": 144191
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Df0.png",
      "is_dir": false,
      "name": "matrix_Df0.png",
      "size": 28441
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/state_space.png",
      "is_dir": false,
      "name": "state_space.png",
      "size": 199210
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Cm0.png",
      "is_dir": false,
      "name": "matrix_Cm0.png",
      "size": 35310
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Am0.png",
      "is_dir": false,
      "name": "matrix_Am0.png",
      "size": 56071
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/combined_matrices.png",
      "is_dir": false,
      "name": "combined_matrices.png",
      "size": 103502
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Df1.png",
      "is_dir": false,
      "name": "matrix_Df1.png",
      "size": 27269
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model",
      "is_dir": true,
      "name": "gnn_active_inference_language_model",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/matrix_Cm1.png",
      "is_dir": false,
      "name": "matrix_Cm1.png",
      "size": 34342
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/model_metadata.json",
      "is_dir": false,
      "name": "model_metadata.json",
      "size": 2295
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/full_model_data.json",
      "is_dir": false,
      "name": "full_model_data.json",
      "size": 14153
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/file_content.md",
      "is_dir": false,
      "name": "file_content.md",
      "size": 27824
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/ontology_annotations.png",
      "is_dir": false,
      "name": "ontology_annotations.png",
      "size": 198382
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/state_space.png",
      "is_dir": false,
      "name": "state_space.png",
      "size": 676778
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/combined_matrices.png",
      "is_dir": false,
      "name": "combined_matrices.png",
      "size": 26564
    },
    {
      "path": "output/gnn_type_check/resource_estimates",
      "is_dir": true,
      "name": "resource_estimates",
      "size": 0
    },
    {
      "path": "output/gnn_type_check/resource_estimates/storage_requirements_html.png",
      "is_dir": false,
      "name": "storage_requirements_html.png",
      "size": 77374
    },
    {
      "path": "output/gnn_type_check/resource_estimates/resource_data.json",
      "is_dir": false,
      "name": "resource_data.json",
      "size": 11391
    },
    {
      "path": "output/gnn_type_check/resource_estimates/resource_report_detailed.html",
      "is_dir": false,
      "name": "resource_report_detailed.html",
      "size": 26000
    },
    {
      "path": "output/gnn_type_check/resource_estimates/memory_usage_html.png",
      "is_dir": false,
      "name": "memory_usage_html.png",
      "size": 73902
    },
    {
      "path": "output/gnn_type_check/resource_estimates/resource_report.md",
      "is_dir": false,
      "name": "resource_report.md",
      "size": 6354
    },
    {
      "path": "output/gnn_type_check/resource_estimates/inference_time_html.png",
      "is_dir": false,
      "name": "inference_time_html.png",
      "size": 77229
    },
    {
      "path": "output/gnn_type_check/resources",
      "is_dir": true,
      "name": "resources",
      "size": 0
    },
    {
      "path": "output/gnn_type_check/resources/type_check_data.json",
      "is_dir": false,
      "name": "type_check_data.json",
      "size": 1079
    },
    {
      "path": "output/gnn_type_check/resource_estimates/html_vis",
      "is_dir": true,
      "name": "html_vis",
      "size": 0
    },
    {
      "path": "output/gnn_type_check/resource_estimates/html_vis/storage_requirements_html.png",
      "is_dir": false,
      "name": "storage_requirements_html.png",
      "size": 77374
    },
    {
      "path": "output/gnn_type_check/resource_estimates/html_vis/memory_usage_html.png",
      "is_dir": false,
      "name": "memory_usage_html.png",
      "size": 73902
    },
    {
      "path": "output/gnn_type_check/resource_estimates/html_vis/inference_time_html.png",
      "is_dir": false,
      "name": "inference_time_html.png",
      "size": 77229
    },
    {
      "path": "output/pymdp_execute_logs",
      "is_dir": true,
      "name": "pymdp_execute_logs",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_POMDP_example_rendered",
      "is_dir": true,
      "name": "gnn_POMDP_example_rendered",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_POMDP_example_rendered/stdout.log",
      "is_dir": false,
      "name": "stdout.log",
      "size": 3519
    },
    {
      "path": "output/pymdp_execute_logs/gnn_POMDP_example_rendered/stderr.log",
      "is_dir": false,
      "name": "stderr.log",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_active_inference_language_model_rendered",
      "is_dir": true,
      "name": "gnn_active_inference_language_model_rendered",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_active_inference_language_model_rendered/stdout.log",
      "is_dir": false,
      "name": "stdout.log",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_active_inference_language_model_rendered/stderr.log",
      "is_dir": false,
      "name": "stderr.log",
      "size": 555
    },
    {
      "path": "output/pymdp_execute_logs/gnn_airplane_trading_pomdp_rendered",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp_rendered",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_airplane_trading_pomdp_rendered/stdout.log",
      "is_dir": false,
      "name": "stdout.log",
      "size": 3599
    },
    {
      "path": "output/pymdp_execute_logs/gnn_airplane_trading_pomdp_rendered/stderr.log",
      "is_dir": false,
      "name": "stderr.log",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_example_pymdp_agent_rendered",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent_rendered",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_example_pymdp_agent_rendered/stdout.log",
      "is_dir": false,
      "name": "stdout.log",
      "size": 3673
    },
    {
      "path": "output/pymdp_execute_logs/gnn_example_pymdp_agent_rendered/stderr.log",
      "is_dir": false,
      "name": "stderr.log",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_poetic_muse_model_rendered",
      "is_dir": true,
      "name": "gnn_poetic_muse_model_rendered",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_poetic_muse_model_rendered/stdout.log",
      "is_dir": false,
      "name": "stdout.log",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_poetic_muse_model_rendered/stderr.log",
      "is_dir": false,
      "name": "stderr.log",
      "size": 507
    },
    {
      "path": "output/gnn_rendered_simulators",
      "is_dir": true,
      "name": "gnn_rendered_simulators",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer",
      "is_dir": true,
      "name": "rxinfer",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_example_pymdp_agent",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_example_pymdp_agent/gnn_example_pymdp_agent_rendered.jl",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent_rendered.jl",
      "size": 517
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_airplane_trading_pomdp",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_rendered.jl",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp_rendered.jl",
      "size": 519
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_poetic_muse_model",
      "is_dir": true,
      "name": "gnn_poetic_muse_model",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_poetic_muse_model/gnn_poetic_muse_model_rendered.jl",
      "is_dir": false,
      "name": "gnn_poetic_muse_model_rendered.jl",
      "size": 527
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_POMDP_example",
      "is_dir": true,
      "name": "gnn_POMDP_example",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_POMDP_example/gnn_POMDP_example_rendered.jl",
      "is_dir": false,
      "name": "gnn_POMDP_example_rendered.jl",
      "size": 515
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_active_inference_language_model",
      "is_dir": true,
      "name": "gnn_active_inference_language_model",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_active_inference_language_model/gnn_active_inference_language_model_rendered.jl",
      "is_dir": false,
      "name": "gnn_active_inference_language_model_rendered.jl",
      "size": 551
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp",
      "is_dir": true,
      "name": "pymdp",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_example_pymdp_agent",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_example_pymdp_agent/gnn_example_pymdp_agent_rendered.py",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent_rendered.py",
      "size": 10074
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_airplane_trading_pomdp",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_rendered.py",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp_rendered.py",
      "size": 9982
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_poetic_muse_model",
      "is_dir": true,
      "name": "gnn_poetic_muse_model",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_poetic_muse_model/gnn_poetic_muse_model_rendered.py",
      "is_dir": false,
      "name": "gnn_poetic_muse_model_rendered.py",
      "size": 8648
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_POMDP_example",
      "is_dir": true,
      "name": "gnn_POMDP_example",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_POMDP_example/gnn_POMDP_example_rendered.py",
      "is_dir": false,
      "name": "gnn_POMDP_example_rendered.py",
      "size": 9972
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_active_inference_language_model",
      "is_dir": true,
      "name": "gnn_active_inference_language_model",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_active_inference_language_model/gnn_active_inference_language_model_rendered.py",
      "is_dir": false,
      "name": "gnn_active_inference_language_model_rendered.py",
      "size": 8698
    },
    {
      "path": "output/llm_processing_step",
      "is_dir": true,
      "name": "llm_processing_step",
      "size": 0
    },
    {
      "path": "output/llm_processing_step/gnn_example_pymdp_agent",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent",
      "size": 0
    },
    {
      "path": "output/llm_processing_step/gnn_example_pymdp_agent/gnn_example_pymdp_agent_comprehensive_analysis.json",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent_comprehensive_analysis.json",
      "size": 5077
    },
    {
      "path": "output/llm_processing_step/gnn_example_pymdp_agent/gnn_example_pymdp_agent_summary.txt",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent_summary.txt",
      "size": 1508
    },
    {
      "path": "output/llm_processing_step/gnn_airplane_trading_pomdp",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp",
      "size": 0
    },
    {
      "path": "output/llm_processing_step/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_comprehensive_analysis.json",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp_comprehensive_analysis.json",
      "size": 7785
    },
    {
      "path": "output/llm_processing_step/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_summary.txt",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp_summary.txt",
      "size": 1866
    },
    {
      "path": "output/llm_processing_step/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_qa.json",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp_qa.json",
      "size": 8441
    },
    {
      "path": "output/llm_processing_step/gnn_POMDP_example",
      "is_dir": true,
      "name": "gnn_POMDP_example",
      "size": 0
    },
    {
      "path": "output/llm_processing_step/gnn_POMDP_example/gnn_POMDP_example_comprehensive_analysis.json",
      "is_dir": false,
      "name": "gnn_POMDP_example_comprehensive_analysis.json",
      "size": 9317
    },
    {
      "path": "output/llm_processing_step/gnn_POMDP_example/gnn_POMDP_example_summary.txt",
      "is_dir": false,
      "name": "gnn_POMDP_example_summary.txt",
      "size": 2260
    },
    {
      "path": "output/llm_processing_step/gnn_POMDP_example/gnn_POMDP_example_qa.json",
      "is_dir": false,
      "name": "gnn_POMDP_example_qa.json",
      "size": 6886
    },
    {
      "path": "output/llm_processing_step/gnn_active_inference_language_model",
      "is_dir": true,
      "name": "gnn_active_inference_language_model",
      "size": 0
    },
    {
      "path": "output/llm_processing_step/gnn_active_inference_language_model/gnn_active_inference_language_model_qa.json",
      "is_dir": false,
      "name": "gnn_active_inference_language_model_qa.json",
      "size": 8032
    },
    {
      "path": "output/llm_processing_step/gnn_active_inference_language_model/gnn_active_inference_language_model_summary.txt",
      "is_dir": false,
      "name": "gnn_active_inference_language_model_summary.txt",
      "size": 2767
    },
    {
      "path": "output/llm_processing_step/gnn_active_inference_language_model/gnn_active_inference_language_model_comprehensive_analysis.json",
      "is_dir": false,
      "name": "gnn_active_inference_language_model_comprehensive_analysis.json",
      "size": 5836
    },
    {
      "path": "doc/cerebrum",
      "is_dir": true,
      "name": "cerebrum",
      "size": 0
    },
    {
      "path": "doc/cerebrum/gnn_cerebrum.md",
      "is_dir": false,
      "name": "gnn_cerebrum.md",
      "size": 26310
    },
    {
      "path": "doc/cerebrum/cerebrum_v1-4.md",
      "is_dir": false,
      "name": "cerebrum_v1-4.md",
      "size": 319958
    },
    {
      "path": "doc/ntqr",
      "is_dir": true,
      "name": "ntqr",
      "size": 0
    },
    {
      "path": "doc/ntqr/gnn_ntqr.md",
      "is_dir": false,
      "name": "gnn_ntqr.md",
      "size": 38
    },
    {
      "path": "doc/other",
      "is_dir": true,
      "name": "other",
      "size": 0
    },
    {
      "path": "doc/other/active_inferant_stream_014-1.md",
      "is_dir": false,
      "name": "active_inferant_stream_014-1.md",
      "size": 339
    },
    {
      "path": "doc/other/triple_play_dialog.md",
      "is_dir": false,
      "name": "triple_play_dialog.md",
      "size": 19940
    },
    {
      "path": "doc/other/from_plaintext_to_triple_play_dialog.md",
      "is_dir": false,
      "name": "from_plaintext_to_triple_play_dialog.md",
      "size": 14235
    },
    {
      "path": "doc/dspy",
      "is_dir": true,
      "name": "dspy",
      "size": 0
    },
    {
      "path": "doc/dspy/gnn_dspy.md",
      "is_dir": false,
      "name": "gnn_dspy.md",
      "size": 41193
    },
    {
      "path": "doc/x402",
      "is_dir": true,
      "name": "x402",
      "size": 0
    },
    {
      "path": "doc/x402/gnn_x402.md",
      "is_dir": false,
      "name": "gnn_x402.md",
      "size": 20304
    },
    {
      "path": "doc/autogenlib",
      "is_dir": true,
      "name": "autogenlib",
      "size": 0
    },
    {
      "path": "doc/autogenlib/gnn_autogenlib.md",
      "is_dir": false,
      "name": "gnn_autogenlib.md",
      "size": 22441
    },
    {
      "path": "doc/rxinfer",
      "is_dir": true,
      "name": "rxinfer",
      "size": 0
    },
    {
      "path": "doc/rxinfer/gnn_rxinfer.md",
      "is_dir": false,
      "name": "gnn_rxinfer.md",
      "size": 18497
    },
    {
      "path": "doc/pymdp",
      "is_dir": true,
      "name": "pymdp",
      "size": 0
    },
    {
      "path": "doc/pymdp/gnn_pymdp.md",
      "is_dir": false,
      "name": "gnn_pymdp.md",
      "size": 17
    },
    {
      "path": "doc/kit",
      "is_dir": true,
      "name": "kit",
      "size": 0
    },
    {
      "path": "doc/kit/gnn_kit.md",
      "is_dir": false,
      "name": "gnn_kit.md",
      "size": 23695
    },
    {
      "path": "doc/mcp",
      "is_dir": true,
      "name": "mcp",
      "size": 0
    },
    {
      "path": "doc/mcp/gnn_mcp_model_context_protocol.md",
      "is_dir": false,
      "name": "gnn_mcp_model_context_protocol.md",
      "size": 23040
    },
    {
      "path": "doc/mcp/fastmcp.md",
      "is_dir": false,
      "name": "fastmcp.md",
      "size": 18818
    },
    {
      "path": "doc/muscle-mem",
      "is_dir": true,
      "name": "muscle-mem",
      "size": 0
    },
    {
      "path": "doc/muscle-mem/gnn-muscle-mem.md",
      "is_dir": false,
      "name": "gnn-muscle-mem.md",
      "size": 27762
    },
    {
      "path": "doc/archive",
      "is_dir": true,
      "name": "archive",
      "size": 0
    },
    {
      "path": "doc/archive/gnn_example_jax_pymdp_learning_agent.md",
      "is_dir": false,
      "name": "gnn_example_jax_pymdp_learning_agent.md",
      "size": 9197
    },
    {
      "path": "doc/archive/gnn_example_dynamic_perception.md",
      "is_dir": false,
      "name": "gnn_example_dynamic_perception.md",
      "size": 1419
    },
    {
      "path": "doc/archive/gnn_example_butterfly_pheromone_agent.md",
      "is_dir": false,
      "name": "gnn_example_butterfly_pheromone_agent.md",
      "size": 8937
    },
    {
      "path": "doc/archive/gnn_poetic_muse_model.md",
      "is_dir": false,
      "name": "gnn_poetic_muse_model.md",
      "size": 9570
    },
    {
      "path": "doc/archive/gnn_example_dynamic_perception_policy.md",
      "is_dir": false,
      "name": "gnn_example_dynamic_perception_policy.md",
      "size": 1838
    },
    {
      "path": "doc/archive/gnn_active_inference_language_model.md",
      "is_dir": false,
      "name": "gnn_active_inference_language_model.md",
      "size": 13768
    },
    {
      "path": "doc/archive/gnn_airplane_trading_pomdp.md",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp.md",
      "size": 10229
    },
    {
      "path": "doc/kit/gnn_kit",
      "is_dir": true,
      "name": "gnn_kit",
      "size": 0
    },
    {
      "path": "doc/kit/gnn_kit/kit_setup.py",
      "is_dir": false,
      "name": "kit_setup.py",
      "size": 587
    }
  ],
  "files": [
    {
      "path": "SECURITY.md",
      "is_dir": false,
      "name": "SECURITY.md",
      "size": 2762
    },
    {
      "path": ".gitignore",
      "is_dir": false,
      "name": ".gitignore",
      "size": 93
    },
    {
      "path": "LICENSE.md",
      "is_dir": false,
      "name": "LICENSE.md",
      "size": 1099
    },
    {
      "path": "SUPPORT.md",
      "is_dir": false,
      "name": "SUPPORT.md",
      "size": 3391
    },
    {
      "path": "CONTRIBUTING.md",
      "is_dir": false,
      "name": "CONTRIBUTING.md",
      "size": 4034
    },
    {
      "path": "README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 15285
    },
    {
      "path": "CODE_OF_CONDUCT.md",
      "is_dir": false,
      "name": "CODE_OF_CONDUCT.md",
      "size": 5369
    },
    {
      "path": "CITATION.cff",
      "is_dir": false,
      "name": "CITATION.cff",
      "size": 2725
    },
    {
      "path": ".cursorrules",
      "is_dir": false,
      "name": ".cursorrules",
      "size": 7558
    },
    {
      "path": "src",
      "is_dir": true,
      "name": "src",
      "size": 0
    },
    {
      "path": "src/7_mcp.py",
      "is_dir": false,
      "name": "7_mcp.py",
      "size": 29577
    },
    {
      "path": "src/2_setup.py",
      "is_dir": false,
      "name": "2_setup.py",
      "size": 11684
    },
    {
      "path": "src/1_gnn.py",
      "is_dir": false,
      "name": "1_gnn.py",
      "size": 27448
    },
    {
      "path": "src/5_export.py",
      "is_dir": false,
      "name": "5_export.py",
      "size": 19195
    },
    {
      "path": "src/9_render.py",
      "is_dir": false,
      "name": "9_render.py",
      "size": 12021
    },
    {
      "path": "src/requirements.txt",
      "is_dir": false,
      "name": "requirements.txt",
      "size": 149
    },
    {
      "path": "src/main.py",
      "is_dir": false,
      "name": "main.py",
      "size": 36462
    },
    {
      "path": "src/6_visualization.py",
      "is_dir": false,
      "name": "6_visualization.py",
      "size": 10713
    },
    {
      "path": "src/12_site.py",
      "is_dir": false,
      "name": "12_site.py",
      "size": 5112
    },
    {
      "path": "src/3_tests.py",
      "is_dir": false,
      "name": "3_tests.py",
      "size": 9718
    },
    {
      "path": "src/10_execute.py",
      "is_dir": false,
      "name": "10_execute.py",
      "size": 8412
    },
    {
      "path": "src/11_llm.py",
      "is_dir": false,
      "name": "11_llm.py",
      "size": 26836
    },
    {
      "path": "src/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 25402
    },
    {
      "path": "src/4_gnn_type_checker.py",
      "is_dir": false,
      "name": "4_gnn_type_checker.py",
      "size": 12715
    },
    {
      "path": "src/8_ontology.py",
      "is_dir": false,
      "name": "8_ontology.py",
      "size": 16852
    },
    {
      "path": "output",
      "is_dir": true,
      "name": "output",
      "size": 0
    },
    {
      "path": "output/gnn_processing_summary.md",
      "is_dir": false,
      "name": "gnn_processing_summary.md",
      "size": 107
    },
    {
      "path": "doc",
      "is_dir": true,
      "name": "doc",
      "size": 0
    },
    {
      "path": "doc/gnn_llm_neurosymbolic_active_inference.md",
      "is_dir": false,
      "name": "gnn_llm_neurosymbolic_active_inference.md",
      "size": 49124
    },
    {
      "path": "doc/gnn_multiagent.md",
      "is_dir": false,
      "name": "gnn_multiagent.md",
      "size": 14606
    },
    {
      "path": "doc/gnn_dsl_manual.md",
      "is_dir": false,
      "name": "gnn_dsl_manual.md",
      "size": 18341
    },
    {
      "path": "doc/gnn_implementation.md",
      "is_dir": false,
      "name": "gnn_implementation.md",
      "size": 22718
    },
    {
      "path": "doc/gnn_syntax.md",
      "is_dir": false,
      "name": "gnn_syntax.md",
      "size": 9524
    },
    {
      "path": "doc/resource_metrics.md",
      "is_dir": false,
      "name": "resource_metrics.md",
      "size": 5235
    },
    {
      "path": "doc/gnn_examples_doc.md",
      "is_dir": false,
      "name": "gnn_examples_doc.md",
      "size": 12749
    },
    {
      "path": "doc/gnn_paper.md",
      "is_dir": false,
      "name": "gnn_paper.md",
      "size": 15143
    },
    {
      "path": "doc/gnn_file_structure_doc.md",
      "is_dir": false,
      "name": "gnn_file_structure_doc.md",
      "size": 9272
    },
    {
      "path": "doc/gnn_overview.md",
      "is_dir": false,
      "name": "gnn_overview.md",
      "size": 6925
    },
    {
      "path": "doc/about_gnn.md",
      "is_dir": false,
      "name": "about_gnn.md",
      "size": 13771
    },
    {
      "path": "doc/ontology_system.md",
      "is_dir": false,
      "name": "ontology_system.md",
      "size": 3574
    },
    {
      "path": "doc/gnn_tools.md",
      "is_dir": false,
      "name": "gnn_tools.md",
      "size": 19577
    },
    {
      "path": "src/gnn_type_checker",
      "is_dir": true,
      "name": "gnn_type_checker",
      "size": 0
    },
    {
      "path": "src/gnn_type_checker/resource_estimator.py",
      "is_dir": false,
      "name": "resource_estimator.py",
      "size": 76070
    },
    {
      "path": "src/gnn_type_checker/__main__.py",
      "is_dir": false,
      "name": "__main__.py",
      "size": 201
    },
    {
      "path": "src/gnn_type_checker/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 10921
    },
    {
      "path": "src/gnn_type_checker/checker.py",
      "is_dir": false,
      "name": "checker.py",
      "size": 21955
    },
    {
      "path": "src/gnn_type_checker/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 1727
    },
    {
      "path": "src/gnn_type_checker/cli.py",
      "is_dir": false,
      "name": "cli.py",
      "size": 8163
    },
    {
      "path": "src/gnn_type_checker/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 336
    },
    {
      "path": "src/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/__pycache__/2_setup.cpython-312.pyc",
      "is_dir": false,
      "name": "2_setup.cpython-312.pyc",
      "size": 10329
    },
    {
      "path": "src/__pycache__/4_gnn_type_checker.cpython-312.pyc",
      "is_dir": false,
      "name": "4_gnn_type_checker.cpython-312.pyc",
      "size": 10958
    },
    {
      "path": "src/__pycache__/7_mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "7_mcp.cpython-312.pyc",
      "size": 25195
    },
    {
      "path": "src/__pycache__/10_execute.cpython-312.pyc",
      "is_dir": false,
      "name": "10_execute.cpython-312.pyc",
      "size": 5866
    },
    {
      "path": "src/__pycache__/3_tests.cpython-312.pyc",
      "is_dir": false,
      "name": "3_tests.cpython-312.pyc",
      "size": 6904
    },
    {
      "path": "src/__pycache__/6_visualization.cpython-312.pyc",
      "is_dir": false,
      "name": "6_visualization.cpython-312.pyc",
      "size": 7913
    },
    {
      "path": "src/__pycache__/8_ontology.cpython-312.pyc",
      "is_dir": false,
      "name": "8_ontology.cpython-312.pyc",
      "size": 15224
    },
    {
      "path": "src/__pycache__/11_llm.cpython-312.pyc",
      "is_dir": false,
      "name": "11_llm.cpython-312.pyc",
      "size": 24565
    },
    {
      "path": "src/__pycache__/5_export.cpython-312.pyc",
      "is_dir": false,
      "name": "5_export.cpython-312.pyc",
      "size": 20642
    },
    {
      "path": "src/__pycache__/1_gnn.cpython-312.pyc",
      "is_dir": false,
      "name": "1_gnn.cpython-312.pyc",
      "size": 19238
    },
    {
      "path": "src/__pycache__/9_render.cpython-312.pyc",
      "is_dir": false,
      "name": "9_render.cpython-312.pyc",
      "size": 8780
    },
    {
      "path": "src/ontology",
      "is_dir": true,
      "name": "ontology",
      "size": 0
    },
    {
      "path": "src/ontology/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 13473
    },
    {
      "path": "src/ontology/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 4559
    },
    {
      "path": "src/ontology/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 131
    },
    {
      "path": "src/ontology/act_inf_ontology_terms.json",
      "is_dir": false,
      "name": "act_inf_ontology_terms.json",
      "size": 8956
    },
    {
      "path": "src/execute",
      "is_dir": true,
      "name": "execute",
      "size": 0
    },
    {
      "path": "src/execute/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 1882
    },
    {
      "path": "src/execute/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 2074
    },
    {
      "path": "src/execute/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 53
    },
    {
      "path": "src/execute/pymdp_runner.py",
      "is_dir": false,
      "name": "pymdp_runner.py",
      "size": 11435
    },
    {
      "path": "src/site",
      "is_dir": true,
      "name": "site",
      "size": 0
    },
    {
      "path": "src/site/generator.py",
      "is_dir": false,
      "name": "generator.py",
      "size": 30449
    },
    {
      "path": "src/site/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 2953
    },
    {
      "path": "src/site/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 141
    },
    {
      "path": "src/tests",
      "is_dir": true,
      "name": "tests",
      "size": 0
    },
    {
      "path": "src/tests/test_gnn_type_checker.py",
      "is_dir": false,
      "name": "test_gnn_type_checker.py",
      "size": 6284
    },
    {
      "path": "src/tests/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 7083
    },
    {
      "path": "src/tests/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 141
    },
    {
      "path": "src/export",
      "is_dir": true,
      "name": "export",
      "size": 0
    },
    {
      "path": "src/export/structured_data_exporters.py",
      "is_dir": false,
      "name": "structured_data_exporters.py",
      "size": 3846
    },
    {
      "path": "src/export/text_exporters.py",
      "is_dir": false,
      "name": "text_exporters.py",
      "size": 5587
    },
    {
      "path": "src/export/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 7976
    },
    {
      "path": "src/export/format_exporters.py",
      "is_dir": false,
      "name": "format_exporters.py",
      "size": 24864
    },
    {
      "path": "src/export/graph_exporters.py",
      "is_dir": false,
      "name": "graph_exporters.py",
      "size": 4014
    },
    {
      "path": "src/utils",
      "is_dir": true,
      "name": "utils",
      "size": 0
    },
    {
      "path": "src/utils/logging_utils.py",
      "is_dir": false,
      "name": "logging_utils.py",
      "size": 2291
    },
    {
      "path": "src/utils/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 131
    },
    {
      "path": "src/setup",
      "is_dir": true,
      "name": "setup",
      "size": 0
    },
    {
      "path": "src/setup/utils.py",
      "is_dir": false,
      "name": "utils.py",
      "size": 1543
    },
    {
      "path": "src/setup/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 4257
    },
    {
      "path": "src/setup/setup.py",
      "is_dir": false,
      "name": "setup.py",
      "size": 9347
    },
    {
      "path": "src/setup/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 202
    },
    {
      "path": "src/gnn",
      "is_dir": true,
      "name": "gnn",
      "size": 0
    },
    {
      "path": "src/gnn/gnn_file_structure.md",
      "is_dir": false,
      "name": "gnn_file_structure.md",
      "size": 2516
    },
    {
      "path": "src/gnn/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 4122
    },
    {
      "path": "src/gnn/gnn_punctuation.md",
      "is_dir": false,
      "name": "gnn_punctuation.md",
      "size": 1789
    },
    {
      "path": "src/gnn/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 131
    },
    {
      "path": "src/mcp",
      "is_dir": true,
      "name": "mcp",
      "size": 0
    },
    {
      "path": "src/mcp/npx_inspector.py",
      "is_dir": false,
      "name": "npx_inspector.py",
      "size": 15868
    },
    {
      "path": "src/mcp/server_stdio.py",
      "is_dir": false,
      "name": "server_stdio.py",
      "size": 7620
    },
    {
      "path": "src/mcp/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 19286
    },
    {
      "path": "src/mcp/test_mcp.py",
      "is_dir": false,
      "name": "test_mcp.py",
      "size": 15921
    },
    {
      "path": "src/mcp/server_http.py",
      "is_dir": false,
      "name": "server_http.py",
      "size": 7731
    },
    {
      "path": "src/mcp/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 8691
    },
    {
      "path": "src/mcp/meta_mcp.py",
      "is_dir": false,
      "name": "meta_mcp.py",
      "size": 4954
    },
    {
      "path": "src/mcp/cli.py",
      "is_dir": false,
      "name": "cli.py",
      "size": 4644
    },
    {
      "path": "src/mcp/mcp_implementation_spec.md",
      "is_dir": false,
      "name": "mcp_implementation_spec.md",
      "size": 69149
    },
    {
      "path": "src/mcp/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 144
    },
    {
      "path": "src/mcp/model_context_protocol.md",
      "is_dir": false,
      "name": "model_context_protocol.md",
      "size": 16713
    },
    {
      "path": "src/visualization",
      "is_dir": true,
      "name": "visualization",
      "size": 0
    },
    {
      "path": "src/visualization/matrix_visualizer.py",
      "is_dir": false,
      "name": "matrix_visualizer.py",
      "size": 10261
    },
    {
      "path": "src/visualization/__main__.py",
      "is_dir": false,
      "name": "__main__.py",
      "size": 266
    },
    {
      "path": "src/visualization/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 5934
    },
    {
      "path": "src/visualization/visualizer.py",
      "is_dir": false,
      "name": "visualizer.py",
      "size": 22967
    },
    {
      "path": "src/visualization/ontology_visualizer.py",
      "is_dir": false,
      "name": "ontology_visualizer.py",
      "size": 3768
    },
    {
      "path": "src/visualization/run_visualization.py",
      "is_dir": false,
      "name": "run_visualization.py",
      "size": 2727
    },
    {
      "path": "src/visualization/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 2242
    },
    {
      "path": "src/visualization/cli.py",
      "is_dir": false,
      "name": "cli.py",
      "size": 2687
    },
    {
      "path": "src/visualization/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 245
    },
    {
      "path": "src/visualization/parser.py",
      "is_dir": false,
      "name": "parser.py",
      "size": 11203
    },
    {
      "path": "src/render",
      "is_dir": true,
      "name": "render",
      "size": 0
    },
    {
      "path": "src/render/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 9330
    },
    {
      "path": "src/render/pymdp_utils.py",
      "is_dir": false,
      "name": "pymdp_utils.py",
      "size": 8155
    },
    {
      "path": "src/render/rxinfer.py",
      "is_dir": false,
      "name": "rxinfer.py",
      "size": 43706
    },
    {
      "path": "src/render/README.md",
      "is_dir": false,
      "name": "README.md",
      "size": 905
    },
    {
      "path": "src/render/render.py",
      "is_dir": false,
      "name": "render.py",
      "size": 9771
    },
    {
      "path": "src/render/pymdp.py",
      "is_dir": false,
      "name": "pymdp.py",
      "size": 84342
    },
    {
      "path": "src/render/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 131
    },
    {
      "path": "src/llm",
      "is_dir": true,
      "name": "llm",
      "size": 0
    },
    {
      "path": "src/llm/llm_operations.py",
      "is_dir": false,
      "name": "llm_operations.py",
      "size": 5079
    },
    {
      "path": "src/llm/mcp.py",
      "is_dir": false,
      "name": "mcp.py",
      "size": 16468
    },
    {
      "path": "src/llm/.env.example",
      "is_dir": false,
      "name": ".env.example",
      "size": 29
    },
    {
      "path": "src/llm/__init__.py",
      "is_dir": false,
      "name": "__init__.py",
      "size": 131
    },
    {
      "path": "src/gnn_type_checker/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/gnn_type_checker/__pycache__/checker.cpython-312.pyc",
      "is_dir": false,
      "name": "checker.cpython-312.pyc",
      "size": 26650
    },
    {
      "path": "src/gnn_type_checker/__pycache__/cli.cpython-310.pyc",
      "is_dir": false,
      "name": "cli.cpython-310.pyc",
      "size": 3011
    },
    {
      "path": "src/gnn_type_checker/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 547
    },
    {
      "path": "src/gnn_type_checker/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 11216
    },
    {
      "path": "src/gnn_type_checker/__pycache__/resource_estimator.cpython-312.pyc",
      "is_dir": false,
      "name": "resource_estimator.cpython-312.pyc",
      "size": 73856
    },
    {
      "path": "src/gnn_type_checker/__pycache__/__main__.cpython-310.pyc",
      "is_dir": false,
      "name": "__main__.cpython-310.pyc",
      "size": 417
    },
    {
      "path": "src/gnn_type_checker/__pycache__/resource_estimator.cpython-310.pyc",
      "is_dir": false,
      "name": "resource_estimator.cpython-310.pyc",
      "size": 46847
    },
    {
      "path": "src/gnn_type_checker/__pycache__/checker.cpython-310.pyc",
      "is_dir": false,
      "name": "checker.cpython-310.pyc",
      "size": 15809
    },
    {
      "path": "src/gnn_type_checker/__pycache__/__init__.cpython-310.pyc",
      "is_dir": false,
      "name": "__init__.cpython-310.pyc",
      "size": 460
    },
    {
      "path": "src/gnn_type_checker/__pycache__/cli.cpython-312.pyc",
      "is_dir": false,
      "name": "cli.cpython-312.pyc",
      "size": 9095
    },
    {
      "path": "src/ontology/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/ontology/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 177
    },
    {
      "path": "src/ontology/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 14549
    },
    {
      "path": "src/execute/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/execute/__pycache__/pymdp_runner.cpython-312.pyc",
      "is_dir": false,
      "name": "pymdp_runner.cpython-312.pyc",
      "size": 13036
    },
    {
      "path": "src/execute/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 176
    },
    {
      "path": "src/execute/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 1062
    },
    {
      "path": "src/site/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/site/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 173
    },
    {
      "path": "src/site/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 4158
    },
    {
      "path": "src/site/__pycache__/generator.cpython-312.pyc",
      "is_dir": false,
      "name": "generator.cpython-312.pyc",
      "size": 32516
    },
    {
      "path": "src/tests/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/tests/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 174
    },
    {
      "path": "src/tests/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 9169
    },
    {
      "path": "src/tests/__pycache__/test_gnn_type_checker.cpython-312-pytest-8.3.5.pyc",
      "is_dir": false,
      "name": "test_gnn_type_checker.cpython-312-pytest-8.3.5.pyc",
      "size": 8977
    },
    {
      "path": "src/export/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/export/__pycache__/structured_data_exporters.cpython-312.pyc",
      "is_dir": false,
      "name": "structured_data_exporters.cpython-312.pyc",
      "size": 5722
    },
    {
      "path": "src/export/__pycache__/format_exporters.cpython-312.pyc",
      "is_dir": false,
      "name": "format_exporters.cpython-312.pyc",
      "size": 24797
    },
    {
      "path": "src/export/__pycache__/format_exporters.cpython-310.pyc",
      "is_dir": false,
      "name": "format_exporters.cpython-310.pyc",
      "size": 19653
    },
    {
      "path": "src/export/__pycache__/text_exporters.cpython-312.pyc",
      "is_dir": false,
      "name": "text_exporters.cpython-312.pyc",
      "size": 7560
    },
    {
      "path": "src/export/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 8188
    },
    {
      "path": "src/export/__pycache__/graph_exporters.cpython-312.pyc",
      "is_dir": false,
      "name": "graph_exporters.cpython-312.pyc",
      "size": 5702
    },
    {
      "path": "src/utils/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/utils/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 174
    },
    {
      "path": "src/utils/__pycache__/logging_utils.cpython-312.pyc",
      "is_dir": false,
      "name": "logging_utils.cpython-312.pyc",
      "size": 2133
    },
    {
      "path": "src/setup/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/setup/__pycache__/utils.cpython-312.pyc",
      "is_dir": false,
      "name": "utils.cpython-312.pyc",
      "size": 2131
    },
    {
      "path": "src/setup/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 425
    },
    {
      "path": "src/setup/__pycache__/setup.cpython-312.pyc",
      "is_dir": false,
      "name": "setup.cpython-312.pyc",
      "size": 12098
    },
    {
      "path": "src/setup/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 4950
    },
    {
      "path": "src/gnn/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/gnn/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 172
    },
    {
      "path": "src/gnn/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 4411
    },
    {
      "path": "src/gnn/examples",
      "is_dir": true,
      "name": "examples",
      "size": 0
    },
    {
      "path": "src/gnn/examples/gnn_POMDP_example.md",
      "is_dir": false,
      "name": "gnn_POMDP_example.md",
      "size": 8049
    },
    {
      "path": "src/gnn/examples/gnn_example_pymdp_agent.md",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent.md",
      "size": 6387
    },
    {
      "path": "src/mcp/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/mcp/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 315
    },
    {
      "path": "src/mcp/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 17709
    },
    {
      "path": "src/visualization/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/visualization/__pycache__/ontology_visualizer.cpython-310.pyc",
      "is_dir": false,
      "name": "ontology_visualizer.cpython-310.pyc",
      "size": 3915
    },
    {
      "path": "src/visualization/__pycache__/visualizer.cpython-310.pyc",
      "is_dir": false,
      "name": "visualizer.cpython-310.pyc",
      "size": 13195
    },
    {
      "path": "src/visualization/__pycache__/cli.cpython-310.pyc",
      "is_dir": false,
      "name": "cli.cpython-310.pyc",
      "size": 2009
    },
    {
      "path": "src/visualization/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 453
    },
    {
      "path": "src/visualization/__pycache__/matrix_visualizer.cpython-312.pyc",
      "is_dir": false,
      "name": "matrix_visualizer.cpython-312.pyc",
      "size": 11810
    },
    {
      "path": "src/visualization/__pycache__/parser.cpython-312.pyc",
      "is_dir": false,
      "name": "parser.cpython-312.pyc",
      "size": 11880
    },
    {
      "path": "src/visualization/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 6443
    },
    {
      "path": "src/visualization/__pycache__/parser.cpython-310.pyc",
      "is_dir": false,
      "name": "parser.cpython-310.pyc",
      "size": 6848
    },
    {
      "path": "src/visualization/__pycache__/ontology_visualizer.cpython-312.pyc",
      "is_dir": false,
      "name": "ontology_visualizer.cpython-312.pyc",
      "size": 5056
    },
    {
      "path": "src/visualization/__pycache__/run_visualization.cpython-310.pyc",
      "is_dir": false,
      "name": "run_visualization.cpython-310.pyc",
      "size": 2284
    },
    {
      "path": "src/visualization/__pycache__/__init__.cpython-310.pyc",
      "is_dir": false,
      "name": "__init__.cpython-310.pyc",
      "size": 435
    },
    {
      "path": "src/visualization/__pycache__/matrix_visualizer.cpython-310.pyc",
      "is_dir": false,
      "name": "matrix_visualizer.cpython-310.pyc",
      "size": 7288
    },
    {
      "path": "src/visualization/__pycache__/cli.cpython-312.pyc",
      "is_dir": false,
      "name": "cli.cpython-312.pyc",
      "size": 3300
    },
    {
      "path": "src/visualization/__pycache__/visualizer.cpython-312.pyc",
      "is_dir": false,
      "name": "visualizer.cpython-312.pyc",
      "size": 24082
    },
    {
      "path": "src/render/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/render/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 175
    },
    {
      "path": "src/render/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 9300
    },
    {
      "path": "src/render/__pycache__/render.cpython-312.pyc",
      "is_dir": false,
      "name": "render.cpython-312.pyc",
      "size": 9385
    },
    {
      "path": "src/render/__pycache__/pymdp_utils.cpython-312.pyc",
      "is_dir": false,
      "name": "pymdp_utils.cpython-312.pyc",
      "size": 10881
    },
    {
      "path": "src/render/__pycache__/pymdp.cpython-312.pyc",
      "is_dir": false,
      "name": "pymdp.cpython-312.pyc",
      "size": 80507
    },
    {
      "path": "src/render/__pycache__/rxinfer.cpython-312.pyc",
      "is_dir": false,
      "name": "rxinfer.cpython-312.pyc",
      "size": 42131
    },
    {
      "path": "src/llm/__pycache__",
      "is_dir": true,
      "name": "__pycache__",
      "size": 0
    },
    {
      "path": "src/llm/__pycache__/__init__.cpython-312.pyc",
      "is_dir": false,
      "name": "__init__.cpython-312.pyc",
      "size": 172
    },
    {
      "path": "src/llm/__pycache__/mcp.cpython-312.pyc",
      "is_dir": false,
      "name": "mcp.cpython-312.pyc",
      "size": 14439
    },
    {
      "path": "src/llm/__pycache__/llm_operations.cpython-312.pyc",
      "is_dir": false,
      "name": "llm_operations.cpython-312.pyc",
      "size": 6450
    },
    {
      "path": "output/mcp_processing_step",
      "is_dir": true,
      "name": "mcp_processing_step",
      "size": 0
    },
    {
      "path": "output/mcp_processing_step/7_mcp_integration_report.md",
      "is_dir": false,
      "name": "7_mcp_integration_report.md",
      "size": 37184
    },
    {
      "path": "output/gnn_exports",
      "is_dir": true,
      "name": "gnn_exports",
      "size": 0
    },
    {
      "path": "output/gnn_exports/5_export_step_report.md",
      "is_dir": false,
      "name": "5_export_step_report.md",
      "size": 421
    },
    {
      "path": "output/logs",
      "is_dir": true,
      "name": "logs",
      "size": 0
    },
    {
      "path": "output/logs/pipeline.log",
      "is_dir": false,
      "name": "pipeline.log",
      "size": 487614
    },
    {
      "path": "output/gnn_processing_step",
      "is_dir": true,
      "name": "gnn_processing_step",
      "size": 0
    },
    {
      "path": "output/gnn_processing_step/1_gnn_discovery_report.md",
      "is_dir": false,
      "name": "1_gnn_discovery_report.md",
      "size": 1528
    },
    {
      "path": "output/test_reports",
      "is_dir": true,
      "name": "test_reports",
      "size": 0
    },
    {
      "path": "output/test_reports/pytest_report.xml",
      "is_dir": false,
      "name": "pytest_report.xml",
      "size": 687
    },
    {
      "path": "output/gnn_type_check",
      "is_dir": true,
      "name": "gnn_type_check",
      "size": 0
    },
    {
      "path": "output/gnn_type_check/type_check_report.md",
      "is_dir": false,
      "name": "type_check_report.md",
      "size": 536
    },
    {
      "path": "output/ontology_processing",
      "is_dir": true,
      "name": "ontology_processing",
      "size": 0
    },
    {
      "path": "output/ontology_processing/ontology_processing_report.md",
      "is_dir": false,
      "name": "ontology_processing_report.md",
      "size": 6284
    },
    {
      "path": "output/gnn_exports/gnn_example_pymdp_agent",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent",
      "size": 0
    },
    {
      "path": "output/gnn_exports/gnn_example_pymdp_agent/gnn_example_pymdp_agent.txt",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent.txt",
      "size": 2763
    },
    {
      "path": "output/gnn_exports/gnn_example_pymdp_agent/gnn_example_pymdp_agent.json",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent.json",
      "size": 15147
    },
    {
      "path": "output/gnn_exports/gnn_example_pymdp_agent/gnn_example_pymdp_agent.xml",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent.xml",
      "size": 16156
    },
    {
      "path": "output/gnn_exports/gnn_example_pymdp_agent/gnn_example_pymdp_agent.gnn",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent.gnn",
      "size": 6108
    },
    {
      "path": "output/gnn_exports/gnn_airplane_trading_pomdp",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp",
      "size": 0
    },
    {
      "path": "output/gnn_exports/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp.gnn",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp.gnn",
      "size": 9946
    },
    {
      "path": "output/gnn_exports/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp.txt",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp.txt",
      "size": 2627
    },
    {
      "path": "output/gnn_exports/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp.json",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp.json",
      "size": 22387
    },
    {
      "path": "output/gnn_exports/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp.xml",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp.xml",
      "size": 23178
    },
    {
      "path": "output/gnn_exports/gnn_poetic_muse_model",
      "is_dir": true,
      "name": "gnn_poetic_muse_model",
      "size": 0
    },
    {
      "path": "output/gnn_exports/gnn_poetic_muse_model/gnn_poetic_muse_model.json",
      "is_dir": false,
      "name": "gnn_poetic_muse_model.json",
      "size": 23143
    },
    {
      "path": "output/gnn_exports/gnn_poetic_muse_model/gnn_poetic_muse_model.txt",
      "is_dir": false,
      "name": "gnn_poetic_muse_model.txt",
      "size": 3388
    },
    {
      "path": "output/gnn_exports/gnn_poetic_muse_model/gnn_poetic_muse_model.xml",
      "is_dir": false,
      "name": "gnn_poetic_muse_model.xml",
      "size": 24543
    },
    {
      "path": "output/gnn_exports/gnn_poetic_muse_model/gnn_poetic_muse_model.gnn",
      "is_dir": false,
      "name": "gnn_poetic_muse_model.gnn",
      "size": 9355
    },
    {
      "path": "output/gnn_exports/gnn_POMDP_example",
      "is_dir": true,
      "name": "gnn_POMDP_example",
      "size": 0
    },
    {
      "path": "output/gnn_exports/gnn_POMDP_example/gnn_POMDP_example.gnn",
      "is_dir": false,
      "name": "gnn_POMDP_example.gnn",
      "size": 7819
    },
    {
      "path": "output/gnn_exports/gnn_POMDP_example/gnn_POMDP_example.json",
      "is_dir": false,
      "name": "gnn_POMDP_example.json",
      "size": 17619
    },
    {
      "path": "output/gnn_exports/gnn_POMDP_example/gnn_POMDP_example.txt",
      "is_dir": false,
      "name": "gnn_POMDP_example.txt",
      "size": 2626
    },
    {
      "path": "output/gnn_exports/gnn_POMDP_example/gnn_POMDP_example.xml",
      "is_dir": false,
      "name": "gnn_POMDP_example.xml",
      "size": 18589
    },
    {
      "path": "output/gnn_exports/gnn_active_inference_language_model",
      "is_dir": true,
      "name": "gnn_active_inference_language_model",
      "size": 0
    },
    {
      "path": "output/gnn_exports/gnn_active_inference_language_model/gnn_active_inference_language_model.json",
      "is_dir": false,
      "name": "gnn_active_inference_language_model.json",
      "size": 28405
    },
    {
      "path": "output/gnn_exports/gnn_active_inference_language_model/gnn_active_inference_language_model.txt",
      "is_dir": false,
      "name": "gnn_active_inference_language_model.txt",
      "size": 5732
    },
    {
      "path": "output/gnn_exports/gnn_active_inference_language_model/gnn_active_inference_language_model.xml",
      "is_dir": false,
      "name": "gnn_active_inference_language_model.xml",
      "size": 30188
    },
    {
      "path": "output/gnn_exports/gnn_active_inference_language_model/gnn_active_inference_language_model.gnn",
      "is_dir": false,
      "name": "gnn_active_inference_language_model.gnn",
      "size": 13517
    },
    {
      "path": "output/gnn_examples_visualization",
      "is_dir": true,
      "name": "gnn_examples_visualization",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Cm1.png",
      "is_dir": false,
      "name": "matrix_Cm1.png",
      "size": 29832
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Am1.png",
      "is_dir": false,
      "name": "matrix_Am1.png",
      "size": 34655
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/model_metadata.json",
      "is_dir": false,
      "name": "model_metadata.json",
      "size": 1427
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/full_model_data.json",
      "is_dir": false,
      "name": "full_model_data.json",
      "size": 6641
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/file_content.md",
      "is_dir": false,
      "name": "file_content.md",
      "size": 13050
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Bf0.png",
      "is_dir": false,
      "name": "matrix_Bf0.png",
      "size": 27677
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Bf1.png",
      "is_dir": false,
      "name": "matrix_Bf1.png",
      "size": 36639
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Am2.png",
      "is_dir": false,
      "name": "matrix_Am2.png",
      "size": 34441
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/ontology_annotations.png",
      "is_dir": false,
      "name": "ontology_annotations.png",
      "size": 155892
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Df0.png",
      "is_dir": false,
      "name": "matrix_Df0.png",
      "size": 27201
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/state_space.png",
      "is_dir": false,
      "name": "state_space.png",
      "size": 205255
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Cm2.png",
      "is_dir": false,
      "name": "matrix_Cm2.png",
      "size": 35738
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Cm0.png",
      "is_dir": false,
      "name": "matrix_Cm0.png",
      "size": 35913
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Am0.png",
      "is_dir": false,
      "name": "matrix_Am0.png",
      "size": 38175
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/connections.png",
      "is_dir": false,
      "name": "connections.png",
      "size": 62403
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/combined_matrices.png",
      "is_dir": false,
      "name": "combined_matrices.png",
      "size": 107750
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/combined_visualization.png",
      "is_dir": false,
      "name": "combined_visualization.png",
      "size": 153622
    },
    {
      "path": "output/gnn_examples_visualization/gnn_example_pymdp_agent/matrix_Df1.png",
      "is_dir": false,
      "name": "matrix_Df1.png",
      "size": 30886
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Cm1.png",
      "is_dir": false,
      "name": "matrix_Cm1.png",
      "size": 25777
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Am1.png",
      "is_dir": false,
      "name": "matrix_Am1.png",
      "size": 62049
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/model_metadata.json",
      "is_dir": false,
      "name": "model_metadata.json",
      "size": 1576
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/full_model_data.json",
      "is_dir": false,
      "name": "full_model_data.json",
      "size": 10678
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/file_content.md",
      "is_dir": false,
      "name": "file_content.md",
      "size": 20737
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Bf0.png",
      "is_dir": false,
      "name": "matrix_Bf0.png",
      "size": 35468
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Bf1.png",
      "is_dir": false,
      "name": "matrix_Bf1.png",
      "size": 48711
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/ontology_annotations.png",
      "is_dir": false,
      "name": "ontology_annotations.png",
      "size": 117131
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Df0.png",
      "is_dir": false,
      "name": "matrix_Df0.png",
      "size": 34160
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/state_space.png",
      "is_dir": false,
      "name": "state_space.png",
      "size": 186485
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Cm0.png",
      "is_dir": false,
      "name": "matrix_Cm0.png",
      "size": 26327
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Am0.png",
      "is_dir": false,
      "name": "matrix_Am0.png",
      "size": 44947
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/connections.png",
      "is_dir": false,
      "name": "connections.png",
      "size": 60686
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/combined_matrices.png",
      "is_dir": false,
      "name": "combined_matrices.png",
      "size": 96171
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/combined_visualization.png",
      "is_dir": false,
      "name": "combined_visualization.png",
      "size": 134102
    },
    {
      "path": "output/gnn_examples_visualization/gnn_airplane_trading_pomdp/matrix_Df1.png",
      "is_dir": false,
      "name": "matrix_Df1.png",
      "size": 34009
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model",
      "is_dir": true,
      "name": "gnn_poetic_muse_model",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/model_metadata.json",
      "is_dir": false,
      "name": "model_metadata.json",
      "size": 1903
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/matrix_Dv2.png",
      "is_dir": false,
      "name": "matrix_Dv2.png",
      "size": 31469
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/full_model_data.json",
      "is_dir": false,
      "name": "full_model_data.json",
      "size": 9849
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/file_content.md",
      "is_dir": false,
      "name": "file_content.md",
      "size": 19414
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/ontology_annotations.png",
      "is_dir": false,
      "name": "ontology_annotations.png",
      "size": 143481
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/matrix_Dv0.png",
      "is_dir": false,
      "name": "matrix_Dv0.png",
      "size": 28607
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/matrix_Dv1.png",
      "is_dir": false,
      "name": "matrix_Dv1.png",
      "size": 28155
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/state_space.png",
      "is_dir": false,
      "name": "state_space.png",
      "size": 243749
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/matrix_Cm0.png",
      "is_dir": false,
      "name": "matrix_Cm0.png",
      "size": 34359
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/matrix_Bv3.png",
      "is_dir": false,
      "name": "matrix_Bv3.png",
      "size": 43976
    },
    {
      "path": "output/gnn_examples_visualization/gnn_poetic_muse_model/combined_matrices.png",
      "is_dir": false,
      "name": "combined_matrices.png",
      "size": 66473
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example",
      "is_dir": true,
      "name": "gnn_POMDP_example",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Cm1.png",
      "is_dir": false,
      "name": "matrix_Cm1.png",
      "size": 32384
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Am1.png",
      "is_dir": false,
      "name": "matrix_Am1.png",
      "size": 44800
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/model_metadata.json",
      "is_dir": false,
      "name": "model_metadata.json",
      "size": 1475
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/full_model_data.json",
      "is_dir": false,
      "name": "full_model_data.json",
      "size": 8316
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/file_content.md",
      "is_dir": false,
      "name": "file_content.md",
      "size": 16368
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/ontology_annotations.png",
      "is_dir": false,
      "name": "ontology_annotations.png",
      "size": 144191
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Df0.png",
      "is_dir": false,
      "name": "matrix_Df0.png",
      "size": 28441
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/state_space.png",
      "is_dir": false,
      "name": "state_space.png",
      "size": 199210
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Cm0.png",
      "is_dir": false,
      "name": "matrix_Cm0.png",
      "size": 35310
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Am0.png",
      "is_dir": false,
      "name": "matrix_Am0.png",
      "size": 56071
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/combined_matrices.png",
      "is_dir": false,
      "name": "combined_matrices.png",
      "size": 103502
    },
    {
      "path": "output/gnn_examples_visualization/gnn_POMDP_example/matrix_Df1.png",
      "is_dir": false,
      "name": "matrix_Df1.png",
      "size": 27269
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model",
      "is_dir": true,
      "name": "gnn_active_inference_language_model",
      "size": 0
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/matrix_Cm1.png",
      "is_dir": false,
      "name": "matrix_Cm1.png",
      "size": 34342
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/model_metadata.json",
      "is_dir": false,
      "name": "model_metadata.json",
      "size": 2295
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/full_model_data.json",
      "is_dir": false,
      "name": "full_model_data.json",
      "size": 14153
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/file_content.md",
      "is_dir": false,
      "name": "file_content.md",
      "size": 27824
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/ontology_annotations.png",
      "is_dir": false,
      "name": "ontology_annotations.png",
      "size": 198382
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/state_space.png",
      "is_dir": false,
      "name": "state_space.png",
      "size": 676778
    },
    {
      "path": "output/gnn_examples_visualization/gnn_active_inference_language_model/combined_matrices.png",
      "is_dir": false,
      "name": "combined_matrices.png",
      "size": 26564
    },
    {
      "path": "output/gnn_type_check/resource_estimates",
      "is_dir": true,
      "name": "resource_estimates",
      "size": 0
    },
    {
      "path": "output/gnn_type_check/resource_estimates/storage_requirements_html.png",
      "is_dir": false,
      "name": "storage_requirements_html.png",
      "size": 77374
    },
    {
      "path": "output/gnn_type_check/resource_estimates/resource_data.json",
      "is_dir": false,
      "name": "resource_data.json",
      "size": 11391
    },
    {
      "path": "output/gnn_type_check/resource_estimates/resource_report_detailed.html",
      "is_dir": false,
      "name": "resource_report_detailed.html",
      "size": 26000
    },
    {
      "path": "output/gnn_type_check/resource_estimates/memory_usage_html.png",
      "is_dir": false,
      "name": "memory_usage_html.png",
      "size": 73902
    },
    {
      "path": "output/gnn_type_check/resource_estimates/resource_report.md",
      "is_dir": false,
      "name": "resource_report.md",
      "size": 6354
    },
    {
      "path": "output/gnn_type_check/resource_estimates/inference_time_html.png",
      "is_dir": false,
      "name": "inference_time_html.png",
      "size": 77229
    },
    {
      "path": "output/gnn_type_check/resources",
      "is_dir": true,
      "name": "resources",
      "size": 0
    },
    {
      "path": "output/gnn_type_check/resources/type_check_data.json",
      "is_dir": false,
      "name": "type_check_data.json",
      "size": 1079
    },
    {
      "path": "output/gnn_type_check/resource_estimates/html_vis",
      "is_dir": true,
      "name": "html_vis",
      "size": 0
    },
    {
      "path": "output/gnn_type_check/resource_estimates/html_vis/storage_requirements_html.png",
      "is_dir": false,
      "name": "storage_requirements_html.png",
      "size": 77374
    },
    {
      "path": "output/gnn_type_check/resource_estimates/html_vis/memory_usage_html.png",
      "is_dir": false,
      "name": "memory_usage_html.png",
      "size": 73902
    },
    {
      "path": "output/gnn_type_check/resource_estimates/html_vis/inference_time_html.png",
      "is_dir": false,
      "name": "inference_time_html.png",
      "size": 77229
    },
    {
      "path": "output/pymdp_execute_logs",
      "is_dir": true,
      "name": "pymdp_execute_logs",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_POMDP_example_rendered",
      "is_dir": true,
      "name": "gnn_POMDP_example_rendered",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_POMDP_example_rendered/stdout.log",
      "is_dir": false,
      "name": "stdout.log",
      "size": 3519
    },
    {
      "path": "output/pymdp_execute_logs/gnn_POMDP_example_rendered/stderr.log",
      "is_dir": false,
      "name": "stderr.log",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_active_inference_language_model_rendered",
      "is_dir": true,
      "name": "gnn_active_inference_language_model_rendered",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_active_inference_language_model_rendered/stdout.log",
      "is_dir": false,
      "name": "stdout.log",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_active_inference_language_model_rendered/stderr.log",
      "is_dir": false,
      "name": "stderr.log",
      "size": 555
    },
    {
      "path": "output/pymdp_execute_logs/gnn_airplane_trading_pomdp_rendered",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp_rendered",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_airplane_trading_pomdp_rendered/stdout.log",
      "is_dir": false,
      "name": "stdout.log",
      "size": 3599
    },
    {
      "path": "output/pymdp_execute_logs/gnn_airplane_trading_pomdp_rendered/stderr.log",
      "is_dir": false,
      "name": "stderr.log",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_example_pymdp_agent_rendered",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent_rendered",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_example_pymdp_agent_rendered/stdout.log",
      "is_dir": false,
      "name": "stdout.log",
      "size": 3673
    },
    {
      "path": "output/pymdp_execute_logs/gnn_example_pymdp_agent_rendered/stderr.log",
      "is_dir": false,
      "name": "stderr.log",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_poetic_muse_model_rendered",
      "is_dir": true,
      "name": "gnn_poetic_muse_model_rendered",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_poetic_muse_model_rendered/stdout.log",
      "is_dir": false,
      "name": "stdout.log",
      "size": 0
    },
    {
      "path": "output/pymdp_execute_logs/gnn_poetic_muse_model_rendered/stderr.log",
      "is_dir": false,
      "name": "stderr.log",
      "size": 507
    },
    {
      "path": "output/gnn_rendered_simulators",
      "is_dir": true,
      "name": "gnn_rendered_simulators",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer",
      "is_dir": true,
      "name": "rxinfer",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_example_pymdp_agent",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_example_pymdp_agent/gnn_example_pymdp_agent_rendered.jl",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent_rendered.jl",
      "size": 517
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_airplane_trading_pomdp",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_rendered.jl",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp_rendered.jl",
      "size": 519
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_poetic_muse_model",
      "is_dir": true,
      "name": "gnn_poetic_muse_model",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_poetic_muse_model/gnn_poetic_muse_model_rendered.jl",
      "is_dir": false,
      "name": "gnn_poetic_muse_model_rendered.jl",
      "size": 527
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_POMDP_example",
      "is_dir": true,
      "name": "gnn_POMDP_example",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_POMDP_example/gnn_POMDP_example_rendered.jl",
      "is_dir": false,
      "name": "gnn_POMDP_example_rendered.jl",
      "size": 515
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_active_inference_language_model",
      "is_dir": true,
      "name": "gnn_active_inference_language_model",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/rxinfer/gnn_active_inference_language_model/gnn_active_inference_language_model_rendered.jl",
      "is_dir": false,
      "name": "gnn_active_inference_language_model_rendered.jl",
      "size": 551
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp",
      "is_dir": true,
      "name": "pymdp",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_example_pymdp_agent",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_example_pymdp_agent/gnn_example_pymdp_agent_rendered.py",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent_rendered.py",
      "size": 10074
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_airplane_trading_pomdp",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_rendered.py",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp_rendered.py",
      "size": 9982
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_poetic_muse_model",
      "is_dir": true,
      "name": "gnn_poetic_muse_model",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_poetic_muse_model/gnn_poetic_muse_model_rendered.py",
      "is_dir": false,
      "name": "gnn_poetic_muse_model_rendered.py",
      "size": 8648
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_POMDP_example",
      "is_dir": true,
      "name": "gnn_POMDP_example",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_POMDP_example/gnn_POMDP_example_rendered.py",
      "is_dir": false,
      "name": "gnn_POMDP_example_rendered.py",
      "size": 9972
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_active_inference_language_model",
      "is_dir": true,
      "name": "gnn_active_inference_language_model",
      "size": 0
    },
    {
      "path": "output/gnn_rendered_simulators/pymdp/gnn_active_inference_language_model/gnn_active_inference_language_model_rendered.py",
      "is_dir": false,
      "name": "gnn_active_inference_language_model_rendered.py",
      "size": 8698
    },
    {
      "path": "output/llm_processing_step",
      "is_dir": true,
      "name": "llm_processing_step",
      "size": 0
    },
    {
      "path": "output/llm_processing_step/gnn_example_pymdp_agent",
      "is_dir": true,
      "name": "gnn_example_pymdp_agent",
      "size": 0
    },
    {
      "path": "output/llm_processing_step/gnn_example_pymdp_agent/gnn_example_pymdp_agent_comprehensive_analysis.json",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent_comprehensive_analysis.json",
      "size": 5077
    },
    {
      "path": "output/llm_processing_step/gnn_example_pymdp_agent/gnn_example_pymdp_agent_summary.txt",
      "is_dir": false,
      "name": "gnn_example_pymdp_agent_summary.txt",
      "size": 1508
    },
    {
      "path": "output/llm_processing_step/gnn_airplane_trading_pomdp",
      "is_dir": true,
      "name": "gnn_airplane_trading_pomdp",
      "size": 0
    },
    {
      "path": "output/llm_processing_step/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_comprehensive_analysis.json",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp_comprehensive_analysis.json",
      "size": 7785
    },
    {
      "path": "output/llm_processing_step/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_summary.txt",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp_summary.txt",
      "size": 1866
    },
    {
      "path": "output/llm_processing_step/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_qa.json",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp_qa.json",
      "size": 8441
    },
    {
      "path": "output/llm_processing_step/gnn_POMDP_example",
      "is_dir": true,
      "name": "gnn_POMDP_example",
      "size": 0
    },
    {
      "path": "output/llm_processing_step/gnn_POMDP_example/gnn_POMDP_example_comprehensive_analysis.json",
      "is_dir": false,
      "name": "gnn_POMDP_example_comprehensive_analysis.json",
      "size": 9317
    },
    {
      "path": "output/llm_processing_step/gnn_POMDP_example/gnn_POMDP_example_summary.txt",
      "is_dir": false,
      "name": "gnn_POMDP_example_summary.txt",
      "size": 2260
    },
    {
      "path": "output/llm_processing_step/gnn_POMDP_example/gnn_POMDP_example_qa.json",
      "is_dir": false,
      "name": "gnn_POMDP_example_qa.json",
      "size": 6886
    },
    {
      "path": "output/llm_processing_step/gnn_active_inference_language_model",
      "is_dir": true,
      "name": "gnn_active_inference_language_model",
      "size": 0
    },
    {
      "path": "output/llm_processing_step/gnn_active_inference_language_model/gnn_active_inference_language_model_qa.json",
      "is_dir": false,
      "name": "gnn_active_inference_language_model_qa.json",
      "size": 8032
    },
    {
      "path": "output/llm_processing_step/gnn_active_inference_language_model/gnn_active_inference_language_model_summary.txt",
      "is_dir": false,
      "name": "gnn_active_inference_language_model_summary.txt",
      "size": 2767
    },
    {
      "path": "output/llm_processing_step/gnn_active_inference_language_model/gnn_active_inference_language_model_comprehensive_analysis.json",
      "is_dir": false,
      "name": "gnn_active_inference_language_model_comprehensive_analysis.json",
      "size": 5836
    },
    {
      "path": "doc/cerebrum",
      "is_dir": true,
      "name": "cerebrum",
      "size": 0
    },
    {
      "path": "doc/cerebrum/gnn_cerebrum.md",
      "is_dir": false,
      "name": "gnn_cerebrum.md",
      "size": 26310
    },
    {
      "path": "doc/cerebrum/cerebrum_v1-4.md",
      "is_dir": false,
      "name": "cerebrum_v1-4.md",
      "size": 319958
    },
    {
      "path": "doc/ntqr",
      "is_dir": true,
      "name": "ntqr",
      "size": 0
    },
    {
      "path": "doc/ntqr/gnn_ntqr.md",
      "is_dir": false,
      "name": "gnn_ntqr.md",
      "size": 38
    },
    {
      "path": "doc/other",
      "is_dir": true,
      "name": "other",
      "size": 0
    },
    {
      "path": "doc/other/active_inferant_stream_014-1.md",
      "is_dir": false,
      "name": "active_inferant_stream_014-1.md",
      "size": 339
    },
    {
      "path": "doc/other/triple_play_dialog.md",
      "is_dir": false,
      "name": "triple_play_dialog.md",
      "size": 19940
    },
    {
      "path": "doc/other/from_plaintext_to_triple_play_dialog.md",
      "is_dir": false,
      "name": "from_plaintext_to_triple_play_dialog.md",
      "size": 14235
    },
    {
      "path": "doc/dspy",
      "is_dir": true,
      "name": "dspy",
      "size": 0
    },
    {
      "path": "doc/dspy/gnn_dspy.md",
      "is_dir": false,
      "name": "gnn_dspy.md",
      "size": 41193
    },
    {
      "path": "doc/x402",
      "is_dir": true,
      "name": "x402",
      "size": 0
    },
    {
      "path": "doc/x402/gnn_x402.md",
      "is_dir": false,
      "name": "gnn_x402.md",
      "size": 20304
    },
    {
      "path": "doc/autogenlib",
      "is_dir": true,
      "name": "autogenlib",
      "size": 0
    },
    {
      "path": "doc/autogenlib/gnn_autogenlib.md",
      "is_dir": false,
      "name": "gnn_autogenlib.md",
      "size": 22441
    },
    {
      "path": "doc/rxinfer",
      "is_dir": true,
      "name": "rxinfer",
      "size": 0
    },
    {
      "path": "doc/rxinfer/gnn_rxinfer.md",
      "is_dir": false,
      "name": "gnn_rxinfer.md",
      "size": 18497
    },
    {
      "path": "doc/pymdp",
      "is_dir": true,
      "name": "pymdp",
      "size": 0
    },
    {
      "path": "doc/pymdp/gnn_pymdp.md",
      "is_dir": false,
      "name": "gnn_pymdp.md",
      "size": 17
    },
    {
      "path": "doc/kit",
      "is_dir": true,
      "name": "kit",
      "size": 0
    },
    {
      "path": "doc/kit/gnn_kit.md",
      "is_dir": false,
      "name": "gnn_kit.md",
      "size": 23695
    },
    {
      "path": "doc/mcp",
      "is_dir": true,
      "name": "mcp",
      "size": 0
    },
    {
      "path": "doc/mcp/gnn_mcp_model_context_protocol.md",
      "is_dir": false,
      "name": "gnn_mcp_model_context_protocol.md",
      "size": 23040
    },
    {
      "path": "doc/mcp/fastmcp.md",
      "is_dir": false,
      "name": "fastmcp.md",
      "size": 18818
    },
    {
      "path": "doc/muscle-mem",
      "is_dir": true,
      "name": "muscle-mem",
      "size": 0
    },
    {
      "path": "doc/muscle-mem/gnn-muscle-mem.md",
      "is_dir": false,
      "name": "gnn-muscle-mem.md",
      "size": 27762
    },
    {
      "path": "doc/archive",
      "is_dir": true,
      "name": "archive",
      "size": 0
    },
    {
      "path": "doc/archive/gnn_example_jax_pymdp_learning_agent.md",
      "is_dir": false,
      "name": "gnn_example_jax_pymdp_learning_agent.md",
      "size": 9197
    },
    {
      "path": "doc/archive/gnn_example_dynamic_perception.md",
      "is_dir": false,
      "name": "gnn_example_dynamic_perception.md",
      "size": 1419
    },
    {
      "path": "doc/archive/gnn_example_butterfly_pheromone_agent.md",
      "is_dir": false,
      "name": "gnn_example_butterfly_pheromone_agent.md",
      "size": 8937
    },
    {
      "path": "doc/archive/gnn_poetic_muse_model.md",
      "is_dir": false,
      "name": "gnn_poetic_muse_model.md",
      "size": 9570
    },
    {
      "path": "doc/archive/gnn_example_dynamic_perception_policy.md",
      "is_dir": false,
      "name": "gnn_example_dynamic_perception_policy.md",
      "size": 1838
    },
    {
      "path": "doc/archive/gnn_active_inference_language_model.md",
      "is_dir": false,
      "name": "gnn_active_inference_language_model.md",
      "size": 13768
    },
    {
      "path": "doc/archive/gnn_airplane_trading_pomdp.md",
      "is_dir": false,
      "name": "gnn_airplane_trading_pomdp.md",
      "size": 10229
    },
    {
      "path": "doc/kit/gnn_kit",
      "is_dir": true,
      "name": "gnn_kit",
      "size": 0
    },
    {
      "path": "doc/kit/gnn_kit/kit_setup.py",
      "is_dir": false,
      "name": "kit_setup.py",
      "size": 587
    }
  ],
  "symbols": {
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/7_mcp.py": [
      {
        "name": "_get_mcp_methods",
        "type": "function",
        "start_line": 99,
        "end_line": 129,
        "code": "def _get_mcp_methods(mcp_file_path: Path, verbose: bool = False):\n    \"\"\"\n    Parses a Python file and extracts top-level function definitions (MCP methods).\n    Returns a list of tuples: (method_name, arguments, docstring_preview).\n    \"\"\"\n    methods = []\n    if not mcp_file_path.exists() or not mcp_file_path.is_file():\n        return methods\n    \n    # This function's verbose prints become logger.debug messages.\n    # They will only show if this module's logger is set to DEBUG.\n    logger.debug(f\"      \ud83d\udc0d Parsing for MCP methods in: {mcp_file_path}\")\n        \n    try:\n        with open(mcp_file_path, 'r', encoding='utf-8') as f:\n            source_code = f.read()\n        tree = ast.parse(source_code)\n        for node in tree.body:\n            if isinstance(node, ast.FunctionDef):\n                method_name = node.name\n                args = [arg.arg for arg in node.args.args]\n                docstring = ast.get_docstring(node)  # Use ast.get_docstring()\n                docstring_preview = \"\"\n                if docstring:\n                    docstring_preview = docstring.split('\\n')[0]\n                \n                methods.append((method_name, args, docstring_preview))\n                logger.debug(f\"        Found method: {method_name}({', '.join(args)}) - \\\"{docstring_preview}\\\"...\")\n    except Exception as e:\n        logger.warning(f\"      \u26a0\ufe0f Error parsing {mcp_file_path} for methods: {e}\") # Was print if verbose\n    return methods",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/7_mcp.py"
      },
      {
        "name": "process_mcp_operations",
        "type": "function",
        "start_line": 131,
        "end_line": 384,
        "code": "def process_mcp_operations(src_root_dir_str: str, mcp_base_dir_str: str, output_dir_str: str, verbose: bool = False):\n    \"\"\"\n    Performs checks related to the project's MCP integration:\n    - Verifies that expected functional modules have their own 'mcp.py' for integration.\n    - Checks for core MCP server files.\n    - Lists available methods in each module's mcp.py using registered MCP info first.\n    - Generates a comprehensive report.\n    \"\"\"\n    src_root_dir = Path(src_root_dir_str)\n    mcp_base_dir = Path(mcp_base_dir_str)\n    output_dir = Path(output_dir_str)\n    \n    mcp_step_output_path = output_dir / \"mcp_processing_step\"\n    mcp_step_output_path.mkdir(parents=True, exist_ok=True)\n    report_file_path = mcp_step_output_path / \"7_mcp_integration_report.md\"\n\n    report_lines = [\"# \ud83e\udd16 MCP Integration and API Report\\n\"]\n    report_lines.append(f\"\ud83d\uddd3\ufe0f Report Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n    report_lines.append(f\"**MCP Core Directory:** `{mcp_base_dir.resolve()}`\")\n    report_lines.append(f\"**Project Source Root (for modules):** `{src_root_dir.resolve()}`\")\n    report_lines.append(f\"**Output Directory for this report:** `{mcp_step_output_path.resolve()}`\\n\")\n    \n    # Control verbosity of the core 'mcp' module (from src/mcp or mcp package)\n    core_mcp_logger_name = \"mcp\" # Default logger name for the core MCP system\n    if initialize_mcp_system and hasattr(initialize_mcp_system, '__module__') and initialize_mcp_system.__module__.startswith(\"src.\"):\n        core_mcp_logger_name = \"src.mcp\" # If imported from src.mcp, its logger is likely src.mcp\n\n    core_mcp_logger = logging.getLogger(core_mcp_logger_name)\n    \n    # The verbosity of this script (7_mcp.py) is controlled by its own logger's level,\n    # which is set by main.py if run as part of the pipeline.\n    # The `verbose` flag passed to this function determines whether core_mcp_logger gets DEBUG or INFO.\n    if verbose: # verbose is from the pipeline's args.verbose\n        # If pipeline is verbose, allow core mcp to show its INFO and DEBUG messages\n        core_mcp_logger.setLevel(logging.DEBUG) \n        logger.debug(f\"Set logger '{core_mcp_logger.name}' to DEBUG for MCP operations.\")\n    else:\n        # If pipeline is not verbose, suppress core mcp INFO/DEBUG messages by setting it to WARNING\n        core_mcp_logger.setLevel(logging.WARNING) \n        logger.debug(f\"Set logger '{core_mcp_logger.name}' to WARNING for MCP operations.\")\n\n    overall_step_success = True # Initialize overall success for this step\n\n    # Initialize the MCP system to discover all tools and their registered descriptions\n    if initialize_mcp_system and mcp_instance:\n        logger.info(\"    \ud83d\ude80 Initializing MCP system to load registered tool descriptions...\")\n        mcp_init_successful_flag = False # Flag for MCP specific initialization\n        try:\n            # Capture all three return values\n            _, sdk_status_from_init, all_modules_loaded = initialize_mcp_system() \n            mcp_init_successful_flag = sdk_status_from_init and all_modules_loaded\n\n            if sdk_status_from_init and all_modules_loaded:\n                logger.info(\"    \u2705 MCP system initialization process completed successfully (SDK status OK, all modules loaded).\")\n            elif sdk_status_from_init and not all_modules_loaded:\n                logger.warning(\"    \u26a0\ufe0f MCP system initialization completed (SDK status OK), BUT ONE OR MORE MCP MODULES FAILED TO LOAD. Check 'mcp' logs for details.\")\n                overall_step_success = False # Mark overall step as problematic due to module load failure\n            else: # sdk_status_from_init is False or other unhandled init issues\n                logger.warning(\"    \u26a0\ufe0f MCP system initialization completed, but SDK status indicates issues (see mcp logger for details). Module loading may also be affected.\")\n                overall_step_success = False # Mark as problematic if SDK status itself is an issue\n\n            # --- BEGIN NEW GLOBAL SUMMARY SECTION ---\n            report_lines.append(\"\\n## \ud83c\udf10 Global Summary of Registered MCP Tools\\n\")\n            if mcp_instance.tools: \n                report_lines.append(\"This section lists all tools currently registered with the MCP system, along with their defining module, arguments, and description.\\n\")\n                \n                sorted_tools = sorted(mcp_instance.tools.items(), key=lambda item: str(item[0]))\n                \n                for tool_name, tool_obj in sorted_tools:\n                    tool_module = \"N/A\"\n                    if hasattr(tool_obj.func, '__module__'):\n                        tool_module = tool_obj.func.__module__\n                    \n                    args_str = \"...\"\n                    try:\n                        sig = inspect.signature(tool_obj.func)\n                        args_list = [param.name for param in sig.parameters.values()]\n                        args_str = f\"({', '.join(args_list)})\"\n                    except (ValueError, TypeError):\n                        logger.debug(f\"Could not retrieve signature for tool {tool_name}\")\n                    \n                    description = tool_obj.description if tool_obj.description else \"No description provided.\"\n                    schema_str = json.dumps(tool_obj.schema, indent=4) if hasattr(tool_obj, 'schema') and tool_obj.schema else \"No schema provided.\"\n                    \n                    report_lines.append(f\"- **Tool:** `{tool_name}`\")\n                    report_lines.append(f\"  - **Defined in Module:** `{tool_module}`\")\n                    report_lines.append(f\"  - **Arguments (from signature):** `{args_str}`\")\n                    report_lines.append(f\"  - **Description:** \\\"{description}\\\"\")\n                    report_lines.append(f\"  - **Schema:**\")\n                    report_lines.append(f\"    ```json\")\n                    report_lines.append(f\"    {schema_str.replace('\\n', '\\n    ')}\") # Indent schema for markdown\n                    report_lines.append(f\"    ```\")\n                report_lines.append(\"\\n\") \n            else:\n                report_lines.append(\"No MCP tools found registered in `mcp_instance.tools` after initialization.\\n\")\n            # --- END NEW GLOBAL SUMMARY SECTION ---\n\n        except MCPSDKNotFoundError as e: # Specific exception from mcp.initialize\n            logger.error(f\"    \u274c Error initializing MCP system (MCPSDKNotFoundError): {e}. Registered descriptions might be unavailable.\", exc_info=True)\n            overall_step_success = False\n            # Add a placeholder line for the global summary in case of error\n            report_lines.append(\"\\n## \ud83c\udf10 Global Summary of Registered MCP Tools\\n\")\n            report_lines.append(f\"MCP SDK Not Found Error during initialization. Tool summary unavailable. Details: {e}\\n\")\n        except Exception as e:\n            logger.error(f\"    \u274c Error initializing MCP system: {e}. Registered descriptions might be unavailable.\", exc_info=True)\n            overall_step_success = False\n            # Add a placeholder line for the global summary in case of error\n            report_lines.append(\"\\n## \ud83c\udf10 Global Summary of Registered MCP Tools\\n\")\n            report_lines.append(\"Failed to initialize MCP system. Tool summary unavailable.\\n\")\n    else:\n        logger.warning(\"    \u26a0\ufe0f MCP instance or initializer not available. Registered tool descriptions will be missing. Falling back to AST parsing for docstrings.\")\n        # Add a placeholder line for the global summary if MCP system is not available\n        # report_lines.append(\"\\n## \ud83c\udf10 Global Summary of Registered MCP Tools\\n\") # Already added if initialized at top\n        # report_lines.append(\"MCP system not available. Tool summary unavailable.\\n\") # Already added if initialized at top\n        # Ensure the section is present even if MCP init fails or not available.\n        if not any(\"\ud83c\udf10 Global Summary of Registered MCP Tools\" in line for line in report_lines):\n            report_lines.append(\"\\n## \ud83c\udf10 Global Summary of Registered MCP Tools\\n\")\n            report_lines.append(\"MCP system not available or initialization failed. Tool summary unavailable.\\n\")\n\n    # verbose parameter here controls whether debug messages from this function are emitted.\n    # The logger's level should already be set by main() based on args.verbose.\n    \n    logger.info(f\"  \ud83d\udd0e Processing MCP integration checks and method discovery...\") # General info\n    logger.debug(f\"    \ud83d\udcd6 MCP Core Directory: {Path(mcp_base_dir).resolve()}\")\n    logger.debug(f\"    \ud83c\udfd7\ufe0f Project Source Root for modules: {Path(src_root_dir).resolve()}\")\n        \n    # 1. Check for core MCP server files in src/mcp/\n    logger.debug(\"    Checking for core MCP files...\")\n    report_lines.append(\"\\n## \ud83d\udd2c Core MCP File Check\\n\") # Added heading for this section\n    report_lines.append(f\"This section verifies the presence of essential MCP files in the core directory: `{mcp_base_dir.resolve()}`\\n\")\n    core_mcp_files = [\"mcp.py\", \"meta_mcp.py\", \"cli.py\", \"server_stdio.py\", \"server_http.py\"]\n    all_core_found = True\n    found_core_files_count = 0\n    for fname in core_mcp_files:\n        fpath = mcp_base_dir / fname\n        if fpath.exists() and fpath.is_file():\n            report_lines.append(f\"- \u2705 `{fname}`: Found ({fpath.stat().st_size} bytes)\")\n            logger.debug(f\"      \ud83d\udcd6 Core MCP file found: {fpath} ({fpath.stat().st_size} bytes)\")\n            found_core_files_count += 1\n        else:\n            report_lines.append(f\"- \u274c `{fname}`: **NOT FOUND**\")\n            all_core_found = False\n            logger.warning(f\"      \u26a0\ufe0f Core MCP file NOT FOUND: {fpath}\")\n    report_lines.append(f\"\\n**Status:** {found_core_files_count}/{len(core_mcp_files)} core MCP files found. {'All core files seem present.' if all_core_found else 'One or more core MCP files are missing.'}\\n\")\n\n    # 2. Verify MCP module integrations (mcp.py in each functional dir) and list methods\n    report_lines.append(\"## \ud83e\udde9 Functional Module MCP Integration & API Check\\n\")\n    report_lines.append(f\"Checking for `mcp.py` in these subdirectories of `{src_root_dir}`: {EXPECTED_MCP_MODULE_DIRS}\\n\")\n    \n    all_integrations_found = True\n    missing_integrations = []\n    found_integrations_count = 0\n\n    # Prepare a set to keep track of methods already documented from mcp_instance\n    # to avoid duplicates when AST parsing later (if we decide to mix)\n    # Key: (module_name, method_name)\n    registered_methods_added_for_this_module = set()\n\n    for module_name in EXPECTED_MCP_MODULE_DIRS:\n        # Initialize the set here for each module\n        registered_methods_added_for_this_module = set()\n        \n        module_dir = src_root_dir / module_name\n        mcp_integration_file = module_dir / \"mcp.py\"\n        logger.debug(f\"      Processing module: {module_name}\")\n\n        module_report_methods = [] # Store (name, args_str, description_str) tuples\n\n        if not module_dir.is_dir():\n            report_lines.append(f\"### Module: `{module_name}` (at `{module_dir}`)\")\n            report_lines.append(f\"- \u2753 **Directory Status:** Directory does not exist. Cannot check for `mcp.py`.\")\n            logger.warning(f\"        \u2753 Module directory not found for '{module_name}': {module_dir}\")\n            report_lines.append(\"\\n---\\n\")\n            continue\n\n        report_lines.append(f\"### Module: `{module_name}` (at `{src_root_dir / module_name}`)\")\n\n        if mcp_integration_file.exists() and mcp_integration_file.is_file():\n            report_lines.append(f\"- \u2705 **`mcp.py` Status:** Found ({mcp_integration_file.stat().st_size} bytes)\")\n            logger.debug(f\"        \u2705 MCP integration file found: {mcp_integration_file} ({mcp_integration_file.stat().st_size} bytes)\")\n            found_integrations_count += 1\n            \n            # 1. List methods from mcp_instance.tools for this module\n            for tool_obj_name, tool_obj in mcp_instance.tools.items():\n                if hasattr(tool_obj.func, '__module__') and tool_obj.func.__module__ == f\"src.{module_name}.mcp\":\n                    try:\n                        sig = inspect.signature(tool_obj.func)\n                        args = [param.name for param in sig.parameters.values()]\n                        args_str_sig = ', '.join(args)\n                    except (ValueError, TypeError):\n                        args_str_sig = \"...\" # Fallback if signature can't be read\n                    \n                    # Use the registered description and schema\n                    desc_str = f\" - *Description: \\\"{tool_obj.description}\\\"\" if tool_obj.description else \"\"\n                    schema_info = \"\"\n                    if hasattr(tool_obj, 'schema') and tool_obj.schema:\n                        schema_dump = json.dumps(tool_obj.schema, indent=2).replace('\\n', '\\n    ') # Indent for display\n                        schema_info = f\"\\n    - Schema:\\n      ```json\\n      {schema_dump}\\n      ```\"\n                    \n                    # Combine method name, signature-derived args, description, and schema for the report line\n                    # The original `module_report_methods` stored (name, args_str, description_str)\n                    # We need to adjust this or how it's used.\n                    # For now, let's make the description string richer for these tools.\n                    full_tool_info_str = f\"`def {tool_obj.name}({args_str_sig})`{desc_str}{schema_info}\"\n                    module_report_methods.append(full_tool_info_str) # Storing the full string\n                    registered_methods_added_for_this_module.add(tool_obj.name)\n                    logger.debug(f\"          Found registered MCP tool: {tool_obj.name}({args_str_sig}) - Description: {tool_obj.description}\")\n            \n            # 2. List other functions (like register_tools) using AST, avoiding duplicates\n            ast_methods = _get_mcp_methods(mcp_integration_file, verbose=verbose)\n            if ast_methods:\n                for name, args, doc_preview in ast_methods:\n                    if name not in registered_methods_added_for_this_module:\n                        args_str = ', '.join(args)\n                        # Use AST-parsed docstring for these non-MCP-tool functions\n                        desc_str = f\" - *\\\"{doc_preview}\\\"\" if doc_preview else \"\"\n                        # Format as a string consistent with MCP tools for sorting\n                        ast_method_info_str = f\"`def {name}({args_str})` (AST parsed){desc_str}\"\n                        module_report_methods.append(ast_method_info_str) \n                        logger.debug(f\"          Found AST method (not a direct MCP tool or already listed): {name}({args_str}) - Docstring: {doc_preview}\")\n\n            if module_report_methods:\n                report_lines.append(\"- **Exposed Methods & Tools:**\")\n                for method_info_str in sorted(module_report_methods): # Sort for consistent output\n                    report_lines.append(f\"  - {method_info_str}\") # Directly use the formatted string\n            else:\n                report_lines.append(\"- **Exposed Methods & Tools:** No methods found or file could not be parsed effectively.\")\n        else:\n            report_lines.append(f\"- \u274c **`mcp.py` Status:** **NOT FOUND**\")\n            all_integrations_found = False\n            missing_integrations.append(module_name)\n            logger.warning(f\"        \u274c MCP integration file NOT FOUND: {mcp_integration_file}\")\n        report_lines.append(\"\\n---\\n\")\n    \n    report_lines.append(\"\\n## \ud83d\udcca Overall Module Integration Summary\\n\")\n    report_lines.append(f\"- **Modules Checked:** {len(EXPECTED_MCP_MODULE_DIRS)}\")\n    report_lines.append(f\"- **`mcp.py` Integrations Found:** {found_integrations_count}/{len(EXPECTED_MCP_MODULE_DIRS)}\")\n    if all_integrations_found:\n        report_lines.append(\"- **Status:** All expected functional modules appear to have an `mcp.py` integration file.\")\n    else:\n        report_lines.append(f\"- **Status:** Missing `mcp.py` integration files in: {', '.join(missing_integrations)}.\")\n    report_lines.append(\"  Please ensure each functional module that should be exposed via MCP has its own `mcp.py` following the project's MCP architecture.\\n\")\n\n    # Write report\n    try:\n        with open(report_file_path, \"w\", encoding=\"utf-8\") as f_report:\n            f_report.write(\"\\n\".join(report_lines))\n        report_size = report_file_path.stat().st_size\n        logger.debug(f\"  \u2705 MCP integration and API report saved: {report_file_path.resolve()} ({report_size} bytes)\")\n    except Exception as e:\n        logger.error(f\"\u274c Failed to write MCP integration report to {report_file_path}: {e}\", exc_info=True)\n        overall_step_success = False # Report writing failure also means overall failure\n            \n    return overall_step_success # Return the overall success status",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/7_mcp.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 386,
        "end_line": 446,
        "code": "def main(args):\n    \"\"\"Main function for the MCP operations step (Step 7).\n\n    Handles path determinations for MCP core and source root directories\n    (considering potential overrides from args), and then calls\n    `process_mcp_operations` to perform MCP integration checks and reporting.\n\n    Args:\n        args (argparse.Namespace): \n            Parsed command-line arguments from `main.py` or standalone execution.\n            Expected attributes include: output_dir, verbose, and optional\n            mcp_core_dir_override, src_root_override.\n    \"\"\"\n    # Set this script's logger level based on parsed_args.verbose\n    # This logger is defined at the module level as logging.getLogger(__name__)\n    log_level_for_this_script = logging.DEBUG if args.verbose else logging.INFO\n    logger.setLevel(log_level_for_this_script)\n    # Log that this happened, but only if we are at DEBUG level already\n    if logger.isEnabledFor(logging.DEBUG):\n        logger.debug(f\"Script logger '{logger.name}' level set to {logging.getLevelName(log_level_for_this_script)}.\")\n\n    script_dir = Path(__file__).parent.resolve() # Should be src/\n    mcp_core_dir = script_dir / \"mcp\" # This is the specific directory for core MCP files: src/mcp/\n                                      # src_root_dir for module scanning is script_dir itself (src/)\n    \n    # When called from main.py, mcp_core_dir_override and src_root_override won't exist on args.\n    # Use getattr to safely access them, defaulting to None if not present.\n    mcp_core_dir_override_val = getattr(args, 'mcp_core_dir_override', None)\n    src_root_override_val = getattr(args, 'src_root_override', None)\n\n    if args.verbose:\n        logger.info(f\"\u25b6\ufe0f  Starting Step 7: MCP Operations ({Path(__file__).name})\")\n        logger.debug(f\"  Parsing options (from main.py or standalone):\")\n        # Display the path that will actually be used, considering overrides or defaults\n        effective_mcp_core_dir = Path(mcp_core_dir_override_val if mcp_core_dir_override_val else mcp_core_dir).resolve()\n        effective_src_root_dir = Path(src_root_override_val if src_root_override_val else script_dir).resolve()\n        logger.debug(f\"    Effective MCP Core Directory: {effective_mcp_core_dir}\")\n        logger.debug(f\"    Effective Project Source Root (for module scanning): {effective_src_root_dir}\")\n        logger.debug(f\"    Output directory for MCP report: {Path(args.output_dir).resolve()}\")\n        logger.debug(f\"    Verbose: {args.verbose}\")\n\n    actual_mcp_core_dir = Path(mcp_core_dir_override_val if mcp_core_dir_override_val else mcp_core_dir)\n    actual_src_root_dir = Path(src_root_override_val if src_root_override_val else script_dir)\n\n    if not actual_mcp_core_dir.exists() or not actual_mcp_core_dir.is_dir():\n        logger.error(f\"\u274c CRITICAL-CHECK: MCP Core directory {actual_mcp_core_dir.resolve()} not found. Core file checks will be affected.\")\n    if not actual_src_root_dir.exists() or not actual_src_root_dir.is_dir():\n        logger.critical(f\"\u274c CRITICAL-ERROR: Project Source Root directory {actual_src_root_dir.resolve()} not found. Cannot perform module MCP integration checks.\")\n        return 1 # This is more critical as no modules can be scanned.\n\n    if not process_mcp_operations(\n        str(actual_src_root_dir), \n        str(actual_mcp_core_dir), \n        args.output_dir, \n        args.verbose\n    ):\n        logger.error(f\"\u274c Step 7: MCP Operations ({Path(__file__).name}) FAILED (report generation or critical error during processing).\")\n        return 1\n        \n    logger.info(f\"\u2705 Step 7: MCP Operations ({Path(__file__).name}) - COMPLETED (Report generated; check report for details on findings)\")\n    return 0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/7_mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/2_setup.py": [
      {
        "name": "verify_directories",
        "type": "function",
        "start_line": 70,
        "end_line": 101,
        "code": "def verify_directories(target_dir, output_dir, verbose=False):\n    \"\"\"Verify that target directory exists and create output directories.\"\"\"\n    target_path = Path(target_dir)\n    \n    # Use logger.debug for verbose messages, logger.info for standard messages\n    logger.debug(f\"Verifying target directory: {target_path.resolve()}\")\n\n    # Check if target directory exists\n    if not target_path.is_dir(): # More specific check for directory\n        logger.error(f\"\u274c Error: Target directory '{target_dir}' does not exist or is not a directory\") # Changed from print\n        return False\n    \n    logger.debug(f\"  Found {sum(1 for f in target_path.rglob('*.md') if f.is_file())} .md files (recursively in target: {target_path.resolve()})\")\n    \n    # Create output directory if it doesn't exist\n    output_path = Path(output_dir)\n    logger.debug(f\"\ud83d\udcc2 Ensuring output directory: {output_path.resolve()}\")\n    output_path.mkdir(parents=True, exist_ok=True)\n    \n    # Create visualization output directory\n    viz_output = output_path / \"gnn_examples_visualization\"\n    logger.debug(f\"  \ud83d\udcc2 Ensuring visualization directory: {viz_output.resolve()}\")\n    viz_output.mkdir(exist_ok=True)\n    \n    # Create type checker output directory\n    type_output = output_path / \"gnn_type_check\"\n    logger.debug(f\"  \ud83d\udcc2 Ensuring type check directory: {type_output.resolve()}\")\n    type_output.mkdir(exist_ok=True)\n    \n    logger.info(f\"\u2705 Output directory structure verified/created: {output_path.resolve()}\") # Was print if verbose\n    \n    return True",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/2_setup.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 103,
        "end_line": 182,
        "code": "def main(parsed_args: argparse.Namespace): # Renamed 'args' to 'cmd_args' and type hinted\n    \"\"\"Main function for the setup step (Step 2).\\n\n    Orchestrates directory verification and Python virtual environment setup.\n\n    Args:\n        parsed_args (argparse.Namespace): Pre-parsed command-line arguments.\n            Expected attributes include: target_dir, output_dir, verbose.\n    \"\"\"    \n    # Setup logging level for this script's logger based on verbosity.\n    log_level = logging.DEBUG if parsed_args.verbose else logging.INFO\n    logger.setLevel(log_level)\n    logger.debug(f\"Script logger '{logger.name}' level set to {logging.getLevelName(log_level)}.\")\n\n    logger.info(\"\u25b6\ufe0f Starting Step 2: Setup\")\n    logger.debug(f\"  Parsed arguments for setup: {parsed_args}\")\n    logger.debug(\"  Phase 1: Verifying project directories...\")\n    \n    target_dir_abs = Path(parsed_args.target_dir).resolve()\n    output_dir_abs = Path(parsed_args.output_dir).resolve()\n\n    # Pass verbose to verify_directories, although it now uses logger levels directly.\n    if not verify_directories(str(target_dir_abs), str(output_dir_abs), parsed_args.verbose):\n        logger.error(\"\u274c Directory verification failed. Halting setup step.\")\n        sys.exit(1)\n    \n    logger.info(\"  \u2705 Project directories verified successfully.\")\n    logger.info(\"  Phase 2: Setting up Python virtual environment and dependencies...\")\n\n    if project_env_setup and hasattr(project_env_setup, 'perform_full_setup'):\n        try:\n            logger.debug(\"  \ud83d\udc0d Attempting to run perform_full_setup from src/setup/setup.py\")\n            # Pass verbose to perform_full_setup. This requires perform_full_setup to accept it.\n            env_setup_result = project_env_setup.perform_full_setup(verbose=parsed_args.verbose) \n            if env_setup_result != 0:\n                logger.error(f\"\u274c Python virtual environment and dependency setup failed (returned code: {env_setup_result}).\")\n                sys.exit(1)\n            logger.info(\"  \u2705 Python virtual environment and dependencies setup completed.\")\n\n            logger.info(\"  Phase 3: Confirming PyMDP availability (informational)...\")\n            pymdp_confirmed_fully = False\n            try:\n                import pymdp # type: ignore\n                logger.info(\"    Successfully imported the 'pymdp' module.\")\n                pymdp_version_str = \"N/A\"\n                try:\n                    import importlib.metadata\n                    pymdp_version_str = importlib.metadata.version('inferactively-pymdp')\n                    logger.info(f\"    Version of 'inferactively-pymdp' via importlib.metadata: {pymdp_version_str}\")\n                except importlib.metadata.PackageNotFoundError:\n                    logger.warning(\"    \u26a0\ufe0f 'inferactively-pymdp' package not found by importlib.metadata. Version unknown.\")\n                except Exception as e_meta:\n                    logger.warning(f\"    \u26a0\ufe0f Error getting version via importlib.metadata: {e_meta}\")\n                pymdp_module_location = getattr(pymdp, '__file__', 'N/A')\n                logger.info(f\"    'pymdp' module location: {pymdp_module_location}\")\n                from pymdp.agent import Agent # type: ignore\n                logger.info(f\"    Successfully imported 'pymdp.agent.Agent': {Agent}\")\n                agent_module = sys.modules.get(Agent.__module__)\n                agent_module_file = getattr(agent_module, '__file__', 'N/A') if agent_module else 'N/A'\n                logger.info(f\"    'pymdp.agent.Agent' module ({Agent.__module__}) location: {agent_module_file}\")\n                logger.info(\"  \u2705 PyMDP module and Agent class appear to be available and importable.\")\n                pymdp_confirmed_fully = True\n            except ImportError as e_imp:\n                logger.warning(f\"  \u26a0\ufe0f Failed to import 'pymdp' or 'pymdp.agent.Agent': {e_imp}\")\n                logger.warning(\"      This may affect PyMDP-dependent steps (e.g., 9_render, 10_execute).\")\n            except Exception as e_other:\n                logger.warning(f\"  \u26a0\ufe0f An unexpected error occurred during PyMDP availability check: {e_other}\", exc_info=parsed_args.verbose)\n            \n            if not pymdp_confirmed_fully:\n                logger.warning(\"  \u26a0\ufe0f PyMDP availability check did not fully succeed. Subsequent PyMDP steps may fail or use unexpected versions.\")\n\n        except Exception as e:\n            logger.error(f\"\u274c Error during virtual environment setup or core dependency installation: {e}\", exc_info=True)\n            sys.exit(1)\n    else:\n        logger.warning(\"\u26a0\ufe0f Warning: 'project_env_setup.perform_full_setup' not available from src/setup/setup.py. Skipping virtual environment setup.\")\n        logger.error(\"\u274c Critical setup phase (virtual environment and dependencies) was skipped due to import issues.\")\n        sys.exit(1)\n    \n    logger.info(\"\u2705 Step 2: Setup complete\")\n    sys.exit(0)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/2_setup.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/1_gnn.py": [
      {
        "name": "_get_relative_path_if_possible",
        "type": "function",
        "start_line": 55,
        "end_line": 62,
        "code": "def _get_relative_path_if_possible(absolute_path_obj: Path, project_root: Path | None) -> str:\n    \"\"\"Returns a path string relative to project_root if provided and applicable, otherwise absolute.\"\"\"\n    if project_root:\n        try:\n            return str(absolute_path_obj.relative_to(project_root))\n        except ValueError:\n            return str(absolute_path_obj) # Not under project root\n    return str(absolute_path_obj)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/1_gnn.py"
      },
      {
        "name": "process_gnn_folder",
        "type": "function",
        "start_line": 64,
        "end_line": 343,
        "code": "def process_gnn_folder(target_dir: Path, output_dir: Path, project_root: Path | None, recursive: bool = False, verbose: bool = False):\n    \"\"\"\n    Process the GNN folder:\n    - Discover .md files.\n    - Perform basic parsing for key GNN sections.\n    - Log findings and simple statistics to a report file.\n    \"\"\"\n    logger.info(f\"Starting GNN file processing for directory: '{_get_relative_path_if_possible(target_dir.resolve(), project_root)}'\")\n    if recursive:\n        logger.info(\"Recursive mode enabled: searching in subdirectories.\")\n    else:\n        logger.info(\"Recursive mode disabled: searching in top-level directory only.\")\n\n    # Determine project root, assuming this script is in 'src/' subdirectory of project root\n    # This is now passed as an argument, but can be determined as a fallback if not provided.\n    # if not project_root:\n    #     try:\n    #         script_file_path = Path(__file__).resolve()\n    #         project_root_determined = script_file_path.parent.parent\n    #         logger.debug(f\"Determined project root internally: {project_root_determined}\")\n    #         # No longer setting global _project_root_path_1_gnn\n    #     except Exception as e:\n    #         logger.warning(f\"Could not automatically determine project root. File paths in report might be absolute or less standardized: {e}\")\n    # else:\n    #     logger.debug(f\"Using provided project root: {project_root}\")\n\n    gnn_target_path_abs = target_dir.resolve()\n\n    if not target_dir.is_dir():\n        logger.warning(f\"GNN target directory '{_get_relative_path_if_possible(gnn_target_path_abs, project_root)}' not found or not a directory. Skipping GNN processing for this target.\")\n        return 2 # Return 2 for warning/non-fatal issue\n\n    # Ensure output directory for this step exists\n    step_output_dir = output_dir / \"gnn_processing_step\"\n    step_output_dir_abs = step_output_dir.resolve()\n    try:\n        step_output_dir.mkdir(parents=True, exist_ok=True)\n        logger.debug(f\"Ensured output directory exists: {step_output_dir_abs}\")\n    except OSError as e:\n        logger.error(f\"Failed to create output directory {step_output_dir_abs}: {e}\")\n        return False # Cannot proceed without output directory\n\n    report_file_path = step_output_dir / \"1_gnn_discovery_report.md\"\n    report_file_path_abs = report_file_path.resolve()\n\n    processed_files_summary = []\n    file_pattern = \"**/*.md\" if recursive else \"*.md\"\n    \n    # --- Counters for summary ---\n    found_model_name_count = 0\n    found_statespace_count = 0\n    found_connections_count = 0\n    files_with_errors_count = 0\n    # --- End Counters ---\n\n    logger.debug(f\"Searching for GNN files matching pattern '{file_pattern}' in '{gnn_target_path_abs}'\")\n    gnn_files = list(target_dir.glob(file_pattern))\n\n    if not gnn_files:\n        logger.info(f\"No .md files found in '{_get_relative_path_if_possible(gnn_target_path_abs, project_root)}' with pattern '{file_pattern}'.\")\n        try:\n            with open(report_file_path, \"w\", encoding=\"utf-8\") as f_report:\n                f_report.write(\"# GNN File Discovery Report\\n\\n\")\n                f_report.write(f\"No .md files found in `{_get_relative_path_if_possible(gnn_target_path_abs, project_root)}` using pattern `{file_pattern}`.\\n\")\n            logger.info(f\"Empty report saved to: {_get_relative_path_if_possible(report_file_path_abs, project_root)}\")\n        except IOError as e:\n            logger.error(f\"Failed to write empty report to {report_file_path_abs}: {e}\")\n            # Decide if this is fatal for the step; for now, non-fatal to allow pipeline progress\n        return 0 # No files found is not an error for the script itself, just an outcome.\n\n    logger.info(f\"Found {len(gnn_files)} .md file(s) to process in '{_get_relative_path_if_possible(gnn_target_path_abs, project_root)}'.\")\n\n    for gnn_file_path_obj in gnn_files:\n        resolved_gnn_file_path = gnn_file_path_obj.resolve() # gnn_file_path_obj is already a Path\n        path_for_report_str = _get_relative_path_if_possible(resolved_gnn_file_path, project_root)\n        \n        logger.debug(f\"Processing file: {path_for_report_str}\")\n        \n        file_summary = {\n            \"file_name\": resolved_gnn_file_path.name, # Use resolved path's name\n            \"path\": path_for_report_str,\n            \"model_name\": \"Not found\", # Added for specific storage\n            \"sections_found\": [],\n            \"model_parameters\": {}, # Added to store parsed ModelParameters\n            \"errors\": []\n        }\n        try:\n            with open(resolved_gnn_file_path, \"r\", encoding=\"utf-8\") as f: # Use resolved path to open\n                content = f.read()\n            logger.debug(f\"Successfully read content from {path_for_report_str}.\")\n            \n            # Basic section parsing\n            # ModelName parsing\n            model_name_section_header_text = \"ModelName\"\n            model_name_str = \"Not found\" # Default status message\n            parsed_model_name = \"Not found\" # Actual parsed name\n\n            # Regex to find the \"## ModelName\" header, case-insensitive for \"ModelName\"\n            # It captures the header itself to know its end position.\n            model_name_header_pattern = re.compile(rf\"^##\\s*{model_name_section_header_text}\\s*$\\r?\", re.IGNORECASE | re.MULTILINE)\n            model_name_header_match = model_name_header_pattern.search(content)\n\n            if model_name_header_match:\n                logger.debug(f\"  Found '## {model_name_section_header_text}' header in {path_for_report_str}\")\n                found_model_name_count += 1 # Count if header is present\n                \n                # Determine the content region for the model name:\n                # from end of its header to start of the next section or end of file.\n                content_after_header = content[model_name_header_match.end():]\n                next_section_header_match = re.search(r\"^##\\s+\\\\w+\", content_after_header, re.MULTILINE)\n                \n                if next_section_header_match:\n                    name_region_content = content_after_header[:next_section_header_match.start()]\n                else:\n                    name_region_content = content_after_header\n                \n                # Find the first suitable line in this region\n                extracted_name_candidate = \"\"\n                for line in name_region_content.splitlines():\n                    stripped_line = line.strip()\n                    if stripped_line and not stripped_line.startswith(\"#\"):\n                        extracted_name_candidate = stripped_line\n                        break # Found the first potential name\n                \n                if extracted_name_candidate:\n                    parsed_model_name = extracted_name_candidate\n                    model_name_str = f\"Found: {parsed_model_name}\" # Status message for report\n                    logger.debug(f\"    Extracted {model_name_section_header_text}: '{parsed_model_name}' from {path_for_report_str}\")\n                else:\n                    # Header was found, but no suitable non-comment/non-empty line followed in its section\n                    parsed_model_name = \"(Header found, but name line empty or only comments)\"\n                    model_name_str = \"Found (header only, name line empty/commented)\" # Status message\n                    logger.debug(f\"    '## {model_name_section_header_text}' header found, but no suitable name line in {path_for_report_str}\")\n            else:\n                # '## ModelName' header itself was not found\n                parsed_model_name = \"Not found\"\n                model_name_str = \"Not found\" # Status message (already default)\n                logger.debug(f\"  '## {model_name_section_header_text}' section header not found in {path_for_report_str}\")\n\n            file_summary[\"model_name\"] = parsed_model_name # Store the parsed name or status\n            # The sections_found list in the report will use model_name_str for its verbose status.\n            # We need to update how sections_found is populated for ModelName.\n            # First, remove any old ModelName entry from sections_found if it exists from a previous iteration logic.\n            file_summary[\"sections_found\"] = [s for s in file_summary[\"sections_found\"] if not s.startswith(\"ModelName:\")]\n            file_summary[\"sections_found\"].insert(0, f\"ModelName: {model_name_str}\") # Insert at beginning\n\n            # StateSpaceBlock parsing\n            statespace_section_header_text = \"StateSpaceBlock\"\n            # Match if line starts with \"## StateSpaceBlock\" (case insensitive for \"StateSpaceBlock\"), allowing only optional comment after.\n            statespace_search_pattern = rf\"^##\\\\s*{re.escape(statespace_section_header_text)}\\\\s*(?:#.*)?$\" \n            statespace_match = re.search(statespace_search_pattern, content, re.MULTILINE | re.IGNORECASE)\n            if statespace_match:\n                file_summary[\"sections_found\"].append(\"StateSpaceBlock: Found\")\n                logger.debug(f\"  Found {statespace_section_header_text} section in {path_for_report_str}\")\n                found_statespace_count += 1\n            else:\n                file_summary[\"sections_found\"].append(\"StateSpaceBlock: Not found\")\n                logger.debug(f\"  {statespace_section_header_text} section not found in {path_for_report_str}\")\n                if verbose:\n                    logger.debug(f\"    Content snippet for {path_for_report_str} (up to 500 chars) where {statespace_section_header_text} was not found:\\n{content[:500]}\")\n\n            # Connections parsing\n            connections_section_header_text = \"Connections\"\n            # Match if line starts with \"## Connections\" (case insensitive for \"Connections\"), allowing only optional comment after.\n            connections_search_pattern = rf\"^##\\\\s*{re.escape(connections_section_header_text)}\\\\s*(?:#.*)?$\"\n            connections_match = re.search(connections_search_pattern, content, re.MULTILINE | re.IGNORECASE)\n            if connections_match:\n                file_summary[\"sections_found\"].append(\"Connections: Found\")\n                logger.debug(f\"  Found {connections_section_header_text} section in {path_for_report_str}\")\n                found_connections_count += 1\n            else:\n                file_summary[\"sections_found\"].append(\"Connections: Not found\")\n                logger.debug(f\"  {connections_section_header_text} section not found in {path_for_report_str}\")\n                if verbose:\n                    logger.debug(f\"    Content snippet for {path_for_report_str} (up to 500 chars) where {connections_section_header_text} was not found:\\n{content[:500]}\")\n\n            # ModelParameters parsing\n            model_params_section_header_text = \"ModelParameters\"\n            model_params_search_pattern = rf\"^##\\s*{re.escape(model_params_section_header_text)}\\s*(?:#.*)?$\"\n            model_params_match = re.search(model_params_search_pattern, content, re.MULTILINE | re.IGNORECASE)\n            if model_params_match:\n                logger.debug(f\"  Found {model_params_section_header_text} section in {path_for_report_str}\")\n                section_content_start = model_params_match.end()\n                # Find the next section header or end of file\n                next_section_match = re.search(r\"^##\\s*\\w+\", content[section_content_start:], re.MULTILINE)\n                section_content_end = next_section_match.start() + section_content_start if next_section_match else len(content)\n                \n                params_content = content[section_content_start:section_content_end]\n                parsed_params_count = 0\n                for line in params_content.splitlines():\n                    line = line.strip()\n                    if not line or line.startswith(\"#\"): # Skip empty lines and comments\n                        continue\n                    \n                    match = re.match(r\"([\\w_]+):\\s*(\\[.*?\\])\\s*(?:#.*)?\", line) # Capture key and list-like value\n                    if match:\n                        key = match.group(1).strip()\n                        value_str = match.group(2).strip()\n                        try:\n                            # Attempt to evaluate the string as a Python literal (e.g., \"[1, 2]\" -> [1, 2])\n                            # This is safer than full eval() but still needs caution if input isn't controlled.\n                            # For GNN, we assume parameters are simple lists of numbers.\n                            import ast\n                            value = ast.literal_eval(value_str)\n                            if isinstance(value, list): # Ensure it's a list\n                                file_summary[\"model_parameters\"][key] = value\n                                logger.debug(f\"    Parsed ModelParameter: {key} = {value}\")\n                                parsed_params_count += 1\n                            else:\n                                logger.warning(f\"    ModelParameter '{key}' value '{value_str}' did not evaluate to a list in {path_for_report_str}. Storing as string.\")\n                                file_summary[\"model_parameters\"][key] = value_str # Store as string if not a list\n                        except (ValueError, SyntaxError) as e:\n                            logger.warning(f\"    Could not parse ModelParameter value for '{key}' ('{value_str}') as list in {path_for_report_str}: {e}. Storing as string.\")\n                            file_summary[\"model_parameters\"][key] = value_str # Store as string on error\n                    elif ':' in line: # Fallback for lines that might not be list format but are key:value\n                        key_part, value_part = line.split(\":\", 1)\n                        key = key_part.strip()\n                        value = value_part.split(\"#\", 1)[0].strip() # Remove comments\n                        file_summary[\"model_parameters\"][key] = value # Store as string\n                        logger.debug(f\"    Parsed ModelParameter (as string): {key} = {value}\")\n                        parsed_params_count +=1\n\n                if parsed_params_count > 0:\n                    file_summary[\"sections_found\"].append(f\"ModelParameters: Found ({parsed_params_count} parameters parsed)\")\n                else:\n                    file_summary[\"sections_found\"].append(\"ModelParameters: Found (section present, but no parameters parsed)\")\n            else:\n                file_summary[\"sections_found\"].append(\"ModelParameters: Not found\")\n                logger.debug(f\"  {model_params_section_header_text} section not found in {path_for_report_str}\")\n\n        except Exception as e:\n            logger.error(f\"Error processing file {path_for_report_str}: {e}\", exc_info=verbose) # Show traceback if verbose\n            file_summary[\"errors\"].append(str(e))\n            files_with_errors_count += 1\n        \n        processed_files_summary.append(file_summary)\n\n    # Generate the report\n    try:\n        with open(report_file_path, \"w\", encoding=\"utf-8\") as f_report:\n            f_report.write(\"# GNN File Discovery Report\\n\\n\") \n            f_report.write(f\"Processed {len(gnn_files)} GNN file(s) from directory: `{_get_relative_path_if_possible(gnn_target_path_abs, project_root)}`\\n\")\n            f_report.write(f\"Search pattern used: `{file_pattern}`\\n\\n\")\n\n            # --- Add Overall Summary ---\n            f_report.write(\"## Overall Summary\\n\\n\")\n            f_report.write(f\"- GNN files processed: {len(gnn_files)}\\n\")\n            f_report.write(f\"- Files with ModelName found: {found_model_name_count}\\n\")\n            f_report.write(f\"- Files with StateSpaceBlock found: {found_statespace_count}\\n\")\n            f_report.write(f\"- Files with Connections section found: {found_connections_count}\\n\")\n            f_report.write(f\"- Files with processing errors: {files_with_errors_count}\\n\\n\")\n            f_report.write(\"---\\n\") \n            # --- End Overall Summary ---\n            \n            f_report.write(\"## Detailed File Analysis\\n\\n\")\n\n            for summary in processed_files_summary:\n                f_report.write(f\"### File: `{summary['path']}`\\n\\n\") \n                f_report.write(\"#### Found Sections:\\n\") \n                if summary[\"sections_found\"]:\n                    for section_info in summary[\"sections_found\"]:\n                        f_report.write(f\"- {section_info}\\n\")\n                else:\n                    f_report.write(\"- (No specific sections parsed or found)\\n\")\n                \n                if summary[\"errors\"]:\n                    f_report.write(\"\\n#### Errors During Processing:\\n\") # Changed from H3 to H4 for consistency\n                    for error in summary[\"errors\"]:\n                        f_report.write(f\"- {error}\\n\")\n                f_report.write(\"\\n---\\n\")\n        logger.info(f\"GNN discovery report saved to: {_get_relative_path_if_possible(report_file_path_abs, project_root)}\")\n    except IOError as e:\n        logger.error(f\"Failed to write GNN discovery report to {report_file_path_abs}: {e}\")\n        return 1 # Failure to write report is an error for this step\n\n    if files_with_errors_count > 0:\n        logger.warning(f\"{files_with_errors_count} file(s) encountered errors during processing.\")\n        return 2 # Success with warnings\n    \n    return 0 # Pure success",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/1_gnn.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 345,
        "end_line": 416,
        "code": "def main(parsed_args: argparse.Namespace):\n    \"\"\"Main function to handle argument parsing and call processing logic.\n\n    Args:\n        parsed_args (argparse.Namespace): Pre-parsed command-line arguments.\n            Expected attributes include: target_dir, output_dir, recursive, verbose.\n    \"\"\"\n    # Setup logging level for this script's logger based on verbosity.\n    # If run standalone, setup_standalone_logging (called in __main__ block) would have already\n    # configured the root logger and potentially this logger's level.\n    # If run as part of a pipeline (main.py), the pipeline's logger is configured,\n    # and this script's logger will inherit. We explicitly set this script's logger level\n    # here to ensure it respects its own verbose flag if the pipeline's verbosity differs\n    # or if setup_standalone_logging didn't target this specific logger name with setLevel.\n    log_level = logging.DEBUG if parsed_args.verbose else logging.INFO\n    logger.setLevel(log_level)\n    # Ensure handlers also respect this level if they were configured higher by a root setup.\n    # This is particularly for the case where main.py sets a global INFO, but this script is --verbose.\n    for handler in logging.getLogger().handlers: # Check root handlers\n        if handler.level > log_level: # only if root handler is less verbose\n            # This is tricky. We don't want to override main.py's console handler level usually.\n            # setup_standalone_logging handles its own logger.setLevel(logger_name) call.\n            # For now, let's assume main.py's verbosity setting for handlers is king if already set.\n            # The script's own logger.setLevel(log_level) above is the main control for this script's messages.\n            pass \n\n    logger.debug(f\"Script logger '{logger.name}' level set to {logging.getLevelName(log_level)}.\")\n\n    # Determine project_root for use in process_gnn_folder\n    # This assumes the script itself (1_gnn.py) is in a 'src' directory, \n    # and 'src' is a direct child of the project root.\n    try:\n        script_file_path = Path(__file__).resolve()\n        current_project_root = script_file_path.parent.parent \n        logger.debug(f\"Project root determined for path relativization: {current_project_root}\")\n    except Exception:\n        current_project_root = None\n        logger.warning(\"Could not determine project root from script location. Paths in report may be absolute.\")\n\n    # Convert string paths from argparse to Path objects if they aren't already\n    # (argparse with type=Path should handle this, but defensive)\n    target_dir_path = Path(parsed_args.target_dir)\n    output_dir_path = Path(parsed_args.output_dir)\n\n    # Ensure paths are absolute before passing to processing function\n    # This is good practice, though process_gnn_folder also resolves them.\n    # Argparse with type=Path and default values based on Path(__file__) should result in absolute paths\n    # if defaults are used, or if user provides absolute paths.\n    # If user provides relative paths, they are relative to CWD. We should resolve them.\n    target_dir_abs = target_dir_path.resolve()\n    output_dir_abs = output_dir_path.resolve()\n\n    logger.info(f\"GNN Step 1: Target directory: {target_dir_abs}\")\n    logger.info(f\"GNN Step 1: Output directory: {output_dir_abs}\")\n    logger.info(f\"GNN Step 1: Recursive: {parsed_args.recursive}\")\n    logger.info(f\"GNN Step 1: Verbose: {parsed_args.verbose}\")\n\n    result_code = process_gnn_folder(\n        target_dir=target_dir_abs, \n        output_dir=output_dir_abs, \n        project_root=current_project_root,\n        recursive=parsed_args.recursive, \n        verbose=parsed_args.verbose\n    )\n    \n    if result_code == 0:\n        logger.info(\"Step 1_gnn completed successfully.\")\n    elif result_code == 2:\n        logger.warning(\"Step 1_gnn completed with warnings.\")\n    else:\n        logger.error(\"Step 1_gnn failed.\")\n        sys.exit(result_code)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/1_gnn.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/5_export.py": [
      {
        "name": "_get_relative_path_if_possible",
        "type": "function",
        "start_line": 97,
        "end_line": 103,
        "code": "def _get_relative_path_if_possible(absolute_path_obj: Path, project_root: Path | None) -> str:\n    if project_root:\n        try:\n            return str(absolute_path_obj.relative_to(project_root))\n        except ValueError:\n            return str(absolute_path_obj)\n    return str(absolute_path_obj)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/5_export.py"
      },
      {
        "name": "generate_export_summary_report",
        "type": "function",
        "start_line": 105,
        "end_line": 127,
        "code": "def generate_export_summary_report(target_dir: str, output_dir: str, num_files_processed: int, num_files_exported: int, num_export_failures: int, recursive: bool = False, verbose: bool = False):\n    \"\"\"Generates a summary report specifically for the export step.\"\"\"\n    logger.info(\"\ud83d\udcc4 Generating GNN Export Step Summary Report...\")\n    output_path = Path(output_dir)\n    summary_file = output_path / \"gnn_exports\" / \"5_export_step_report.md\"\n    summary_file.parent.mkdir(parents=True, exist_ok=True)\n    \n    project_root = Path(__file__).resolve().parent.parent\n    reported_target_dir = _get_relative_path_if_possible(Path(target_dir).resolve(), project_root)\n    reported_output_dir = _get_relative_path_if_possible(output_path.resolve(), project_root)\n\n    with open(summary_file, \"w\") as f:\n        f.write(\"# \ud83d\udce4 GNN Export Step Summary\\n\\n\")\n        f.write(f\"\ud83d\uddd3\ufe0f Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n        f.write(\"## \u2699\ufe0f Configuration\\n\")\n        f.write(f\"- **Source Directory for GNN files:** `{reported_target_dir}`\\n\")\n        f.write(f\"- **Base Output for Exports:** `{Path(reported_output_dir) / 'gnn_exports'}`\\n\")\n        f.write(f\"- **Recursive Search:** {'\u2705 Enabled' if recursive else '\u274c Disabled'}\\n\\n\")\n        f.write(\"## \ud83d\udcca Export Statistics\\n\")\n        f.write(f\"- **GNN Files Found/Attempted:** {num_files_processed}\\n\")\n        f.write(f\"- **GNN Files with Successful Exports (all selected formats):** {num_files_exported - num_export_failures}\\n\")\n        f.write(f\"- **GNN Files with At Least One Export Failure:** {num_export_failures}\\n\")\n    logger.info(f\"\ud83d\udcc4 Export step summary report generated: {summary_file}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/5_export.py"
      },
      {
        "name": "export_gnn_file_to_selected_formats",
        "type": "function",
        "start_line": 129,
        "end_line": 201,
        "code": "def export_gnn_file_to_selected_formats(gnn_file_path: Path, base_output_dir: Path, formats_to_export: list[str], project_root_for_reporting: Path, verbose: bool = False):\n    \"\"\"\n    Parses a single GNN file and exports it to selected formats.\n    Outputs are saved in a subdirectory of base_output_dir/gnn_exports/, named after the GNN file.\n    Returns True if all selected exports for this file were successful, False otherwise.\n    \"\"\"\n    if not FORMAT_EXPORTERS_LOADED:\n        logger.error(f\"Skipping export for {_get_relative_path_if_possible(gnn_file_path, project_root_for_reporting)} as format exporters module is not loaded.\")\n        return False\n\n    # Use a relative path for logging if possible\n    gnn_file_display_name = _get_relative_path_if_possible(gnn_file_path, project_root_for_reporting)\n    logger.info(f\"  Processing exports for GNN file: {gnn_file_display_name}\")\n\n    try:\n        # _gnn_model_to_dict expects a string path\n        gnn_model_dict = _gnn_model_to_dict(str(gnn_file_path))\n    except FileNotFoundError:\n        logger.error(f\"    \u274c File not found: {gnn_file_display_name}. Skipping export for this file.\")\n        return False\n    except Exception as e:\n        logger.error(f\"    \u274c Error parsing GNN file {gnn_file_display_name}: {e}. Skipping export for this file.\", exc_info=verbose)\n        return False\n\n    # Create a dedicated output subdirectory for this GNN file's exports\n    # e.g., <pipeline_output_dir>/gnn_exports/<model_name>/\n    file_specific_export_dir = base_output_dir / \"gnn_exports\" / gnn_file_path.stem\n    try:\n        file_specific_export_dir.mkdir(parents=True, exist_ok=True)\n        logger.debug(f\"    \ud83d\udce4 Ensured export subdirectory: {file_specific_export_dir}\")\n    except OSError as e:\n        logger.error(f\"    \u274c Failed to create export subdirectory {file_specific_export_dir}: {e}. Skipping exports for {gnn_file_display_name}.\")\n        return False\n\n    success_count = 0\n    failure_count = 0\n\n    if not formats_to_export:\n        logger.info(f\"    \u2139\ufe0f No specific formats requested for export for {gnn_file_display_name}. Nothing to do.\")\n        return True # No failures if nothing was requested\n\n    for fmt_key in formats_to_export:\n        if fmt_key not in AVAILABLE_EXPORT_FUNCTIONS:\n            logger.warning(f\"    \u26a0\ufe0f Unknown or unavailable export format '{fmt_key}' requested for {gnn_file_display_name}. Skipping this format.\")\n            failure_count += 1\n            continue\n\n        export_func = AVAILABLE_EXPORT_FUNCTIONS[fmt_key]\n\n        file_extension = \"gnn\" if fmt_key == \"dsl\" else fmt_key\n        if fmt_key == \"txt_summary\": file_extension = \"txt\"\n        # For json_adj, it will be .json_adj if fmt_key is 'json_adj'\n\n        output_file = file_specific_export_dir / f\"{gnn_file_path.stem}.{file_extension}\"\n        try:\n            logger.debug(f\"      \ud83d\udce4 Exporting to {fmt_key.upper()} -> {_get_relative_path_if_possible(output_file, project_root_for_reporting)}\")\n            export_func(gnn_model_dict, str(output_file)) # Pass the parsed dict\n            logger.info(f\"      \u2705 Successfully exported to {output_file.name} (format: {fmt_key})\")\n            success_count += 1\n        except Exception as e:\n            logger.error(f\"      \u274c Error exporting to {fmt_key.upper()} ({output_file.name}): {e}\", exc_info=verbose)\n            failure_count += 1\n            # Optionally, clean up partially written file if necessary, though most write ops are atomic or overwrite.\n\n    if failure_count > 0 and success_count > 0:\n        logger.warning(f\"    \u26a0\ufe0f Partially completed exports for {gnn_file_display_name}: {success_count} succeeded, {failure_count} failed.\")\n    elif failure_count > 0 and success_count == 0:\n        logger.error(f\"    \u274c Failed all {len(formats_to_export)} requested export(s) for {gnn_file_display_name}.\")\n    elif success_count == len(formats_to_export) and success_count > 0:\n        logger.info(f\"    \u2705 All {success_count} requested exports for {gnn_file_display_name} completed successfully.\")\n    # If formats_to_export was empty, this point isn't reached for this file due to early return.\n\n    return failure_count == 0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/5_export.py"
      },
      {
        "name": "generate_overall_pipeline_summary_report",
        "type": "function",
        "start_line": 203,
        "end_line": 214,
        "code": "def generate_overall_pipeline_summary_report(target_dir_abs: Path, output_dir_abs: Path, project_root: Path, recursive: bool, verbose: bool):\n    \"\"\"Generates the main gnn_processing_summary.md for the pipeline.\"\"\"\n    logger.info(\"\ud83d\udcc4 Generating Overall GNN Processing Summary Report...\")\n    summary_file = output_dir_abs / \"gnn_processing_summary.md\"\n\n    md_files = list(target_dir_abs.glob(\"**/*.md\" if recursive else \"*.md\"))\n    logger.debug(f\"  \ud83d\udcca Found {len(md_files)} .md files for overall summary in '{target_dir_abs}'.\")\n\n    with open(summary_file, \"w\") as f:\n        f.write(\"# \ud83d\udcca GNN Processing Summary\\n\\n\")\n        f.write(f\"\ud83d\uddd3\ufe0f Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n        f.write(\"## \u2699\ufe0f Processing Configuration\\n\\n\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/5_export.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 216,
        "end_line": 306,
        "code": "def main(parsed_args: argparse.Namespace):\n    \"\"\"Main function for the GNN export step (Step 5).\\n\n    Orchestrates the process of finding GNN files, exporting them to selected formats,\n    and generating summary reports.\n\n    Args:\n        parsed_args (argparse.Namespace): Pre-parsed command-line arguments.\n            Expected attributes: target_dir, output_dir, recursive, formats, verbose.\n    \"\"\"\n    script_file_path = Path(__file__).resolve()\n    project_root = script_file_path.parent.parent # Assuming this script is in src/\n\n    # Configure logger for this script\n    log_level = logging.DEBUG if parsed_args.verbose else logging.INFO\n    logger.setLevel(log_level)\n    logger.debug(f\"Script logger '{logger.name}' level set to {logging.getLevelName(log_level)}.\")\n    \n    logger.info(f\"\u25b6\ufe0f Starting Step 5: Export ({script_file_path.name})\")\n    logger.debug(f\"  Parsed args: {parsed_args}\")\n\n    target_dir_abs = parsed_args.target_dir.resolve()\n    output_dir_abs = parsed_args.output_dir.resolve()\n\n    try:\n        output_dir_abs.mkdir(parents=True, exist_ok=True)\n        (output_dir_abs / \"gnn_exports\").mkdir(parents=True, exist_ok=True)\n        logger.info(f\"  Ensured output directory for exports: {output_dir_abs / 'gnn_exports'}\")\n    except OSError as e:\n        logger.error(f\"  \u274c Failed to create output directories: {e}. Aborting export step.\")\n        return 1\n\n    formats_input_str = parsed_args.formats.lower()\n    if \"all\" in formats_input_str or not formats_input_str.strip():\n        selected_formats = list(AVAILABLE_EXPORT_FUNCTIONS.keys())\n        logger.info(f\"  Exporting to all available formats: {selected_formats}\")\n    else:\n        requested_formats_list = [f.strip() for f in formats_input_str.split(',') if f.strip()]\n        selected_formats = []\n        for req_f in requested_formats_list:\n            if req_f in AVAILABLE_EXPORT_FUNCTIONS:\n                selected_formats.append(req_f)\n            else:\n                logger.warning(f\"  \u26a0\ufe0f Requested export format '{req_f}' is not available/supported. Skipping.\")\n        logger.info(f\"  Selected formats for export: {selected_formats}\")\n\n    if not FORMAT_EXPORTERS_LOADED:\n        logger.critical(\"CRITICAL: Cannot perform GNN exports because 'format_exporters' module failed to load.\")\n        generate_overall_pipeline_summary_report(target_dir_abs, output_dir_abs, project_root, parsed_args.recursive, parsed_args.verbose)\n        return 1\n \n    overall_export_status_code = 0 # Default to success\n    num_files_processed = 0\n    num_successful_file_exports = 0\n    num_files_with_failures = 0\n\n    if not selected_formats:\n        logger.warning(\"No valid/available export formats selected. Skipping GNN model exports.\")\n    else:\n        glob_pattern = \"**/*.md\" if parsed_args.recursive else \"*.md\"\n        gnn_files_to_export = list(target_dir_abs.glob(glob_pattern))\n        num_files_processed = len(gnn_files_to_export)\n\n        if not gnn_files_to_export:\n            logger.info(f\"No GNN files (.md) found in '{target_dir_abs}' (pattern: '{glob_pattern}') to export.\")\n        else:\n            logger.info(f\"Found {len(gnn_files_to_export)} GNN file(s) to process for export from '{target_dir_abs}'.\")\n            for gnn_file in gnn_files_to_export:\n                file_all_formats_succeeded = export_gnn_file_to_selected_formats(\n                    gnn_file,\n                    output_dir_abs, \n                    selected_formats,\n                    project_root, \n                    parsed_args.verbose\n                )\n                if file_all_formats_succeeded:\n                    num_successful_file_exports += 1\n                else:\n                    num_files_with_failures += 1\n            \n            logger.info(f\"Export processing complete. Files with all formats successful: {num_successful_file_exports}, Files with at least one failure: {num_files_with_failures}\")\n            if num_files_with_failures > 0:\n                overall_export_status_code = 1\n    \n    # Generate the export-specific summary report\n    generate_export_summary_report(str(target_dir_abs), str(output_dir_abs), num_files_processed, num_successful_file_exports + num_files_with_failures, num_files_with_failures, parsed_args.recursive, parsed_args.verbose)\n\n    # Generate the main pipeline summary report (gnn_processing_summary.md)\n    generate_overall_pipeline_summary_report(target_dir_abs, output_dir_abs, project_root, parsed_args.recursive, parsed_args.verbose)\n    \n    logger.info(f\"\u2705 Step 5: Export operations finished.\")\n    return overall_export_status_code",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/5_export.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/9_render.py": [
      {
        "name": "main",
        "type": "function",
        "start_line": 50,
        "end_line": 182,
        "code": "def main(args: argparse.Namespace) -> int:\n    \"\"\"\n    Entry point for the GNN rendering pipeline step (Step 9).\n\n    This function imports and calls the main function from the `render.py` module\n    (expected in `src/render/`). It identifies GNN specification files\n    (typically JSON exports from Step 5) in a subdirectory of `args.output_dir`\n    (conventionally `args.output_dir/gnn_exports/`) and attempts to render them\n    into specified simulator formats (e.g., pymdp, rxinfer).\n\n    Args:\n        args (argparse.Namespace):\n            Parsed command-line arguments. Expected attributes include:\n            output_dir (PathLike): Main pipeline output directory.\n            recursive (bool): Whether to search for GNN spec files recursively.\n            verbose (bool): Flag for verbose logging.\n\n    Returns:\n        int: 0 for success, 1 for failure.\n    \"\"\"\n    # Set logging level for noisy libraries\n    logging.getLogger('matplotlib').setLevel(logging.WARNING)\n\n    current_script_path = Path(__file__).resolve()\n    # Add 'src' to sys.path to allow 'from render import render'\n    # This assumes '9_render.py' is in 'src/' and 'render.py' is in 'src/render/'\n    src_dir = current_script_path.parent\n    if str(src_dir) not in sys.path:\n        sys.path.insert(0, str(src_dir))\n\n    try:\n        from render import render as render_module\n        logger.info(\"Successfully imported render module.\")\n    except ImportError as e:\n        logger.error(f\"Failed to import the render module from {src_dir / 'render'}: {e}\")\n        logger.error(\"Please ensure 'render.py' exists in the 'src/render/' directory.\")\n        logger.error(f\"Current sys.path: {sys.path}\")\n        return 1\n\n    logger.info(f\"Executing render step with arguments from main pipeline: {args}\")\n\n    # The render step should process GNN files exported by a previous pipeline step (e.g., 5_export.py).\n    # These exported GNN specifications (expected to be *.json or *.gnn files)\n    # are typically found in a subdirectory of the main pipeline output directory.\n    # We'll use \"gnn_exports\" as the conventional name for this subdirectory.\n    gnn_export_subdir_name = \"gnn_exports\"\n    base_target_dir = Path(args.output_dir).resolve() / gnn_export_subdir_name\n    logger.info(f\"Render step will target GNN specifications from: {base_target_dir}\")\n\n    # Specific output subdirectory for this rendering step\n    step_output_dir_name = \"gnn_rendered_simulators\" # Changed from \"gnn_renders\" for clarity\n    base_output_dir = Path(args.output_dir).resolve() / step_output_dir_name\n    \n    supported_formats = [\"pymdp\", \"rxinfer\"]\n    overall_success = True\n    files_processed_count = 0\n\n    # Determine glob pattern for GNN files\n    # Common patterns could be *.gnn.json or simply *.json if the directory only contains GNN specs.\n    # For now, let's assume *.json as a common case for GNN specs.\n    # Users can place their GNN JSON files directly in gnn/examples or subdirectories.\n    glob_pattern = \"*.json\" \n    \n    if not base_target_dir.is_dir():\n        logger.error(f\"Target directory for GNN specs not found or is not a directory: {base_target_dir}\")\n        return 1\n\n    logger.info(f\"Searching for GNN specification files ({glob_pattern}) in {base_target_dir} (recursive: {args.recursive})\")\n\n    if args.recursive:\n        gnn_files = list(base_target_dir.rglob(glob_pattern))\n    else:\n        gnn_files = list(base_target_dir.glob(glob_pattern))\n\n    if not gnn_files:\n        logger.warning(f\"No GNN specification files ({glob_pattern}) found in {base_target_dir}.\")\n        # Still return 0 as this isn't an error of the script itself, but no work to do.\n        return 0\n\n    logger.info(f\"Found {len(gnn_files)} GNN specification files to process.\")\n\n    for gnn_file_path in gnn_files:\n        files_processed_count +=1\n        logger.info(f\"Processing GNN specification: {gnn_file_path}\")\n        \n        relative_path_from_base_target = gnn_file_path.relative_to(base_target_dir)\n\n        for target_format in supported_formats:\n            logger.info(f\"  Rendering to format: {target_format}\")\n\n            # Construct specific output directory for this file and format\n            # e.g., ../output/gnn_rendered_simulators/pymdp/subdir_if_any/\n            render_output_subdir = base_output_dir / target_format / relative_path_from_base_target.parent\n            render_output_subdir.mkdir(parents=True, exist_ok=True)\n\n            # Determine output filename for the render_module\n            # render_module.main will add _rendered.ext if --output_filename is not given\n            # or use the provided name. We can just pass the stem.\n            output_file_stem = gnn_file_path.stem\n            if output_file_stem.endswith(\".gnn\"): # e.g., my_model.gnn -> my_model\n                output_file_stem = Path(output_file_stem).stem\n\n            render_cli_args = [\n                str(gnn_file_path),\n                str(render_output_subdir),\n                target_format,\n                \"--output_filename\", output_file_stem # Pass the stem, render.py handles adding _rendered.ext\n            ]\n\n            if args.verbose: # Pass verbose flag from main pipeline args\n                render_cli_args.append(\"--verbose\")\n            \n            logger.debug(f\"    Calling render_module.main with args: {render_cli_args}\")\n            \n            try:\n                render_result = render_module.main(cli_args=render_cli_args)\n                if render_result == 0:\n                    logger.info(f\"    Successfully rendered {gnn_file_path.name} to {target_format} in {render_output_subdir}\")\n                else:\n                    logger.error(f\"    Failed to render {gnn_file_path.name} to {target_format}. Exit code: {render_result}\")\n                    overall_success = False\n            except Exception as e:\n                logger.error(f\"    Exception during rendering {gnn_file_path.name} to {target_format}: {e}\", exc_info=True)\n                overall_success = False\n                \n    if files_processed_count > 0 and overall_success:\n        logger.info(f\"Render step completed successfully for {files_processed_count} GNN file(s).\")\n    elif files_processed_count > 0 and not overall_success:\n        logger.error(f\"Render step completed for {files_processed_count} GNN file(s), but some renderings failed.\")\n    elif files_processed_count == 0: # This case is already handled if gnn_files is empty, but for completeness\n        logger.info(\"Render step completed. No GNN files were processed.\")\n        \n    return 0 if overall_success else 1",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/9_render.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/main.py": [
      {
        "name": "parse_arguments",
        "type": "function",
        "start_line": 63,
        "end_line": 146,
        "code": "def parse_arguments():\n    project_root = Path(__file__).resolve().parent.parent\n    \n    default_output_dir = project_root / \"output\"\n    default_target_dir = project_root / \"src\" / \"gnn\" / \"examples\"\n    default_ontology_terms_file = project_root / \"src\" / \"ontology\" / \"act_inf_ontology_terms.json\"\n    default_pipeline_summary_file = default_output_dir / \"pipeline_execution_summary.json\"\n\n    parser = argparse.ArgumentParser(\n        description=\"GNN Processing Pipeline: Orchestrates GNN file processing, analysis, and export.\",\n        formatter_class=argparse.RawTextHelpFormatter\n    )\n    parser.add_argument(\n        \"--target-dir\",\n        type=Path,\n        default=default_target_dir,\n        help=(f\"Target directory for GNN source files (e.g., .md GNN specifications).\\\\n\"\n              f\"Default: {default_target_dir.relative_to(project_root) if default_target_dir.is_relative_to(project_root) else default_target_dir}\")\n    )\n    parser.add_argument(\n        \"--output-dir\",\n        type=Path,\n        default=default_output_dir,\n        help=(f\"Main directory to save all pipeline outputs.\\\\n\"\n              f\"Default: {default_output_dir.relative_to(project_root) if default_output_dir.is_relative_to(project_root) else default_output_dir}\")\n    )\n    parser.add_argument(\n        \"--recursive\", default=True, action=argparse.BooleanOptionalAction,\n        help=\"Recursively process GNN files in the target directory. Enabled by default. Use --no-recursive to disable.\"\n    )\n    parser.add_argument(\n        \"--skip-steps\", default=\"\",\n        help='Comma-separated list of step numbers or names to skip (e.g., \"1,7_mcp\" or \"1_gnn,7\").'\n    )\n    parser.add_argument(\n        \"--only-steps\", default=\"\",\n        help='Comma-separated list of step numbers or names to run exclusively (e.g., \"4,6_visualization\").'\n    )\n    parser.add_argument(\n        \"--verbose\", \n        default=True, \n        action=argparse.BooleanOptionalAction, \n        help=\"Enable verbose output for the pipeline and its steps. On by default (use --no-verbose to disable).\"\n    )\n    parser.add_argument(\n        \"--strict\", action=\"store_true\",\n        help=\"Enable strict type checking mode (passed to 4_gnn_type_checker.py).\"\n    )\n    parser.add_argument(\n        \"--estimate-resources\", default=True, action=argparse.BooleanOptionalAction,\n        help=\"Estimate computational resources (passed to 4_gnn_type_checker.py). Enabled by default.\"\n    )\n    parser.add_argument(\n        \"--ontology-terms-file\",\n        type=Path,\n        default=default_ontology_terms_file,\n        help=(f\"Path to a JSON file defining valid ontological terms (for 8_ontology.py).\\\\n\"\n              f\"Default: {default_ontology_terms_file.relative_to(project_root) if default_ontology_terms_file.is_relative_to(project_root) else default_ontology_terms_file}\")\n    )\n    parser.add_argument(\n        \"--llm-tasks\", default=\"all\", type=str,\n        help='Comma-separated list of LLM tasks for 11_llm.py (e.g., \"overview,purpose,ontology\"). Default: \"all\".'\n    )\n    parser.add_argument(\n        \"--llm-timeout\",\n        type=int,\n        default=360, # Default to 6 minutes for the entire LLM script\n        help=\"Timeout in seconds for the LLM processing step (11_llm.py). Default: 360\"\n    )\n    parser.add_argument(\n        \"--pipeline-summary-file\",\n        type=Path,\n        default=default_pipeline_summary_file,\n        help=(f\"Path to save the final pipeline summary report (JSON format).\\n\"\n              f\"Default: {default_pipeline_summary_file.relative_to(project_root) if default_pipeline_summary_file.is_relative_to(project_root) else default_pipeline_summary_file}\")\n    )\n    parser.add_argument(\n        \"--site-html-filename\",\n        type=str,\n        default=\"gnn_pipeline_summary_site.html\",\n        help=(f\"Filename for the generated HTML summary site (for 12_site.py). It will be saved in the main output directory.\\n\"\n              f\"Default: gnn_pipeline_summary_site.html\")\n    )\n    return parser.parse_args()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/main.py"
      },
      {
        "name": "get_pipeline_scripts",
        "type": "function",
        "start_line": 148,
        "end_line": 170,
        "code": "def get_pipeline_scripts(current_dir: Path) -> list[str]:\n    potential_scripts_pattern = current_dir / \"*_*.py\"\n    logger.debug(f\"\u2139\ufe0f Discovering potential pipeline scripts using pattern: {potential_scripts_pattern}\")\n    all_candidate_files = glob.glob(str(potential_scripts_pattern))\n    \n    pipeline_scripts_info = []\n    script_name_regex = re.compile(r\"^(\\d+)_.*\\.py$\")\n\n    for script_path_str in all_candidate_files:\n        script_basename = os.path.basename(script_path_str)\n        match = script_name_regex.match(script_basename)\n        if match:\n            script_num = int(match.group(1))\n            pipeline_scripts_info.append({'num': script_num, 'basename': script_basename, 'path': Path(script_path_str)})\n            if logger.isEnabledFor(logging.DEBUG):\n                 logger.debug(f\"\u2139\ufe0f Matched script for pipeline: {script_basename} (Number: {script_num})\")\n    \n    pipeline_scripts_info.sort(key=lambda x: (x['num'], x['basename']))\n    sorted_script_basenames = [info['basename'] for info in pipeline_scripts_info]\n\n    if logger.isEnabledFor(logging.DEBUG): \n        logger.debug(f\"\u2139\ufe0f Found and sorted script basenames: {sorted_script_basenames}\")\n    return sorted_script_basenames",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/main.py"
      },
      {
        "name": "get_venv_python",
        "type": "function",
        "start_line": 172,
        "end_line": 203,
        "code": "def get_venv_python(script_dir: Path) -> tuple[Path | None, Path | None]:\n    venv_path = script_dir / \".venv\"\n    venv_python_path = None\n    site_packages_path = None\n\n    if venv_path.is_dir():\n        potential_python_executables = [\n            venv_path / \"bin\" / \"python\",\n            venv_path / \"bin\" / \"python3\",\n            venv_path / \"Scripts\" / \"python.exe\", # Windows\n        ]\n        for py_exec in potential_python_executables:\n            if py_exec.exists() and py_exec.is_file():\n                venv_python_path = py_exec\n                logger.debug(f\"\ud83d\udc0d Found virtual environment Python: {venv_python_path}\")\n                break\n        \n        lib_path = venv_path / \"lib\"\n        if lib_path.is_dir():\n            for python_version_dir in lib_path.iterdir():\n                if python_version_dir.is_dir() and python_version_dir.name.startswith(\"python\"):\n                    current_site_packages = python_version_dir / \"site-packages\"\n                    if current_site_packages.is_dir():\n                        site_packages_path = current_site_packages\n                        logger.debug(f\"Found site-packages at: {site_packages_path}\")\n                        break\n    \n    if not venv_python_path:\n        logger.warning(\"\u26a0\ufe0f Virtual environment Python not found. Using system Python. This may lead to issues if dependencies are not globally available.\")\n        venv_python_path = Path(sys.executable) # Fallback to current interpreter\n    \n    return venv_python_path, site_packages_path",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/main.py"
      },
      {
        "name": "run_pipeline",
        "type": "function",
        "start_line": 205,
        "end_line": 524,
        "code": "def run_pipeline(args: argparse.Namespace):\n    logger.info(\"\"\"\n\n \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557   \u2588\u2588\u2557\u2588\u2588\u2588\u2557   \u2588\u2588\u2557  \n\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2551  \n\u2588\u2588\u2551  \u2588\u2588\u2588\u2557\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\n\u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551    \n\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551    \n                                                                                 \n    Generalized Notation Notation Processing Pipeline \n    \n    Version 0.1.1 ~ Improvements by AI Assistant\n            \n    Initializing GNN Processing Pipeline...\n    \"\"\")\n\n    current_script_dir = Path(__file__).resolve().parent\n    venv_python_path, _venv_site_packages_path_for_subproc = get_venv_python(current_script_dir)\n\n    try:\n        args.output_dir.mkdir(parents=True, exist_ok=True)\n        logger.info(f\"\u2705 Ensured output directory exists: {args.output_dir}\")\n    except OSError as e:\n        logger.error(f\"\u274c Failed to create output directory {args.output_dir}: {e}\")\n        return 1\n\n    all_scripts = get_pipeline_scripts(current_script_dir)\n    if not all_scripts:\n        logger.error(\"\u274c No pipeline scripts found in src/. Cannot proceed.\")\n        return 1\n    \n    logger.info(\"\ud83d\ude80 Starting GNN Processing Pipeline...\")\n    if args.verbose:\n        logger.debug(f\"\u2139\ufe0f All discovered script modules (basenames): {all_scripts}\")\n\n    skip_steps_input = {s.strip() for s in args.skip_steps.split(\",\") if s.strip()}\n    only_steps_input = {s.strip() for s in args.only_steps.split(\",\") if s.strip()}\n    \n    pipeline_run_data = {\n        \"start_time\": datetime.datetime.now().isoformat(),\n        \"arguments\": {k: str(v) if isinstance(v, Path) else v for k, v in vars(args).items()},\n        \"steps\": []\n    }\n    \n    overall_status = \"SUCCESS\" # Will change to FAILED or SUCCESS_WITH_WARNINGS\n\n    for i, script_file_basename in enumerate(all_scripts):\n        script_name_no_ext = Path(script_file_basename).stem\n        step_num_str = script_name_no_ext.split(\"_\")[0]\n        \n        step_log_data = {\n            \"step_number\": i + 1,\n            \"script_name\": script_name_no_ext,\n            \"status\": \"SKIPPED\",\n            \"start_time\": None,\n            \"end_time\": None,\n            \"duration_seconds\": None,\n            \"details\": \"\",\n            \"stdout\": \"\",\n            \"stderr\": \"\"\n        }\n        \n        step_header = f\"Step {i+1}/{len(all_scripts)}: {script_name_no_ext}\"\n        is_critical_step = (script_name_no_ext == \"2_setup\")\n\n        should_skip = False\n        if only_steps_input:\n            if not (script_name_no_ext in only_steps_input or step_num_str in only_steps_input):\n                should_skip = True\n                step_log_data[\"details\"] = \"Skipped due to --only-steps filter.\"\n        elif skip_steps_input:\n            if (script_name_no_ext in skip_steps_input or step_num_str in skip_steps_input):\n                should_skip = True\n                step_log_data[\"details\"] = \"Skipped due to --skip-steps filter.\"\n        \n        if should_skip:\n            logger.info(f\"\u23ed\ufe0f {step_header} - SKIPPED ({step_log_data['details']})\")\n            pipeline_run_data[\"steps\"].append(step_log_data)\n            continue\n        \n        logger.info(\"\") # Add spacing before step start\n        logger.info(f\"\u2699\ufe0f {step_header} (from {script_file_basename}) - STARTING\")\n        step_log_data[\"start_time\"] = datetime.datetime.now().isoformat()\n        \n        script_full_path = current_script_dir / script_file_basename\n        cmd_list = [str(venv_python_path), str(script_full_path)]\n\n        # Common arguments\n        cmd_list.extend([\"--output-dir\", str(args.output_dir)])\n        if args.verbose: \n            cmd_list.append(\"--verbose\")\n        else:\n            cmd_list.append(\"--no-verbose\")\n\n        # Script-specific arguments\n        if script_name_no_ext == \"1_gnn\":\n            cmd_list.extend([\"--target-dir\", str(args.target_dir)])\n            if args.recursive: cmd_list.append(\"--recursive\")\n        elif script_name_no_ext == \"2_setup\":\n            cmd_list.extend([\"--target-dir\", str(args.target_dir)])\n        elif script_name_no_ext == \"3_tests\":\n            pass # Uses venv_python_path internally for pytest\n        elif script_name_no_ext == \"4_gnn_type_checker\":\n            cmd_list.extend([\"--target-dir\", str(args.target_dir)])\n            if args.recursive:\n                cmd_list.append(\"--recursive\")\n            else:\n                cmd_list.append(\"--no-recursive\")\n            if args.strict: cmd_list.append(\"--strict\")\n            cmd_list.append(\"--estimate-resources\" if args.estimate_resources else \"--no-estimate-resources\")\n        elif script_name_no_ext == \"5_export\":\n            cmd_list.extend([\"--target-dir\", str(args.target_dir)])\n            if args.recursive: cmd_list.append(\"--recursive\")\n        elif script_name_no_ext == \"6_visualization\":\n            cmd_list.extend([\"--target-dir\", str(args.target_dir)])\n            if args.recursive: cmd_list.append(\"--recursive\")\n        elif script_name_no_ext == \"7_mcp\":\n            pass # Common args are sufficient\n        elif script_name_no_ext == \"8_ontology\":\n            cmd_list.extend([\"--target-dir\", str(args.target_dir)])\n            if args.recursive: cmd_list.append(\"--recursive\") # Script needs to support this\n            cmd_list.extend([\"--ontology-terms-file\", str(args.ontology_terms_file)])\n        elif script_name_no_ext == \"9_render\":\n            if args.recursive: cmd_list.append(\"--recursive\") # Searches in output_dir/gnn_exports\n        elif script_name_no_ext == \"10_execute\":\n            if args.recursive: cmd_list.append(\"--recursive\") # Searches in output_dir/gnn_rendered_simulators\n        elif script_name_no_ext == \"11_llm\":\n            cmd_list.extend([\"--target-dir\", str(args.target_dir)])\n            if args.recursive: cmd_list.append(\"--recursive\")\n            if args.llm_tasks:\n                tasks = [task.strip() for task in args.llm_tasks.split(',') if task.strip()]\n                if tasks:\n                    cmd_list.append(\"--llm-tasks\")\n                    cmd_list.extend(tasks)\n        elif script_name_no_ext == \"12_site\":\n            # 12_site.py uses --output-dir (where it reads from) \n            # and --site-html-file (the name of the file it creates within output-dir)\n            cmd_list.extend([\"--site-html-file\", str(args.site_html_filename)])\n\n        step_process_env = os.environ.copy()\n        if _venv_site_packages_path_for_subproc:\n            python_path_parts = {str(_venv_site_packages_path_for_subproc)}\n            if \"PYTHONPATH\" in step_process_env:\n                python_path_parts.update(step_process_env[\"PYTHONPATH\"].split(os.pathsep))\n            step_process_env[\"PYTHONPATH\"] = os.pathsep.join(python_path_parts)\n        \n        logger.debug(f\"  Running command: {' '.join(cmd_list)}\")\n        if args.verbose and \"PYTHONPATH\" in step_process_env:\n            logger.debug(f\"    with PYTHONPATH: {step_process_env['PYTHONPATH']}\")\n\n        try:\n            return_code = -1 # Default return code\n\n            if args.verbose:\n                logger.debug(f\"  Streaming output for command: {' '.join(cmd_list)}\")\n                # Use Popen to stream output for verbose mode\n                process = subprocess.Popen(\n                    cmd_list,\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                    text=True,\n                    env=step_process_env,\n                    cwd=current_script_dir,\n                    bufsize=1,  # Line buffered\n                    universal_newlines=True # Ensure text mode for iter\n                )\n                \n                stdout_lines = []\n                stderr_lines = []\n\n                # Log stdout\n                if process.stdout:\n                    for line in iter(process.stdout.readline, ''):\n                        stripped_line = line.strip()\n                        if stripped_line: # Avoid logging empty lines from child process\n                            # Log stdout from subprocess at DEBUG level when main.py is verbose\n                            logger.debug(f\"    [{script_name_no_ext}-STDOUT] {stripped_line}\")\n                        stdout_lines.append(line)\n                    process.stdout.close()\n                \n                # Log stderr\n                if process.stderr:\n                    for line in iter(process.stderr.readline, ''):\n                        stripped_line = line.strip()\n                        if stripped_line: # Avoid logging empty lines\n                            # Log all stderr from subprocess with a clear prefix and as a warning/error\n                            logger.warning(f\"    [{script_name_no_ext}-STDERR] {stripped_line}\")\n                        stderr_lines.append(line)\n                    process.stderr.close()\n                    \n                # Determine timeout for wait() based on the script\n                current_step_timeout = None\n                if script_name_no_ext == \"11_llm\":\n                    current_step_timeout = args.llm_timeout\n                    logger.debug(f\"  Applying LLM step-specific timeout of {current_step_timeout}s for wait().\")\n\n                return_code = process.wait(timeout=current_step_timeout)\n                step_log_data[\"stdout\"] = \"\".join(stdout_lines)\n                step_log_data[\"stderr\"] = \"\".join(stderr_lines)\n            else:\n                # Original behavior for non-verbose mode\n                # Determine timeout for run() based on the script\n                current_step_timeout_run = None\n                if script_name_no_ext == \"11_llm\":\n                    current_step_timeout_run = args.llm_timeout\n                    logger.debug(f\"  Applying LLM step-specific timeout of {current_step_timeout_run}s for run().\")\n\n                step_process_result = subprocess.run(\n                    cmd_list, \n                    capture_output=True, \n                    text=True, \n                    check=False, \n                    env=step_process_env, \n                    cwd=current_script_dir,\n                    timeout=current_step_timeout_run\n                )\n                step_log_data[\"stdout\"] = step_process_result.stdout\n                step_log_data[\"stderr\"] = step_process_result.stderr\n                return_code = step_process_result.returncode\n\n            if return_code == 0:\n                step_log_data[\"status\"] = \"SUCCESS\"\n                logger.info(f\"\u2705 {step_header} - COMPLETED successfully.\")\n                logger.info(\"\") # Add spacing after step completion\n                # For non-verbose successful runs, if there's any output, log it at DEBUG level.\n                # For verbose runs, it's already streamed.\n                if not args.verbose and step_log_data[\"stdout\"] and step_log_data[\"stdout\"].strip():\n                    logger.debug(f\"   Output from {script_name_no_ext}:\\n{step_log_data['stdout'].strip()}\")\n                if not args.verbose and step_log_data[\"stderr\"] and step_log_data[\"stderr\"].strip(): # Also log stderr if any for non-verbose success\n                    # If main is not verbose, but a script wrote to stderr and succeeded,\n                    # it's good to see this at least at DEBUG level in main log.\n                    logger.debug(f\"   Stderr from {script_name_no_ext} (non-verbose main, step success):\\n{step_log_data['stderr'].strip()}\")\n\n            elif return_code == 2: # Special code for success with warnings\n                step_log_data[\"status\"] = \"SUCCESS_WITH_WARNINGS\"\n                logger.warning(f\"\u26a0\ufe0f {step_header} - COMPLETED with warnings (Code 2). Check script output.\")\n                logger.info(\"\") # Add spacing after step completion\n                if overall_status == \"SUCCESS\": overall_status = \"SUCCESS_WITH_WARNINGS\"\n                # Log stdout/stderr for warnings as well (if not already streamed in verbose)\n                if not args.verbose:\n                    if step_log_data[\"stdout\"] and step_log_data[\"stdout\"].strip(): \n                        logger.warning(f\"   Stdout for warnings from {script_name_no_ext}:\\n{step_log_data['stdout'].strip()}\")\n                    if step_log_data[\"stderr\"] and step_log_data[\"stderr\"].strip(): \n                        logger.warning(f\"   Stderr for warnings from {script_name_no_ext}:\\n{step_log_data['stderr'].strip()}\")\n            else:\n                step_log_data[\"status\"] = \"FAILED\"\n                step_log_data[\"details\"] = f\"Exited with code {return_code}.\"\n                logger.error(f\"\u274c {step_header} - FAILED (Code: {return_code}).\")\n                logger.info(\"\") # Add spacing after step completion\n                overall_status = \"FAILED\"\n                # Log stdout/stderr for failures (if not already streamed in verbose)\n                if not args.verbose:\n                    if step_log_data[\"stdout\"] and step_log_data[\"stdout\"].strip(): \n                        logger.error(f\"   Stdout from {script_name_no_ext}:\\n{step_log_data['stdout'].strip()}\")\n                    if step_log_data[\"stderr\"] and step_log_data[\"stderr\"].strip(): \n                        logger.error(f\"   Stderr from {script_name_no_ext}:\\n{step_log_data['stderr'].strip()}\")\n                if is_critical_step:\n                    logger.critical(f\"\ud83d\udd25 Critical step {script_name_no_ext} failed. Halting pipeline.\")\n                    step_log_data[\"details\"] += \" Critical step failure, pipeline halted.\"\n                    pipeline_run_data[\"steps\"].append(step_log_data)\n                    break \n        \n        except subprocess.TimeoutExpired:\n            step_log_data[\"status\"] = \"FAILED_TIMEOUT\"\n            timeout_duration = current_step_timeout if args.verbose else current_step_timeout_run\n            step_log_data[\"details\"] = f\"Step timed out after {timeout_duration} seconds.\"\n            logger.error(f\"\u274c {step_header} - FAILED due to TIMEOUT after {timeout_duration}s.\")\n            logger.info(\"\") # Add spacing after step completion\n            overall_status = \"FAILED\"\n            # Ensure process is killed if it timed out during wait()\n            if args.verbose and process:\n                try:\n                    logger.warning(f\"  Attempting to terminate timed-out process for {script_name_no_ext} (PID: {process.pid})\")\n                    process.kill() # or process.terminate()\n                    #oudates to captured stdout/stderr might be lost or partial\n                    process.wait() # wait for termination to complete\n                    logger.info(f\"  Process {script_name_no_ext} terminated.\")\n                except Exception as e_kill:\n                    logger.error(f\"  Error trying to terminate process {script_name_no_ext}: {e_kill}\")\n            \n            # For non-verbose, subprocess.run() handles termination on timeout.\n            # Capture any output that might have occurred before timeout\n            if args.verbose and process.stdout:\n                 step_log_data[\"stdout\"] = \"\".join(stdout_lines) + \"\\n[TIMEOUT OCCURRED - STDOUT MAY BE INCOMPLETE]\"\n            if args.verbose and process.stderr:\n                step_log_data[\"stderr\"] = \"\".join(stderr_lines) + \"\\n[TIMEOUT OCCURRED - STDERR MAY BE INCOMPLETE]\"\n            # For non-verbose, this is already handled by subprocess.run returning the captured output up to timeout.\n            \n            if is_critical_step:\n                logger.critical(f\"\ud83d\udd25 Critical step {script_name_no_ext} timed out. Halting pipeline.\")\n                step_log_data[\"details\"] += \" Critical step timeout, pipeline halted.\"\n                pipeline_run_data[\"steps\"].append(step_log_data)\n                break\n\n        except Exception as e:\n            step_log_data[\"status\"] = \"ERROR_UNHANDLED_EXCEPTION\"\n            step_log_data[\"details\"] = f\"Unhandled exception: {str(e)}\"\n            logger.error(f\"\u274c Unhandled exception in {step_header}: {e}\")\n            logger.info(\"\") # Add spacing after step completion\n            logger.debug(traceback.format_exc())\n            overall_status = \"FAILED\"\n            if is_critical_step:\n                logger.critical(f\"\ud83d\udd25 Critical step {script_name_no_ext} failed due to unhandled exception. Halting pipeline.\")\n                step_log_data[\"details\"] += \" Critical step failure, pipeline halted.\"\n                pipeline_run_data[\"steps\"].append(step_log_data)\n                break\n        \n        finally:\n            step_log_data[\"end_time\"] = datetime.datetime.now().isoformat()\n            if step_log_data[\"start_time\"]:\n                duration = datetime.datetime.fromisoformat(step_log_data[\"end_time\"]) - datetime.datetime.fromisoformat(step_log_data[\"start_time\"])\n                step_log_data[\"duration_seconds\"] = duration.total_seconds()\n            pipeline_run_data[\"steps\"].append(step_log_data)\n\n    pipeline_run_data[\"end_time\"] = datetime.datetime.now().isoformat()\n    pipeline_run_data[\"overall_status\"] = overall_status\n    # Log a brief summary before returning from run_pipeline\n    logger.info(f\"\ud83c\udfc1 Pipeline processing completed. Overall Status: {overall_status}\")\n\n    return 0 if overall_status in [\"SUCCESS\", \"SUCCESS_WITH_WARNINGS\"] else 1, pipeline_run_data, all_scripts, overall_status",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/main.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 526,
        "end_line": 686,
        "code": "def main():\n    # Configure logging early. If GNN_Pipeline or root logger has no handlers,\n    # set up a basic one. The user's traceback suggests handlers are present,\n    # so this configuration is for robustness, especially if run in different contexts.\n    pipeline_logger = logging.getLogger(\"GNN_Pipeline\") # Use the specific logger\n\n    if not pipeline_logger.hasHandlers() and not logging.getLogger().hasHandlers():\n        logging.basicConfig(\n            level=logging.INFO, # Default level\n            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n            datefmt=None, # Explicitly use default to get milliseconds\n            stream=sys.stdout\n        )\n        pipeline_logger.info(\"Initialized basic logging config as no handlers were found for GNN_Pipeline or root.\")\n\n    args = parse_arguments()\n\n    # Quieten noisy dependency loggers (PIL, Matplotlib) unconditionally\n    logging.getLogger('PIL').setLevel(logging.WARNING)\n    logging.getLogger('matplotlib').setLevel(logging.WARNING)\n    # Add other noisy libraries here if needed, e.g.:\n    # logging.getLogger('some_other_library').setLevel(logging.WARNING)\n\n    logger.info(\"Starting GNN Processing Pipeline...\")\n\n    # --- File Handler Setup (after args are parsed) ---\n    # Ensure logs directory exists\n    log_dir = args.output_dir / \"logs\"\n    try:\n        log_dir.mkdir(parents=True, exist_ok=True)\n        # Add a file handler to the GNN_Pipeline logger\n        log_file_path = log_dir / \"pipeline.log\"\n        file_handler = logging.FileHandler(log_file_path, mode='w') # 'w' to overwrite each run\n        # Use the same format as basicConfig, explicitly ensure milliseconds\n        file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt=None)\n        file_handler.setFormatter(file_formatter)\n        # The level of the file_handler will be determined by the pipeline_logger's effective level,\n        # which is set below based on args.verbose.\n        pipeline_logger.addHandler(file_handler)\n        # Log this message *after* the handler is added so it goes to the file too.\n        pipeline_logger.info(f\"File logging configured to: {log_file_path}\") \n    except Exception as e:\n        # Log this error to console, as file handler might have failed.\n        temp_error_logger = logging.getLogger(\"GNN_Pipeline.FileHandlerSetup\")\n        # Ensure this specific error message can make it to console/stderr if main logger isn't fully working\n        if not temp_error_logger.handlers:\n            err_handler = logging.StreamHandler(sys.stderr)\n            # Use a more specific format for this temp logger to distinguish its origin\n            err_formatter = logging.Formatter('%(asctime)s - %(name)s - [TEMP_SETUP_ERROR] - %(levelname)s - %(message)s')\n            err_handler.setFormatter(err_formatter)\n            temp_error_logger.addHandler(err_handler)\n            temp_error_logger.propagate = False # Don't double log this specific error message\n        temp_error_logger.error(f\"Failed to configure file logging to {log_dir / 'pipeline.log'}: {e}. Continuing with console logging only.\")\n    # --- End File Handler Setup ---\n\n    # Configure logger level based on verbose flag AFTER parsing args\n    if args.verbose:\n        pipeline_logger.setLevel(logging.DEBUG)\n        # Propagate level to handlers if they exist and basicConfig wasn't just called\n        for handler in pipeline_logger.handlers + logging.getLogger().handlers: # Ensure root handlers also set\n            # Only set level if handler's current level is not effectively DEBUG or lower\n            if handler.level == 0 or handler.level > logging.DEBUG: # 0 means NOTSET, effectively inherits.\n                current_level_name = logging.getLevelName(handler.level)\n                logger.debug(f\"Updating handler {type(handler).__name__} level from {current_level_name} to DEBUG\")\n                handler.setLevel(logging.DEBUG)\n        # For Popen streaming, we use GNN_Pipeline's INFO and ERROR, so DEBUG on GNN_Pipeline is fine.\n    else:\n        pipeline_logger.setLevel(logging.INFO)\n        # Propagate level to handlers\n        for handler in pipeline_logger.handlers + logging.getLogger().handlers: # Ensure root handlers also set\n            if handler.level == 0 or handler.level > logging.INFO:\n                current_level_name = logging.getLevelName(handler.level)\n                logger.debug(f\"Updating handler {type(handler).__name__} level from {current_level_name} to INFO\")\n                handler.setLevel(logging.INFO)\n\n    pipeline_logger.debug(\"Logger level configured based on verbosity.\")\n\n    # --- Defensive Path Conversion ---\n    # Ensure critical path arguments are pathlib.Path objects.\n    # argparse with type=Path should handle this, but this adds robustness.\n    path_args_to_check = [\n        'output_dir', 'target_dir', 'ontology_terms_file', 'pipeline_summary_file'\n    ]\n\n    for arg_name in path_args_to_check:\n        if not hasattr(args, arg_name):\n            pipeline_logger.debug(f\"Argument --{arg_name.replace('_', '-')} not present in args namespace.\")\n            continue\n\n        arg_value = getattr(args, arg_name)\n        \n        # Only proceed if arg_value is not None. If it's None, it might be an optional Path not provided.\n        if arg_value is not None and not isinstance(arg_value, Path):\n            pipeline_logger.warning(\n                f\"Argument --{arg_name.replace('_', '-')} was unexpectedly a {type(arg_value).__name__} \"\n                f\"(value: '{arg_value}') instead of pathlib.Path. Converting explicitly. \"\n                \"This might indicate an issue with argument parsing configuration or an external override.\"\n            )\n            try:\n                setattr(args, arg_name, Path(arg_value))\n            except TypeError as e:\n                pipeline_logger.error(\n                    f\"Failed to convert argument --{arg_name.replace('_', '-')} (value: '{arg_value}') to Path: {e}. \"\n                    \"This could be due to an unsuitable value for a path.\"\n                )\n                # If a critical path like output_dir fails conversion, it's a fatal error for the script's purpose.\n                if arg_name in ['output_dir', 'target_dir']:\n                    pipeline_logger.critical(f\"Critical path argument --{arg_name.replace('_', '-')} could not be converted to Path. Exiting.\")\n                    sys.exit(1)\n        elif arg_value is None and arg_name in ['output_dir', 'target_dir']: # These should always have a default Path value.\n             pipeline_logger.critical(\n                f\"Critical path argument --{arg_name.replace('_', '-')} is None after parsing. \"\n                \"This indicates a problem with default value setup in argparse. Exiting.\"\n             )\n             sys.exit(1)\n    # --- End Defensive Path Conversion ---\n\n    pipeline_logger.info(f\"\ud83d\ude80 Initializing GNN Pipeline with Target: '{args.target_dir}', Output: '{args.output_dir}'\")\n    \n    # Log the arguments being used, showing their types after potential conversion\n    if pipeline_logger.isEnabledFor(logging.DEBUG): # Check level before formatting potentially many lines\n        log_msgs = [\"\ud83d\udee0\ufe0f Effective Arguments (after potential defensive conversion):\"]\n        for arg, value in sorted(vars(args).items()):\n            log_msgs.append(f\"  --{arg.replace('_', '-')}: {value} (Type: {type(value).__name__})\")\n        pipeline_logger.debug('\\n'.join(log_msgs))\n\n\n    # Call the main pipeline execution function\n    exit_code, pipeline_run_data, all_scripts, overall_status = run_pipeline(args)\n\n    # --- Pipeline Summary Report ---\n    logger.info(\"\\n--- Pipeline Execution Summary ---\")\n    num_total = len(pipeline_run_data[\"steps\"])\n    num_success = len([s for s in pipeline_run_data[\"steps\"] if s[\"status\"] == \"SUCCESS\"])\n    num_warn = len([s for s in pipeline_run_data[\"steps\"] if s[\"status\"] == \"SUCCESS_WITH_WARNINGS\"])\n    num_failed = len([s for s in pipeline_run_data[\"steps\"] if \"FAILED\" in s[\"status\"] or \"ERROR\" in s[\"status\"]])\n    num_skipped = len([s for s in pipeline_run_data[\"steps\"] if s[\"status\"] == \"SKIPPED\"])\n\n    logger.info(f\"\ud83d\udcca Total Steps Attempted/Processed: {num_total - num_skipped} / {len(all_scripts)}\")\n    logger.info(f\"  \u2705 Successful: {num_success}\")\n    logger.info(f\"  \u26a0\ufe0f Success with Warnings: {num_warn}\")\n    logger.info(f\"  \u274c Failed/Error: {num_failed}\")\n    logger.info(f\"  \u23ed\ufe0f Skipped: {num_skipped}\")\n\n    if overall_status == \"SUCCESS\":\n        logger.info(\"\ud83c\udf89 PIPELINE FINISHED SUCCESSFULLY.\")\n    elif overall_status == \"SUCCESS_WITH_WARNINGS\":\n        logger.warning(\"\ud83c\udf89 PIPELINE FINISHED, but with warnings from some steps.\")\n    else: # FAILED\n        logger.error(\"\ud83d\uded1 PIPELINE FINISHED WITH ERRORS.\")\n\n    # Save detailed summary report\n    try:\n        args.pipeline_summary_file.parent.mkdir(parents=True, exist_ok=True)\n        with open(args.pipeline_summary_file, 'w') as f_summary:\n            json.dump(pipeline_run_data, f_summary, indent=4)\n        logger.info(f\"\ud83d\udcbe Detailed pipeline execution summary (JSON) saved to: {args.pipeline_summary_file}\")\n    except Exception as e:\n        logger.error(f\"\u274c Error saving pipeline summary report: {e}\")\n\n    sys.exit(exit_code)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/main.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/6_visualization.py": [
      {
        "name": "run_visualization",
        "type": "function",
        "start_line": 59,
        "end_line": 132,
        "code": "def run_visualization(target_dir: str, \n                        pipeline_output_dir: str, # Main output dir for the whole pipeline \n                        recursive: bool = False, \n                        verbose: bool = False):\n    \"\"\"Generate visualizations for GNN files using the visualization module.\"\"\"\n    # Set logging level for this script's logger\n    if verbose:\n        logger.setLevel(logging.DEBUG)\n    else:\n        logger.setLevel(logging.INFO)\n\n    # Set logging level for noisy libraries\n    logging.getLogger('PIL').setLevel(logging.WARNING)\n    logging.getLogger('matplotlib').setLevel(logging.WARNING)\n\n    # Configure logging level for the visualization module based on pipeline verbosity\n    viz_module_logger = logging.getLogger(\"visualization\") # Get the parent logger for the module\n    if verbose:\n        viz_module_logger.setLevel(logging.INFO) # Allow its INFO messages if pipeline is verbose\n    else:\n        viz_module_logger.setLevel(logging.WARNING) # Silence its INFO messages by default\n\n    if not visualization_cli:\n        logger.error(\"\u274c\ud83c\udfa8 Visualization CLI module not loaded. Cannot proceed.\") # Changed from print\n        return False # Indicate failure\n\n    viz_step_output_dir = Path(pipeline_output_dir) / \"gnn_examples_visualization\"\n    \n    logger.info(\"\ud83d\uddbc\ufe0f Preparing to generate GNN visualizations...\") # Was print if verbose\n    logger.debug(f\"  \ud83c\udfaf Target GNN files in: {Path(target_dir).resolve()}\") # Was print if verbose\n    logger.debug(f\"  \u0565\u056c Output visualizations will be in: {viz_step_output_dir.resolve()}\") # Was print if verbose\n    if recursive:\n        logger.debug(\"  \ud83d\udd04 Recursive mode: Enabled\") # Was print if verbose\n    else:\n        logger.debug(\"  \u27a1\ufe0f Recursive mode: Disabled\") # Was print if verbose\n\n    # Determine project root for relative paths in sub-module reports\n    project_root = Path(__file__).resolve().parent.parent\n\n    cli_args = [\n        target_dir, \n        \"--output-dir\", str(viz_step_output_dir),\n        \"--project-root\", str(project_root) # Pass project root to the CLI\n    ]\n    \n    if recursive:\n        cli_args.append(\"--recursive\")\n        \n    logger.debug(f\"  \ud83d\udc0d Invoking GNN Visualization module (visualization.cli.main)\") # Was print if verbose\n    logger.debug(f\"     Arguments: {' '.join(cli_args)}\") # Was print if verbose\n    \n    try:\n        exit_code = visualization_cli.main(cli_args)\n        \n        if exit_code == 0:\n            logger.info(\"\u2705 GNN Visualization module completed successfully.\") # Was print if verbose\n            logger.debug(f\"  \ud83d\uddbc\ufe0f Visualizations should be available in: {viz_step_output_dir.resolve()}\") # Was print if verbose\n            # Check if the directory was created and if it has content\n            if viz_step_output_dir.exists() and any(viz_step_output_dir.iterdir()):\n                num_items = len(list(viz_step_output_dir.glob('**/*'))) # Counts files and dirs\n                logger.debug(f\"  \ud83d\udcca Found {num_items} items (files/directories) in the output directory.\") # Was print if verbose\n            else: # This case was only logged if verbose before, now always if dir is empty\n                logger.warning(f\"\u26a0\ufe0f Output directory {viz_step_output_dir.resolve()} is empty or was not created as expected by the visualization module.\") # Was print if verbose\n            return True\n        else:\n            logger.error(f\"\u274c\ud83c\udfa8 GNN Visualization module (visualization.cli.main) reported errors (exit code: {exit_code}).\") # Changed from print\n            return False\n            \n    except Exception as e:\n        logger.error(f\"\u274c\ud83c\udfa8 An unexpected error occurred while running the GNN Visualization module: {e}\", exc_info=verbose) # Changed from print, added exc_info=verbose\n        # if verbose: # Handled by exc_info=verbose\n        #     import traceback\n        #     traceback.print_exc()\n        return False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/6_visualization.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 134,
        "end_line": 168,
        "code": "def main(args):\n    \"\"\"Main function for the visualization step (Step 6).\n\n    This function serves as the entry point when 6_visualization.py is called.\n    It logs the start of the step and invokes the `run_visualization` function\n    with the parsed arguments.\n\n    Args:\n        args (argparse.Namespace): \n            Parsed command-line arguments from `main.py` or standalone execution.\n            Expected attributes include: target_dir, output_dir, recursive, verbose.\n    \"\"\"\n    # Set this script's logger level based on pipeline's args.verbose\n    # This is typically handled by main.py for child modules, and run_visualization also sets levels.\n    # if args.verbose:\n    #     logger.setLevel(logging.DEBUG)\n    # else:\n    #     logger.setLevel(logging.INFO)\n\n    logger.info(f\"\u25b6\ufe0f Starting Step 6: Visualization ({Path(__file__).name})\") \n    logger.debug(f\"  Parsing options:\") # Was print if verbose\n    logger.debug(f\"    Target directory/file: {args.target_dir}\") # Was print if verbose\n    logger.debug(f\"    Pipeline output directory: {args.output_dir}\") # Was print if verbose\n    logger.debug(f\"    Recursive: {args.recursive}\") # Was print if verbose\n    logger.debug(f\"    Verbose: {args.verbose}\") # Was print if verbose\n\n    if not run_visualization(args.target_dir, \n                             args.output_dir, \n                             args.recursive if hasattr(args, 'recursive') else False, \n                             args.verbose):\n        logger.error(f\"\u274c Step 6: Visualization ({Path(__file__).name}) FAILED.\") # Changed from print\n        return 1\n    \n    logger.info(f\"\u2705 Step 6: Visualization ({Path(__file__).name}) - COMPLETED\") # Was print if verbose\n    return 0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/6_visualization.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/12_site.py": [
      {
        "name": "parse_arguments",
        "type": "function",
        "start_line": 27,
        "end_line": 48,
        "code": "def parse_arguments() -> argparse.Namespace:\n    \"\"\"Parses command-line arguments for the site generation script.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Generates an HTML summary site for GNN pipeline outputs.\")\n    \n    parser.add_argument(\n        \"--output-dir\",\n        type=Path,\n        required=True,\n        help=\"The main output directory of the GNN pipeline (e.g., ../output or output/). This script reads from this directory.\"\n    )\n    parser.add_argument(\n        \"--site-html-file\",\n        type=str,\n        default=\"gnn_pipeline_summary_site.html\",\n        help=\"Filename for the generated HTML site. This file will be saved inside the --output-dir. Default: gnn_pipeline_summary_site.html\"\n    )\n    parser.add_argument(\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Enable verbose logging for this script and the site generator.\"\n    )\n    return parser.parse_args()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/12_site.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 50,
        "end_line": 109,
        "code": "def main():\n    \"\"\"Main execution function for the 12_site.py pipeline step.\"\"\"\n    args = parse_arguments()\n\n    # Configure logging for this script\n    if args.verbose:\n        logger.setLevel(logging.DEBUG)\n        generator_logger.setLevel(logging.DEBUG)\n    else:\n        logger.setLevel(logging.INFO)\n        generator_logger.setLevel(logging.INFO)\n\n    # If running standalone and no handlers are configured for this logger or the root logger,\n    # add a default console handler to make logs visible.\n    # This helps in direct testing of the script.\n    if __name__ == \"__main__\" and not logger.hasHandlers() and not logging.getLogger().hasHandlers():\n        ch_script = logging.StreamHandler(sys.stdout)\n        formatter_script = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        ch_script.setFormatter(formatter_script)\n        logger.addHandler(ch_script)\n        # Also ensure generator_logger gets a handler if it doesn't have one in this standalone context\n        if not generator_logger.hasHandlers():\n             ch_gen = logging.StreamHandler(sys.stdout)\n             formatter_gen = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n             ch_gen.setFormatter(formatter_gen)\n             generator_logger.addHandler(ch_gen)\n             generator_logger.propagate = False # Avoid double log if root gets handler from basicConfig\n\n    logger.info(f\"Starting pipeline step: 12_site.py - Generate HTML Summary Site\")\n    logger.info(f\"Reading from pipeline output directory: {args.output_dir}\")\n    logger.info(f\"Generated site will be saved as: {args.output_dir / args.site_html_file}\")\n\n    # Construct the full path for the site output file\n    site_output_file_path = args.output_dir.resolve() / args.site_html_file\n\n    try:\n        # Ensure the main output directory (which is input for this script) exists\n        if not args.output_dir.is_dir():\n            logger.error(f\"Specified output directory does not exist: {args.output_dir}\")\n            sys.exit(1)\n            \n        # Ensure the parent directory for the HTML site file exists (it should be output_dir)\n        site_output_file_path.parent.mkdir(parents=True, exist_ok=True)\n\n        logger.debug(f\"Calling generate_html_report with output_dir='{args.output_dir.resolve()}' and site_output_file='{site_output_file_path}'\")\n        generate_html_report(args.output_dir.resolve(), site_output_file_path)\n        \n        logger.info(f\"HTML summary site generated successfully: {site_output_file_path}\")\n        sys.exit(0) # Success\n    except FileNotFoundError as fnf_error:\n        logger.error(f\"File not found during site generation: {fnf_error}\")\n        sys.exit(1)\n    except PermissionError as perm_error:\n        logger.error(f\"Permission error during site generation: {perm_error}\")\n        sys.exit(1)\n    except Exception as e:\n        logger.error(f\"An unexpected error occurred during site generation: {e}\", exc_info=args.verbose)\n        if args.verbose:\n            logger.debug(e, exc_info=True) # Log full traceback if verbose\n        sys.exit(1)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/12_site.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/3_tests.py": [
      {
        "name": "run_tests",
        "type": "function",
        "start_line": 52,
        "end_line": 140,
        "code": "def run_tests(tests_dir: Path, output_dir: Path, verbose: bool = False) -> int:\n    \"\"\"Run tests using pytest and generate a JUnit XML report.\n    Returns:\n        0 if tests pass or no tests found (or tests_dir missing - considered warning).\n        1 if tests fail or pytest cannot be run.\n        2 if tests_dir is missing (treated as a warning, not a failure of the test runner itself)\n    \"\"\"\n    logger.info(f\"\u2139\ufe0f Running tests from directory: {tests_dir}\")\n        \n    if not tests_dir.is_dir():\n        logger.warning(f\"\u26a0\ufe0f Tests directory '{tests_dir}' not found or not a directory. Skipping tests.\")\n        return 2 # Non-fatal issue, treat as warning for the step\n\n    # Ensure test reports directory exists\n    test_reports_dir = output_dir / \"test_reports\"\n    try:\n        test_reports_dir.mkdir(parents=True, exist_ok=True)\n        logger.debug(f\"Ensured test reports directory exists: {test_reports_dir}\")\n    except OSError as e:\n        logger.error(f\"\u274c Failed to create test reports directory {test_reports_dir}: {e}\")\n        return 1 # Cannot save reports, treat as failure\n    \n    report_xml_path = test_reports_dir / \"pytest_report.xml\"\n\n    # sys.executable should be the python from the .venv when run via main.py\n    pytest_command = [sys.executable, \"-m\", \"pytest\", str(tests_dir), f\"--junitxml={str(report_xml_path)}\"]\n    \n    if verbose:\n        pytest_command.append(\"-v\") # Add pytest verbose flag\n        pytest_command.append(\"-rA\") # Show summary of all tests (passed, failed, skipped etc.)\n    \n    logger.debug(f\"  \ud83d\udc0d Executing test command: {' '.join(pytest_command)}\")\n\n    try:\n        # Run tests from the project's src/ directory (parent of this script's location)\n        # This is typically where pytest is configured to run from to correctly discover modules.\n        run_cwd = Path(__file__).resolve().parent.parent # Should be project_root / src\n        logger.debug(f\"  \ud83d\udcc2 Running tests with CWD: {run_cwd}\")\n\n        # PYTHONPATH should be set by main.py for this script's environment.\n        # sys.executable -m pytest will run within that environment.\n        env = os.environ.copy() # Inherit environment from main.py\n\n        result = subprocess.run(pytest_command, capture_output=True, text=True, check=False, cwd=run_cwd, env=env, errors='replace')\n        \n        # Always log where the report is, even if tests fail, as it might contain info\n        logger.info(f\"\u2139\ufe0f JUnit XML test report will be at: {report_xml_path}\")\n\n        if result.returncode != 0:\n            logger.error(\"--- Test Output (stdout) ---\")\n            logger.error(result.stdout.strip() if result.stdout else \"<No stdout>\")\n            logger.error(\"--- Test Errors (stderr) ---\")\n            logger.error(result.stderr.strip() if result.stderr else \"<No stderr>\")\n            logger.error(\"-------------------------\")\n        elif verbose:\n            logger.debug(\"--- Test Output (stdout) ---\")\n            logger.debug(result.stdout.strip() if result.stdout else \"<No stdout>\")\n            if result.stderr.strip(): # Only log stderr if it has content\n                logger.debug(\"--- Test Errors (stderr) ---\")\n                logger.debug(result.stderr.strip())\n            logger.debug(\"-------------------------\")\n\n        # Pytest exit codes:\n        # 0: all tests passed\n        # 1: tests were collected and run but some failed\n        # 2: test execution was interrupted by the user\n        # 3: internal error encountered while running tests\n        # 4: pytest command line usage error\n        # 5: no tests were collected\n\n        if result.returncode == 0:\n            logger.info(\"\u2705 All tests passed.\")\n            return 0\n        elif result.returncode == 5:\n            logger.warning(\"\u26a0\ufe0f No tests were collected by pytest. Ensure tests exist and are discoverable.\")\n            return 2 # Treat as warning, not a hard failure of the test runner\n        else:\n            logger.error(f\"\u274c Some tests failed or pytest reported an error. Pytest exit code: {result.returncode}\")\n            return 1 # Test failures or pytest error\n            \n    except FileNotFoundError:\n        # This means \"python -m pytest\" could not be started. Highly problematic.\n        logger.error(f\"\u274c Error: Failed to execute '{sys.executable} -m pytest'.\")\n        logger.error(\"   Please ensure pytest is installed in the correct Python environment ('{sys.executable}').\")\n        logger.error(\"   This step (3_tests.py) cannot proceed without pytest.\")\n        return 1 # Critical failure for this step\n    except Exception as e:\n        logger.error(f\"\u274c An unexpected error occurred while trying to run tests: {e}\", exc_info=verbose)\n        return 1 # Critical failure for this step",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/3_tests.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 142,
        "end_line": 173,
        "code": "def main(parsed_args: argparse.Namespace): # Renamed 'cmd_args' and type hinted\n    \"\"\"Main function for the testing step (Step 3).\\n\n    Invokes the test runner.\n\n    Args:\n        parsed_args (argparse.Namespace): Pre-parsed command-line arguments.\n            Expected attributes include: output_dir, verbose.\n    \"\"\"\n    log_level = logging.DEBUG if parsed_args.verbose else logging.INFO\n    logger.setLevel(log_level)\n    logger.debug(f\"Script logger '{logger.name}' level set to {logging.getLevelName(log_level)}.\")\n\n    logger.info(\"\u25b6\ufe0f Starting Step 3: Tests\")\n    logger.debug(f\"  Parsed arguments for tests: {parsed_args}\")\n\n    script_dir = Path(__file__).parent\n    # Tests are expected to be in src/tests/\n    tests_dir_to_run = script_dir / \"tests\" \n\n    # output_dir is the main pipeline output dir. Test reports go into a subdir.\n    output_dir_path = Path(parsed_args.output_dir).resolve()\n\n    result_code = run_tests(tests_dir_to_run, output_dir_path, parsed_args.verbose)\n    \n    if result_code == 0:\n        logger.info(\"\u2705 Step 3: Tests completed successfully.\")\n    elif result_code == 2:\n        logger.warning(\"\u26a0\ufe0f Step 3: Tests completed with warnings (e.g., no tests found or tests_dir missing).\")\n    else: # result_code == 1\n        logger.error(\"\u274c Step 3: Tests failed or encountered a critical error.\")\n        \n    sys.exit(result_code)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/3_tests.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/10_execute.py": [
      {
        "name": "main",
        "type": "function",
        "start_line": 67,
        "end_line": 121,
        "code": "def main(args: argparse.Namespace) -> int:\n    \"\"\"Main function for the GNN model execution step (Step 10).\n\n    This function serves as the entry point for executing rendered GNN simulators.\n    It primarily focuses on orchestrating the execution of PyMDP scripts generated\n    by Step 9, using the `pymdp_runner` module.\n\n    Args:\n        args (argparse.Namespace):\n            Parsed command-line arguments from `main.py` or standalone execution.\n            Expected attributes include: output_dir (PathLike), recursive (bool),\n            and verbose (bool).\n\n    Returns:\n        int: 0 for success, 1 for failure.\n    \"\"\"\n    # Logger level for this script's logger (__name__) should be set by main.py\n    # based on args.verbose, or by standalone __main__ block.\n\n    logger.info(f\"\u25b6\ufe0f Starting Step 10: Execute Rendered Simulators ({Path(__file__).name})\")\n    if args.verbose:\n        logger.debug(f\"  Pipeline arguments received: {args}\")\n\n    if not pymdp_runner or not hasattr(pymdp_runner, 'run_pymdp_scripts'):\n        logger.error(\"\u274c PyMDP runner module or function not loaded. Cannot proceed with execution step.\")\n        return 1 # Indicate failure\n\n    logger.info(\"  Executing PyMDP rendered scripts...\")\n    \n    # Key arguments for the runner:\n    # - args.output_dir: This is the main pipeline output directory.\n    #   The runner will construct the path to <output_dir>/gnn_rendered_simulators/pymdp/ from this.\n    # - args.recursive: From main pipeline args, to control search within the pymdp folder.\n    # - args.verbose: To control verbosity of the runner itself.\n    \n    try:\n        success = pymdp_runner.run_pymdp_scripts(\n            pipeline_output_dir=args.output_dir,\n            recursive_search=args.recursive, # Assumes main.py's recursive applies here\n            verbose=args.verbose\n        )\n        \n        if success:\n            logger.info(\"\u2705 All found PyMDP scripts executed successfully or no scripts were found to run.\")\n            logger.info(f\"\u2705 Step 10: Execute Rendered Simulators ({Path(__file__).name}) - COMPLETED\")\n            return 0 # Indicate success\n        else:\n            logger.error(\"\u274c Some PyMDP scripts failed during execution.\")\n            logger.error(f\"\u274c Step 10: Execute Rendered Simulators ({Path(__file__).name}) - FAILED\")\n            return 1 # Indicate failure\n            \n    except Exception as e:\n        logger.error(f\"\u274c An unexpected error occurred during the execution step: {e}\", exc_info=args.verbose)\n        logger.error(f\"\u274c Step 10: Execute Rendered Simulators ({Path(__file__).name}) - FAILED CRITICALLY\")\n        return 1 # Indicate critical failure of the step itself",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/10_execute.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/11_llm.py": [
      {
        "name": "process_gnn_with_llm",
        "type": "function",
        "start_line": 92,
        "end_line": 296,
        "code": "def process_gnn_with_llm(gnn_file_path: Path, output_dir_for_file: Path, tasks_to_run: list[str], verbose: bool = False):\n    \"\"\"\n    Processes a single GNN file with specified LLM tasks and saves results.\n    Tasks:\n    1. General Summary of the GNN file.\n    2. Comprehensive Analysis (structured into sections like purpose, components, interactions, ontology mapping).\n    3. Generate 3-5 relevant questions about the GNN file.\n    4. Answer those generated questions based on the GNN file.\n    \"\"\"\n    if not llm_operations or not llm_mcp or not mcp_instance:\n        logger.error(f\"LLM operations module, LLM MCP, or main MCP instance not available. Skipping {gnn_file_path.name}\")\n        return\n\n    # Ensure LLM tools are registered (this also handles API key loading)\n    try:\n        logger.info(f\"Ensuring LLM tools are registered for {gnn_file_path.name}...\")\n        llm_mcp.ensure_llm_tools_registered(mcp_instance) # Pass the actual mcp_instance\n        # Check if the API key was loaded successfully.\n        # Assuming a function `is_api_key_loaded()` exists or can be added to llm_operations.\n        # For now, we'll rely on the logging within ensure_llm_tools_registered/initialize_llm_module.\n        # If mcp_instance.sdk_status is available and relevant to LLM, could check that too.\n        logger.info(f\"LLM tools registration check complete for {gnn_file_path.name}.\")\n    except Exception as e_reg:\n        logger.error(f\"Failed to ensure LLM tools were registered for {gnn_file_path.name}: {e_reg}\", exc_info=True)\n        return # Cannot proceed if tools are not registered\n\n    logger.info(f\"Processing GNN file with LLM: {gnn_file_path.name}\")\n\n    try:\n        with open(gnn_file_path, 'r', encoding='utf-8') as f:\n            gnn_content = f.read()\n        if not gnn_content.strip():\n            logger.warning(f\"GNN file {gnn_file_path.name} is empty. Skipping LLM processing.\")\n            return\n    except Exception as e:\n        logger.error(f\"Error reading GNN file {gnn_file_path}: {e}\", exc_info=True)\n        return\n\n    output_dir_for_file.mkdir(parents=True, exist_ok=True)\n\n    # --- Task 1: General Summary ---\n    summary_output_path = output_dir_for_file / (gnn_file_path.stem + SUMMARY_FILE_SUFFIX)\n    if TASK_SUMMARY in tasks_to_run:\n        logger.info(f\"Task 1: Generating summary for {gnn_file_path.name}...\")\n        try:\n            # Using the MCP tool for summarization as an example, though direct llm_operations can also be used.\n            # summarize_gnn_file_content is defined in src/llm/mcp.py\n            summary_prompt_suffix = \"Focus on the model's purpose, main components, and interactions.\"\n            # summary_response = llm_mcp.summarize_gnn_file_content(str(gnn_file_path), user_prompt_suffix=summary_prompt_suffix)\n            \n            # Direct call for more control and specific prompt construction\n            summary_task_desc = f\"Provide a concise summary of the following GNN model, highlighting its key components (ModelName, primary states/observations, and main connections). {summary_prompt_suffix}\"\n            summary_prompt = llm_operations.construct_prompt([f\"GNN File Content ({gnn_file_path.name}):\\n{gnn_content}\"], summary_task_desc)\n            \n            logger.debug(f\"Summary prompt for {gnn_file_path.name} (first 500 chars): {summary_prompt[:500]}...\")\n            summary_response = llm_operations.get_llm_response(summary_prompt, model=\"gpt-4o-mini\", max_tokens=1000) # Increased max_tokens for summary\n\n            if summary_response.startswith(\"Error:\"):\n                logger.error(f\"LLM summary generation failed for {gnn_file_path.name}: {summary_response}\")\n            else:\n                with open(summary_output_path, 'w', encoding='utf-8') as f:\n                    f.write(summary_response)\n                file_size = summary_output_path.stat().st_size\n                logger.info(f\"Successfully generated summary for {gnn_file_path.name}. Saved to: {summary_output_path} (Size: {file_size} bytes)\")\n        except Exception as e:\n            logger.error(f\"Error during summary generation for {gnn_file_path.name}: {e}\", exc_info=True)\n    else:\n        logger.info(f\"Skipping Task 1 (Summary) for {gnn_file_path.name} as it's not in the requested tasks.\")\n\n    # --- Task 2: Comprehensive Analysis (Structured JSON Output) ---\n    analysis_output_path = output_dir_for_file / (gnn_file_path.stem + COMPREHENSIVE_ANALYSIS_FILE_SUFFIX)\n    if TASK_ANALYSIS in tasks_to_run:\n        logger.info(f\"Task 2: Generating comprehensive analysis for {gnn_file_path.name}...\")\n        try:\n            analysis_task_desc = (\n                \"Analyze the provided GNN file in detail. Structure your response as a JSON object with the following keys: \"\n                \"\\'model_purpose\\', \\'key_components\\', \\'component_interactions\\', \\'data_types_and_dimensions\\', \"\n                \"\\'potential_applications\\', \\'limitations_or_ambiguities\\', and \\'ontology_mapping_assessment\\'. \"\n                \"For \\'key_components\\', describe states, observations, actions, etc. \"\n                \"For \\'ontology_mapping_assessment\\', briefly assess if ActInfOntology terms are present and relevant if any.\"\n            )\n            analysis_prompt = llm_operations.construct_prompt([f\"GNN File Content ({gnn_file_path.name}):\\n{gnn_content}\"], analysis_task_desc)\n            \n            logger.debug(f\"Comprehensive analysis prompt for {gnn_file_path.name} (first 500 chars): {analysis_prompt[:500]}...\")\n            analysis_response_str = llm_operations.get_llm_response(analysis_prompt, model=\"gpt-4o-mini\", max_tokens=3000) # Increased tokens\n\n            if analysis_response_str.startswith(\"Error:\"):\n                logger.error(f\"LLM comprehensive analysis generation failed for {gnn_file_path.name}: {analysis_response_str}\")\n            else:\n                # Attempt to parse as JSON, with fallback for non-JSON response\n                try:\n                    # The LLM might wrap the JSON in backticks or \"json\" language specifier\n                    cleaned_response_str = analysis_response_str.strip()\n                    if cleaned_response_str.startswith(\"```json\"):\n                        cleaned_response_str = cleaned_response_str[len(\"```json\"):]\n                    if cleaned_response_str.startswith(\"```\"): # Generic backticks\n                        cleaned_response_str = cleaned_response_str[len(\"```\"):]\n                    if cleaned_response_str.endswith(\"```\"):\n                        cleaned_response_str = cleaned_response_str[:-len(\"```\")]\n                    \n                    analysis_data = json.loads(cleaned_response_str.strip())\n                    with open(analysis_output_path, 'w', encoding='utf-8') as f:\n                        json.dump(analysis_data, f, indent=4)\n                    file_size = analysis_output_path.stat().st_size\n                    logger.info(f\"Successfully generated comprehensive analysis for {gnn_file_path.name}. Saved to: {analysis_output_path} (Size: {file_size} bytes)\")\n                except json.JSONDecodeError:\n                    logger.warning(f\"LLM comprehensive analysis for {gnn_file_path.name} was not valid JSON. Saving as raw text.\")\n                    # Fallback: save as text if not valid JSON\n                    analysis_output_path_txt = analysis_output_path.with_suffix(\".txt\")\n                    with open(analysis_output_path_txt, 'w', encoding='utf-8') as f:\n                        f.write(analysis_response_str)\n                    file_size = analysis_output_path_txt.stat().st_size\n                    logger.info(f\"Saved raw analysis output to: {analysis_output_path_txt} (Size: {file_size} bytes)\")\n\n        except Exception as e:\n            logger.error(f\"Error during comprehensive analysis for {gnn_file_path.name}: {e}\", exc_info=True)\n    else:\n        logger.info(f\"Skipping Task 2 (Comprehensive Analysis) for {gnn_file_path.name} as it's not in the requested tasks.\")\n\n    # --- Tasks 3 & 4: Generate Questions and Answers (Structured JSON Output) ---\n    qa_output_path = output_dir_for_file / (gnn_file_path.stem + QA_FILE_SUFFIX)\n    if TASK_QA in tasks_to_run:\n        logger.info(f\"Tasks 3 & 4: Generating Q&A for {gnn_file_path.name}...\")\n        try:\n            # Task 3: Generate 3-5 relevant questions\n            question_gen_task_desc = (\n                \"Based on the provided GNN file, generate 3 to 5 insightful questions that would help understand the model's nuances, assumptions, or implications. \"\n                \"Return these questions as a JSON list of strings.\"\n            )\n            question_gen_prompt = llm_operations.construct_prompt([f\"GNN File Content ({gnn_file_path.name}):\\n{gnn_content}\"], question_gen_task_desc)\n            \n            logger.debug(f\"Question generation prompt for {gnn_file_path.name} (first 500 chars): {question_gen_prompt[:500]}...\")\n            questions_response_str = llm_operations.get_llm_response(question_gen_prompt, model=\"gpt-4o-mini\", max_tokens=1000)\n\n            generated_questions = []\n            if questions_response_str.startswith(\"Error:\"):\n                logger.error(f\"LLM question generation failed for {gnn_file_path.name}: {questions_response_str}\")\n            else:\n                try:\n                    # Clean potential markdown/code block markers\n                    cleaned_q_response = questions_response_str.strip()\n                    if cleaned_q_response.startswith(\"```json\"):\n                        cleaned_q_response = cleaned_q_response[len(\"```json\"):]\n                    if cleaned_q_response.startswith(\"```\"):\n                         cleaned_q_response = cleaned_q_response[len(\"```\"):]\n                    if cleaned_q_response.endswith(\"```\"):\n                        cleaned_q_response = cleaned_q_response[:-len(\"```\")]\n                    \n                    generated_questions = json.loads(cleaned_q_response.strip())\n                    if not isinstance(generated_questions, list):\n                        logger.warning(f\"LLM generated questions for {gnn_file_path.name} was not a list. Found: {type(generated_questions)}\")\n                        generated_questions = [] # Reset if not a list\n                    else:\n                        logger.info(f\"Successfully generated {len(generated_questions)} questions for {gnn_file_path.name}.\")\n                except json.JSONDecodeError:\n                    logger.warning(f\"LLM generated questions for {gnn_file_path.name} was not valid JSON: {questions_response_str[:200]}...\")\n                    # Fallback: try to parse as a list of strings if it's just text lines\n                    if isinstance(questions_response_str, str) and \"\\n\" in questions_response_str: # Check if it's a multi-line string\n                        generated_questions = [q.strip() for q in questions_response_str.split(\"\\n\") if q.strip()]\n                        if generated_questions:\n                             logger.info(f\"Fallback: Parsed {len(generated_questions)} questions from raw text for {gnn_file_path.name}.\")\n\n\n            # Task 4: Answer the generated questions\n            qa_pairs = []\n            if generated_questions:\n                logger.info(f\"Answering {len(generated_questions)} generated questions for {gnn_file_path.name}...\")\n                for i, question in enumerate(generated_questions):\n                    if not isinstance(question, str) or not question.strip(): # Skip empty or non-string questions\n                        logger.warning(f\"Skipping invalid question at index {i} for {gnn_file_path.name}: {question}\")\n                        continue\n\n                    logger.debug(f\"Answering question {i+1}/{len(generated_questions)}: '{question}'\")\n                    answer_task_desc = (\n                        f\"Based *solely* on the provided GNN file content, answer the following question: '{question}'. \"\n                        \"If the GNN file does not contain enough information to answer, state that explicitly. \"\n                        \"Be concise and directly address the question.\"\n                    )\n                    answer_prompt = llm_operations.construct_prompt([f\"GNN File Content ({gnn_file_path.name}):\\n{gnn_content}\"], answer_task_desc)\n                    \n                    answer_response = llm_operations.get_llm_response(answer_prompt, model=\"gpt-4o-mini\", max_tokens=1000)\n\n                    if answer_response.startswith(\"Error:\"):\n                        logger.error(f\"LLM answer generation failed for question '{question}' on {gnn_file_path.name}: {answer_response}\")\n                        qa_pairs.append({\"question\": question, \"answer\": \"Error during answer generation.\"})\n                    else:\n                        qa_pairs.append({\"question\": question, \"answer\": answer_response})\n                        logger.debug(f\"Answer for '{question}': {answer_response[:100]}...\")\n                \n                if qa_pairs:\n                    with open(qa_output_path, 'w', encoding='utf-8') as f:\n                        json.dump(qa_pairs, f, indent=4)\n                    file_size = qa_output_path.stat().st_size\n                    logger.info(f\"Successfully generated and answered questions for {gnn_file_path.name}. Saved to: {qa_output_path} (Size: {file_size} bytes)\")\n                else:\n                    logger.warning(f\"No valid Q&A pairs were generated for {gnn_file_path.name}.\")\n            else:\n                logger.warning(f\"No questions were generated for {gnn_file_path.name}, so no Q&A will be saved.\")\n\n        except Exception as e:\n            logger.error(f\"Error during Q&A generation for {gnn_file_path.name}: {e}\", exc_info=True)\n    else:\n        logger.info(f\"Skipping Tasks 3 & 4 (Q&A) for {gnn_file_path.name} as it's not in the requested tasks.\")\n\n    logger.info(f\"Finished LLM processing for GNN file: {gnn_file_path.name}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/11_llm.py"
      },
      {
        "name": "discover_gnn_files",
        "type": "function",
        "start_line": 299,
        "end_line": 316,
        "code": "def discover_gnn_files(target_dir: Path, recursive: bool = False) -> list[Path]:\n    \"\"\"Discovers GNN files (.gnn.md, .md, .json) in the target directory.\"\"\"\n    patterns = [\"*.gnn.md\", \"*.md\", \"*.json\"] # Added .json as per user instruction context. Consider if .json is always a GNN file.\n    gnn_files = []\n    for pattern in patterns:\n        if recursive:\n            gnn_files.extend(list(target_dir.rglob(pattern)))\n        else:\n            gnn_files.extend(list(target_dir.glob(pattern)))\n    \n    # Filter out files from .venv or other common non-gnn directories if necessary\n    # For now, assume all found files are candidates\n    unique_files = sorted(list(set(gnn_files))) # Deduplicate and sort\n    logger.info(f\"Discovered {len(unique_files)} potential GNN input files.\")\n    if logger.isEnabledFor(logging.DEBUG): # Check logger level for verbose discovery log\n        for f_path in unique_files:\n            logger.debug(f\"  - Found: {f_path}\")\n    return unique_files",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/11_llm.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 318,
        "end_line": 378,
        "code": "def main(args: argparse.Namespace) -> int:\n    \"\"\"\n    Main function to orchestrate LLM processing of GNN files.\n    \"\"\"\n    # Set this script's logger level based on args.verbose.\n    # If run standalone, setup_standalone_logging in __main__ will have already configured handlers\n    # and potentially set this logger's level. This call ensures it respects args.verbose.\n    # If run by main.py, main.py's logging config applies, and this sets this script's specific level.\n    log_level_for_this_script = logging.DEBUG if args.verbose else logging.INFO\n    logger.setLevel(log_level_for_this_script)\n    if logger.isEnabledFor(logging.DEBUG): # Log this only if we are actually in debug mode now\n        logger.debug(f\"Script logger '{logger.name}' level set to {logging.getLevelName(log_level_for_this_script)}.\")\n    \n    # If verbose, also set level for llm_operations module if it exists.\n    if args.verbose and llm_operations and hasattr(llm_operations, '__name__'):\n        logging.getLogger(llm_operations.__name__).setLevel(logging.DEBUG)\n        logger.debug(f\"Verbose mode: Set logger for '{llm_operations.__name__}' to DEBUG.\")\n\n    logger.info(f\"Starting LLM processing step. Target directory: {args.target_dir}, Output directory: {args.output_dir}\")\n    logger.debug(f\"Full arguments: {args}\")\n\n    if not llm_operations or not llm_mcp or not mcp_instance:\n        logger.critical(\"LLM support modules (llm_operations, llm_mcp, or mcp_instance) are not available. Terminating LLM processing.\")\n        return 1 # Indicate failure\n\n    target_dir = Path(args.target_dir)\n    pipeline_output_dir = Path(args.output_dir) # This is the main output dir for the whole pipeline\n    \n    # Specific output directory for this LLM step\n    llm_step_output_dir = pipeline_output_dir / LLM_OUTPUT_DIR_NAME\n    llm_step_output_dir.mkdir(parents=True, exist_ok=True)\n    logger.info(f\"LLM outputs will be saved in: {llm_step_output_dir}\")\n\n    selected_tasks = []\n    if \"all\" in args.llm_tasks:\n        selected_tasks = ALL_TASKS\n    else:\n        selected_tasks = [task for task in args.llm_tasks if task in ALL_TASKS]\n        if not selected_tasks:\n            logger.warning(f\"No valid LLM tasks specified or recognized: {args.llm_tasks}. Defaulting to all tasks.\")\n            selected_tasks = ALL_TASKS # Or could choose to run no tasks / error out\n    \n    logger.info(f\"LLM tasks to run: {', '.join(selected_tasks)}\")\n\n    gnn_files_to_process = discover_gnn_files(target_dir, args.recursive)\n\n    if not gnn_files_to_process:\n        logger.info(\"No GNN files found to process.\")\n        return 0\n\n    for gnn_file_path in gnn_files_to_process:\n        # Create a subdirectory for each GNN file's outputs within the llm_step_output_dir\n        # e.g., output/llm_processing_step/gnn_example_A/\n        file_specific_output_dir = llm_step_output_dir / gnn_file_path.stem\n        file_specific_output_dir.mkdir(parents=True, exist_ok=True)\n        \n        logger.info(f\"--- Processing GNN file: {gnn_file_path.relative_to(target_dir) if gnn_file_path.is_relative_to(target_dir) else gnn_file_path} ---\")\n        process_gnn_with_llm(gnn_file_path, file_specific_output_dir, selected_tasks, args.verbose)\n\n    logger.info(\"LLM processing step completed.\")\n    return 0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/11_llm.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/4_gnn_type_checker.py": [
      {
        "name": "run_type_checker",
        "type": "function",
        "start_line": 65,
        "end_line": 153,
        "code": "def run_type_checker(target_dir: str, \n                     pipeline_output_dir: str, # Main output dir for the whole pipeline\n                     recursive: bool = False, \n                     strict: bool = False, \n                     estimate_resources: bool = False, \n                     verbose: bool = False): # verbose is for this script, cli handles its own verbosity\n    \"\"\"\n    Run type checking on GNN files in the target directory using the gnn_type_checker module.\n    \"\"\"\n    # Set level for this script's logger. If run standalone via __main__ and setup_standalone_logging was used\n    # with logger_name=__name__, this logger's level might already be set. Re-setting is fine.\n    # If run by main.py, main.py sets its own logger, this script's logger inherits and then is set here.\n    current_script_log_level = logging.DEBUG if verbose else logging.INFO\n    logger.setLevel(current_script_log_level)\n    logger.debug(f\"Set logger '{logger.name}' to {logging.getLevelName(current_script_log_level)} within run_type_checker.\")\n\n    type_checker_module_logger = logging.getLogger(\"gnn_type_checker\")\n    # It's good to control the verbosity of the module we are calling\n    type_checker_module_log_level = logging.INFO if verbose else logging.WARNING # Let type_checker be a bit verbose if we are, otherwise only warnings\n    type_checker_module_logger.setLevel(type_checker_module_log_level)\n    logger.debug(f\"Set logger '{type_checker_module_logger.name}' to {logging.getLevelName(type_checker_module_log_level)}.\")\n\n    if not gnn_type_checker_cli:\n        logger.error(\"\u274c GNN Type Checker CLI module not loaded. Cannot proceed.\")\n        return False # Indicate failure\n\n    # Define the specific output directory for this step's artifacts\n    type_checker_step_output_dir = Path(pipeline_output_dir) / \"gnn_type_check\"\n    type_checker_step_output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # The main markdown report filename for the type checker\n    report_filename = \"type_check_report.md\" # Hardcoded back\n\n    # Determine project root for relative paths in sub-module reports\n    project_root = Path(__file__).resolve().parent.parent\n\n    # Prepare arguments for the gnn_type_checker.cli.main() function\n    cli_args = [\n        str(target_dir), # input_path, ensure it's a string\n        \"--output-dir\", str(type_checker_step_output_dir),\n        \"--report-file\", report_filename, # This filename will be created inside type_checker_step_output_dir\n        \"--project-root\", str(project_root) # Pass project root to the CLI\n    ]\n    \n    if recursive:\n        cli_args.append(\"--recursive\")\n    if strict:\n        cli_args.append(\"--strict\")\n    if estimate_resources:\n        cli_args.append(\"--estimate-resources\")\n    # The gnn_type_checker.cli.main itself doesn't have a global --verbose flag in its parser\n    # It prints its own progress/summary. If verbose for this script is on, we print extra info.\n\n    if verbose:\n        # Use logger for informational messages\n        logger.info(f\"  \ud83d\udc0d Invoking GNN Type Checker module with arguments: {' '.join(cli_args)}\")\n        logger.info(f\"  \u2139\ufe0f Target GNN files in: {target_dir}\")\n        logger.info(f\"  \u2139\ufe0f Type checker outputs will be in: {type_checker_step_output_dir}\")\n        logger.info(f\"  \ud83d\udcdd Main type check report will be: {type_checker_step_output_dir / report_filename}\")\n\n    try:\n        # Call the main function of the type checker's CLI\n        # The cli.main function is expected to return 0 for success, 1 for errors.\n        type_checker_cli_exit_code = gnn_type_checker_cli.main(cli_args)\n        \n        type_checker_successful = (type_checker_cli_exit_code == 0)\n\n        if type_checker_successful:\n            if verbose:\n                logger.info(f\"\u2705 GNN Type Checker module completed successfully.\")\n        else:\n            # Use logger for error messages\n            logger.error(f\"\u274c GNN Type Checker module reported errors (exit code: {type_checker_cli_exit_code}).\")\n            logger.error(f\"   Check logs and reports in {type_checker_step_output_dir} for details.\")\n            # Resource estimation will still be attempted by the CLI if the flag was passed,\n            # even if type checking reported errors, as per cli.py logic.\n\n        # The GNN Type Checker CLI now handles resource estimation internally if the flag is passed.\n        # No need to call it separately here.\n            \n        return type_checker_successful # Success of the step is based on type checking\n            \n    except Exception as e:\n        # Use logger for critical/exception messages\n        logger.critical(f\"\u274c An unexpected error occurred while running the GNN Type Checker module: {e}\", exc_info=verbose) # exc_info=True will log traceback if verbose\n        # if verbose: # exc_info=verbose handles this\n        #     import traceback\n        #     traceback.print_exc()\n        return False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/4_gnn_type_checker.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 155,
        "end_line": 187,
        "code": "def main(args):\n    \"\"\"Main function for the type checking step (Step 4).\n\n    Orchestrates the GNN type checking process by invoking 'run_type_checker'.\n    This function is typically called by the main pipeline (`main.py`) with\n    a pre-populated args object, or by the standalone execution block which\n    parses command-line arguments.\n\n    Args:\n        args (argparse.Namespace): \n            Parsed command-line arguments. Expected attributes include:\n            target_dir, output_dir, recursive, strict, estimate_resources, verbose.\n    \"\"\"\n    # The logger level for this module (__name__) and for \"gnn_type_checker\"\n    # should be set by run_type_checker based on args.verbose, or if run standalone,\n    # by the __main__ block. Direct setLevel here is redundant if called by main.py.\n\n    logger.info(f\"\u25b6\ufe0f Starting Step 4: Type Checking ({Path(__file__).name})...\") \n    \n    if not run_type_checker(\n        args.target_dir, \n        args.output_dir, \n        recursive=args.recursive,\n        strict=args.strict if hasattr(args, 'strict') else False,\n        estimate_resources=args.estimate_resources if hasattr(args, 'estimate_resources') else False,\n        verbose=args.verbose # Pass verbose to run_type_checker to control its specific logging\n    ):\n        logger.error(\"\u274c Step 4: Type Checking failed.\") \n        return 1\n    \n    if args.verbose:\n        logger.info(\"\u2705 Step 4: Type Checking complete.\") \n    return 0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/4_gnn_type_checker.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/8_ontology.py": [
      {
        "name": "process_ontology_operations",
        "type": "function",
        "start_line": 75,
        "end_line": 218,
        "code": "def process_ontology_operations(target_dir_str: str, output_dir_str: str, ontology_terms_file: str = None, recursive: bool = False, verbose: bool = False):\n    \"\"\"Processes GNN files to extract, validate, and report on ontology annotations.\"\"\"\n    if not ontology_mcp:\n        logger.error(\"\u274c\ud83e\uddec MCP for ontology (ontology.mcp) not available. Cannot process ontology operations.\")\n        return False, 0\n\n    # Log initial parameters at DEBUG level\n    logger.info(f\"  \ud83d\udd0e Processing ontology related tasks...\")\n    logger.debug(f\"    \ud83c\udfaf Target GNN files in: {Path(target_dir_str).resolve()}\")\n    logger.debug(f\"    \u0565\u056c Output directory for ontology report: {Path(output_dir_str).resolve()}\")\n    logger.debug(f\"    \ud83d\udd04 Recursive mode: {'Enabled' if recursive else 'Disabled'}\")\n    if ontology_terms_file:\n        logger.debug(f\"    \ud83d\udcd6 Using ontology terms definition from: {Path(ontology_terms_file).resolve()}\")\n    else:\n        logger.warning(\"    \u26a0\ufe0f No ontology terms definition file provided. Validation will be skipped.\")\n\n    # Conceptual Ontology Logging (if verbose)\n    logger.debug(\"    \ud83e\udde0 Conceptual Note: Ontologies provide a formal way to represent knowledge.\")\n    logger.debug(\"      - Informal ontologies (like folksonomies or taxonomies) help organize concepts.\")\n    logger.debug(\"      - Formal ontologies (e.g., in OWL, RDF) allow for logical reasoning and consistency checks.\")\n    logger.debug(\"      - This script focuses on extracting and validating terms based on a predefined JSON schema.\")\n    logger.debug(\"      - Different ontology languages (OWL, RDF, SKOS) offer varying expressiveness.\")\n\n    target_dir = Path(target_dir_str)\n    output_dir = Path(output_dir_str)\n    ontology_output_path = output_dir / \"ontology_processing\"\n    ontology_output_path.mkdir(parents=True, exist_ok=True)\n    logger.debug(f\"    \u270d\ufe0f Ontology report will be saved in: {ontology_output_path.resolve()}\")\n\n    # Determine project root for relative paths in report\n    project_root = Path(__file__).resolve().parent.parent\n\n    defined_ontology_terms = {}\n    if ontology_terms_file:\n        logger.debug(f\"    \ud83e\uddd0 Loading defined ontology terms from: {ontology_terms_file}\")\n        defined_ontology_terms = ontology_mcp.load_defined_ontology_terms(ontology_terms_file, verbose=verbose)\n        if defined_ontology_terms:\n            logger.debug(f\"      \ud83d\udcda Loaded {len(defined_ontology_terms)} ontology terms successfully.\")\n        else:\n            logger.warning(f\"      \u26a0\ufe0f Could not load or no terms found in {ontology_terms_file}. Validation may be limited.\")\n\n    report_title = \"# \ud83e\uddec GNN Ontological Annotations Report\"\n    all_reports_parts = [report_title]\n    all_reports_parts.append(f\"\ufffd\ufffd\ufe0f Report Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n    # Make paths relative to project root for the report\n    try:\n        reported_target_dir = target_dir.relative_to(project_root)\n    except ValueError:\n        reported_target_dir = target_dir # Keep absolute if not under project_root (e.g. symlink or unusual setup)\n    all_reports_parts.append(f\"\ud83c\udfaf GNN Source Directory: `{reported_target_dir}`\")\n    \n    if ontology_terms_file:\n        try:\n            reported_ontology_file = Path(ontology_terms_file).resolve().relative_to(project_root)\n        except ValueError:\n            reported_ontology_file = Path(ontology_terms_file).resolve() # Keep absolute if not under project root\n        all_reports_parts.append(f\"\ud83d\udcd6 Ontology Terms Definition: `{reported_ontology_file}` (Loaded: {len(defined_ontology_terms)} terms)\")\n    else:\n        all_reports_parts.append(\"\u26a0\ufe0f Ontology Terms Validation: Skipped (no definition file provided)\")\n    all_reports_parts.append(\"\\n---\\n\")\n\n    search_pattern = \"**/*.md\" if recursive else \"*.md\"\n    gnn_files = list(target_dir.glob(search_pattern))\n\n    if not gnn_files:\n        logger.info(f\"    \u2139\ufe0f No .md files found in '{target_dir}' with search pattern '{search_pattern}'.\")\n        all_reports_parts.append(\"**No GNN (.md) files found to process in the specified target directory.**\\n\")\n    else:\n        logger.debug(f\"    \ud83d\udcca Found {len(gnn_files)} GNN (.md) files to process.\")\n\n    processed_file_count = 0\n    total_annotations_found = 0\n    total_validations_passed = 0\n    total_validations_failed = 0\n\n    for gnn_file_path in gnn_files:\n        logger.debug(f\"    \ud83d\udcc4 Processing file: {gnn_file_path.name} ({gnn_file_path.stat().st_size} bytes)\")\n        try:\n            with open(gnn_file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n            \n            # Assuming parse_gnn_ontology_section returns a list/dict of annotations\n            parsed_annotations = ontology_mcp.parse_gnn_ontology_section(content, verbose=verbose)\n            num_file_annotations = len(parsed_annotations) if parsed_annotations else 0\n            total_annotations_found += num_file_annotations\n            if num_file_annotations > 0:\n                logger.debug(f\"      Found {num_file_annotations} ontology annotations in {gnn_file_path.name}.\")\n            \n            validation_results = None\n            file_valid = 0\n            file_invalid = 0\n            if defined_ontology_terms and parsed_annotations:\n                validation_results = ontology_mcp.validate_annotations(parsed_annotations, defined_ontology_terms, verbose=verbose)\n                if validation_results:\n                    # Directly use the counts from the validation_results structure\n                    file_valid = len(validation_results.get(\"valid_mappings\", {}))\n                    file_invalid = len(validation_results.get(\"invalid_terms\", {}))\n                    \n                    total_validations_passed += file_valid\n                    total_validations_failed += file_invalid\n                    if file_valid > 0 or file_invalid > 0:\n                        logger.debug(f\"        Validated for {gnn_file_path.name}: {file_valid} passed, {file_invalid} failed.\")\n            \n            # The path passed to generate_ontology_report_for_file needs to be relative to project root.\n            # Original: str(gnn_file_path.relative_to(target_dir.parent if target_dir.is_dir() else target_dir.parent.parent))\n            # gnn_file_path is absolute here. target_dir is also absolute.\n            # We want path relative to project_root, e.g. src/gnn/examples/file.md\n            try:\n                report_file_display_path = gnn_file_path.resolve().relative_to(project_root)\n            except ValueError:\n                report_file_display_path = gnn_file_path.name # Fallback to just filename if not in project root\n\n            file_report_str = ontology_mcp.generate_ontology_report_for_file(\n                str(report_file_display_path),\n                parsed_annotations, \n                validation_results\n            )\n            all_reports_parts.append(file_report_str)\n            processed_file_count +=1\n        except Exception as e:\n            logger.error(f\"    \u274c Error processing file {gnn_file_path.name}: {e}\", exc_info=True)\n            all_reports_parts.append(f\"### Error processing `{gnn_file_path.name}`\\n - {str(e)}\\n\\n---\\n\")\n\n    # Add a summary section to the report\n    all_reports_parts.insert(1, f\"\\n## \ud83d\udcca Summary of Ontology Processing\\n\")\n    all_reports_parts.insert(2, f\"- **Files Processed:** {processed_file_count} / {len(gnn_files)}\")\n    all_reports_parts.insert(3, f\"- **Total Ontological Annotations Found:** {total_annotations_found}\")\n    if defined_ontology_terms:\n        all_reports_parts.insert(4, f\"- **Total Annotations Validated:** {total_validations_passed + total_validations_failed}\")\n        all_reports_parts.insert(5, f\"  - \u2705 Passed: {total_validations_passed}\")\n        all_reports_parts.insert(6, f\"  - \u274c Failed: {total_validations_failed}\")\n    all_reports_parts.insert(7, \"\\n---\\n\")\n            \n    report_file_path = ontology_output_path / \"ontology_processing_report.md\"\n    try:\n        with open(report_file_path, 'w', encoding='utf-8') as f_report:\n            f_report.write(\"\\n\".join(all_reports_parts))\n        report_size = report_file_path.stat().st_size\n        logger.debug(f\"  \u2705 Ontology processing report saved: {report_file_path.resolve()} ({report_size} bytes)\")\n    except Exception as e:\n        logger.error(f\"\u274c Failed to write ontology report to {report_file_path}: {e}\", exc_info=True)\n        return False, 0\n        \n    return True, total_validations_failed",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/8_ontology.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 220,
        "end_line": 275,
        "code": "def main(args):\n    \"\"\"Main function for the ontology operations step (Step 8).\n\n    This function is the entry point for ontology processing. It logs the start\n    of the step and calls `process_ontology_operations` with the necessary arguments\n    derived from the `args` Namespace object.\n\n    Args:\n        args (argparse.Namespace): \n            Parsed command-line arguments from `main.py` or standalone execution.\n            Expected attributes include: target_dir, output_dir, ontology_terms_file,\n            recursive, verbose.\n    \"\"\"\n    # Set this script's logger level based on pipeline's args.verbose\n    # This is typically handled by main.py for child modules.\n    # The __main__ block handles it for standalone execution.\n    # if args.verbose:\n    #     logger.setLevel(logging.DEBUG)\n    # else:\n    #     logger.setLevel(logging.INFO)\n\n    logger.info(f\"\u25b6\ufe0f Starting Step 8: Ontology Operations ({Path(__file__).name})\")\n    logger.debug(f\"  Parsed options (from main.py or standalone):\")\n    logger.debug(f\"    Target GNN files directory: {args.target_dir}\")\n    logger.debug(f\"    Output directory for report: {args.output_dir}\")\n    logger.debug(f\"    Recursive: {args.recursive}\")\n    if args.ontology_terms_file:\n        logger.debug(f\"    Ontology terms definition file: {args.ontology_terms_file}\")\n    else:\n        logger.debug(f\"    Ontology terms file: Not provided (validation will be skipped)\")\n    logger.debug(f\"    Verbose flag from args: {args.verbose}\")\n\n    success, num_failed_validations = process_ontology_operations(\n        args.target_dir, \n        args.output_dir, \n        args.ontology_terms_file,\n        args.recursive if hasattr(args, 'recursive') else False, \n        args.verbose\n    )\n\n    if not success:\n        logger.error(f\"\u274c Step 8: Ontology Operations ({Path(__file__).name}) FAILED critically.\")\n        return 1 # Critical failure\n    \n    if num_failed_validations > 0:\n        warning_message = (\n            f\"Ontology validation completed with {num_failed_validations} failed term(s). \"\n            f\"Check '{Path(args.output_dir) / 'ontology_processing/ontology_processing_report.md'}' \"\n            f\"for details.\"\n        )\n        logger.warning(f\"\u26a0\ufe0f Step 8: {warning_message}\")\n        # Return 2 for success with warnings, aligning with main.py expectations\n        return 2 \n        \n    logger.info(f\"\u2705 Step 8: Ontology Operations ({Path(__file__).name}) - COMPLETED without validation errors.\")\n    return 0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/8_ontology.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py": [
      {
        "name": "GNNResourceEstimator",
        "type": "class",
        "start_line": 22,
        "end_line": 1696,
        "code": "class GNNResourceEstimator:\n    \"\"\"\n    Estimates computational resources required for GNN models.\n    \"\"\"\n    \n    # Default computational cost factors (realistic units)\n    MEMORY_FACTORS = {\n        'float': 4,    # bytes per float (single precision)\n        'double': 8,   # bytes per double (double precision)\n        'int': 4,      # bytes per int (32-bit)\n        'long': 8,     # bytes per long (64-bit)\n        'bool': 1,     # bytes per bool\n        'string': 16,  # average bytes per string reference\n        'categorical': 4  # bytes per category (int encoding)\n    }\n    \n    # Operation cost factors in FLOPS\n    OPERATION_COSTS = {\n        'matrix_multiply': 2,  # 2 FLOPS per element (multiply and add)\n        'scalar_multiply': 1,  # 1 FLOP per element\n        'addition': 1,        # 1 FLOP per element\n        'division': 4,        # ~4 FLOPS per element\n        'exp': 20,            # ~20 FLOPS for exponential\n        'log': 20,            # ~20 FLOPS for logarithm\n        'softmax': 30,        # ~30 FLOPS per element (exp, sum, div)\n        'sigmoid': 25,        # ~25 FLOPS per element\n        'tanh': 30            # ~30 FLOPS per element\n    }\n    \n    # Inference speed factors (relative to static models)\n    INFERENCE_FACTORS = {\n        'Static': 1.0,          # Base reference\n        'Dynamic': 2.5,         # Dynamic models ~2.5x more expensive\n        'Hierarchical': 3.5,    # Hierarchical models ~3.5x more expensive\n        'float': 1.0,           # Base reference\n        'double': 1.8,          # Double precision ~1.8x slower\n        'int': 0.8,             # Integers ~0.8x of float cost\n        'bool': 0.5,            # Booleans ~0.5x of float cost\n        'string': 1.2,          # String ops ~1.2x of float cost\n        'categorical': 1.1      # Categorical ~1.1x of float cost\n    }\n    \n    # Hardware specifications (representative values)\n    HARDWARE_SPECS = {\n        'cpu_flops_per_second': 50e9,   # 50 GFLOPS for typical CPU\n        'memory_bandwidth': 25e9,       # 25 GB/s memory bandwidth\n        'disk_read_speed': 500e6,       # 500 MB/s disk read\n        'disk_write_speed': 450e6,      # 450 MB/s disk write\n    }\n    \n    def __init__(self, type_check_data: Optional[str] = None):\n        \"\"\"\n        Initialize the resource estimator.\n        \n        Args:\n            type_check_data: Path to JSON data from type checker\n        \"\"\"\n        self.results = {}\n        self.detailed_metrics = {}\n        \n        if type_check_data:\n            try:\n                with open(type_check_data, 'r') as f:\n                    self.type_check_data = json.load(f)\n            except (FileNotFoundError, json.JSONDecodeError) as e:\n                print(f\"Warning: Could not load type check data: {e}\")\n                self.type_check_data = None\n        else:\n            self.type_check_data = None\n    \n    def estimate_from_file(self, file_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Estimate resources for a single GNN file.\n        \n        Args:\n            file_path: Path to GNN file\n            \n        Returns:\n            Dictionary with resource estimates\n        \"\"\"\n        from visualization.parser import GNNParser\n        \n        parser = GNNParser()\n        \n        try:\n            # Parse the file\n            content = parser.parse_file(file_path)\n            return self._analyze_model(content, file_path)\n        except Exception as e:\n            print(f\"Error analyzing {file_path}: {str(e)}\")\n            return {\n                \"file\": file_path,\n                \"error\": str(e),\n                \"memory_estimate\": None,\n                \"inference_estimate\": None,\n                \"storage_estimate\": None\n            }\n    \n    def estimate_from_directory(self, dir_path: str, recursive: bool = False) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Estimate resources for all GNN files in a directory.\n        \n        Args:\n            dir_path: Path to directory with GNN files\n            recursive: Whether to recursively process subdirectories\n            \n        Returns:\n            Dictionary mapping file paths to resource estimates\n        \"\"\"\n        path = Path(dir_path)\n        results = {}\n        \n        # Define pattern for GNN files\n        pattern = \"**/*.md\" if recursive else \"*.md\"\n        \n        for file_path in path.glob(pattern):\n            file_str = str(file_path)\n            results[file_str] = self.estimate_from_file(file_str)\n        \n        self.results = results\n        return results\n    \n    def _analyze_model(self, content: Dict[str, Any], file_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a GNN model and estimate resources.\n        \n        Args:\n            content: Parsed GNN content\n            file_path: Path to source file\n            \n        Returns:\n            Dictionary with resource estimates\n        \"\"\"\n        # Extract key model information\n        variables = content.get('Variables', {})\n        time_spec = content.get('Time', 'Static').split('\\n')[0].strip()\n        edges = content.get('Edges', [])\n        equations = content.get('Equations', '')\n        \n        # Extract model name\n        model_name = content.get('ModelName', os.path.basename(file_path))\n        \n        # Determine if model is hierarchical\n        is_hierarchical = any('hierarchical' in key.lower() for key in content.keys())\n        if is_hierarchical:\n            model_type = 'Hierarchical'\n        else:\n            model_type = time_spec\n        \n        # Basic estimates\n        memory_estimate = self._estimate_memory(variables)\n        inference_estimate = self._estimate_inference(variables, model_type, edges, equations)\n        storage_estimate = self._estimate_storage(variables, edges, equations)\n        \n        # Advanced estimates\n        flops_estimate = self._estimate_flops(variables, edges, equations, model_type)\n        inference_time_estimate = self._estimate_inference_time(flops_estimate)\n        batched_inference_estimate = self._estimate_batched_inference(variables, model_type, flops_estimate)\n        model_overhead = self._estimate_model_overhead(variables, edges, equations)\n        \n        # More detailed matrix operation estimates\n        matrix_operation_costs = self._estimate_matrix_operation_costs(variables, edges, equations)\n        \n        # Detailed memory breakdowns\n        memory_breakdown = self._detailed_memory_breakdown(variables)\n        \n        # Calculate complexity metrics\n        complexity = self._calculate_complexity(variables, edges, equations)\n        \n        # Store detailed metrics for HTML report\n        self.detailed_metrics[file_path] = {\n            \"flops_estimate\": flops_estimate,\n            \"inference_time_estimate\": inference_time_estimate,\n            \"batched_inference_estimate\": batched_inference_estimate,\n            \"model_overhead\": model_overhead,\n            \"matrix_operation_costs\": matrix_operation_costs,\n            \"memory_breakdown\": memory_breakdown,\n            \"model_type\": model_type\n        }\n        \n        return {\n            \"file\": file_path,\n            \"model_name\": model_name,\n            \"memory_estimate\": memory_estimate,\n            \"inference_estimate\": inference_estimate,\n            \"storage_estimate\": storage_estimate,\n            \"flops_estimate\": flops_estimate,\n            \"inference_time_estimate\": inference_time_estimate,\n            \"batched_inference_estimate\": batched_inference_estimate,\n            \"model_overhead\": model_overhead,\n            \"complexity\": complexity,\n            \"model_info\": {\n                \"variables_count\": len(variables),\n                \"edges_count\": len(edges),\n                \"time_spec\": time_spec,\n                \"equation_count\": len(equations.split('\\n'))\n            }\n        }\n    \n    def _estimate_memory(self, variables: Dict[str, Any]) -> float:\n        \"\"\"\n        Estimate memory requirements based on variables.\n        \n        Args:\n            variables: Dictionary of model variables\n            \n        Returns:\n            Memory estimate in KB\n        \"\"\"\n        total_memory = 0.0\n        \n        for var_name, var_info in variables.items():\n            var_type = var_info.get('type', 'float')\n            dims = var_info.get('dimensions', [1])\n            \n            # Calculate size of this variable\n            size_factor = self.MEMORY_FACTORS.get(var_type, self.MEMORY_FACTORS['float'])\n            \n            # Process dimensions with caution - handle symbolic dimensions\n            try:\n                dimension_values = []\n                for d in dims:\n                    if isinstance(d, (int, float)):\n                        dimension_values.append(d)\n                    elif isinstance(d, str) and d.isdigit():\n                        dimension_values.append(int(d))\n                    elif isinstance(d, str) and 'len' in d and '\u03c0' in d:\n                        # Approximate the size for dynamic dimensions referencing policy length\n                        dimension_values.append(3)  # Reasonable default for policy length\n                    elif isinstance(d, str) and d.startswith('='):\n                        # Handle '=[2]' or '=[2,1]' format by extracting numbers\n                        import re\n                        matches = re.findall(r'\\d+', d)\n                        if matches:\n                            dimension_values.append(int(matches[0]))\n                        else:\n                            dimension_values.append(1)\n                    else:\n                        dimension_values.append(1)  # Default for unparseable dimensions\n                \n                total_size = size_factor * math.prod(dimension_values)\n            except Exception as e:\n                print(f\"Warning: Error calculating size for variable {var_name}: {e}\")\n                # Use a default size based on variable type\n                total_size = size_factor * 2  # Assume small dimensions as fallback\n            \n            total_memory += total_size\n        \n        # Convert to KB\n        return total_memory / 1024.0\n    \n    def _detailed_memory_breakdown(self, variables: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Create detailed memory breakdown by variable and type.\n        \n        Args:\n            variables: Dictionary of model variables\n            \n        Returns:\n            Dictionary with detailed memory breakdown\n        \"\"\"\n        breakdown = {\n            \"by_variable\": {},\n            \"by_type\": {t: 0 for t in self.MEMORY_FACTORS.keys()},\n            \"total_bytes\": 0,\n            \"representation_overhead\": 0  # Additional overhead for representation\n        }\n        \n        # Fixed overhead for model structure\n        breakdown[\"representation_overhead\"] = 1024  # Approx 1KB for basic model structure\n        \n        for var_name, var_info in variables.items():\n            var_type = var_info.get('type', 'float')\n            dims = var_info.get('dimensions', [1])\n            \n            # Calculate size of this variable\n            size_factor = self.MEMORY_FACTORS.get(var_type, self.MEMORY_FACTORS['float'])\n            \n            # Process dimensions\n            try:\n                dimension_values = []\n                for d in dims:\n                    if isinstance(d, (int, float)):\n                        dimension_values.append(d)\n                    elif isinstance(d, str) and d.isdigit():\n                        dimension_values.append(int(d))\n                    elif isinstance(d, str) and ('len' in d or '\u03c0' in d):\n                        dimension_values.append(3)\n                    elif isinstance(d, str) and d.startswith('='):\n                        import re\n                        matches = re.findall(r'\\d+', d)\n                        if matches:\n                            dimension_values.append(int(matches[0]))\n                        else:\n                            dimension_values.append(1)\n                    else:\n                        dimension_values.append(1)\n                \n                element_count = math.prod(dimension_values)\n                var_size = size_factor * element_count\n                \n                # Additional overhead for variable names and metadata\n                var_overhead = len(var_name) + 24  # ~24 bytes overhead per variable\n                \n                breakdown[\"by_variable\"][var_name] = {\n                    \"size_bytes\": var_size,\n                    \"elements\": element_count,\n                    \"dimensions\": dimension_values,\n                    \"type\": var_type,\n                    \"overhead_bytes\": var_overhead,\n                    \"total_bytes\": var_size + var_overhead\n                }\n                \n                # Add to type totals\n                breakdown[\"by_type\"][var_type] = breakdown[\"by_type\"].get(var_type, 0) + var_size\n                \n                # Add to total bytes\n                breakdown[\"total_bytes\"] += var_size + var_overhead\n                \n                # Add to representation overhead\n                breakdown[\"representation_overhead\"] += var_overhead\n                \n            except Exception as e:\n                print(f\"Warning: Error in memory breakdown for {var_name}: {e}\")\n        \n        # Convert totals to KB for convenience\n        breakdown[\"total_kb\"] = breakdown[\"total_bytes\"] / 1024.0\n        breakdown[\"overhead_kb\"] = breakdown[\"representation_overhead\"] / 1024.0\n        \n        return breakdown\n    \n    def _estimate_flops(self, variables: Dict[str, Any], edges: List[Dict[str, Any]], \n                       equations: str, model_type: str) -> Dict[str, Any]:\n        \"\"\"\n        Estimate floating-point operations (FLOPS) required for inference.\n        \n        Args:\n            variables: Dictionary of model variables\n            edges: List of edges in the model\n            equations: Equations in the model\n            model_type: Type of model (Static, Dynamic, Hierarchical)\n            \n        Returns:\n            Dictionary with FLOPS estimates\n        \"\"\"\n        flops_estimate = {\n            \"total_flops\": 0,\n            \"matrix_operations\": 0,\n            \"element_operations\": 0,\n            \"nonlinear_operations\": 0\n        }\n        \n        # Count matrices and their dimensions\n        matrices = {}\n        for var_name, var_info in variables.items():\n            dims = var_info.get('dimensions', [1])\n            if len(dims) >= 2:  # It's a matrix\n                matrices[var_name] = dims\n        \n        # Estimate matrix multiplication costs (dominant operation)\n        for edge in edges:\n            source = edge.get('source', '')\n            target = edge.get('target', '')\n            \n            if source in matrices and target in matrices:\n                source_dims = matrices[source]\n                target_dims = matrices[target]\n                \n                # Matrix multiply cost: m\u00d7n\u00d7p operations for m\u00d7n * n\u00d7p matrices\n                if len(source_dims) >= 2 and len(target_dims) >= 2:\n                    try:\n                        # Extract dimensions as integers when possible\n                        m = int(source_dims[0]) if isinstance(source_dims[0], (int, str)) and (isinstance(source_dims[0], int) or source_dims[0].isdigit()) else 2\n                        n = int(source_dims[1]) if isinstance(source_dims[1], (int, str)) and (isinstance(source_dims[1], int) or source_dims[1].isdigit()) else 2\n                        p = int(target_dims[1]) if len(target_dims) > 1 and isinstance(target_dims[1], (int, str)) and (isinstance(target_dims[1], int) or target_dims[1].isdigit()) else 2\n                        \n                        # 2 FLOPS per element (multiply and add)\n                        flops = m * n * p * self.OPERATION_COSTS['matrix_multiply']\n                        flops_estimate[\"matrix_operations\"] += flops\n                        flops_estimate[\"total_flops\"] += flops\n                    except (ValueError, TypeError) as e:\n                        # Default estimation if conversion fails\n                        flops_estimate[\"matrix_operations\"] += 100  # Assume small matrices\n                        flops_estimate[\"total_flops\"] += 100\n        \n        # Estimate element-wise operations from equations\n        eq_lines = equations.split('\\n')\n        for line in eq_lines:\n            element_ops = 0\n            nonlinear_ops = 0\n            \n            # Count arithmetic operations\n            element_ops += line.count('+') * self.OPERATION_COSTS['addition']\n            element_ops += line.count('*') * self.OPERATION_COSTS['scalar_multiply']\n            element_ops += line.count('/') * self.OPERATION_COSTS['division']\n            \n            # Count nonlinear operations (approximate)\n            nonlinear_ops += line.count('exp') * self.OPERATION_COSTS['exp']\n            nonlinear_ops += line.count('log') * self.OPERATION_COSTS['log']\n            nonlinear_ops += line.count('softmax') * self.OPERATION_COSTS['softmax']\n            nonlinear_ops += line.count('sigma') * self.OPERATION_COSTS['sigmoid']\n            \n            flops_estimate[\"element_operations\"] += element_ops\n            flops_estimate[\"nonlinear_operations\"] += nonlinear_ops\n            flops_estimate[\"total_flops\"] += element_ops + nonlinear_ops\n        \n        # Apply model type multiplier\n        if model_type == 'Dynamic':\n            flops_estimate[\"total_flops\"] *= 2.5  # Dynamic models more expensive\n        elif model_type == 'Hierarchical':\n            flops_estimate[\"total_flops\"] *= 3.5  # Hierarchical models most expensive\n        \n        # If no specific operations detected, estimate based on variable count and model type\n        if flops_estimate[\"total_flops\"] == 0:\n            base_flops = len(variables) * 20  # 20 FLOPS per variable as baseline\n            if model_type == 'Static':\n                flops_estimate[\"total_flops\"] = base_flops\n            elif model_type == 'Dynamic':\n                flops_estimate[\"total_flops\"] = base_flops * 2.5\n            else:  # Hierarchical\n                flops_estimate[\"total_flops\"] = base_flops * 3.5\n        \n        return flops_estimate\n    \n    def _estimate_inference_time(self, flops_estimate: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"\n        Estimate inference time based on FLOPS and hardware specs.\n        \n        Args:\n            flops_estimate: Dictionary with FLOPS estimates\n            \n        Returns:\n            Dictionary with inference time estimates in various units\n        \"\"\"\n        total_flops = flops_estimate[\"total_flops\"]\n        \n        # Calculate time based on hardware specs\n        cpu_time_seconds = total_flops / self.HARDWARE_SPECS[\"cpu_flops_per_second\"]\n        \n        return {\n            \"cpu_time_seconds\": cpu_time_seconds,\n            \"cpu_time_ms\": cpu_time_seconds * 1000,\n            \"cpu_time_us\": cpu_time_seconds * 1_000_000\n        }\n    \n    def _estimate_batched_inference(self, variables: Dict[str, Any], model_type: str, \n                                   flops_estimate: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Estimate batched inference performance.\n        \n        Args:\n            variables: Dictionary of model variables\n            model_type: Type of model (Static, Dynamic, Hierarchical)\n            flops_estimate: Dictionary with FLOPS estimates\n            \n        Returns:\n            Dictionary with batched inference estimates\n        \"\"\"\n        total_flops = flops_estimate[\"total_flops\"]\n        \n        # Batch sizes to estimate\n        batch_sizes = [1, 8, 32, 128, 512]\n        \n        # Estimate batch throughput\n        batch_estimates = {}\n        for batch_size in batch_sizes:\n            # Batched FLOPS (not perfectly linear due to overhead)\n            if batch_size == 1:\n                batch_flops = total_flops\n            else:\n                # Diminishing returns with larger batches\n                scale_factor = 0.7 + 0.3 / math.log2(batch_size + 1)\n                batch_flops = total_flops * batch_size * scale_factor\n            \n            # Estimate time for batched inference\n            time_seconds = batch_flops / self.HARDWARE_SPECS[\"cpu_flops_per_second\"]\n            \n            # Throughput in samples per second\n            throughput = batch_size / time_seconds if time_seconds > 0 else 0\n            \n            batch_estimates[f\"batch_{batch_size}\"] = {\n                \"flops\": batch_flops,\n                \"time_seconds\": time_seconds,\n                \"throughput_per_second\": throughput\n            }\n        \n        return batch_estimates\n\n    def _estimate_matrix_operation_costs(self, variables: Dict[str, Any], edges: List[Dict[str, Any]], \n                                      equations: str) -> Dict[str, Any]:\n        \"\"\"\n        Provide detailed estimates of matrix operation costs.\n        \n        Args:\n            variables: Dictionary of model variables\n            edges: List of edges in the model\n            equations: Equations in the model\n            \n        Returns:\n            Dictionary with matrix operation costs\n        \"\"\"\n        operation_costs = {\n            \"matrix_multiply\": [],\n            \"matrix_transpose\": [],\n            \"matrix_inversion\": [],\n            \"element_wise\": [],\n            \"total_matrix_flops\": 0\n        }\n        \n        # Identify matrices and their dimensions\n        matrices = {}\n        for var_name, var_info in variables.items():\n            dims = var_info.get('dimensions', [1])\n            if len(dims) >= 2:  # It's a matrix\n                # Convert dimensions to integers when possible\n                int_dims = []\n                for d in dims:\n                    if isinstance(d, int):\n                        int_dims.append(d)\n                    elif isinstance(d, str) and d.isdigit():\n                        int_dims.append(int(d))\n                    else:\n                        int_dims.append(2)  # Default dimension\n                \n                matrices[var_name] = int_dims\n        \n        # Analyze edge connections for matrix operations\n        for edge in edges:\n            source = edge.get('source', '')\n            target = edge.get('target', '')\n            \n            if source in matrices and target in matrices:\n                source_dims = matrices[source]\n                target_dims = matrices[target]\n                \n                # Matrix multiplication cost\n                if len(source_dims) >= 2 and len(target_dims) >= 2:\n                    m = source_dims[0]\n                    n = source_dims[1] if len(source_dims) > 1 else 1\n                    p = target_dims[1] if len(target_dims) > 1 else 1\n                    \n                    flops = m * n * p * self.OPERATION_COSTS['matrix_multiply']\n                    \n                    operation_costs[\"matrix_multiply\"].append({\n                        \"operation\": f\"{source} \u00d7 {target}\",\n                        \"dimensions\": f\"{m}\u00d7{n} * {n}\u00d7{p}\",\n                        \"flops\": flops\n                    })\n                    \n                    operation_costs[\"total_matrix_flops\"] += flops\n        \n        # Analyze equations for matrix operations\n        eq_lines = equations.split('\\n')\n        for line in eq_lines:\n            # Look for matrix transpose operations (A^T or transpose(A))\n            if '^T' in line or 'transpose' in line:\n                for matrix_name in matrices:\n                    if matrix_name in line and (f\"{matrix_name}^T\" in line or f\"transpose({matrix_name})\" in line):\n                        dims = matrices[matrix_name]\n                        m = dims[0]\n                        n = dims[1] if len(dims) > 1 else 1\n                        \n                        # Transpose costs m*n operations\n                        flops = m * n\n                        \n                        operation_costs[\"matrix_transpose\"].append({\n                            \"operation\": f\"{matrix_name}^T\",\n                            \"dimensions\": f\"{m}\u00d7{n}\",\n                            \"flops\": flops\n                        })\n                        \n                        operation_costs[\"total_matrix_flops\"] += flops\n            \n            # Look for matrix inversion operations (A^-1 or inv(A))\n            if '^-1' in line or 'inv(' in line:\n                for matrix_name in matrices:\n                    if matrix_name in line and (f\"{matrix_name}^-1\" in line or f\"inv({matrix_name})\" in line):\n                        dims = matrices[matrix_name]\n                        n = dims[0]  # Assume square matrix for inversion\n                        \n                        # Inversion costs approximately n^3 operations\n                        flops = n**3\n                        \n                        operation_costs[\"matrix_inversion\"].append({\n                            \"operation\": f\"{matrix_name}^-1\",\n                            \"dimensions\": f\"{n}\u00d7{n}\",\n                            \"flops\": flops\n                        })\n                        \n                        operation_costs[\"total_matrix_flops\"] += flops\n        \n        return operation_costs\n\n    def _estimate_model_overhead(self, variables: Dict[str, Any], edges: List[Dict[str, Any]], \n                               equations: str) -> Dict[str, Any]:\n        \"\"\"\n        Estimate model overhead including compile-time and optimization costs.\n        \n        Args:\n            variables: Dictionary of model variables\n            edges: List of edges in the model\n            equations: Equations in the model\n            \n        Returns:\n            Dictionary with model overhead estimates\n        \"\"\"\n        overhead = {\n            \"compilation_ms\": 0,\n            \"optimization_ms\": 0,\n            \"memory_overhead_kb\": 0\n        }\n        \n        # Estimate compilation time based on model complexity\n        var_count = len(variables)\n        edge_count = len(edges)\n        eq_count = len(equations.split('\\n'))\n        \n        # Simple heuristic: ~10ms base + 2ms per variable + 1ms per edge + 5ms per equation\n        compilation_ms = 10 + (var_count * 2) + (edge_count * 1) + (eq_count * 5)\n        overhead[\"compilation_ms\"] = compilation_ms\n        \n        # Optimization costs roughly scale with variables^2\n        optimization_ms = 20 + (var_count**2 * 0.5)\n        overhead[\"optimization_ms\"] = optimization_ms\n        \n        # Memory overhead: ~1KB base + 50 bytes per variable + 30 bytes per edge + 100 bytes per equation\n        memory_overhead_bytes = 1024 + (var_count * 50) + (edge_count * 30) + (eq_count * 100)\n        overhead[\"memory_overhead_kb\"] = memory_overhead_bytes / 1024.0\n        \n        return overhead\n    \n    def _estimate_inference(self, variables: Dict[str, Any], model_type: str, \n                            edges: List[Dict[str, Any]], equations: str) -> float:\n        \"\"\"\n        Estimate inference time requirements based on model complexity.\n        \n        Args:\n            variables: Dictionary of model variables\n            model_type: Type of model (Static, Dynamic, Hierarchical)\n            edges: List of edges in the model\n            equations: Equations in the model\n            \n        Returns:\n            Inference time estimate (arbitrary units)\n        \"\"\"\n        # Base time depends on model type\n        base_time = self.INFERENCE_FACTORS.get(model_type, self.INFERENCE_FACTORS['Static'])\n        \n        # Add time for variable processing - consider variable types\n        var_time = 0\n        for var_name, var_info in variables.items():\n            var_type = var_info.get('type', 'float')\n            dims = var_info.get('dimensions', [1])\n            \n            # Extract dimensions as integers or defaults\n            try:\n                # Get element count based on dimensions\n                element_count = 1\n                for d in dims:\n                    if isinstance(d, (int, float)):\n                        element_count *= int(d)\n                    elif isinstance(d, str) and d.isdigit():\n                        element_count *= int(d)\n                    elif isinstance(d, str) and 'len' in d:\n                        element_count *= 3  # Reasonable default\n                    elif isinstance(d, str) and d.startswith('='):\n                        import re\n                        matches = re.findall(r'\\d+', d)\n                        if matches:\n                            element_count *= int(matches[0])\n                        else:\n                            element_count *= 1\n                    else:\n                        element_count *= 1\n                \n                # Scale by type factor and element count\n                type_factor = self.INFERENCE_FACTORS.get(var_type, self.INFERENCE_FACTORS['float'])\n                var_time += type_factor * math.log2(element_count + 1)  # log scale to avoid explosion\n                \n            except Exception as e:\n                # Use default if calculation fails\n                var_time += self.INFERENCE_FACTORS.get(var_type, 1.0)\n        \n        # Add time for edge traversal - more for complex connections\n        # Each edge represents signal propagation with potential transformations\n        edge_time = 0\n        for edge in edges:\n            source = edge.get('source', '')\n            target = edge.get('target', '')\n            \n            # Temporal connections cost more (Dynamic models)\n            if '+' in source or '+' in target:\n                edge_time += 1.0  # Temporal connection\n            else:\n                edge_time += 0.5  # Standard connection\n        \n        # Add time for equation evaluation\n        equation_lines = equations.split('\\n')\n        equation_time = 0\n        \n        for line in equation_lines:\n            # Basic cost per equation\n            eq_cost = 2.0\n            \n            # Additional cost for complex operations\n            if 'softmax' in line or 'sigma' in line:\n                eq_cost += 1.5  # Nonlinear functions cost more\n            if '^' in line:  # Power operations or matrix transposes\n                eq_cost += 1.0\n            if 'sum' in line or '\u2211' in line:  # Summation operations\n                eq_cost += 1.0\n            \n            equation_time += eq_cost\n        \n        # For models with no equations, assume default complexity\n        if equation_time == 0 and len(equation_lines) > 0:\n            equation_time = len(equation_lines) * 2.0\n        \n        # Combine factors with weights\n        # - Base model type is most important (40%)\n        # - Variables and equations matter significantly (25% each)\n        # - Edge structure has some impact (10%)\n        weighted_time = (\n            base_time * 4.0 +\n            var_time * 2.5 +\n            edge_time * 1.0 +\n            equation_time * 2.5\n        ) / 10.0\n        \n        return weighted_time * 10.0  # Scale to get reasonable units\n    \n    def _estimate_storage(self, variables: Dict[str, Any], edges: List[Dict[str, Any]], equations: str) -> float:\n        \"\"\"\n        Estimate storage requirements based on model structure and size.\n        \n        Args:\n            variables: Dictionary of model variables\n            edges: List of edges in the model\n            equations: Equations in the model\n            \n        Returns:\n            Storage estimate in KB\n        \"\"\"\n        # Memory footprint forms the base of our storage estimate\n        memory_estimate = self._estimate_memory(variables)\n        \n        # Calculate structural overhead\n        # Model structure, format overhead, metadata, descriptions: ~1KB base + per-item costs\n        structural_overhead_kb = 1.0  \n        \n        # Add overhead for variable names, descriptions, and metadata\n        var_overhead_kb = 0.0\n        for var_name, var_info in variables.items():\n            # Each variable has name, type, dimension info, comments\n            var_desc_length = len(var_info.get('comment', ''))\n            var_overhead_kb += (len(var_name) + 24 + var_desc_length) / 1024.0\n        \n        # Add overhead for edge definitions\n        edge_overhead_kb = len(edges) * 0.1  # ~100 bytes per edge definition\n        \n        # Add overhead for equations (consider actual text length)\n        equation_overhead_kb = len(equations) * 0.001  # ~1 byte per character\n        \n        # Textual representation adds overhead on top of binary storage\n        format_overhead_kb = 0.5  # GNN format markup, spaces, structure\n        \n        # Combine all storage components\n        total_storage_kb = (\n            memory_estimate * 1.2 +  # Binary data storage with padding\n            structural_overhead_kb +\n            var_overhead_kb +\n            edge_overhead_kb +\n            equation_overhead_kb +\n            format_overhead_kb\n        )\n        \n        # Make sure we don't get unreasonably low estimates\n        return max(total_storage_kb, 1.0)\n    \n    def _calculate_complexity(self, variables: Dict[str, Any], edges: List[Dict[str, Any]], equations: str) -> Dict[str, float]:\n        \"\"\"\n        Calculate detailed complexity metrics for the model.\n        \n        Args:\n            variables: Dictionary of model variables\n            edges: List of edges in the model\n            equations: Equations in the model\n            \n        Returns:\n            Dictionary with complexity metrics\n        \"\"\"\n        # Get total dimensionality (state space complexity)\n        total_dims = 0\n        max_dim = 0\n        for var_info in variables.values():\n            dims = var_info.get('dimensions', [1])\n            # Convert dimensions to integers when possible\n            int_dims = []\n            for d in dims:\n                if isinstance(d, int):\n                    int_dims.append(d)\n                elif isinstance(d, str) and d.isdigit():\n                    int_dims.append(int(d))\n                else:\n                    int_dims.append(2)  # Default dimension size\n            \n            # Sum up total dimensionality\n            dim_size = math.prod(int_dims)\n            total_dims += dim_size\n            max_dim = max(max_dim, dim_size)\n        \n        # Calculate graph metrics\n        var_count = len(variables)\n        edge_count = len(edges)\n        \n        # Topological complexity\n        # Graph density: 0 (unconnected) to 1 (fully connected)\n        density = 0.0\n        if var_count > 1:\n            max_possible_edges = var_count * (var_count - 1)  # Directed graph\n            density = edge_count / max_possible_edges if max_possible_edges > 0 else 0\n        \n        # Calculate connectivity patterns\n        in_degree = {}\n        out_degree = {}\n        for edge in edges:\n            source = edge.get('source', '').split('+')[0]  # Remove time indices\n            target = edge.get('target', '').split('+')[0]\n            \n            out_degree[source] = out_degree.get(source, 0) + 1\n            in_degree[target] = in_degree.get(target, 0) + 1\n        \n        # Average degrees\n        avg_in_degree = sum(in_degree.values()) / max(len(in_degree), 1)\n        avg_out_degree = sum(out_degree.values()) / max(len(out_degree), 1)\n        \n        # Max degrees\n        max_in_degree = max(in_degree.values()) if in_degree else 0\n        max_out_degree = max(out_degree.values()) if out_degree else 0\n        \n        # Cyclic complexity - check for cyclic patterns (excluding self-loops)\n        # Simple approximation: higher connectivity often means more cycles\n        cyclic_score = 0\n        if edge_count > var_count:\n            cyclic_score = (edge_count - var_count) / max(var_count, 1)\n        \n        # Temporal complexity (look for time indices in edges)\n        temporal_edges = 0\n        for edge in edges:\n            if '+' in edge.get('source', '') or '+' in edge.get('target', ''):\n                temporal_edges += 1\n        \n        temporal_complexity = temporal_edges / max(edge_count, 1)\n        \n        # Equation complexity\n        eq_lines = equations.split('\\n')\n        avg_eq_length = sum(len(line) for line in eq_lines) / max(len(eq_lines), 1)\n        \n        # Count operators in equations as a measure of complexity\n        operators = 0\n        for line in eq_lines:\n            operators += line.count('+') + line.count('-') + line.count('*') + line.count('/') + line.count('^')\n        \n        # Higher-order operators indicate more complexity\n        higher_order_ops = 0\n        for line in eq_lines:\n            higher_order_ops += line.count('sum') + line.count('prod') + line.count('log') + line.count('exp')\n            higher_order_ops += line.count('softmax') + line.count('tanh') + line.count('sigma')\n        \n        # Combined equation complexity\n        equation_complexity = 0\n        if eq_lines:\n            equation_complexity = (avg_eq_length + operators + 3*higher_order_ops) / len(eq_lines)\n        \n        # State space complexity (measure of information capacity)\n        state_space_complexity = math.log2(total_dims + 1) if total_dims > 0 else 0\n        \n        # Overall complexity combines several factors:\n        # - State space (information capacity)\n        # - Connectivity (graph structure)\n        # - Temporal aspects (time dependencies)\n        # - Algorithmic complexity (equations)\n        overall_complexity = (\n            state_space_complexity * 0.25 +\n            (density + cyclic_score) * 0.25 +\n            temporal_complexity * 0.2 +\n            equation_complexity * 0.3\n        )\n        \n        # Scale to a reasonable range (0-10)\n        overall_complexity = min(10, overall_complexity * 2)\n        \n        return {\n            \"state_space_complexity\": state_space_complexity,\n            \"graph_density\": density,\n            \"avg_in_degree\": avg_in_degree,\n            \"avg_out_degree\": avg_out_degree,\n            \"max_in_degree\": max_in_degree,\n            \"max_out_degree\": max_out_degree,\n            \"cyclic_complexity\": cyclic_score,\n            \"temporal_complexity\": temporal_complexity,\n            \"equation_complexity\": equation_complexity,\n            \"overall_complexity\": overall_complexity,\n            \"variable_count\": var_count,\n            \"edge_count\": edge_count,\n            \"total_state_space_dim\": total_dims,\n            \"max_variable_dim\": max_dim\n        }\n    \n    def generate_html_report(self, output_dir: Optional[str] = None) -> str:\n        \"\"\"\n        Generate a comprehensive HTML report with visualizations and detailed explanations.\n        \n        Args:\n            output_dir: Directory to save report files\n            \n        Returns:\n            Path to the generated HTML report\n        \"\"\"\n        import json\n        from datetime import datetime\n        \n        if not self.results:\n            return \"No results to report. Run estimation first.\"\n        \n        # Create output directory\n        if output_dir:\n            output_path = Path(output_dir)\n        else:\n            output_path = Path(\"output/gnn_type_checker/resources\")\n        \n        output_path.mkdir(parents=True, exist_ok=True)\n        \n        # Generate visualizations for HTML embedding\n        vis_path = output_path / \"html_vis\"\n        vis_path.mkdir(exist_ok=True)\n        self._generate_visualizations_for_html(vis_path)\n        \n        # Create model comparison arrays for visualizations\n        models = []\n        memory_values = []\n        inference_values = []\n        storage_values = []\n        flops_values = []\n        \n        for file_path, result in sorted(self.results.items()):\n            if \"error\" not in result:\n                models.append(os.path.basename(file_path).replace(\".md\", \"\"))\n                memory_values.append(result[\"memory_estimate\"])\n                inference_values.append(result[\"inference_estimate\"])\n                storage_values.append(result[\"storage_estimate\"])\n                if \"flops_estimate\" in result:\n                    flops_values.append(result[\"flops_estimate\"][\"total_flops\"])\n                else:\n                    flops_values.append(0)\n        \n        # Start creating HTML content\n        html_content = f\"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>GNN Resource Estimation Report</title>\n    <script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n    <style>\n        body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; color: #333; max-width: 1200px; margin: 0 auto; }}\n        h1 {{ color: #2c3e50; margin-top: 20px; }}\n        h2 {{ color: #3498db; margin-top: 30px; }}\n        h3 {{ color: #2980b9; }}\n        .summary {{ background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px; }}\n        .chart-container {{ width: 100%; height: 400px; margin-bottom: 30px; }}\n        .metric-container {{ display: flex; flex-wrap: wrap; gap: 20px; margin-bottom: 30px; }}\n        .metric-box {{ flex: 1; min-width: 200px; background-color: #f8f9fa; padding: 15px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}\n        .metric-value {{ font-size: 24px; font-weight: bold; color: #2980b9; }}\n        .model-card {{ background-color: #fff; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 20px; padding: 15px; }}\n        .caption {{ font-style: italic; color: #555; margin-top: 5px; text-align: center; }}\n        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}\n        th, td {{ padding: 10px; text-align: left; border-bottom: 1px solid #ddd; }}\n        th {{ background-color: #f2f2f2; }}\n        tr:hover {{ background-color: #f5f5f5; }}\n        .resource-comparison {{ display: flex; gap: 20px; margin-bottom: 30px; }}\n        .resource-comparison > div {{ flex: 1; }}\n        .footer {{ margin-top: 30px; font-size: 0.8em; color: #777; text-align: center; }}\n    </style>\n</head>\n<body>\n    <h1>GNN Resource Estimation Report</h1>\n    <p>Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n    \n    <div class=\"summary\">\n        <h2>Summary</h2>\n        <p>This report provides detailed resource estimates for {len(models)} GNN models, analyzing their memory usage, computational requirements, and storage needs.</p>\n        \n        <div class=\"metric-container\">\n            <div class=\"metric-box\">\n                <h3>Average Memory Usage</h3>\n                <div class=\"metric-value\">{sum(memory_values)/len(memory_values):.2f} KB</div>\n                <p>RAM required to hold model in memory</p>\n            </div>\n            <div class=\"metric-box\">\n                <h3>Average Inference Time</h3>\n                <div class=\"metric-value\">{sum(inference_values)/len(inference_values):.2f} units</div>\n                <p>Relative computational cost</p>\n            </div>\n            <div class=\"metric-box\">\n                <h3>Average Storage</h3>\n                <div class=\"metric-value\">{sum(storage_values)/len(storage_values):.2f} KB</div>\n                <p>Disk space required to store model</p>\n            </div>\n        </div>\n    </div>\n    \n    <h2>Resource Visualizations</h2>\n    <p>The following visualizations provide a comparative analysis of resource requirements across different models.</p>\n    \n    <h3>Memory Usage Comparison</h3>\n    <div class=\"chart-container\">\n        <canvas id=\"memoryChart\"></canvas>\n    </div>\n    <p class=\"caption\">\n        <strong>Figure 1:</strong> Memory usage comparison showing RAM requirements (in KB) for each GNN model. \n        Memory usage is determined by the size and number of matrices and variables in the model. \n        Hierarchical models typically require more memory due to their multi-level structure.\n    </p>\n    \n    <h3>Inference Time Comparison</h3>\n    <div class=\"chart-container\">\n        <canvas id=\"inferenceChart\"></canvas>\n    </div>\n    <p class=\"caption\">\n        <strong>Figure 2:</strong> Inference time comparison showing relative computational cost for each model.\n        Higher values indicate more complex computations requiring more CPU/GPU time.\n        Dynamic models with temporal dependencies typically have higher inference costs than static models.\n    </p>\n    \n    <h3>Storage Requirements Comparison</h3>\n    <div class=\"chart-container\">\n        <canvas id=\"storageChart\"></canvas>\n    </div>\n    <p class=\"caption\">\n        <strong>Figure 3:</strong> Storage requirements showing disk space (in KB) needed to store each model.\n        Storage includes the base memory requirements plus additional overhead for model structure, \n        metadata, and equation representations.\n    </p>\n    \n    <h3>Normalized Resource Comparison</h3>\n    <div class=\"chart-container\">\n        <canvas id=\"comparisonChart\"></canvas>\n    </div>\n    <p class=\"caption\">\n        <strong>Figure 4:</strong> Normalized resource comparison showing relative requirements across all resource types.\n        Values are normalized to the highest value in each category to allow for direct comparison.\n        This visualization helps identify which resource dimension is most constraining for each model.\n    </p>\n\"\"\"\n\n        # Add computational complexity section\n        html_content += \"\"\"\n    <h2>Computational Complexity Analysis</h2>\n    <p>This section breaks down the computational complexity of each model in terms of operations required and algorithmic efficiency.</p>\n    \n    <div class=\"chart-container\">\n        <canvas id=\"flopsChart\"></canvas>\n    </div>\n    <p class=\"caption\">\n        <strong>Figure 5:</strong> Estimated floating-point operations (FLOPS) required for a single inference pass.\n        FLOPS count is calculated based on matrix operations, element-wise operations, and nonlinear function evaluations\n        in the model. Higher FLOPS indicate more computationally intensive models.\n    </p>\n    \n    <h3>Matrix Operation Costs</h3>\n    <p>Matrix operations typically dominate the computational cost of GNN models. The following table shows estimated costs for key operations.</p>\n    \n    <table>\n        <thead>\n            <tr>\n                <th>Model</th>\n                <th>Matrix Multiplications</th>\n                <th>Element-wise Ops</th>\n                <th>Nonlinear Ops</th>\n                <th>Total FLOPS</th>\n            </tr>\n        </thead>\n        <tbody>\n\"\"\"\n\n        # Add rows for each model with detailed FLOPS breakdown\n        for file_path, result in sorted(self.results.items()):\n            if \"error\" not in result and \"flops_estimate\" in result:\n                model_name = os.path.basename(file_path).replace(\".md\", \"\")\n                flops = result[\"flops_estimate\"]\n                \n                html_content += f\"\"\"\n            <tr>\n                <td>{model_name}</td>\n                <td>{flops.get(\"matrix_operations\", 0):.0f}</td>\n                <td>{flops.get(\"element_operations\", 0):.0f}</td>\n                <td>{flops.get(\"nonlinear_operations\", 0):.0f}</td>\n                <td>{flops.get(\"total_flops\", 0):.0f}</td>\n            </tr>\"\"\"\n\n        html_content += \"\"\"\n        </tbody>\n    </table>\n    <p class=\"caption\">\n        <strong>Table 1:</strong> Breakdown of computational operations by type for each model. \n        Matrix multiplications, element-wise operations, and nonlinear function evaluations contribute to the total FLOPS.\n    </p>\n\"\"\"\n\n        # Add model details section\n        html_content += \"\"\"\n    <h2>Individual Model Analysis</h2>\n    <p>This section provides detailed resource profiles for each individual model.</p>\n    \n    <div class=\"model-container\">\n\"\"\"\n\n        # Add cards for each model with detailed metrics\n        for file_path, result in sorted(self.results.items()):\n            if \"error\" not in result:\n                model_name = os.path.basename(file_path).replace(\".md\", \"\")\n                \n                # Get model type\n                model_type = \"Static\"\n                if file_path in self.detailed_metrics:\n                    model_type = self.detailed_metrics[file_path].get(\"model_type\", \"Static\")\n                \n                # Get complexity metrics\n                complexity = result.get(\"complexity\", {})\n                \n                # Create memory breakdown\n                memory_breakdown = {}\n                if file_path in self.detailed_metrics:\n                    memory_breakdown = self.detailed_metrics[file_path].get(\"memory_breakdown\", {})\n                \n                html_content += f\"\"\"\n        <div class=\"model-card\">\n            <h3>{model_name}</h3>\n            <p><strong>Type:</strong> {model_type} model</p>\n            \n            <div class=\"resource-comparison\">\n                <div>\n                    <h4>Memory Usage</h4>\n                    <div class=\"metric-value\">{result[\"memory_estimate\"]:.2f} KB</div>\n                    <p>Variables: {result[\"model_info\"][\"variables_count\"]}</p>\n                </div>\n                <div>\n                    <h4>Inference Time</h4>\n                    <div class=\"metric-value\">{result[\"inference_estimate\"]:.2f} units</div>\n                    <p>Edges: {result[\"model_info\"][\"edges_count\"]}</p>\n                </div>\n                <div>\n                    <h4>Storage</h4>\n                    <div class=\"metric-value\">{result[\"storage_estimate\"]:.2f} KB</div>\n                    <p>Equations: {result[\"model_info\"][\"equation_count\"]}</p>\n                </div>\n            </div>\n            \n            <h4>Complexity Metrics</h4>\n            <table>\n                <tr>\n                    <td>State Space Complexity</td>\n                    <td>{complexity.get(\"state_space_complexity\", 0):.2f}</td>\n                    <td>Graph Density</td>\n                    <td>{complexity.get(\"graph_density\", 0):.2f}</td>\n                </tr>\n                <tr>\n                    <td>Temporal Complexity</td>\n                    <td>{complexity.get(\"temporal_complexity\", 0):.2f}</td>\n                    <td>Equation Complexity</td>\n                    <td>{complexity.get(\"equation_complexity\", 0):.2f}</td>\n                </tr>\n                <tr>\n                    <td>Overall Complexity</td>\n                    <td colspan=\"3\">{complexity.get(\"overall_complexity\", 0):.2f} / 10.0</td>\n                </tr>\n            </table>\n        </div>\n\"\"\"\n\n        # Add explanation section\n        html_content += \"\"\"\n    </div>\n    \n    <h2>Understanding Resource Metrics</h2>\n    <p>This section explains how each resource metric is calculated and what it means for model performance.</p>\n    \n    <h3>Memory Usage</h3>\n    <p>Memory usage estimates the amount of RAM required to hold the model in memory during inference. It accounts for:</p>\n    <ul>\n        <li><strong>Variable Storage:</strong> Size of all matrices and vectors in the model</li>\n        <li><strong>Type Considerations:</strong> Different data types (float, int, bool) require different amounts of memory</li>\n        <li><strong>Dimension Analysis:</strong> Higher-dimensional state spaces consume more memory</li>\n    </ul>\n    <p>The memory estimate is calculated based on the dimensions of each variable and its data type, using standard sizes (4 bytes for float/int, 1 byte for bool, etc.).</p>\n    \n    <h3>Inference Time</h3>\n    <p>Inference time estimates the relative computational cost of running the model for a single inference pass. It considers:</p>\n    <ul>\n        <li><strong>Model Type:</strong> Static vs. Dynamic vs. Hierarchical architecture</li>\n        <li><strong>Matrix Operations:</strong> Primarily matrix multiplications which dominate computational cost</li>\n        <li><strong>Nonlinear Functions:</strong> Operations like softmax, sigmoid, or tanh which are computationally expensive</li>\n        <li><strong>Connectivity:</strong> Edge structure and temporal relationships that affect computation flow</li>\n    </ul>\n    <p>The inference time is provided in relative units, with higher values indicating more complex computations requiring more processing time.</p>\n    \n    <h3>Storage Requirements</h3>\n    <p>Storage requirements estimate the disk space needed to persist the model. This includes:</p>\n    <ul>\n        <li><strong>Base Memory Footprint:</strong> Same as memory usage</li>\n        <li><strong>Format Overhead:</strong> Additional space for storing the model structure</li>\n        <li><strong>Metadata:</strong> Variable names, comments, equations, etc.</li>\n    </ul>\n    <p>Storage is typically larger than memory usage due to the additional structural information needed to fully represent the model on disk.</p>\n    \n    <h3>Computational Complexity</h3>\n    <p>Computational complexity provides a deeper analysis of the algorithmic efficiency of the model:</p>\n    <ul>\n        <li><strong>FLOPS (Floating Point Operations):</strong> Count of arithmetic operations needed for inference</li>\n        <li><strong>Matrix Operation Costs:</strong> Detailed breakdown of matrix multiplication, transpose, and inversion costs</li>\n        <li><strong>State Space Complexity:</strong> Measure of the model's information capacity</li>\n        <li><strong>Structural Complexity:</strong> Analysis of the edge structure and connectivity patterns</li>\n    </ul>\n    <p>These metrics help identify bottlenecks and optimize model architecture for better performance.</p>\n\"\"\"\n\n        # Add JavaScript for chart rendering\n        html_content += f\"\"\"\n    <script>\n        // Memory usage chart\n        const memoryCtx = document.getElementById('memoryChart').getContext('2d');\n        new Chart(memoryCtx, {{\n            type: 'bar',\n            data: {{\n                labels: {json.dumps(models)},\n                datasets: [{{\n                    label: 'Memory Usage (KB)',\n                    data: {json.dumps(memory_values)},\n                    backgroundColor: 'rgba(75, 192, 192, 0.2)',\n                    borderColor: 'rgba(75, 192, 192, 1)',\n                    borderWidth: 1\n                }}]\n            }},\n            options: {{\n                scales: {{\n                    y: {{\n                        beginAtZero: true,\n                        title: {{\n                            display: true,\n                            text: 'Memory Usage (KB)'\n                        }}\n                    }},\n                    x: {{\n                        title: {{\n                            display: true,\n                            text: 'Model'\n                        }}\n                    }}\n                }},\n                plugins: {{\n                    legend: {{\n                        display: false\n                    }}\n                }}\n            }}\n        }});\n        \n        // Inference time chart\n        const inferenceCtx = document.getElementById('inferenceChart').getContext('2d');\n        new Chart(inferenceCtx, {{\n            type: 'bar',\n            data: {{\n                labels: {json.dumps(models)},\n                datasets: [{{\n                    label: 'Inference Time (units)',\n                    data: {json.dumps(inference_values)},\n                    backgroundColor: 'rgba(153, 102, 255, 0.2)',\n                    borderColor: 'rgba(153, 102, 255, 1)',\n                    borderWidth: 1\n                }}]\n            }},\n            options: {{\n                scales: {{\n                    y: {{\n                        beginAtZero: true,\n                        title: {{\n                            display: true,\n                            text: 'Inference Time (arbitrary units)'\n                        }}\n                    }},\n                    x: {{\n                        title: {{\n                            display: true,\n                            text: 'Model'\n                        }}\n                    }}\n                }},\n                plugins: {{\n                    legend: {{\n                        display: false\n                    }}\n                }}\n            }}\n        }});\n        \n        // Storage chart\n        const storageCtx = document.getElementById('storageChart').getContext('2d');\n        new Chart(storageCtx, {{\n            type: 'bar',\n            data: {{\n                labels: {json.dumps(models)},\n                datasets: [{{\n                    label: 'Storage (KB)',\n                    data: {json.dumps(storage_values)},\n                    backgroundColor: 'rgba(255, 159, 64, 0.2)',\n                    borderColor: 'rgba(255, 159, 64, 1)',\n                    borderWidth: 1\n                }}]\n            }},\n            options: {{\n                scales: {{\n                    y: {{\n                        beginAtZero: true,\n                        title: {{\n                            display: true,\n                            text: 'Storage Requirements (KB)'\n                        }}\n                    }},\n                    x: {{\n                        title: {{\n                            display: true,\n                            text: 'Model'\n                        }}\n                    }}\n                }},\n                plugins: {{\n                    legend: {{\n                        display: false\n                    }}\n                }}\n            }}\n        }});\n        \n        // Normalized comparison chart\n        const comparisonCtx = document.getElementById('comparisonChart').getContext('2d');\n        \n        // Normalize data\n        const maxMemory = Math.max(...{json.dumps(memory_values)});\n        const maxInference = Math.max(...{json.dumps(inference_values)});\n        const maxStorage = Math.max(...{json.dumps(storage_values)});\n        \n        const normMemory = {json.dumps(memory_values)}.map(v => v / maxMemory);\n        const normInference = {json.dumps(inference_values)}.map(v => v / maxInference);\n        const normStorage = {json.dumps(storage_values)}.map(v => v / maxStorage);\n        \n        new Chart(comparisonCtx, {{\n            type: 'bar',\n            data: {{\n                labels: {json.dumps(models)},\n                datasets: [\n                    {{\n                        label: 'Memory',\n                        data: normMemory,\n                        backgroundColor: 'rgba(75, 192, 192, 0.2)',\n                        borderColor: 'rgba(75, 192, 192, 1)',\n                        borderWidth: 1\n                    }},\n                    {{\n                        label: 'Inference',\n                        data: normInference,\n                        backgroundColor: 'rgba(153, 102, 255, 0.2)',\n                        borderColor: 'rgba(153, 102, 255, 1)',\n                        borderWidth: 1\n                    }},\n                    {{\n                        label: 'Storage',\n                        data: normStorage,\n                        backgroundColor: 'rgba(255, 159, 64, 0.2)',\n                        borderColor: 'rgba(255, 159, 64, 1)',\n                        borderWidth: 1\n                    }}\n                ]\n            }},\n            options: {{\n                scales: {{\n                    y: {{\n                        beginAtZero: true,\n                        title: {{\n                            display: true,\n                            text: 'Normalized Resource Usage'\n                        }}\n                    }},\n                    x: {{\n                        title: {{\n                            display: true,\n                            text: 'Model'\n                        }}\n                    }}\n                }}\n            }}\n        }});\n        \n        // FLOPS chart\n        const flopsCtx = document.getElementById('flopsChart').getContext('2d');\n        new Chart(flopsCtx, {{\n            type: 'bar',\n            data: {{\n                labels: {json.dumps(models)},\n                datasets: [{{\n                    label: 'FLOPS',\n                    data: {json.dumps(flops_values)},\n                    backgroundColor: 'rgba(54, 162, 235, 0.2)',\n                    borderColor: 'rgba(54, 162, 235, 1)',\n                    borderWidth: 1\n                }}]\n            }},\n            options: {{\n                scales: {{\n                    y: {{\n                        beginAtZero: true,\n                        title: {{\n                            display: true,\n                            text: 'Floating Point Operations'\n                        }}\n                    }},\n                    x: {{\n                        title: {{\n                            display: true,\n                            text: 'Model'\n                        }}\n                    }}\n                }},\n                plugins: {{\n                    legend: {{\n                        display: false\n                    }}\n                }}\n            }}\n        }});\n    </script>\n    \n    <div class=\"footer\">\n        <p>Generated by GNN Resource Estimator | GNN Type Checker</p>\n    </div>\n</body>\n</html>\n\"\"\"\n\n        # Save HTML report\n        html_report_path = output_path / \"resource_report_detailed.html\"\n        with open(html_report_path, 'w') as f:\n            f.write(html_content)\n        \n        return str(html_report_path)\n    \n    def _generate_visualizations_for_html(self, output_dir: Path) -> None:\n        \"\"\"\n        Generate visualizations specifically for HTML embedding.\n        \n        Args:\n            output_dir: Directory to save visualizations\n        \"\"\"\n        if not self.results:\n            return\n        \n        # Extract data for plots\n        files = [os.path.basename(file_path) for file_path in self.results.keys()]\n        memory_values = [result[\"memory_estimate\"] for result in self.results.values() if \"error\" not in result and result[\"memory_estimate\"] is not None]\n        inference_values = [result[\"inference_estimate\"] for result in self.results.values() if \"error\" not in result and result[\"inference_estimate\"] is not None]\n        storage_values = [result[\"storage_estimate\"] for result in self.results.values() if \"error\" not in result and result[\"storage_estimate\"] is not None]\n        \n        # Check if we have any valid data for visualization\n        if not memory_values or not inference_values or not storage_values:\n            print(\"Warning: No valid resource estimates available for HTML visualizations\")\n            return\n            \n        # Short file names for better display\n        short_files = [f[:20] + \"...\" if len(f) > 20 else f for f in files[:len(memory_values)]]\n        \n        # Memory usage plot with custom styling for HTML\n        plt.figure(figsize=(10, 6))\n        ax = plt.gca()\n        bars = plt.bar(short_files, memory_values, color='skyblue')\n        \n        # Add data labels on top of bars\n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                    f'{height:.2f}',\n                    ha='center', va='bottom', fontsize=9)\n        \n        plt.title('Memory Usage Estimates', fontsize=14, fontweight='bold')\n        plt.xlabel('Model File', fontsize=12)\n        plt.ylabel('Memory Usage (KB)', fontsize=12)\n        plt.xticks(rotation=45, ha='right', fontsize=10)\n        plt.grid(axis='y', linestyle='--', alpha=0.7)\n        plt.tight_layout()\n        plt.savefig(output_dir / \"memory_usage_html.png\", dpi=120, bbox_inches='tight')\n        plt.close()\n        \n        # Inference time plot with custom styling\n        plt.figure(figsize=(10, 6))\n        bars = plt.bar(short_files, inference_values, color='lightgreen')\n        \n        # Add data labels\n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                    f'{height:.2f}',\n                    ha='center', va='bottom', fontsize=9)\n        \n        plt.title('Inference Time Estimates', fontsize=14, fontweight='bold')\n        plt.xlabel('Model File', fontsize=12)\n        plt.ylabel('Inference Time (arbitrary units)', fontsize=12)\n        plt.xticks(rotation=45, ha='right', fontsize=10)\n        plt.grid(axis='y', linestyle='--', alpha=0.7)\n        plt.tight_layout()\n        plt.savefig(output_dir / \"inference_time_html.png\", dpi=120, bbox_inches='tight')\n        plt.close()\n        \n        # Storage requirements plot with custom styling\n        plt.figure(figsize=(10, 6))\n        bars = plt.bar(short_files, storage_values, color='salmon')\n        \n        # Add data labels\n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                    f'{height:.2f}',\n                    ha='center', va='bottom', fontsize=9)\n        \n        plt.title('Storage Requirements Estimates', fontsize=14, fontweight='bold')\n        plt.xlabel('Model File', fontsize=12)\n        plt.ylabel('Storage (KB)', fontsize=12)\n        plt.xticks(rotation=45, ha='right', fontsize=10)\n        plt.grid(axis='y', linestyle='--', alpha=0.7)\n        plt.tight_layout()\n        plt.savefig(output_dir / \"storage_requirements_html.png\", dpi=120, bbox_inches='tight')\n        plt.close()\n\n    def generate_report(self, output_dir: Optional[str] = None, project_root_path: Optional[Union[str, Path]] = None) -> str:\n        \"\"\"\n        Generate a markdown report and JSON data of the resource estimates.\n        \n        Args:\n            output_dir: Directory to save the report and JSON data. \n                        If None, defaults to a subdirectory 'resource_estimates' in the current working directory.\n            project_root_path: Optional path to the project root for making file paths relative in the report.\n\n        Returns:\n            String summary of the report.\n        \"\"\"\n        if not self.results:\n            return \"No GNN models processed for resource estimation.\"\n\n        output_path = Path(output_dir if output_dir else \"resource_estimates\").resolve()\n        output_path.mkdir(parents=True, exist_ok=True)\n        \n        report_file = output_path / \"resource_report.md\"\n        json_file = output_path / \"resource_data.json\"\n\n        # Resolve project_root once\n        actual_project_root = None\n        if project_root_path:\n            actual_project_root = Path(project_root_path).resolve()\n\n        # Calculate averages\n        total_files = len(self.results)\n        valid_results = [r for r in self.results.values() if \"error\" not in r and r[\"memory_estimate\"] is not None]\n        \n        if valid_results:\n            avg_memory = sum(r[\"memory_estimate\"] for r in valid_results) / len(valid_results)\n            avg_inference = sum(r[\"inference_estimate\"] for r in valid_results) / len(valid_results)\n            avg_storage = sum(r[\"storage_estimate\"] for r in valid_results) / len(valid_results)\n            \n            report_content = [\"# GNN Resource Estimation Report\", \"\"]\n            report_content.append(f\"Analyzed {total_files} files\")\n            report_content.append(f\"Average Memory Usage: {avg_memory:.2f} KB\")\n            report_content.append(f\"Average Inference Time: {avg_inference:.2f} units\")\n            report_content.append(f\"Average Storage: {avg_storage:.2f} KB\")\n            report_content.append(\"\")\n        else:\n            report_content = [\"# GNN Resource Estimation Report\", \"\"]\n            report_content.append(f\"Analyzed {total_files} files, but no valid results were obtained.\")\n            report_content.append(\"Check for errors in the analysis.\")\n            report_content.append(\"\")\n\n        for file_path_str, res in self.results.items():\n            if res.get(\"error\"):\n                report_content.append(f\"## {Path(file_path_str).name}\")\n                report_content.append(f\"Path: {file_path_str}\") # Keep original path if error occurred before resolving\n                report_content.append(f\"Error: {res['error']}\")\n                report_content.append(\"\")\n                continue\n            \n            file_path_obj = Path(file_path_str).resolve()\n            display_path = file_path_str\n            if actual_project_root:\n                try:\n                    display_path = str(file_path_obj.relative_to(actual_project_root))\n                except ValueError:\n                    display_path = file_path_obj.name # Fallback\n\n            report_content.append(f\"## {file_path_obj.name}\")\n            report_content.append(f\"Path: {display_path}\")\n            report_content.append(f\"Memory Estimate: {res['memory_estimate']:.2f} KB\")\n            report_content.append(f\"Inference Estimate: {res['inference_estimate']:.2f} units\")\n            report_content.append(f\"Storage Estimate: {res['storage_estimate']:.2f} KB\")\n            report_content.append(\"\")\n            \n            report_content.append(\"### Model Info\")\n            for key, value in res[\"model_info\"].items():\n                report_content.append(f\"- {key}: {value}\")\n            \n            report_content.append(\"\")\n            \n            report_content.append(\"### Complexity Metrics\")\n            for key, value in res[\"complexity\"].items():\n                if isinstance(value, (int, float)):\n                    report_content.append(f\"- {key}: {value:.4f}\")\n                else:\n                    report_content.append(f\"- {key}: {value}\")\n            \n            report_content.append(\"\")\n\n        report_content.append(\"# Metric Definitions\")\n        report_content.append(\"\")\n        report_content.append(\"## General Metrics\")\n        report_content.append(\"- **Memory Estimate (KB):** Estimated RAM required to hold the model's variables and data structures in memory. Calculated based on variable dimensions and data types (e.g., float: 4 bytes, int: 4 bytes).\")\n        report_content.append(\"- **Inference Estimate (units):** A relative, abstract measure of computational cost for a single inference pass. It is derived from factors like model type (Static, Dynamic, Hierarchical), the number and type of variables, the complexity of connections (edges), and the operations defined in equations. Higher values indicate a more computationally intensive model. These units are not tied to a specific hardware time (e.g., milliseconds) but allow for comparison between different GNN models.\")\n        report_content.append(\"- **Storage Estimate (KB):** Estimated disk space required to store the model file. This includes the memory footprint of the data plus overhead for the GNN textual representation, metadata, comments, and equations.\")\n        report_content.append(\"\")\n        report_content.append(\"## Complexity Metrics (scores are generally relative; higher often means more complex)\")\n        report_content.append(\"- **state_space_complexity:** Logarithmic measure of the total dimensionality of all variables (sum of the product of dimensions for each variable). Represents the model's theoretical information capacity or the size of its state space.\")\n        report_content.append(\"- **graph_density:** Ratio of actual edges to the maximum possible edges in the model graph. A value of 0 indicates no connections, while 1 would mean a fully connected graph. Measures how interconnected the variables are.\")\n        report_content.append(\"- **avg_in_degree:** Average number of incoming connections (edges) per variable.\")\n        report_content.append(\"- **avg_out_degree:** Average number of outgoing connections (edges) per variable.\")\n        report_content.append(\"- **max_in_degree:** Maximum number of incoming connections for any single variable in the model.\")\n        report_content.append(\"- **max_out_degree:** Maximum number of outgoing connections for any single variable in the model.\")\n        report_content.append(\"- **cyclic_complexity:** A score indicating the presence and extent of cyclic patterns or feedback loops in the graph. Approximated based on the ratio of edges to variables; higher values suggest more complex recurrent interactions.\")\n        report_content.append(\"- **temporal_complexity:** Proportion of edges that involve time dependencies (e.g., connecting a variable at time `t` to one at `t+1`). Indicates the degree to which the model's behavior depends on past states or sequences.\")\n        report_content.append(\"- **equation_complexity:** A measure based on the average length, number, and types of mathematical operators (e.g., +, *, log, softmax) used in the model's equations. Higher values suggest more intricate mathematical relationships between variables.\")\n        report_content.append(\"- **overall_complexity:** A weighted composite score (typically scaled, e.g., 0-10) that combines state space size, graph structure (density, cyclicity), temporal aspects, and equation complexity to provide a single, holistic measure of the model's intricacy.\")\n        report_content.append(\"\")\n\n        report = \"\\n\".join(report_content)\n        \n        # Save text report\n        report_path = output_path / \"resource_report.md\"\n        with open(report_path, 'w') as f:\n            f.write(report)\n        \n        # Generate visualizations\n        self._generate_visualizations_for_html(output_path)\n        \n        # Generate HTML report with detailed explanations\n        html_report_path = self.generate_html_report(str(output_path))\n        \n        # Save JSON data\n        json_path = output_path / \"resource_data.json\"\n        with open(json_path, 'w') as f:\n            json.dump(self.results, f, indent=2)\n        \n        return report\n\n    def _generate_visualizations(self, output_dir: Path) -> None:\n        \"\"\"\n        Generate visualizations of resource estimates.\n        \n        Args:\n            output_dir: Directory to save visualizations\n        \"\"\"\n        # For backward compatibility, just call the new method\n        self._generate_visualizations_for_html(output_dir)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 72,
        "end_line": 90,
        "code": "def __init__(self, type_check_data: Optional[str] = None):\n        \"\"\"\n        Initialize the resource estimator.\n        \n        Args:\n            type_check_data: Path to JSON data from type checker\n        \"\"\"\n        self.results = {}\n        self.detailed_metrics = {}\n        \n        if type_check_data:\n            try:\n                with open(type_check_data, 'r') as f:\n                    self.type_check_data = json.load(f)\n            except (FileNotFoundError, json.JSONDecodeError) as e:\n                print(f\"Warning: Could not load type check data: {e}\")\n                self.type_check_data = None\n        else:\n            self.type_check_data = None",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "estimate_from_file",
        "type": "method",
        "start_line": 92,
        "end_line": 118,
        "code": "def estimate_from_file(self, file_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Estimate resources for a single GNN file.\n        \n        Args:\n            file_path: Path to GNN file\n            \n        Returns:\n            Dictionary with resource estimates\n        \"\"\"\n        from visualization.parser import GNNParser\n        \n        parser = GNNParser()\n        \n        try:\n            # Parse the file\n            content = parser.parse_file(file_path)\n            return self._analyze_model(content, file_path)\n        except Exception as e:\n            print(f\"Error analyzing {file_path}: {str(e)}\")\n            return {\n                \"file\": file_path,\n                \"error\": str(e),\n                \"memory_estimate\": None,\n                \"inference_estimate\": None,\n                \"storage_estimate\": None\n            }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "estimate_from_directory",
        "type": "method",
        "start_line": 120,
        "end_line": 142,
        "code": "def estimate_from_directory(self, dir_path: str, recursive: bool = False) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Estimate resources for all GNN files in a directory.\n        \n        Args:\n            dir_path: Path to directory with GNN files\n            recursive: Whether to recursively process subdirectories\n            \n        Returns:\n            Dictionary mapping file paths to resource estimates\n        \"\"\"\n        path = Path(dir_path)\n        results = {}\n        \n        # Define pattern for GNN files\n        pattern = \"**/*.md\" if recursive else \"*.md\"\n        \n        for file_path in path.glob(pattern):\n            file_str = str(file_path)\n            results[file_str] = self.estimate_from_file(file_str)\n        \n        self.results = results\n        return results",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_analyze_model",
        "type": "method",
        "start_line": 144,
        "end_line": 219,
        "code": "def _analyze_model(self, content: Dict[str, Any], file_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a GNN model and estimate resources.\n        \n        Args:\n            content: Parsed GNN content\n            file_path: Path to source file\n            \n        Returns:\n            Dictionary with resource estimates\n        \"\"\"\n        # Extract key model information\n        variables = content.get('Variables', {})\n        time_spec = content.get('Time', 'Static').split('\\n')[0].strip()\n        edges = content.get('Edges', [])\n        equations = content.get('Equations', '')\n        \n        # Extract model name\n        model_name = content.get('ModelName', os.path.basename(file_path))\n        \n        # Determine if model is hierarchical\n        is_hierarchical = any('hierarchical' in key.lower() for key in content.keys())\n        if is_hierarchical:\n            model_type = 'Hierarchical'\n        else:\n            model_type = time_spec\n        \n        # Basic estimates\n        memory_estimate = self._estimate_memory(variables)\n        inference_estimate = self._estimate_inference(variables, model_type, edges, equations)\n        storage_estimate = self._estimate_storage(variables, edges, equations)\n        \n        # Advanced estimates\n        flops_estimate = self._estimate_flops(variables, edges, equations, model_type)\n        inference_time_estimate = self._estimate_inference_time(flops_estimate)\n        batched_inference_estimate = self._estimate_batched_inference(variables, model_type, flops_estimate)\n        model_overhead = self._estimate_model_overhead(variables, edges, equations)\n        \n        # More detailed matrix operation estimates\n        matrix_operation_costs = self._estimate_matrix_operation_costs(variables, edges, equations)\n        \n        # Detailed memory breakdowns\n        memory_breakdown = self._detailed_memory_breakdown(variables)\n        \n        # Calculate complexity metrics\n        complexity = self._calculate_complexity(variables, edges, equations)\n        \n        # Store detailed metrics for HTML report\n        self.detailed_metrics[file_path] = {\n            \"flops_estimate\": flops_estimate,\n            \"inference_time_estimate\": inference_time_estimate,\n            \"batched_inference_estimate\": batched_inference_estimate,\n            \"model_overhead\": model_overhead,\n            \"matrix_operation_costs\": matrix_operation_costs,\n            \"memory_breakdown\": memory_breakdown,\n            \"model_type\": model_type\n        }\n        \n        return {\n            \"file\": file_path,\n            \"model_name\": model_name,\n            \"memory_estimate\": memory_estimate,\n            \"inference_estimate\": inference_estimate,\n            \"storage_estimate\": storage_estimate,\n            \"flops_estimate\": flops_estimate,\n            \"inference_time_estimate\": inference_time_estimate,\n            \"batched_inference_estimate\": batched_inference_estimate,\n            \"model_overhead\": model_overhead,\n            \"complexity\": complexity,\n            \"model_info\": {\n                \"variables_count\": len(variables),\n                \"edges_count\": len(edges),\n                \"time_spec\": time_spec,\n                \"equation_count\": len(equations.split('\\n'))\n            }\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_estimate_memory",
        "type": "method",
        "start_line": 221,
        "end_line": 271,
        "code": "def _estimate_memory(self, variables: Dict[str, Any]) -> float:\n        \"\"\"\n        Estimate memory requirements based on variables.\n        \n        Args:\n            variables: Dictionary of model variables\n            \n        Returns:\n            Memory estimate in KB\n        \"\"\"\n        total_memory = 0.0\n        \n        for var_name, var_info in variables.items():\n            var_type = var_info.get('type', 'float')\n            dims = var_info.get('dimensions', [1])\n            \n            # Calculate size of this variable\n            size_factor = self.MEMORY_FACTORS.get(var_type, self.MEMORY_FACTORS['float'])\n            \n            # Process dimensions with caution - handle symbolic dimensions\n            try:\n                dimension_values = []\n                for d in dims:\n                    if isinstance(d, (int, float)):\n                        dimension_values.append(d)\n                    elif isinstance(d, str) and d.isdigit():\n                        dimension_values.append(int(d))\n                    elif isinstance(d, str) and 'len' in d and '\u03c0' in d:\n                        # Approximate the size for dynamic dimensions referencing policy length\n                        dimension_values.append(3)  # Reasonable default for policy length\n                    elif isinstance(d, str) and d.startswith('='):\n                        # Handle '=[2]' or '=[2,1]' format by extracting numbers\n                        import re\n                        matches = re.findall(r'\\d+', d)\n                        if matches:\n                            dimension_values.append(int(matches[0]))\n                        else:\n                            dimension_values.append(1)\n                    else:\n                        dimension_values.append(1)  # Default for unparseable dimensions\n                \n                total_size = size_factor * math.prod(dimension_values)\n            except Exception as e:\n                print(f\"Warning: Error calculating size for variable {var_name}: {e}\")\n                # Use a default size based on variable type\n                total_size = size_factor * 2  # Assume small dimensions as fallback\n            \n            total_memory += total_size\n        \n        # Convert to KB\n        return total_memory / 1024.0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_detailed_memory_breakdown",
        "type": "method",
        "start_line": 273,
        "end_line": 351,
        "code": "def _detailed_memory_breakdown(self, variables: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Create detailed memory breakdown by variable and type.\n        \n        Args:\n            variables: Dictionary of model variables\n            \n        Returns:\n            Dictionary with detailed memory breakdown\n        \"\"\"\n        breakdown = {\n            \"by_variable\": {},\n            \"by_type\": {t: 0 for t in self.MEMORY_FACTORS.keys()},\n            \"total_bytes\": 0,\n            \"representation_overhead\": 0  # Additional overhead for representation\n        }\n        \n        # Fixed overhead for model structure\n        breakdown[\"representation_overhead\"] = 1024  # Approx 1KB for basic model structure\n        \n        for var_name, var_info in variables.items():\n            var_type = var_info.get('type', 'float')\n            dims = var_info.get('dimensions', [1])\n            \n            # Calculate size of this variable\n            size_factor = self.MEMORY_FACTORS.get(var_type, self.MEMORY_FACTORS['float'])\n            \n            # Process dimensions\n            try:\n                dimension_values = []\n                for d in dims:\n                    if isinstance(d, (int, float)):\n                        dimension_values.append(d)\n                    elif isinstance(d, str) and d.isdigit():\n                        dimension_values.append(int(d))\n                    elif isinstance(d, str) and ('len' in d or '\u03c0' in d):\n                        dimension_values.append(3)\n                    elif isinstance(d, str) and d.startswith('='):\n                        import re\n                        matches = re.findall(r'\\d+', d)\n                        if matches:\n                            dimension_values.append(int(matches[0]))\n                        else:\n                            dimension_values.append(1)\n                    else:\n                        dimension_values.append(1)\n                \n                element_count = math.prod(dimension_values)\n                var_size = size_factor * element_count\n                \n                # Additional overhead for variable names and metadata\n                var_overhead = len(var_name) + 24  # ~24 bytes overhead per variable\n                \n                breakdown[\"by_variable\"][var_name] = {\n                    \"size_bytes\": var_size,\n                    \"elements\": element_count,\n                    \"dimensions\": dimension_values,\n                    \"type\": var_type,\n                    \"overhead_bytes\": var_overhead,\n                    \"total_bytes\": var_size + var_overhead\n                }\n                \n                # Add to type totals\n                breakdown[\"by_type\"][var_type] = breakdown[\"by_type\"].get(var_type, 0) + var_size\n                \n                # Add to total bytes\n                breakdown[\"total_bytes\"] += var_size + var_overhead\n                \n                # Add to representation overhead\n                breakdown[\"representation_overhead\"] += var_overhead\n                \n            except Exception as e:\n                print(f\"Warning: Error in memory breakdown for {var_name}: {e}\")\n        \n        # Convert totals to KB for convenience\n        breakdown[\"total_kb\"] = breakdown[\"total_bytes\"] / 1024.0\n        breakdown[\"overhead_kb\"] = breakdown[\"representation_overhead\"] / 1024.0\n        \n        return breakdown",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_estimate_flops",
        "type": "method",
        "start_line": 353,
        "end_line": 444,
        "code": "def _estimate_flops(self, variables: Dict[str, Any], edges: List[Dict[str, Any]], \n                       equations: str, model_type: str) -> Dict[str, Any]:\n        \"\"\"\n        Estimate floating-point operations (FLOPS) required for inference.\n        \n        Args:\n            variables: Dictionary of model variables\n            edges: List of edges in the model\n            equations: Equations in the model\n            model_type: Type of model (Static, Dynamic, Hierarchical)\n            \n        Returns:\n            Dictionary with FLOPS estimates\n        \"\"\"\n        flops_estimate = {\n            \"total_flops\": 0,\n            \"matrix_operations\": 0,\n            \"element_operations\": 0,\n            \"nonlinear_operations\": 0\n        }\n        \n        # Count matrices and their dimensions\n        matrices = {}\n        for var_name, var_info in variables.items():\n            dims = var_info.get('dimensions', [1])\n            if len(dims) >= 2:  # It's a matrix\n                matrices[var_name] = dims\n        \n        # Estimate matrix multiplication costs (dominant operation)\n        for edge in edges:\n            source = edge.get('source', '')\n            target = edge.get('target', '')\n            \n            if source in matrices and target in matrices:\n                source_dims = matrices[source]\n                target_dims = matrices[target]\n                \n                # Matrix multiply cost: m\u00d7n\u00d7p operations for m\u00d7n * n\u00d7p matrices\n                if len(source_dims) >= 2 and len(target_dims) >= 2:\n                    try:\n                        # Extract dimensions as integers when possible\n                        m = int(source_dims[0]) if isinstance(source_dims[0], (int, str)) and (isinstance(source_dims[0], int) or source_dims[0].isdigit()) else 2\n                        n = int(source_dims[1]) if isinstance(source_dims[1], (int, str)) and (isinstance(source_dims[1], int) or source_dims[1].isdigit()) else 2\n                        p = int(target_dims[1]) if len(target_dims) > 1 and isinstance(target_dims[1], (int, str)) and (isinstance(target_dims[1], int) or target_dims[1].isdigit()) else 2\n                        \n                        # 2 FLOPS per element (multiply and add)\n                        flops = m * n * p * self.OPERATION_COSTS['matrix_multiply']\n                        flops_estimate[\"matrix_operations\"] += flops\n                        flops_estimate[\"total_flops\"] += flops\n                    except (ValueError, TypeError) as e:\n                        # Default estimation if conversion fails\n                        flops_estimate[\"matrix_operations\"] += 100  # Assume small matrices\n                        flops_estimate[\"total_flops\"] += 100\n        \n        # Estimate element-wise operations from equations\n        eq_lines = equations.split('\\n')\n        for line in eq_lines:\n            element_ops = 0\n            nonlinear_ops = 0\n            \n            # Count arithmetic operations\n            element_ops += line.count('+') * self.OPERATION_COSTS['addition']\n            element_ops += line.count('*') * self.OPERATION_COSTS['scalar_multiply']\n            element_ops += line.count('/') * self.OPERATION_COSTS['division']\n            \n            # Count nonlinear operations (approximate)\n            nonlinear_ops += line.count('exp') * self.OPERATION_COSTS['exp']\n            nonlinear_ops += line.count('log') * self.OPERATION_COSTS['log']\n            nonlinear_ops += line.count('softmax') * self.OPERATION_COSTS['softmax']\n            nonlinear_ops += line.count('sigma') * self.OPERATION_COSTS['sigmoid']\n            \n            flops_estimate[\"element_operations\"] += element_ops\n            flops_estimate[\"nonlinear_operations\"] += nonlinear_ops\n            flops_estimate[\"total_flops\"] += element_ops + nonlinear_ops\n        \n        # Apply model type multiplier\n        if model_type == 'Dynamic':\n            flops_estimate[\"total_flops\"] *= 2.5  # Dynamic models more expensive\n        elif model_type == 'Hierarchical':\n            flops_estimate[\"total_flops\"] *= 3.5  # Hierarchical models most expensive\n        \n        # If no specific operations detected, estimate based on variable count and model type\n        if flops_estimate[\"total_flops\"] == 0:\n            base_flops = len(variables) * 20  # 20 FLOPS per variable as baseline\n            if model_type == 'Static':\n                flops_estimate[\"total_flops\"] = base_flops\n            elif model_type == 'Dynamic':\n                flops_estimate[\"total_flops\"] = base_flops * 2.5\n            else:  # Hierarchical\n                flops_estimate[\"total_flops\"] = base_flops * 3.5\n        \n        return flops_estimate",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_estimate_inference_time",
        "type": "method",
        "start_line": 446,
        "end_line": 465,
        "code": "def _estimate_inference_time(self, flops_estimate: Dict[str, Any]) -> Dict[str, float]:\n        \"\"\"\n        Estimate inference time based on FLOPS and hardware specs.\n        \n        Args:\n            flops_estimate: Dictionary with FLOPS estimates\n            \n        Returns:\n            Dictionary with inference time estimates in various units\n        \"\"\"\n        total_flops = flops_estimate[\"total_flops\"]\n        \n        # Calculate time based on hardware specs\n        cpu_time_seconds = total_flops / self.HARDWARE_SPECS[\"cpu_flops_per_second\"]\n        \n        return {\n            \"cpu_time_seconds\": cpu_time_seconds,\n            \"cpu_time_ms\": cpu_time_seconds * 1000,\n            \"cpu_time_us\": cpu_time_seconds * 1_000_000\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_estimate_batched_inference",
        "type": "method",
        "start_line": 467,
        "end_line": 508,
        "code": "def _estimate_batched_inference(self, variables: Dict[str, Any], model_type: str, \n                                   flops_estimate: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Estimate batched inference performance.\n        \n        Args:\n            variables: Dictionary of model variables\n            model_type: Type of model (Static, Dynamic, Hierarchical)\n            flops_estimate: Dictionary with FLOPS estimates\n            \n        Returns:\n            Dictionary with batched inference estimates\n        \"\"\"\n        total_flops = flops_estimate[\"total_flops\"]\n        \n        # Batch sizes to estimate\n        batch_sizes = [1, 8, 32, 128, 512]\n        \n        # Estimate batch throughput\n        batch_estimates = {}\n        for batch_size in batch_sizes:\n            # Batched FLOPS (not perfectly linear due to overhead)\n            if batch_size == 1:\n                batch_flops = total_flops\n            else:\n                # Diminishing returns with larger batches\n                scale_factor = 0.7 + 0.3 / math.log2(batch_size + 1)\n                batch_flops = total_flops * batch_size * scale_factor\n            \n            # Estimate time for batched inference\n            time_seconds = batch_flops / self.HARDWARE_SPECS[\"cpu_flops_per_second\"]\n            \n            # Throughput in samples per second\n            throughput = batch_size / time_seconds if time_seconds > 0 else 0\n            \n            batch_estimates[f\"batch_{batch_size}\"] = {\n                \"flops\": batch_flops,\n                \"time_seconds\": time_seconds,\n                \"throughput_per_second\": throughput\n            }\n        \n        return batch_estimates",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_estimate_matrix_operation_costs",
        "type": "method",
        "start_line": 510,
        "end_line": 613,
        "code": "def _estimate_matrix_operation_costs(self, variables: Dict[str, Any], edges: List[Dict[str, Any]], \n                                      equations: str) -> Dict[str, Any]:\n        \"\"\"\n        Provide detailed estimates of matrix operation costs.\n        \n        Args:\n            variables: Dictionary of model variables\n            edges: List of edges in the model\n            equations: Equations in the model\n            \n        Returns:\n            Dictionary with matrix operation costs\n        \"\"\"\n        operation_costs = {\n            \"matrix_multiply\": [],\n            \"matrix_transpose\": [],\n            \"matrix_inversion\": [],\n            \"element_wise\": [],\n            \"total_matrix_flops\": 0\n        }\n        \n        # Identify matrices and their dimensions\n        matrices = {}\n        for var_name, var_info in variables.items():\n            dims = var_info.get('dimensions', [1])\n            if len(dims) >= 2:  # It's a matrix\n                # Convert dimensions to integers when possible\n                int_dims = []\n                for d in dims:\n                    if isinstance(d, int):\n                        int_dims.append(d)\n                    elif isinstance(d, str) and d.isdigit():\n                        int_dims.append(int(d))\n                    else:\n                        int_dims.append(2)  # Default dimension\n                \n                matrices[var_name] = int_dims\n        \n        # Analyze edge connections for matrix operations\n        for edge in edges:\n            source = edge.get('source', '')\n            target = edge.get('target', '')\n            \n            if source in matrices and target in matrices:\n                source_dims = matrices[source]\n                target_dims = matrices[target]\n                \n                # Matrix multiplication cost\n                if len(source_dims) >= 2 and len(target_dims) >= 2:\n                    m = source_dims[0]\n                    n = source_dims[1] if len(source_dims) > 1 else 1\n                    p = target_dims[1] if len(target_dims) > 1 else 1\n                    \n                    flops = m * n * p * self.OPERATION_COSTS['matrix_multiply']\n                    \n                    operation_costs[\"matrix_multiply\"].append({\n                        \"operation\": f\"{source} \u00d7 {target}\",\n                        \"dimensions\": f\"{m}\u00d7{n} * {n}\u00d7{p}\",\n                        \"flops\": flops\n                    })\n                    \n                    operation_costs[\"total_matrix_flops\"] += flops\n        \n        # Analyze equations for matrix operations\n        eq_lines = equations.split('\\n')\n        for line in eq_lines:\n            # Look for matrix transpose operations (A^T or transpose(A))\n            if '^T' in line or 'transpose' in line:\n                for matrix_name in matrices:\n                    if matrix_name in line and (f\"{matrix_name}^T\" in line or f\"transpose({matrix_name})\" in line):\n                        dims = matrices[matrix_name]\n                        m = dims[0]\n                        n = dims[1] if len(dims) > 1 else 1\n                        \n                        # Transpose costs m*n operations\n                        flops = m * n\n                        \n                        operation_costs[\"matrix_transpose\"].append({\n                            \"operation\": f\"{matrix_name}^T\",\n                            \"dimensions\": f\"{m}\u00d7{n}\",\n                            \"flops\": flops\n                        })\n                        \n                        operation_costs[\"total_matrix_flops\"] += flops\n            \n            # Look for matrix inversion operations (A^-1 or inv(A))\n            if '^-1' in line or 'inv(' in line:\n                for matrix_name in matrices:\n                    if matrix_name in line and (f\"{matrix_name}^-1\" in line or f\"inv({matrix_name})\" in line):\n                        dims = matrices[matrix_name]\n                        n = dims[0]  # Assume square matrix for inversion\n                        \n                        # Inversion costs approximately n^3 operations\n                        flops = n**3\n                        \n                        operation_costs[\"matrix_inversion\"].append({\n                            \"operation\": f\"{matrix_name}^-1\",\n                            \"dimensions\": f\"{n}\u00d7{n}\",\n                            \"flops\": flops\n                        })\n                        \n                        operation_costs[\"total_matrix_flops\"] += flops\n        \n        return operation_costs",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_estimate_model_overhead",
        "type": "method",
        "start_line": 615,
        "end_line": 651,
        "code": "def _estimate_model_overhead(self, variables: Dict[str, Any], edges: List[Dict[str, Any]], \n                               equations: str) -> Dict[str, Any]:\n        \"\"\"\n        Estimate model overhead including compile-time and optimization costs.\n        \n        Args:\n            variables: Dictionary of model variables\n            edges: List of edges in the model\n            equations: Equations in the model\n            \n        Returns:\n            Dictionary with model overhead estimates\n        \"\"\"\n        overhead = {\n            \"compilation_ms\": 0,\n            \"optimization_ms\": 0,\n            \"memory_overhead_kb\": 0\n        }\n        \n        # Estimate compilation time based on model complexity\n        var_count = len(variables)\n        edge_count = len(edges)\n        eq_count = len(equations.split('\\n'))\n        \n        # Simple heuristic: ~10ms base + 2ms per variable + 1ms per edge + 5ms per equation\n        compilation_ms = 10 + (var_count * 2) + (edge_count * 1) + (eq_count * 5)\n        overhead[\"compilation_ms\"] = compilation_ms\n        \n        # Optimization costs roughly scale with variables^2\n        optimization_ms = 20 + (var_count**2 * 0.5)\n        overhead[\"optimization_ms\"] = optimization_ms\n        \n        # Memory overhead: ~1KB base + 50 bytes per variable + 30 bytes per edge + 100 bytes per equation\n        memory_overhead_bytes = 1024 + (var_count * 50) + (edge_count * 30) + (eq_count * 100)\n        overhead[\"memory_overhead_kb\"] = memory_overhead_bytes / 1024.0\n        \n        return overhead",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_estimate_inference",
        "type": "method",
        "start_line": 653,
        "end_line": 751,
        "code": "def _estimate_inference(self, variables: Dict[str, Any], model_type: str, \n                            edges: List[Dict[str, Any]], equations: str) -> float:\n        \"\"\"\n        Estimate inference time requirements based on model complexity.\n        \n        Args:\n            variables: Dictionary of model variables\n            model_type: Type of model (Static, Dynamic, Hierarchical)\n            edges: List of edges in the model\n            equations: Equations in the model\n            \n        Returns:\n            Inference time estimate (arbitrary units)\n        \"\"\"\n        # Base time depends on model type\n        base_time = self.INFERENCE_FACTORS.get(model_type, self.INFERENCE_FACTORS['Static'])\n        \n        # Add time for variable processing - consider variable types\n        var_time = 0\n        for var_name, var_info in variables.items():\n            var_type = var_info.get('type', 'float')\n            dims = var_info.get('dimensions', [1])\n            \n            # Extract dimensions as integers or defaults\n            try:\n                # Get element count based on dimensions\n                element_count = 1\n                for d in dims:\n                    if isinstance(d, (int, float)):\n                        element_count *= int(d)\n                    elif isinstance(d, str) and d.isdigit():\n                        element_count *= int(d)\n                    elif isinstance(d, str) and 'len' in d:\n                        element_count *= 3  # Reasonable default\n                    elif isinstance(d, str) and d.startswith('='):\n                        import re\n                        matches = re.findall(r'\\d+', d)\n                        if matches:\n                            element_count *= int(matches[0])\n                        else:\n                            element_count *= 1\n                    else:\n                        element_count *= 1\n                \n                # Scale by type factor and element count\n                type_factor = self.INFERENCE_FACTORS.get(var_type, self.INFERENCE_FACTORS['float'])\n                var_time += type_factor * math.log2(element_count + 1)  # log scale to avoid explosion\n                \n            except Exception as e:\n                # Use default if calculation fails\n                var_time += self.INFERENCE_FACTORS.get(var_type, 1.0)\n        \n        # Add time for edge traversal - more for complex connections\n        # Each edge represents signal propagation with potential transformations\n        edge_time = 0\n        for edge in edges:\n            source = edge.get('source', '')\n            target = edge.get('target', '')\n            \n            # Temporal connections cost more (Dynamic models)\n            if '+' in source or '+' in target:\n                edge_time += 1.0  # Temporal connection\n            else:\n                edge_time += 0.5  # Standard connection\n        \n        # Add time for equation evaluation\n        equation_lines = equations.split('\\n')\n        equation_time = 0\n        \n        for line in equation_lines:\n            # Basic cost per equation\n            eq_cost = 2.0\n            \n            # Additional cost for complex operations\n            if 'softmax' in line or 'sigma' in line:\n                eq_cost += 1.5  # Nonlinear functions cost more\n            if '^' in line:  # Power operations or matrix transposes\n                eq_cost += 1.0\n            if 'sum' in line or '\u2211' in line:  # Summation operations\n                eq_cost += 1.0\n            \n            equation_time += eq_cost\n        \n        # For models with no equations, assume default complexity\n        if equation_time == 0 and len(equation_lines) > 0:\n            equation_time = len(equation_lines) * 2.0\n        \n        # Combine factors with weights\n        # - Base model type is most important (40%)\n        # - Variables and equations matter significantly (25% each)\n        # - Edge structure has some impact (10%)\n        weighted_time = (\n            base_time * 4.0 +\n            var_time * 2.5 +\n            edge_time * 1.0 +\n            equation_time * 2.5\n        ) / 10.0\n        \n        return weighted_time * 10.0  # Scale to get reasonable units",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_estimate_storage",
        "type": "method",
        "start_line": 753,
        "end_line": 799,
        "code": "def _estimate_storage(self, variables: Dict[str, Any], edges: List[Dict[str, Any]], equations: str) -> float:\n        \"\"\"\n        Estimate storage requirements based on model structure and size.\n        \n        Args:\n            variables: Dictionary of model variables\n            edges: List of edges in the model\n            equations: Equations in the model\n            \n        Returns:\n            Storage estimate in KB\n        \"\"\"\n        # Memory footprint forms the base of our storage estimate\n        memory_estimate = self._estimate_memory(variables)\n        \n        # Calculate structural overhead\n        # Model structure, format overhead, metadata, descriptions: ~1KB base + per-item costs\n        structural_overhead_kb = 1.0  \n        \n        # Add overhead for variable names, descriptions, and metadata\n        var_overhead_kb = 0.0\n        for var_name, var_info in variables.items():\n            # Each variable has name, type, dimension info, comments\n            var_desc_length = len(var_info.get('comment', ''))\n            var_overhead_kb += (len(var_name) + 24 + var_desc_length) / 1024.0\n        \n        # Add overhead for edge definitions\n        edge_overhead_kb = len(edges) * 0.1  # ~100 bytes per edge definition\n        \n        # Add overhead for equations (consider actual text length)\n        equation_overhead_kb = len(equations) * 0.001  # ~1 byte per character\n        \n        # Textual representation adds overhead on top of binary storage\n        format_overhead_kb = 0.5  # GNN format markup, spaces, structure\n        \n        # Combine all storage components\n        total_storage_kb = (\n            memory_estimate * 1.2 +  # Binary data storage with padding\n            structural_overhead_kb +\n            var_overhead_kb +\n            edge_overhead_kb +\n            equation_overhead_kb +\n            format_overhead_kb\n        )\n        \n        # Make sure we don't get unreasonably low estimates\n        return max(total_storage_kb, 1.0)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_calculate_complexity",
        "type": "method",
        "start_line": 801,
        "end_line": 929,
        "code": "def _calculate_complexity(self, variables: Dict[str, Any], edges: List[Dict[str, Any]], equations: str) -> Dict[str, float]:\n        \"\"\"\n        Calculate detailed complexity metrics for the model.\n        \n        Args:\n            variables: Dictionary of model variables\n            edges: List of edges in the model\n            equations: Equations in the model\n            \n        Returns:\n            Dictionary with complexity metrics\n        \"\"\"\n        # Get total dimensionality (state space complexity)\n        total_dims = 0\n        max_dim = 0\n        for var_info in variables.values():\n            dims = var_info.get('dimensions', [1])\n            # Convert dimensions to integers when possible\n            int_dims = []\n            for d in dims:\n                if isinstance(d, int):\n                    int_dims.append(d)\n                elif isinstance(d, str) and d.isdigit():\n                    int_dims.append(int(d))\n                else:\n                    int_dims.append(2)  # Default dimension size\n            \n            # Sum up total dimensionality\n            dim_size = math.prod(int_dims)\n            total_dims += dim_size\n            max_dim = max(max_dim, dim_size)\n        \n        # Calculate graph metrics\n        var_count = len(variables)\n        edge_count = len(edges)\n        \n        # Topological complexity\n        # Graph density: 0 (unconnected) to 1 (fully connected)\n        density = 0.0\n        if var_count > 1:\n            max_possible_edges = var_count * (var_count - 1)  # Directed graph\n            density = edge_count / max_possible_edges if max_possible_edges > 0 else 0\n        \n        # Calculate connectivity patterns\n        in_degree = {}\n        out_degree = {}\n        for edge in edges:\n            source = edge.get('source', '').split('+')[0]  # Remove time indices\n            target = edge.get('target', '').split('+')[0]\n            \n            out_degree[source] = out_degree.get(source, 0) + 1\n            in_degree[target] = in_degree.get(target, 0) + 1\n        \n        # Average degrees\n        avg_in_degree = sum(in_degree.values()) / max(len(in_degree), 1)\n        avg_out_degree = sum(out_degree.values()) / max(len(out_degree), 1)\n        \n        # Max degrees\n        max_in_degree = max(in_degree.values()) if in_degree else 0\n        max_out_degree = max(out_degree.values()) if out_degree else 0\n        \n        # Cyclic complexity - check for cyclic patterns (excluding self-loops)\n        # Simple approximation: higher connectivity often means more cycles\n        cyclic_score = 0\n        if edge_count > var_count:\n            cyclic_score = (edge_count - var_count) / max(var_count, 1)\n        \n        # Temporal complexity (look for time indices in edges)\n        temporal_edges = 0\n        for edge in edges:\n            if '+' in edge.get('source', '') or '+' in edge.get('target', ''):\n                temporal_edges += 1\n        \n        temporal_complexity = temporal_edges / max(edge_count, 1)\n        \n        # Equation complexity\n        eq_lines = equations.split('\\n')\n        avg_eq_length = sum(len(line) for line in eq_lines) / max(len(eq_lines), 1)\n        \n        # Count operators in equations as a measure of complexity\n        operators = 0\n        for line in eq_lines:\n            operators += line.count('+') + line.count('-') + line.count('*') + line.count('/') + line.count('^')\n        \n        # Higher-order operators indicate more complexity\n        higher_order_ops = 0\n        for line in eq_lines:\n            higher_order_ops += line.count('sum') + line.count('prod') + line.count('log') + line.count('exp')\n            higher_order_ops += line.count('softmax') + line.count('tanh') + line.count('sigma')\n        \n        # Combined equation complexity\n        equation_complexity = 0\n        if eq_lines:\n            equation_complexity = (avg_eq_length + operators + 3*higher_order_ops) / len(eq_lines)\n        \n        # State space complexity (measure of information capacity)\n        state_space_complexity = math.log2(total_dims + 1) if total_dims > 0 else 0\n        \n        # Overall complexity combines several factors:\n        # - State space (information capacity)\n        # - Connectivity (graph structure)\n        # - Temporal aspects (time dependencies)\n        # - Algorithmic complexity (equations)\n        overall_complexity = (\n            state_space_complexity * 0.25 +\n            (density + cyclic_score) * 0.25 +\n            temporal_complexity * 0.2 +\n            equation_complexity * 0.3\n        )\n        \n        # Scale to a reasonable range (0-10)\n        overall_complexity = min(10, overall_complexity * 2)\n        \n        return {\n            \"state_space_complexity\": state_space_complexity,\n            \"graph_density\": density,\n            \"avg_in_degree\": avg_in_degree,\n            \"avg_out_degree\": avg_out_degree,\n            \"max_in_degree\": max_in_degree,\n            \"max_out_degree\": max_out_degree,\n            \"cyclic_complexity\": cyclic_score,\n            \"temporal_complexity\": temporal_complexity,\n            \"equation_complexity\": equation_complexity,\n            \"overall_complexity\": overall_complexity,\n            \"variable_count\": var_count,\n            \"edge_count\": edge_count,\n            \"total_state_space_dim\": total_dims,\n            \"max_variable_dim\": max_dim\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "generate_html_report",
        "type": "method",
        "start_line": 931,
        "end_line": 1476,
        "code": "def generate_html_report(self, output_dir: Optional[str] = None) -> str:\n        \"\"\"\n        Generate a comprehensive HTML report with visualizations and detailed explanations.\n        \n        Args:\n            output_dir: Directory to save report files\n            \n        Returns:\n            Path to the generated HTML report\n        \"\"\"\n        import json\n        from datetime import datetime\n        \n        if not self.results:\n            return \"No results to report. Run estimation first.\"\n        \n        # Create output directory\n        if output_dir:\n            output_path = Path(output_dir)\n        else:\n            output_path = Path(\"output/gnn_type_checker/resources\")\n        \n        output_path.mkdir(parents=True, exist_ok=True)\n        \n        # Generate visualizations for HTML embedding\n        vis_path = output_path / \"html_vis\"\n        vis_path.mkdir(exist_ok=True)\n        self._generate_visualizations_for_html(vis_path)\n        \n        # Create model comparison arrays for visualizations\n        models = []\n        memory_values = []\n        inference_values = []\n        storage_values = []\n        flops_values = []\n        \n        for file_path, result in sorted(self.results.items()):\n            if \"error\" not in result:\n                models.append(os.path.basename(file_path).replace(\".md\", \"\"))\n                memory_values.append(result[\"memory_estimate\"])\n                inference_values.append(result[\"inference_estimate\"])\n                storage_values.append(result[\"storage_estimate\"])\n                if \"flops_estimate\" in result:\n                    flops_values.append(result[\"flops_estimate\"][\"total_flops\"])\n                else:\n                    flops_values.append(0)\n        \n        # Start creating HTML content\n        html_content = f\"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>GNN Resource Estimation Report</title>\n    <script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n    <style>\n        body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; color: #333; max-width: 1200px; margin: 0 auto; }}\n        h1 {{ color: #2c3e50; margin-top: 20px; }}\n        h2 {{ color: #3498db; margin-top: 30px; }}\n        h3 {{ color: #2980b9; }}\n        .summary {{ background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px; }}\n        .chart-container {{ width: 100%; height: 400px; margin-bottom: 30px; }}\n        .metric-container {{ display: flex; flex-wrap: wrap; gap: 20px; margin-bottom: 30px; }}\n        .metric-box {{ flex: 1; min-width: 200px; background-color: #f8f9fa; padding: 15px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}\n        .metric-value {{ font-size: 24px; font-weight: bold; color: #2980b9; }}\n        .model-card {{ background-color: #fff; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 20px; padding: 15px; }}\n        .caption {{ font-style: italic; color: #555; margin-top: 5px; text-align: center; }}\n        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}\n        th, td {{ padding: 10px; text-align: left; border-bottom: 1px solid #ddd; }}\n        th {{ background-color: #f2f2f2; }}\n        tr:hover {{ background-color: #f5f5f5; }}\n        .resource-comparison {{ display: flex; gap: 20px; margin-bottom: 30px; }}\n        .resource-comparison > div {{ flex: 1; }}\n        .footer {{ margin-top: 30px; font-size: 0.8em; color: #777; text-align: center; }}\n    </style>\n</head>\n<body>\n    <h1>GNN Resource Estimation Report</h1>\n    <p>Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n    \n    <div class=\"summary\">\n        <h2>Summary</h2>\n        <p>This report provides detailed resource estimates for {len(models)} GNN models, analyzing their memory usage, computational requirements, and storage needs.</p>\n        \n        <div class=\"metric-container\">\n            <div class=\"metric-box\">\n                <h3>Average Memory Usage</h3>\n                <div class=\"metric-value\">{sum(memory_values)/len(memory_values):.2f} KB</div>\n                <p>RAM required to hold model in memory</p>\n            </div>\n            <div class=\"metric-box\">\n                <h3>Average Inference Time</h3>\n                <div class=\"metric-value\">{sum(inference_values)/len(inference_values):.2f} units</div>\n                <p>Relative computational cost</p>\n            </div>\n            <div class=\"metric-box\">\n                <h3>Average Storage</h3>\n                <div class=\"metric-value\">{sum(storage_values)/len(storage_values):.2f} KB</div>\n                <p>Disk space required to store model</p>\n            </div>\n        </div>\n    </div>\n    \n    <h2>Resource Visualizations</h2>\n    <p>The following visualizations provide a comparative analysis of resource requirements across different models.</p>\n    \n    <h3>Memory Usage Comparison</h3>\n    <div class=\"chart-container\">\n        <canvas id=\"memoryChart\"></canvas>\n    </div>\n    <p class=\"caption\">\n        <strong>Figure 1:</strong> Memory usage comparison showing RAM requirements (in KB) for each GNN model. \n        Memory usage is determined by the size and number of matrices and variables in the model. \n        Hierarchical models typically require more memory due to their multi-level structure.\n    </p>\n    \n    <h3>Inference Time Comparison</h3>\n    <div class=\"chart-container\">\n        <canvas id=\"inferenceChart\"></canvas>\n    </div>\n    <p class=\"caption\">\n        <strong>Figure 2:</strong> Inference time comparison showing relative computational cost for each model.\n        Higher values indicate more complex computations requiring more CPU/GPU time.\n        Dynamic models with temporal dependencies typically have higher inference costs than static models.\n    </p>\n    \n    <h3>Storage Requirements Comparison</h3>\n    <div class=\"chart-container\">\n        <canvas id=\"storageChart\"></canvas>\n    </div>\n    <p class=\"caption\">\n        <strong>Figure 3:</strong> Storage requirements showing disk space (in KB) needed to store each model.\n        Storage includes the base memory requirements plus additional overhead for model structure, \n        metadata, and equation representations.\n    </p>\n    \n    <h3>Normalized Resource Comparison</h3>\n    <div class=\"chart-container\">\n        <canvas id=\"comparisonChart\"></canvas>\n    </div>\n    <p class=\"caption\">\n        <strong>Figure 4:</strong> Normalized resource comparison showing relative requirements across all resource types.\n        Values are normalized to the highest value in each category to allow for direct comparison.\n        This visualization helps identify which resource dimension is most constraining for each model.\n    </p>\n\"\"\"\n\n        # Add computational complexity section\n        html_content += \"\"\"\n    <h2>Computational Complexity Analysis</h2>\n    <p>This section breaks down the computational complexity of each model in terms of operations required and algorithmic efficiency.</p>\n    \n    <div class=\"chart-container\">\n        <canvas id=\"flopsChart\"></canvas>\n    </div>\n    <p class=\"caption\">\n        <strong>Figure 5:</strong> Estimated floating-point operations (FLOPS) required for a single inference pass.\n        FLOPS count is calculated based on matrix operations, element-wise operations, and nonlinear function evaluations\n        in the model. Higher FLOPS indicate more computationally intensive models.\n    </p>\n    \n    <h3>Matrix Operation Costs</h3>\n    <p>Matrix operations typically dominate the computational cost of GNN models. The following table shows estimated costs for key operations.</p>\n    \n    <table>\n        <thead>\n            <tr>\n                <th>Model</th>\n                <th>Matrix Multiplications</th>\n                <th>Element-wise Ops</th>\n                <th>Nonlinear Ops</th>\n                <th>Total FLOPS</th>\n            </tr>\n        </thead>\n        <tbody>\n\"\"\"\n\n        # Add rows for each model with detailed FLOPS breakdown\n        for file_path, result in sorted(self.results.items()):\n            if \"error\" not in result and \"flops_estimate\" in result:\n                model_name = os.path.basename(file_path).replace(\".md\", \"\")\n                flops = result[\"flops_estimate\"]\n                \n                html_content += f\"\"\"\n            <tr>\n                <td>{model_name}</td>\n                <td>{flops.get(\"matrix_operations\", 0):.0f}</td>\n                <td>{flops.get(\"element_operations\", 0):.0f}</td>\n                <td>{flops.get(\"nonlinear_operations\", 0):.0f}</td>\n                <td>{flops.get(\"total_flops\", 0):.0f}</td>\n            </tr>\"\"\"\n\n        html_content += \"\"\"\n        </tbody>\n    </table>\n    <p class=\"caption\">\n        <strong>Table 1:</strong> Breakdown of computational operations by type for each model. \n        Matrix multiplications, element-wise operations, and nonlinear function evaluations contribute to the total FLOPS.\n    </p>\n\"\"\"\n\n        # Add model details section\n        html_content += \"\"\"\n    <h2>Individual Model Analysis</h2>\n    <p>This section provides detailed resource profiles for each individual model.</p>\n    \n    <div class=\"model-container\">\n\"\"\"\n\n        # Add cards for each model with detailed metrics\n        for file_path, result in sorted(self.results.items()):\n            if \"error\" not in result:\n                model_name = os.path.basename(file_path).replace(\".md\", \"\")\n                \n                # Get model type\n                model_type = \"Static\"\n                if file_path in self.detailed_metrics:\n                    model_type = self.detailed_metrics[file_path].get(\"model_type\", \"Static\")\n                \n                # Get complexity metrics\n                complexity = result.get(\"complexity\", {})\n                \n                # Create memory breakdown\n                memory_breakdown = {}\n                if file_path in self.detailed_metrics:\n                    memory_breakdown = self.detailed_metrics[file_path].get(\"memory_breakdown\", {})\n                \n                html_content += f\"\"\"\n        <div class=\"model-card\">\n            <h3>{model_name}</h3>\n            <p><strong>Type:</strong> {model_type} model</p>\n            \n            <div class=\"resource-comparison\">\n                <div>\n                    <h4>Memory Usage</h4>\n                    <div class=\"metric-value\">{result[\"memory_estimate\"]:.2f} KB</div>\n                    <p>Variables: {result[\"model_info\"][\"variables_count\"]}</p>\n                </div>\n                <div>\n                    <h4>Inference Time</h4>\n                    <div class=\"metric-value\">{result[\"inference_estimate\"]:.2f} units</div>\n                    <p>Edges: {result[\"model_info\"][\"edges_count\"]}</p>\n                </div>\n                <div>\n                    <h4>Storage</h4>\n                    <div class=\"metric-value\">{result[\"storage_estimate\"]:.2f} KB</div>\n                    <p>Equations: {result[\"model_info\"][\"equation_count\"]}</p>\n                </div>\n            </div>\n            \n            <h4>Complexity Metrics</h4>\n            <table>\n                <tr>\n                    <td>State Space Complexity</td>\n                    <td>{complexity.get(\"state_space_complexity\", 0):.2f}</td>\n                    <td>Graph Density</td>\n                    <td>{complexity.get(\"graph_density\", 0):.2f}</td>\n                </tr>\n                <tr>\n                    <td>Temporal Complexity</td>\n                    <td>{complexity.get(\"temporal_complexity\", 0):.2f}</td>\n                    <td>Equation Complexity</td>\n                    <td>{complexity.get(\"equation_complexity\", 0):.2f}</td>\n                </tr>\n                <tr>\n                    <td>Overall Complexity</td>\n                    <td colspan=\"3\">{complexity.get(\"overall_complexity\", 0):.2f} / 10.0</td>\n                </tr>\n            </table>\n        </div>\n\"\"\"\n\n        # Add explanation section\n        html_content += \"\"\"\n    </div>\n    \n    <h2>Understanding Resource Metrics</h2>\n    <p>This section explains how each resource metric is calculated and what it means for model performance.</p>\n    \n    <h3>Memory Usage</h3>\n    <p>Memory usage estimates the amount of RAM required to hold the model in memory during inference. It accounts for:</p>\n    <ul>\n        <li><strong>Variable Storage:</strong> Size of all matrices and vectors in the model</li>\n        <li><strong>Type Considerations:</strong> Different data types (float, int, bool) require different amounts of memory</li>\n        <li><strong>Dimension Analysis:</strong> Higher-dimensional state spaces consume more memory</li>\n    </ul>\n    <p>The memory estimate is calculated based on the dimensions of each variable and its data type, using standard sizes (4 bytes for float/int, 1 byte for bool, etc.).</p>\n    \n    <h3>Inference Time</h3>\n    <p>Inference time estimates the relative computational cost of running the model for a single inference pass. It considers:</p>\n    <ul>\n        <li><strong>Model Type:</strong> Static vs. Dynamic vs. Hierarchical architecture</li>\n        <li><strong>Matrix Operations:</strong> Primarily matrix multiplications which dominate computational cost</li>\n        <li><strong>Nonlinear Functions:</strong> Operations like softmax, sigmoid, or tanh which are computationally expensive</li>\n        <li><strong>Connectivity:</strong> Edge structure and temporal relationships that affect computation flow</li>\n    </ul>\n    <p>The inference time is provided in relative units, with higher values indicating more complex computations requiring more processing time.</p>\n    \n    <h3>Storage Requirements</h3>\n    <p>Storage requirements estimate the disk space needed to persist the model. This includes:</p>\n    <ul>\n        <li><strong>Base Memory Footprint:</strong> Same as memory usage</li>\n        <li><strong>Format Overhead:</strong> Additional space for storing the model structure</li>\n        <li><strong>Metadata:</strong> Variable names, comments, equations, etc.</li>\n    </ul>\n    <p>Storage is typically larger than memory usage due to the additional structural information needed to fully represent the model on disk.</p>\n    \n    <h3>Computational Complexity</h3>\n    <p>Computational complexity provides a deeper analysis of the algorithmic efficiency of the model:</p>\n    <ul>\n        <li><strong>FLOPS (Floating Point Operations):</strong> Count of arithmetic operations needed for inference</li>\n        <li><strong>Matrix Operation Costs:</strong> Detailed breakdown of matrix multiplication, transpose, and inversion costs</li>\n        <li><strong>State Space Complexity:</strong> Measure of the model's information capacity</li>\n        <li><strong>Structural Complexity:</strong> Analysis of the edge structure and connectivity patterns</li>\n    </ul>\n    <p>These metrics help identify bottlenecks and optimize model architecture for better performance.</p>\n\"\"\"\n\n        # Add JavaScript for chart rendering\n        html_content += f\"\"\"\n    <script>\n        // Memory usage chart\n        const memoryCtx = document.getElementById('memoryChart').getContext('2d');\n        new Chart(memoryCtx, {{\n            type: 'bar',\n            data: {{\n                labels: {json.dumps(models)},\n                datasets: [{{\n                    label: 'Memory Usage (KB)',\n                    data: {json.dumps(memory_values)},\n                    backgroundColor: 'rgba(75, 192, 192, 0.2)',\n                    borderColor: 'rgba(75, 192, 192, 1)',\n                    borderWidth: 1\n                }}]\n            }},\n            options: {{\n                scales: {{\n                    y: {{\n                        beginAtZero: true,\n                        title: {{\n                            display: true,\n                            text: 'Memory Usage (KB)'\n                        }}\n                    }},\n                    x: {{\n                        title: {{\n                            display: true,\n                            text: 'Model'\n                        }}\n                    }}\n                }},\n                plugins: {{\n                    legend: {{\n                        display: false\n                    }}\n                }}\n            }}\n        }});\n        \n        // Inference time chart\n        const inferenceCtx = document.getElementById('inferenceChart').getContext('2d');\n        new Chart(inferenceCtx, {{\n            type: 'bar',\n            data: {{\n                labels: {json.dumps(models)},\n                datasets: [{{\n                    label: 'Inference Time (units)',\n                    data: {json.dumps(inference_values)},\n                    backgroundColor: 'rgba(153, 102, 255, 0.2)',\n                    borderColor: 'rgba(153, 102, 255, 1)',\n                    borderWidth: 1\n                }}]\n            }},\n            options: {{\n                scales: {{\n                    y: {{\n                        beginAtZero: true,\n                        title: {{\n                            display: true,\n                            text: 'Inference Time (arbitrary units)'\n                        }}\n                    }},\n                    x: {{\n                        title: {{\n                            display: true,\n                            text: 'Model'\n                        }}\n                    }}\n                }},\n                plugins: {{\n                    legend: {{\n                        display: false\n                    }}\n                }}\n            }}\n        }});\n        \n        // Storage chart\n        const storageCtx = document.getElementById('storageChart').getContext('2d');\n        new Chart(storageCtx, {{\n            type: 'bar',\n            data: {{\n                labels: {json.dumps(models)},\n                datasets: [{{\n                    label: 'Storage (KB)',\n                    data: {json.dumps(storage_values)},\n                    backgroundColor: 'rgba(255, 159, 64, 0.2)',\n                    borderColor: 'rgba(255, 159, 64, 1)',\n                    borderWidth: 1\n                }}]\n            }},\n            options: {{\n                scales: {{\n                    y: {{\n                        beginAtZero: true,\n                        title: {{\n                            display: true,\n                            text: 'Storage Requirements (KB)'\n                        }}\n                    }},\n                    x: {{\n                        title: {{\n                            display: true,\n                            text: 'Model'\n                        }}\n                    }}\n                }},\n                plugins: {{\n                    legend: {{\n                        display: false\n                    }}\n                }}\n            }}\n        }});\n        \n        // Normalized comparison chart\n        const comparisonCtx = document.getElementById('comparisonChart').getContext('2d');\n        \n        // Normalize data\n        const maxMemory = Math.max(...{json.dumps(memory_values)});\n        const maxInference = Math.max(...{json.dumps(inference_values)});\n        const maxStorage = Math.max(...{json.dumps(storage_values)});\n        \n        const normMemory = {json.dumps(memory_values)}.map(v => v / maxMemory);\n        const normInference = {json.dumps(inference_values)}.map(v => v / maxInference);\n        const normStorage = {json.dumps(storage_values)}.map(v => v / maxStorage);\n        \n        new Chart(comparisonCtx, {{\n            type: 'bar',\n            data: {{\n                labels: {json.dumps(models)},\n                datasets: [\n                    {{\n                        label: 'Memory',\n                        data: normMemory,\n                        backgroundColor: 'rgba(75, 192, 192, 0.2)',\n                        borderColor: 'rgba(75, 192, 192, 1)',\n                        borderWidth: 1\n                    }},\n                    {{\n                        label: 'Inference',\n                        data: normInference,\n                        backgroundColor: 'rgba(153, 102, 255, 0.2)',\n                        borderColor: 'rgba(153, 102, 255, 1)',\n                        borderWidth: 1\n                    }},\n                    {{\n                        label: 'Storage',\n                        data: normStorage,\n                        backgroundColor: 'rgba(255, 159, 64, 0.2)',\n                        borderColor: 'rgba(255, 159, 64, 1)',\n                        borderWidth: 1\n                    }}\n                ]\n            }},\n            options: {{\n                scales: {{\n                    y: {{\n                        beginAtZero: true,\n                        title: {{\n                            display: true,\n                            text: 'Normalized Resource Usage'\n                        }}\n                    }},\n                    x: {{\n                        title: {{\n                            display: true,\n                            text: 'Model'\n                        }}\n                    }}\n                }}\n            }}\n        }});\n        \n        // FLOPS chart\n        const flopsCtx = document.getElementById('flopsChart').getContext('2d');\n        new Chart(flopsCtx, {{\n            type: 'bar',\n            data: {{\n                labels: {json.dumps(models)},\n                datasets: [{{\n                    label: 'FLOPS',\n                    data: {json.dumps(flops_values)},\n                    backgroundColor: 'rgba(54, 162, 235, 0.2)',\n                    borderColor: 'rgba(54, 162, 235, 1)',\n                    borderWidth: 1\n                }}]\n            }},\n            options: {{\n                scales: {{\n                    y: {{\n                        beginAtZero: true,\n                        title: {{\n                            display: true,\n                            text: 'Floating Point Operations'\n                        }}\n                    }},\n                    x: {{\n                        title: {{\n                            display: true,\n                            text: 'Model'\n                        }}\n                    }}\n                }},\n                plugins: {{\n                    legend: {{\n                        display: false\n                    }}\n                }}\n            }}\n        }});\n    </script>\n    \n    <div class=\"footer\">\n        <p>Generated by GNN Resource Estimator | GNN Type Checker</p>\n    </div>\n</body>\n</html>\n\"\"\"\n\n        # Save HTML report\n        html_report_path = output_path / \"resource_report_detailed.html\"\n        with open(html_report_path, 'w') as f:\n            f.write(html_content)\n        \n        return str(html_report_path)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_generate_visualizations_for_html",
        "type": "method",
        "start_line": 1478,
        "end_line": 1561,
        "code": "def _generate_visualizations_for_html(self, output_dir: Path) -> None:\n        \"\"\"\n        Generate visualizations specifically for HTML embedding.\n        \n        Args:\n            output_dir: Directory to save visualizations\n        \"\"\"\n        if not self.results:\n            return\n        \n        # Extract data for plots\n        files = [os.path.basename(file_path) for file_path in self.results.keys()]\n        memory_values = [result[\"memory_estimate\"] for result in self.results.values() if \"error\" not in result and result[\"memory_estimate\"] is not None]\n        inference_values = [result[\"inference_estimate\"] for result in self.results.values() if \"error\" not in result and result[\"inference_estimate\"] is not None]\n        storage_values = [result[\"storage_estimate\"] for result in self.results.values() if \"error\" not in result and result[\"storage_estimate\"] is not None]\n        \n        # Check if we have any valid data for visualization\n        if not memory_values or not inference_values or not storage_values:\n            print(\"Warning: No valid resource estimates available for HTML visualizations\")\n            return\n            \n        # Short file names for better display\n        short_files = [f[:20] + \"...\" if len(f) > 20 else f for f in files[:len(memory_values)]]\n        \n        # Memory usage plot with custom styling for HTML\n        plt.figure(figsize=(10, 6))\n        ax = plt.gca()\n        bars = plt.bar(short_files, memory_values, color='skyblue')\n        \n        # Add data labels on top of bars\n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                    f'{height:.2f}',\n                    ha='center', va='bottom', fontsize=9)\n        \n        plt.title('Memory Usage Estimates', fontsize=14, fontweight='bold')\n        plt.xlabel('Model File', fontsize=12)\n        plt.ylabel('Memory Usage (KB)', fontsize=12)\n        plt.xticks(rotation=45, ha='right', fontsize=10)\n        plt.grid(axis='y', linestyle='--', alpha=0.7)\n        plt.tight_layout()\n        plt.savefig(output_dir / \"memory_usage_html.png\", dpi=120, bbox_inches='tight')\n        plt.close()\n        \n        # Inference time plot with custom styling\n        plt.figure(figsize=(10, 6))\n        bars = plt.bar(short_files, inference_values, color='lightgreen')\n        \n        # Add data labels\n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                    f'{height:.2f}',\n                    ha='center', va='bottom', fontsize=9)\n        \n        plt.title('Inference Time Estimates', fontsize=14, fontweight='bold')\n        plt.xlabel('Model File', fontsize=12)\n        plt.ylabel('Inference Time (arbitrary units)', fontsize=12)\n        plt.xticks(rotation=45, ha='right', fontsize=10)\n        plt.grid(axis='y', linestyle='--', alpha=0.7)\n        plt.tight_layout()\n        plt.savefig(output_dir / \"inference_time_html.png\", dpi=120, bbox_inches='tight')\n        plt.close()\n        \n        # Storage requirements plot with custom styling\n        plt.figure(figsize=(10, 6))\n        bars = plt.bar(short_files, storage_values, color='salmon')\n        \n        # Add data labels\n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                    f'{height:.2f}',\n                    ha='center', va='bottom', fontsize=9)\n        \n        plt.title('Storage Requirements Estimates', fontsize=14, fontweight='bold')\n        plt.xlabel('Model File', fontsize=12)\n        plt.ylabel('Storage (KB)', fontsize=12)\n        plt.xticks(rotation=45, ha='right', fontsize=10)\n        plt.grid(axis='y', linestyle='--', alpha=0.7)\n        plt.tight_layout()\n        plt.savefig(output_dir / \"storage_requirements_html.png\", dpi=120, bbox_inches='tight')\n        plt.close()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "generate_report",
        "type": "method",
        "start_line": 1563,
        "end_line": 1686,
        "code": "def generate_report(self, output_dir: Optional[str] = None, project_root_path: Optional[Union[str, Path]] = None) -> str:\n        \"\"\"\n        Generate a markdown report and JSON data of the resource estimates.\n        \n        Args:\n            output_dir: Directory to save the report and JSON data. \n                        If None, defaults to a subdirectory 'resource_estimates' in the current working directory.\n            project_root_path: Optional path to the project root for making file paths relative in the report.\n\n        Returns:\n            String summary of the report.\n        \"\"\"\n        if not self.results:\n            return \"No GNN models processed for resource estimation.\"\n\n        output_path = Path(output_dir if output_dir else \"resource_estimates\").resolve()\n        output_path.mkdir(parents=True, exist_ok=True)\n        \n        report_file = output_path / \"resource_report.md\"\n        json_file = output_path / \"resource_data.json\"\n\n        # Resolve project_root once\n        actual_project_root = None\n        if project_root_path:\n            actual_project_root = Path(project_root_path).resolve()\n\n        # Calculate averages\n        total_files = len(self.results)\n        valid_results = [r for r in self.results.values() if \"error\" not in r and r[\"memory_estimate\"] is not None]\n        \n        if valid_results:\n            avg_memory = sum(r[\"memory_estimate\"] for r in valid_results) / len(valid_results)\n            avg_inference = sum(r[\"inference_estimate\"] for r in valid_results) / len(valid_results)\n            avg_storage = sum(r[\"storage_estimate\"] for r in valid_results) / len(valid_results)\n            \n            report_content = [\"# GNN Resource Estimation Report\", \"\"]\n            report_content.append(f\"Analyzed {total_files} files\")\n            report_content.append(f\"Average Memory Usage: {avg_memory:.2f} KB\")\n            report_content.append(f\"Average Inference Time: {avg_inference:.2f} units\")\n            report_content.append(f\"Average Storage: {avg_storage:.2f} KB\")\n            report_content.append(\"\")\n        else:\n            report_content = [\"# GNN Resource Estimation Report\", \"\"]\n            report_content.append(f\"Analyzed {total_files} files, but no valid results were obtained.\")\n            report_content.append(\"Check for errors in the analysis.\")\n            report_content.append(\"\")\n\n        for file_path_str, res in self.results.items():\n            if res.get(\"error\"):\n                report_content.append(f\"## {Path(file_path_str).name}\")\n                report_content.append(f\"Path: {file_path_str}\") # Keep original path if error occurred before resolving\n                report_content.append(f\"Error: {res['error']}\")\n                report_content.append(\"\")\n                continue\n            \n            file_path_obj = Path(file_path_str).resolve()\n            display_path = file_path_str\n            if actual_project_root:\n                try:\n                    display_path = str(file_path_obj.relative_to(actual_project_root))\n                except ValueError:\n                    display_path = file_path_obj.name # Fallback\n\n            report_content.append(f\"## {file_path_obj.name}\")\n            report_content.append(f\"Path: {display_path}\")\n            report_content.append(f\"Memory Estimate: {res['memory_estimate']:.2f} KB\")\n            report_content.append(f\"Inference Estimate: {res['inference_estimate']:.2f} units\")\n            report_content.append(f\"Storage Estimate: {res['storage_estimate']:.2f} KB\")\n            report_content.append(\"\")\n            \n            report_content.append(\"### Model Info\")\n            for key, value in res[\"model_info\"].items():\n                report_content.append(f\"- {key}: {value}\")\n            \n            report_content.append(\"\")\n            \n            report_content.append(\"### Complexity Metrics\")\n            for key, value in res[\"complexity\"].items():\n                if isinstance(value, (int, float)):\n                    report_content.append(f\"- {key}: {value:.4f}\")\n                else:\n                    report_content.append(f\"- {key}: {value}\")\n            \n            report_content.append(\"\")\n\n        report_content.append(\"# Metric Definitions\")\n        report_content.append(\"\")\n        report_content.append(\"## General Metrics\")\n        report_content.append(\"- **Memory Estimate (KB):** Estimated RAM required to hold the model's variables and data structures in memory. Calculated based on variable dimensions and data types (e.g., float: 4 bytes, int: 4 bytes).\")\n        report_content.append(\"- **Inference Estimate (units):** A relative, abstract measure of computational cost for a single inference pass. It is derived from factors like model type (Static, Dynamic, Hierarchical), the number and type of variables, the complexity of connections (edges), and the operations defined in equations. Higher values indicate a more computationally intensive model. These units are not tied to a specific hardware time (e.g., milliseconds) but allow for comparison between different GNN models.\")\n        report_content.append(\"- **Storage Estimate (KB):** Estimated disk space required to store the model file. This includes the memory footprint of the data plus overhead for the GNN textual representation, metadata, comments, and equations.\")\n        report_content.append(\"\")\n        report_content.append(\"## Complexity Metrics (scores are generally relative; higher often means more complex)\")\n        report_content.append(\"- **state_space_complexity:** Logarithmic measure of the total dimensionality of all variables (sum of the product of dimensions for each variable). Represents the model's theoretical information capacity or the size of its state space.\")\n        report_content.append(\"- **graph_density:** Ratio of actual edges to the maximum possible edges in the model graph. A value of 0 indicates no connections, while 1 would mean a fully connected graph. Measures how interconnected the variables are.\")\n        report_content.append(\"- **avg_in_degree:** Average number of incoming connections (edges) per variable.\")\n        report_content.append(\"- **avg_out_degree:** Average number of outgoing connections (edges) per variable.\")\n        report_content.append(\"- **max_in_degree:** Maximum number of incoming connections for any single variable in the model.\")\n        report_content.append(\"- **max_out_degree:** Maximum number of outgoing connections for any single variable in the model.\")\n        report_content.append(\"- **cyclic_complexity:** A score indicating the presence and extent of cyclic patterns or feedback loops in the graph. Approximated based on the ratio of edges to variables; higher values suggest more complex recurrent interactions.\")\n        report_content.append(\"- **temporal_complexity:** Proportion of edges that involve time dependencies (e.g., connecting a variable at time `t` to one at `t+1`). Indicates the degree to which the model's behavior depends on past states or sequences.\")\n        report_content.append(\"- **equation_complexity:** A measure based on the average length, number, and types of mathematical operators (e.g., +, *, log, softmax) used in the model's equations. Higher values suggest more intricate mathematical relationships between variables.\")\n        report_content.append(\"- **overall_complexity:** A weighted composite score (typically scaled, e.g., 0-10) that combines state space size, graph structure (density, cyclicity), temporal aspects, and equation complexity to provide a single, holistic measure of the model's intricacy.\")\n        report_content.append(\"\")\n\n        report = \"\\n\".join(report_content)\n        \n        # Save text report\n        report_path = output_path / \"resource_report.md\"\n        with open(report_path, 'w') as f:\n            f.write(report)\n        \n        # Generate visualizations\n        self._generate_visualizations_for_html(output_path)\n        \n        # Generate HTML report with detailed explanations\n        html_report_path = self.generate_html_report(str(output_path))\n        \n        # Save JSON data\n        json_path = output_path / \"resource_data.json\"\n        with open(json_path, 'w') as f:\n            json.dump(self.results, f, indent=2)\n        \n        return report",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "_generate_visualizations",
        "type": "method",
        "start_line": 1688,
        "end_line": 1696,
        "code": "def _generate_visualizations(self, output_dir: Path) -> None:\n        \"\"\"\n        Generate visualizations of resource estimates.\n        \n        Args:\n            output_dir: Directory to save visualizations\n        \"\"\"\n        # For backward compatibility, just call the new method\n        self._generate_visualizations_for_html(output_dir)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 1699,
        "end_line": 1737,
        "code": "def main():\n    \"\"\"\n    Main function to run the resource estimator from command line.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"GNN Resource Estimator\")\n    parser.add_argument(\"input_path\", help=\"Path to GNN file or directory\")\n    parser.add_argument(\"-t\", \"--type-check-data\", help=\"Path to type check JSON data\")\n    parser.add_argument(\"-o\", \"--output-dir\", help=\"Directory to save resource reports\")\n    parser.add_argument(\"--recursive\", action=\"store_true\", help=\"Recursively process directories\")\n    parser.add_argument(\"--html-only\", action=\"store_true\", help=\"Generate only HTML report with visualizations\")\n    \n    args = parser.parse_args()\n    \n    estimator = GNNResourceEstimator(args.type_check_data)\n    \n    input_path = args.input_path\n    path = Path(input_path)\n    \n    if path.is_file():\n        # Estimate single file\n        result = estimator.estimate_from_file(str(path))\n        estimator.results = {str(path): result}\n    else:\n        # Estimate directory\n        estimator.estimate_from_directory(str(path), recursive=args.recursive)\n    \n    # Generate and display report\n    report = estimator.generate_report(args.output_dir)\n    \n    if not args.html_only:\n        print(report)\n    else:\n        # When HTML only mode is selected, just print a simple summary and HTML location\n        output_dir = args.output_dir if args.output_dir else \"output/gnn_type_checker/resources\"\n        html_path = os.path.join(output_dir, \"resource_report_detailed.html\")\n        print(f\"Generated HTML resource report at: {html_path}\")\n        print(f\"Analyzed {len(estimator.results)} files\")\n    \n    return 0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/resource_estimator.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/__main__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py": [
      {
        "name": "GNNTypeChecker",
        "type": "class",
        "start_line": 28,
        "end_line": 37,
        "code": "class GNNTypeChecker:\n        def check_file(self, file_path: str) -> tuple[bool, list, list]:\n            logger.debug(f\"Mock GNNTypeChecker.check_file called for {file_path}\")\n            return True, [], []\n        def check_directory(self, dir_path: str, recursive: bool = False) -> dict:\n            logger.debug(f\"Mock GNNTypeChecker.check_directory called for {dir_path}\")\n            return {dir_path: {\"is_valid\": True, \"errors\": [], \"warnings\": []}}\n        def generate_report(self, results: dict, output_dir_base: Path, report_md_filename: str = \"type_check_report.md\") -> str:\n            logger.debug(f\"Mock GNNTypeChecker.generate_report called.\")\n            return \"Mock report content\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "check_file",
        "type": "method",
        "start_line": 29,
        "end_line": 31,
        "code": "def check_file(self, file_path: str) -> tuple[bool, list, list]:\n            logger.debug(f\"Mock GNNTypeChecker.check_file called for {file_path}\")\n            return True, [], []",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "check_directory",
        "type": "method",
        "start_line": 32,
        "end_line": 34,
        "code": "def check_directory(self, dir_path: str, recursive: bool = False) -> dict:\n            logger.debug(f\"Mock GNNTypeChecker.check_directory called for {dir_path}\")\n            return {dir_path: {\"is_valid\": True, \"errors\": [], \"warnings\": []}}",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "generate_report",
        "type": "method",
        "start_line": 35,
        "end_line": 37,
        "code": "def generate_report(self, results: dict, output_dir_base: Path, report_md_filename: str = \"type_check_report.md\") -> str:\n            logger.debug(f\"Mock GNNTypeChecker.generate_report called.\")\n            return \"Mock report content\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "GNNResourceEstimator",
        "type": "class",
        "start_line": 43,
        "end_line": 47,
        "code": "class GNNResourceEstimator:\n        def estimate_from_file(self, file_path: str) -> dict:\n            return {\"error\": \"GNNResourceEstimator not available\"}\n        def estimate_from_directory(self, dir_path: str, recursive: bool = False) -> dict:\n            return {\"error\": \"GNNResourceEstimator not available\"}",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "estimate_from_file",
        "type": "method",
        "start_line": 44,
        "end_line": 45,
        "code": "def estimate_from_file(self, file_path: str) -> dict:\n            return {\"error\": \"GNNResourceEstimator not available\"}",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "estimate_from_directory",
        "type": "method",
        "start_line": 46,
        "end_line": 47,
        "code": "def estimate_from_directory(self, dir_path: str, recursive: bool = False) -> dict:\n            return {\"error\": \"GNNResourceEstimator not available\"}",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "type_check_gnn_file_mcp",
        "type": "function",
        "start_line": 52,
        "end_line": 78,
        "code": "def type_check_gnn_file_mcp(file_path: str) -> Dict[str, Any]:\n    \"\"\"\n    Run the GNN type checker on a single GNN file. Exposed via MCP.\n    \n    Args:\n        file_path: Path to the GNN file to check.\n        \n    Returns:\n        Dictionary containing type checker results (is_valid, errors, warnings).\n    \"\"\"\n    try:\n        checker = GNNTypeChecker()\n        is_valid, errors, warnings = checker.check_file(file_path)\n        return {\n            \"success\": True,\n            \"file_path\": file_path,\n            \"is_valid\": is_valid,\n            \"errors\": errors,\n            \"warnings\": warnings\n        }\n    except Exception as e:\n        logger.error(f\"Error in type_check_gnn_file_mcp for {file_path}: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"file_path\": file_path,\n            \"error\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "type_check_gnn_directory_mcp",
        "type": "function",
        "start_line": 80,
        "end_line": 123,
        "code": "def type_check_gnn_directory_mcp(dir_path: str, recursive: bool = False, output_dir_base: Optional[str] = None, report_md_filename: Optional[str] = \"type_check_report.md\") -> Dict[str, Any]:\n    \"\"\"\n    Run the GNN type checker on all GNN files in a directory. Exposed via MCP.\n    \n    Args:\n        dir_path: Path to the directory containing GNN files.\n        recursive: Whether to search recursively (default: False).\n        output_dir_base: Optional base directory path to save the generated report.\n        report_md_filename: Optional filename for the markdown report. Defaults to type_check_report.md.\n\n    Returns:\n        Dictionary containing aggregated type checker results and report path if generated.\n    \"\"\"\n    try:\n        checker = GNNTypeChecker()\n        results = checker.check_directory(dir_path, recursive=recursive)\n\n        report_generated_path = None\n        if output_dir_base and report_md_filename:\n            output_path = Path(output_dir_base)\n            # The checker's generate_report now handles creating subdirs and all its files (HTML, JSON)\n            # and returns the main markdown report content.\n            # It also prints where files are saved.\n            checker.generate_report(results, output_path, report_md_filename=report_md_filename)\n            report_generated_path = str(output_path / report_md_filename)\n            \n        return {\n            \"success\": True,\n            \"directory_path\": dir_path,\n            \"results_summary\": {\n                \"total_files\": len(results),\n                \"valid_count\": sum(1 for r in results.values() if r.get(\"is_valid\", False)), # Ensure key exists\n                \"invalid_count\": sum(1 for r in results.values() if not r.get(\"is_valid\", True)), # Ensure key exists\n            },\n            \"results_detail\": results,\n            \"report_generated_at\": report_generated_path\n        }\n    except Exception as e:\n        logger.error(f\"Error in type_check_gnn_directory_mcp for {dir_path}: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"directory_path\": dir_path,\n            \"error\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "estimate_resources_for_gnn_file_mcp",
        "type": "function",
        "start_line": 126,
        "end_line": 150,
        "code": "def estimate_resources_for_gnn_file_mcp(file_path: str) -> Dict[str, Any]:\n    \"\"\"\n    Estimate computational resources for a single GNN file. Exposed via MCP.\n    \n    Args:\n        file_path: Path to the GNN file.\n        \n    Returns:\n        Dictionary containing resource estimates.\n    \"\"\"\n    try:\n        estimator = GNNResourceEstimator()\n        estimates = estimator.estimate_from_file(file_path)\n        return {\n            \"success\": True,\n            \"file_path\": file_path,\n            \"estimates\": estimates\n        }\n    except Exception as e:\n        logger.error(f\"Error in estimate_resources_for_gnn_file_mcp for {file_path}: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"file_path\": file_path,\n            \"error\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "estimate_resources_for_gnn_directory_mcp",
        "type": "function",
        "start_line": 152,
        "end_line": 177,
        "code": "def estimate_resources_for_gnn_directory_mcp(dir_path: str, recursive: bool = False) -> Dict[str, Any]:\n    \"\"\"\n    Estimate resources for all GNN files in a directory. Exposed via MCP.\n    \n    Args:\n        dir_path: Path to the directory containing GNN files.\n        recursive: Whether to search recursively (default: False).\n        \n    Returns:\n        Dictionary mapping file paths to resource estimates.\n    \"\"\"\n    try:\n        estimator = GNNResourceEstimator()\n        all_estimates = estimator.estimate_from_directory(dir_path, recursive=recursive)\n        return {\n            \"success\": True,\n            \"directory_path\": dir_path,\n            \"all_estimates\": all_estimates\n        }\n    except Exception as e:\n        logger.error(f\"Error in estimate_resources_for_gnn_directory_mcp for {dir_path}: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"directory_path\": dir_path,\n            \"error\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      },
      {
        "name": "register_tools",
        "type": "function",
        "start_line": 180,
        "end_line": 244,
        "code": "def register_tools(mcp_instance): # Changed 'mcp' to 'mcp_instance' for clarity\n    \"\"\"Register GNN type checker and resource estimator tools with the MCP.\"\"\"\n    \n    mcp_instance.register_tool(\n        \"type_check_gnn_file\",\n        type_check_gnn_file_mcp,\n        {\n            \"file_path\": {\"type\": \"string\", \"description\": \"Path to the GNN file to be type-checked.\"}\n        },\n        \"Runs the GNN type checker on a specified GNN model file.\"\n    )\n    \n    mcp_instance.register_tool(\n        \"type_check_gnn_directory\",\n        type_check_gnn_directory_mcp,\n        {\n            \"dir_path\": {\"type\": \"string\", \"description\": \"Path to the directory containing GNN files to be type-checked.\"},\n            \"recursive\": {\"type\": \"boolean\", \"description\": \"Search directory recursively. Defaults to False.\", \"optional\": True},\n            \"output_dir_base\": {\"type\": \"string\", \"description\": \"Optional base directory to save the report and other artifacts (HTML, JSON).\", \"optional\": True},\n            \"report_md_filename\": {\"type\": \"string\", \"description\": \"Optional filename for the markdown report (e.g., 'my_report.md'). Defaults to 'type_check_report.md'.\", \"optional\": True}\n        },\n        \"Runs the GNN type checker on all GNN files in a specified directory. If output_dir_base is provided, reports are generated.\"\n    )\n    \n    if 'GNNResourceEstimator' in globals() and hasattr(GNNResourceEstimator, 'estimate_from_file'): # More robust check\n        # Check if the class is the actual one, not the mock, by checking a method\n        try:\n            # Attempt to instantiate and check a method to ensure it's not the mock\n            # This is a bit heuristic; a more robust way would be to avoid mocks in production if possible\n            # or have a clearer way to distinguish them.\n            estimator_instance = GNNResourceEstimator()\n            # Check if estimate_from_file method exists and its docstring does not contain \"mock\"\n            if hasattr(estimator_instance, 'estimate_from_file') and \\\n               (estimator_instance.estimate_from_file.__doc__ is None or \\\n                \"mock\" not in estimator_instance.estimate_from_file.__doc__.lower()):\n                 is_real_estimator = True\n            else:\n                 is_real_estimator = False\n        except: # pylint: disable=bare-except\n            is_real_estimator = False # Fallback if instantiation fails\n\n        if is_real_estimator:\n            mcp_instance.register_tool(\n                \"estimate_resources_for_gnn_file\",\n                estimate_resources_for_gnn_file_mcp,\n                {\n                    \"file_path\": {\"type\": \"string\", \"description\": \"Path to the GNN file for resource estimation.\"}\n                },\n                \"Estimates computational resources (memory, inference, storage) for a GNN model file.\"\n            )\n            \n            mcp_instance.register_tool(\n                \"estimate_resources_for_gnn_directory\",\n                estimate_resources_for_gnn_directory_mcp,\n                {\n                    \"dir_path\": {\"type\": \"string\", \"description\": \"Path to the directory for GNN resource estimation.\"},\n                    \"recursive\": {\"type\": \"boolean\", \"description\": \"Search directory recursively. Defaults to False.\", \"optional\": True}\n                },\n                \"Estimates computational resources for all GNN files in a specified directory.\"\n            )\n        else:\n            logger.warning(\"GNNResourceEstimator appears to be a mock or unavailable. Resource estimation MCP tools will not be registered.\")\n            \n    logger.info(\"GNN Type Checker module MCP tools registered.\")\n    # No specific resources to register for type_checker beyond the files it might create (handled by report_file param) ",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py": [
      {
        "name": "GNNTypeChecker",
        "type": "class",
        "start_line": 20,
        "end_line": 552,
        "code": "class GNNTypeChecker:\n    \"\"\"\n    Type checker for GNN files to validate they adhere to the specification\n    and have consistent typing.\n    \"\"\"\n    \n    # Required sections per GNN specification\n    REQUIRED_SECTIONS = {\n        'GNNSection',\n        'GNNVersionAndFlags',\n        'ModelName',\n        'StateSpaceBlock',\n        'Connections',\n        'Footer',\n        'Signature'\n    }\n    \n    # Allowed time specifications\n    VALID_TIME_SPECS = {\n        'Static', \n        'Dynamic'\n    }\n    \n    # Valid types for variables\n    VALID_TYPES = {\n        'float', \n        'int', \n        'bool', \n        'string', \n        'categorical'\n    }\n    \n    def __init__(self, strict_mode: bool = False):\n        \"\"\"\n        Initialize the GNN type checker.\n        \n        Args:\n            strict_mode: Whether to enforce strict type checking rules\n        \"\"\"\n        self.parser = GNNParser()\n        self.strict_mode = strict_mode\n        self.errors = []\n        self.warnings = []\n        logger.info(f\"GNNTypeChecker initialized. Strict mode: {strict_mode}\")\n        \n    def check_file(self, file_path: str) -> Tuple[bool, List[str], List[str]]:\n        \"\"\"\n        Check a GNN file for type and structure validity.\n        \n        Args:\n            file_path: Path to the GNN file to check\n            \n        Returns:\n            Tuple of (is_valid, errors, warnings)\n        \"\"\"\n        logger.info(f\"Starting GNN check for file: {file_path}\")\n        self.errors = []\n        self.warnings = []\n        \n        try:\n            # Parse the file\n            parsed_content = self.parser.parse_file(file_path)\n            logger.debug(f\"Successfully parsed file: {file_path}\")\n            \n            # Check required sections\n            self._check_required_sections(parsed_content)\n            \n            # Check state space variables and types\n            self._check_state_space(parsed_content)\n            \n            # Check connections for consistency\n            self._check_connections(parsed_content)\n            \n            # Check time specification\n            self._check_time_specification(parsed_content)\n            \n            # Check equations\n            self._check_equations(parsed_content)\n            \n            # Check version and flags\n            self._check_version_and_flags(parsed_content)\n            \n        except Exception as e:\n            logger.error(f\"Failed to parse or check file {file_path}: {str(e)}\", exc_info=True)\n            self.errors.append(f\"Failed to parse or check file: {str(e)}\")\n        \n        # Log final errors and warnings for the file\n        if self.errors:\n            logger.warning(f\"File {file_path} has {len(self.errors)} errors: {self.errors}\")\n        if self.warnings:\n            logger.info(f\"File {file_path} has {len(self.warnings)} warnings: {self.warnings}\")\n            \n        is_valid = len(self.errors) == 0\n        logger.info(f\"Finished GNN check for file: {file_path}. Valid: {is_valid}\")\n        return is_valid, self.errors, self.warnings\n    \n    def check_directory(self, dir_path: str, recursive: bool = False) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Check all GNN files in a directory.\n        \n        Args:\n            dir_path: Path to the directory containing GNN files\n            recursive: Whether to recursively check subdirectories\n            \n        Returns:\n            Dictionary mapping file paths to check results\n        \"\"\"\n        logger.info(f\"Starting GNN check for directory: {dir_path}, Recursive: {recursive}\")\n        results = {}\n        path = Path(dir_path)\n        \n        # Define pattern for GNN files\n        pattern = \"**/*.md\" if recursive else \"*.md\"\n        \n        file_count = 0\n        for file_path in path.glob(pattern):\n            file_count += 1\n            file_str = str(file_path)\n            logger.debug(f\"Processing file in directory: {file_str}\")\n            is_valid, errors, warnings = self.check_file(file_str)\n            results[file_str] = {\n                \"is_valid\": is_valid,\n                \"errors\": errors,\n                \"warnings\": warnings\n            }\n        logger.info(f\"Finished checking directory {dir_path}. Processed {file_count} files.\")\n        return results\n    \n    def _check_required_sections(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check if all required sections are present in the GNN file.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        missing_sections = self.REQUIRED_SECTIONS - set(content.keys())\n        \n        for section in missing_sections:\n            error_msg = f\"Missing required section: {section}\"\n            self.errors.append(error_msg)\n            logger.debug(f\"Validation Error: {error_msg}\")\n    \n    def _check_state_space(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check state space variables and their types.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        if 'Variables' not in content:\n            error_msg = \"No variables extracted from StateSpaceBlock\"\n            self.errors.append(error_msg)\n            logger.debug(f\"Validation Error: {error_msg}\")\n            return\n        \n        variables = content['Variables']\n        \n        for var_name, var_info in variables.items():\n            # Check if dimensions are properly specified\n            dims = var_info.get('dimensions', [])\n            if not dims:\n                error_msg = f\"Variable '{var_name}' has no dimensions specified\"\n                self.errors.append(error_msg)\n                logger.debug(f\"Validation Error: {error_msg}\")\n            \n            # Check variable type if specified\n            var_type = var_info.get('type')\n            if var_type and var_type not in self.VALID_TYPES:\n                error_msg = f\"Variable '{var_name}' has invalid type: {var_type}\"\n                self.errors.append(error_msg)\n                logger.debug(f\"Validation Error: {error_msg}\")\n    \n    def _check_connections(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check connections for consistency with declared variables.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        if 'Edges' not in content or 'Variables' not in content:\n            return\n        \n        edges = content['Edges']\n        variables = content['Variables']\n        var_names = set(variables.keys())\n        \n        # Check for undefined variables in connections\n        for edge in edges:\n            source = edge.get('source')\n            target = edge.get('target')\n            \n            # Extract base variable names (without time indices)\n            source_base = re.sub(r'_t(?:\\+\\d+)?', '', source)\n            target_base = re.sub(r'_t(?:\\+\\d+)?', '', target)\n            \n            if source_base not in var_names:\n                error_msg = f\"Connection references undefined variable: {source}\"\n                self.errors.append(error_msg)\n                logger.debug(f\"Validation Error: {error_msg}\")\n            \n            if target_base not in var_names:\n                error_msg = f\"Connection references undefined variable: {target}\"\n                self.errors.append(error_msg)\n                logger.debug(f\"Validation Error: {error_msg}\")\n    \n    def _check_time_specification(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check time specification for validity.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        if 'Time' not in content:\n            warning_msg = \"Time section not specified\"\n            self.warnings.append(warning_msg)\n            logger.debug(f\"Validation Warning: {warning_msg}\")\n            return\n        \n        time_spec = content['Time']\n        lines = time_spec.split('\\n')\n        \n        primary_spec = lines[0].strip() if lines else \"\"\n        \n        if primary_spec not in self.VALID_TIME_SPECS:\n            error_msg = f\"Invalid time specification: {primary_spec}\"\n            self.errors.append(error_msg)\n            logger.debug(f\"Validation Error: {error_msg}\")\n        \n        # If dynamic, check additional time specifications\n        if primary_spec == 'Dynamic':\n            has_time_var = False\n            for line in lines[1:]:\n                if line.startswith('DiscreteTime=') or line.startswith('ContinuousTime='):\n                    has_time_var = True\n                    time_var = line.split('=')[1].strip()\n                    \n                    # Check if the time variable is defined\n                    if 'Variables' in content and time_var not in content['Variables']:\n                        error_msg = f\"Time variable {time_var} not defined in StateSpaceBlock\"\n                        self.errors.append(error_msg)\n                        logger.debug(f\"Validation Error: {error_msg}\")\n            \n            if not has_time_var and self.strict_mode:\n                error_msg = \"Dynamic model requires DiscreteTime or ContinuousTime specification\"\n                self.errors.append(error_msg)\n                logger.debug(f\"Validation Error: {error_msg}\")\n    \n    def _check_equations(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check equations for references to undefined variables.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        if 'Equations' not in content or 'Variables' not in content:\n            return\n        \n        equations = content['Equations']\n        variables = content['Variables']\n        var_names = set(variables.keys())\n        \n        # Extract variable names from equations using simple regex\n        # This is a simplistic approach and might not catch all variable references\n        equation_lines = equations.split('\\n')\n        referenced_in_equation = set()\n        for line in equation_lines:\n            if '=' in line:\n                left_side = line.split('=')[0].strip()\n                \n                # Extract the variable name from lhs (handle subscripts and superscripts)\n                match = re.match(r'([a-zA-Z0-9_]+)(?:_[a-zA-Z0-9{}\\+]+)?(?:\\^[a-zA-Z0-9{}]+)?', left_side)\n                if match:\n                    var_name = match.group(1)\n                    if var_name not in var_names and not self._is_common_math_function(var_name):\n                        error_msg = f\"Equation '{line}' references undefined variable: {var_name}\"\n                        self.errors.append(error_msg)\n                        logger.debug(f\"Validation Error: {error_msg}\")\n                        referenced_in_equation.add(var_name)\n    \n    def _check_version_and_flags(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check GNN version and flags for validity.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        if 'GNNVersionAndFlags' not in content:\n            return\n        \n        version_flags = content['GNNVersionAndFlags']\n        \n        # Check if GNN version is specified\n        if not re.search(r'GNN v\\d+(?:\\.\\d+)?', version_flags):\n            self.errors.append(\"Invalid GNNVersionAndFlags: Missing GNN version\")\n    \n    def _is_common_math_function(self, name: str) -> bool:\n        # Basic check for common math functions to avoid false positives\n        return name.lower() in ['ln', 'log', 'exp', 'sin', 'cos', 'tan', 'sqrt', 'softmax', 'sigmoid']\n\n    def generate_report(self, results: Dict[str, Dict[str, Any]], \n                        output_dir_base: Path, \n                        report_md_filename: str = \"type_check_report.md\",\n                        project_root_path: Optional[Union[str, Path]] = None) -> str:\n        \"\"\"\n        Generate a markdown report of the type checking results.\n        \n        Args:\n            results: Dictionary mapping file paths to check results\n            output_dir_base: The base directory where type checking outputs (like this report) are saved.\n            report_md_filename: The specific name for the markdown report file.\n            project_root_path: Optional path to the project root for making file paths relative.\n            \n        Returns:\n            String summary of the report.\n        \"\"\"\n        logger.info(f\"Generating type check report: {report_md_filename} in {output_dir_base}\")\n        report_parts = [\"# GNN Type Checker Report\"]\n        valid_count = 0\n        invalid_count = 0\n\n        # Resolve project_root once\n        actual_project_root = None\n        if project_root_path:\n            actual_project_root = Path(project_root_path).resolve()\n\n        for file_path_str, result in results.items():\n            file_path_obj = Path(file_path_str).resolve()\n            display_path = file_path_str # Default to original string if not made relative\n            if actual_project_root:\n                try:\n                    display_path = str(file_path_obj.relative_to(actual_project_root))\n                except ValueError:\n                    display_path = file_path_obj.name # Fallback to filename if not in project root\n            \n            if result[\"is_valid\"]:\n                valid_count += 1\n                report_parts.append(f\"## {file_path_obj.name}: \u2705 VALID\")\n                report_parts.append(f\"Path: {display_path}\")\n                if result.get(\"warnings\"):\n                    report_parts.append(\"Warnings:\")\n                    for warning in result[\"warnings\"]:\n                        report_parts.append(f\"  - {warning}\")\n            else:\n                invalid_count += 1\n                report_parts.append(f\"## {file_path_obj.name}: \u274c INVALID\")\n                report_parts.append(f\"Path: {display_path}\")\n                if result.get(\"errors\"):\n                    report_parts.append(\"Errors:\")\n                    for error in result[\"errors\"]:\n                        report_parts.append(f\"  - {error}\")\n                if result.get(\"warnings\"):\n                    report_parts.append(\"Warnings:\")\n                    for warning in result[\"warnings\"]:\n                        report_parts.append(f\"  - {warning}\")\n            report_parts.append(\"\")  # Add a blank line for spacing\n\n        summary = f\"Checked {len(results)} files, {valid_count} valid, {invalid_count} invalid\"\n        report_parts.append(summary)\n        report_parts.append(\"\")\n\n        full_report_str = \"\\n\".join(report_parts)\n        \n        report_path = output_dir_base / report_md_filename\n        report_path.parent.mkdir(parents=True, exist_ok=True)\n        with open(report_path, 'w') as f:\n            f.write(full_report_str)\n            \n        logger.info(f\"Successfully wrote GNN type check report to: {report_path}\")\n        return full_report_str\n    \n    def _generate_html_report(self, results: Dict[str, Dict[str, Any]], output_file: Path) -> None:\n        \"\"\"\n        Generate an HTML report with visualizations.\n        \n        Args:\n            results: Dictionary mapping file paths to check results\n            output_file: Path to save the HTML report\n        \"\"\"\n        import json\n        from pathlib import Path\n        \n        # Count error and warning types for visualization\n        error_types = {}\n        warning_types = {}\n        \n        for result in results.values():\n            for error in result[\"errors\"]:\n                error_type = error.split(\":\")[0] if \":\" in error else error\n                error_types[error_type] = error_types.get(error_type, 0) + 1\n            \n            for warning in result[\"warnings\"]:\n                warning_type = warning.split(\":\")[0] if \":\" in warning else warning\n                warning_types[warning_type] = warning_types.get(warning_type, 0) + 1\n        \n        # Create HTML content with embedded charts\n        html_content = f\"\"\"<!DOCTYPE html>\n        <html>\n        <head>\n            <title>GNN Type Checking Visualization</title>\n            <script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n            <style>\n                body {{ font-family: Arial, sans-serif; margin: 20px; }}\n                .chart-container {{ width: 600px; height: 400px; margin-bottom: 30px; }}\n                .summary {{ margin-bottom: 20px; }}\n            </style>\n        </head>\n        <body>\n            <h1>GNN Type Checking Visualization</h1>\n            \n            <div class=\"summary\">\n                <h2>Summary</h2>\n                <p>Total files: {len(results)}</p>\n                <p>Valid files: {sum(1 for r in results.values() if r[\"is_valid\"])}</p>\n                <p>Invalid files: {sum(1 for r in results.values() if not r[\"is_valid\"])}</p>\n                <p>Total errors: {sum(len(r[\"errors\"]) for r in results.values())}</p>\n                <p>Total warnings: {sum(len(r[\"warnings\"]) for r in results.values())}</p>\n            </div>\n            \n            <div class=\"chart-container\">\n                <h2>File Validity</h2>\n                <canvas id=\"validityChart\"></canvas>\n            </div>\n            \n            <div class=\"chart-container\">\n                <h2>Error Types</h2>\n                <canvas id=\"errorsChart\"></canvas>\n            </div>\n            \n            <div class=\"chart-container\">\n                <h2>Warning Types</h2>\n                <canvas id=\"warningsChart\"></canvas>\n            </div>\n            \n            <script>\n                // Validity pie chart\n                const validityCtx = document.getElementById('validityChart').getContext('2d');\n                new Chart(validityCtx, {{\n                    type: 'pie',\n                    data: {{\n                        labels: ['Valid', 'Invalid'],\n                        datasets: [{{\n                            data: [\n                                {sum(1 for r in results.values() if r[\"is_valid\"])}, \n                                {sum(1 for r in results.values() if not r[\"is_valid\"])}\n                            ],\n                            backgroundColor: ['rgba(75, 192, 192, 0.2)', 'rgba(255, 99, 132, 0.2)'],\n                            borderColor: ['rgba(75, 192, 192, 1)', 'rgba(255, 99, 132, 1)'],\n                            borderWidth: 1\n                        }}]\n                    }}\n                }});\n                \n                // Error types chart\n                const errorsCtx = document.getElementById('errorsChart').getContext('2d');\n                new Chart(errorsCtx, {{\n                    type: 'bar',\n                    data: {{\n                        labels: {json.dumps(list(error_types.keys()))},\n                        datasets: [{{\n                            label: 'Count',\n                            data: {json.dumps(list(error_types.values()))},\n                            backgroundColor: 'rgba(255, 99, 132, 0.2)',\n                            borderColor: 'rgba(255, 99, 132, 1)',\n                            borderWidth: 1\n                        }}]\n                    }},\n                    options: {{\n                        scales: {{\n                            y: {{\n                                beginAtZero: true\n                            }}\n                        }}\n                    }}\n                }});\n                \n                // Warning types chart\n                const warningsCtx = document.getElementById('warningsChart').getContext('2d');\n                new Chart(warningsCtx, {{\n                    type: 'bar',\n                    data: {{\n                        labels: {json.dumps(list(warning_types.keys()))},\n                        datasets: [{{\n                            label: 'Count',\n                            data: {json.dumps(list(warning_types.values()))},\n                            backgroundColor: 'rgba(255, 206, 86, 0.2)',\n                            borderColor: 'rgba(255, 206, 86, 1)',\n                            borderWidth: 1\n                        }}]\n                    }},\n                    options: {{\n                        scales: {{\n                            y: {{\n                                beginAtZero: true\n                            }}\n                        }}\n                    }}\n                }});\n            </script>\n        </body>\n        </html>\n        \"\"\"\n        \n        # Save HTML report\n        with open(output_file, 'w') as f:\n            f.write(html_content)\n        logger.info(f\"Successfully wrote HTML report to: {output_file}\")\n    \n    def generate_json_data(self, results: Dict[str, Dict[str, Any]], output_file: Path) -> None:\n        \"\"\"\n        Generate JSON data for resource estimator and general use.\n        \n        Args:\n            results: Dictionary mapping file paths to check results\n            output_file: Path to save the JSON data\n        \"\"\"\n        import json\n        \n        # Prepare data for resource estimator\n        json_data = {\n            \"type_check_results\": results,\n            \"summary\": {\n                \"total_files\": len(results),\n                \"valid_files\": sum(1 for r in results.values() if r[\"is_valid\"]),\n                \"invalid_files\": sum(1 for r in results.values() if not r[\"is_valid\"]),\n                \"total_errors\": sum(len(r[\"errors\"]) for r in results.values()),\n                \"total_warnings\": sum(len(r[\"warnings\"]) for r in results.values())\n            }\n        }\n        \n        # Save JSON data\n        with open(output_file, 'w') as f:\n            json.dump(json_data, f, indent=2)\n        logger.info(f\"Successfully wrote JSON data to: {output_file}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 52,
        "end_line": 63,
        "code": "def __init__(self, strict_mode: bool = False):\n        \"\"\"\n        Initialize the GNN type checker.\n        \n        Args:\n            strict_mode: Whether to enforce strict type checking rules\n        \"\"\"\n        self.parser = GNNParser()\n        self.strict_mode = strict_mode\n        self.errors = []\n        self.warnings = []\n        logger.info(f\"GNNTypeChecker initialized. Strict mode: {strict_mode}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "check_file",
        "type": "method",
        "start_line": 65,
        "end_line": 114,
        "code": "def check_file(self, file_path: str) -> Tuple[bool, List[str], List[str]]:\n        \"\"\"\n        Check a GNN file for type and structure validity.\n        \n        Args:\n            file_path: Path to the GNN file to check\n            \n        Returns:\n            Tuple of (is_valid, errors, warnings)\n        \"\"\"\n        logger.info(f\"Starting GNN check for file: {file_path}\")\n        self.errors = []\n        self.warnings = []\n        \n        try:\n            # Parse the file\n            parsed_content = self.parser.parse_file(file_path)\n            logger.debug(f\"Successfully parsed file: {file_path}\")\n            \n            # Check required sections\n            self._check_required_sections(parsed_content)\n            \n            # Check state space variables and types\n            self._check_state_space(parsed_content)\n            \n            # Check connections for consistency\n            self._check_connections(parsed_content)\n            \n            # Check time specification\n            self._check_time_specification(parsed_content)\n            \n            # Check equations\n            self._check_equations(parsed_content)\n            \n            # Check version and flags\n            self._check_version_and_flags(parsed_content)\n            \n        except Exception as e:\n            logger.error(f\"Failed to parse or check file {file_path}: {str(e)}\", exc_info=True)\n            self.errors.append(f\"Failed to parse or check file: {str(e)}\")\n        \n        # Log final errors and warnings for the file\n        if self.errors:\n            logger.warning(f\"File {file_path} has {len(self.errors)} errors: {self.errors}\")\n        if self.warnings:\n            logger.info(f\"File {file_path} has {len(self.warnings)} warnings: {self.warnings}\")\n            \n        is_valid = len(self.errors) == 0\n        logger.info(f\"Finished GNN check for file: {file_path}. Valid: {is_valid}\")\n        return is_valid, self.errors, self.warnings",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "check_directory",
        "type": "method",
        "start_line": 116,
        "end_line": 146,
        "code": "def check_directory(self, dir_path: str, recursive: bool = False) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Check all GNN files in a directory.\n        \n        Args:\n            dir_path: Path to the directory containing GNN files\n            recursive: Whether to recursively check subdirectories\n            \n        Returns:\n            Dictionary mapping file paths to check results\n        \"\"\"\n        logger.info(f\"Starting GNN check for directory: {dir_path}, Recursive: {recursive}\")\n        results = {}\n        path = Path(dir_path)\n        \n        # Define pattern for GNN files\n        pattern = \"**/*.md\" if recursive else \"*.md\"\n        \n        file_count = 0\n        for file_path in path.glob(pattern):\n            file_count += 1\n            file_str = str(file_path)\n            logger.debug(f\"Processing file in directory: {file_str}\")\n            is_valid, errors, warnings = self.check_file(file_str)\n            results[file_str] = {\n                \"is_valid\": is_valid,\n                \"errors\": errors,\n                \"warnings\": warnings\n            }\n        logger.info(f\"Finished checking directory {dir_path}. Processed {file_count} files.\")\n        return results",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "_check_required_sections",
        "type": "method",
        "start_line": 148,
        "end_line": 160,
        "code": "def _check_required_sections(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check if all required sections are present in the GNN file.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        missing_sections = self.REQUIRED_SECTIONS - set(content.keys())\n        \n        for section in missing_sections:\n            error_msg = f\"Missing required section: {section}\"\n            self.errors.append(error_msg)\n            logger.debug(f\"Validation Error: {error_msg}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "_check_state_space",
        "type": "method",
        "start_line": 162,
        "end_line": 190,
        "code": "def _check_state_space(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check state space variables and their types.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        if 'Variables' not in content:\n            error_msg = \"No variables extracted from StateSpaceBlock\"\n            self.errors.append(error_msg)\n            logger.debug(f\"Validation Error: {error_msg}\")\n            return\n        \n        variables = content['Variables']\n        \n        for var_name, var_info in variables.items():\n            # Check if dimensions are properly specified\n            dims = var_info.get('dimensions', [])\n            if not dims:\n                error_msg = f\"Variable '{var_name}' has no dimensions specified\"\n                self.errors.append(error_msg)\n                logger.debug(f\"Validation Error: {error_msg}\")\n            \n            # Check variable type if specified\n            var_type = var_info.get('type')\n            if var_type and var_type not in self.VALID_TYPES:\n                error_msg = f\"Variable '{var_name}' has invalid type: {var_type}\"\n                self.errors.append(error_msg)\n                logger.debug(f\"Validation Error: {error_msg}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "_check_connections",
        "type": "method",
        "start_line": 192,
        "end_line": 223,
        "code": "def _check_connections(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check connections for consistency with declared variables.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        if 'Edges' not in content or 'Variables' not in content:\n            return\n        \n        edges = content['Edges']\n        variables = content['Variables']\n        var_names = set(variables.keys())\n        \n        # Check for undefined variables in connections\n        for edge in edges:\n            source = edge.get('source')\n            target = edge.get('target')\n            \n            # Extract base variable names (without time indices)\n            source_base = re.sub(r'_t(?:\\+\\d+)?', '', source)\n            target_base = re.sub(r'_t(?:\\+\\d+)?', '', target)\n            \n            if source_base not in var_names:\n                error_msg = f\"Connection references undefined variable: {source}\"\n                self.errors.append(error_msg)\n                logger.debug(f\"Validation Error: {error_msg}\")\n            \n            if target_base not in var_names:\n                error_msg = f\"Connection references undefined variable: {target}\"\n                self.errors.append(error_msg)\n                logger.debug(f\"Validation Error: {error_msg}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "_check_time_specification",
        "type": "method",
        "start_line": 225,
        "end_line": 265,
        "code": "def _check_time_specification(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check time specification for validity.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        if 'Time' not in content:\n            warning_msg = \"Time section not specified\"\n            self.warnings.append(warning_msg)\n            logger.debug(f\"Validation Warning: {warning_msg}\")\n            return\n        \n        time_spec = content['Time']\n        lines = time_spec.split('\\n')\n        \n        primary_spec = lines[0].strip() if lines else \"\"\n        \n        if primary_spec not in self.VALID_TIME_SPECS:\n            error_msg = f\"Invalid time specification: {primary_spec}\"\n            self.errors.append(error_msg)\n            logger.debug(f\"Validation Error: {error_msg}\")\n        \n        # If dynamic, check additional time specifications\n        if primary_spec == 'Dynamic':\n            has_time_var = False\n            for line in lines[1:]:\n                if line.startswith('DiscreteTime=') or line.startswith('ContinuousTime='):\n                    has_time_var = True\n                    time_var = line.split('=')[1].strip()\n                    \n                    # Check if the time variable is defined\n                    if 'Variables' in content and time_var not in content['Variables']:\n                        error_msg = f\"Time variable {time_var} not defined in StateSpaceBlock\"\n                        self.errors.append(error_msg)\n                        logger.debug(f\"Validation Error: {error_msg}\")\n            \n            if not has_time_var and self.strict_mode:\n                error_msg = \"Dynamic model requires DiscreteTime or ContinuousTime specification\"\n                self.errors.append(error_msg)\n                logger.debug(f\"Validation Error: {error_msg}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "_check_equations",
        "type": "method",
        "start_line": 267,
        "end_line": 297,
        "code": "def _check_equations(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check equations for references to undefined variables.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        if 'Equations' not in content or 'Variables' not in content:\n            return\n        \n        equations = content['Equations']\n        variables = content['Variables']\n        var_names = set(variables.keys())\n        \n        # Extract variable names from equations using simple regex\n        # This is a simplistic approach and might not catch all variable references\n        equation_lines = equations.split('\\n')\n        referenced_in_equation = set()\n        for line in equation_lines:\n            if '=' in line:\n                left_side = line.split('=')[0].strip()\n                \n                # Extract the variable name from lhs (handle subscripts and superscripts)\n                match = re.match(r'([a-zA-Z0-9_]+)(?:_[a-zA-Z0-9{}\\+]+)?(?:\\^[a-zA-Z0-9{}]+)?', left_side)\n                if match:\n                    var_name = match.group(1)\n                    if var_name not in var_names and not self._is_common_math_function(var_name):\n                        error_msg = f\"Equation '{line}' references undefined variable: {var_name}\"\n                        self.errors.append(error_msg)\n                        logger.debug(f\"Validation Error: {error_msg}\")\n                        referenced_in_equation.add(var_name)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "_check_version_and_flags",
        "type": "method",
        "start_line": 299,
        "end_line": 313,
        "code": "def _check_version_and_flags(self, content: Dict[str, Any]) -> None:\n        \"\"\"\n        Check GNN version and flags for validity.\n        \n        Args:\n            content: Parsed GNN content\n        \"\"\"\n        if 'GNNVersionAndFlags' not in content:\n            return\n        \n        version_flags = content['GNNVersionAndFlags']\n        \n        # Check if GNN version is specified\n        if not re.search(r'GNN v\\d+(?:\\.\\d+)?', version_flags):\n            self.errors.append(\"Invalid GNNVersionAndFlags: Missing GNN version\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "_is_common_math_function",
        "type": "method",
        "start_line": 315,
        "end_line": 317,
        "code": "def _is_common_math_function(self, name: str) -> bool:\n        # Basic check for common math functions to avoid false positives\n        return name.lower() in ['ln', 'log', 'exp', 'sin', 'cos', 'tan', 'sqrt', 'softmax', 'sigmoid']",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "generate_report",
        "type": "method",
        "start_line": 319,
        "end_line": 388,
        "code": "def generate_report(self, results: Dict[str, Dict[str, Any]], \n                        output_dir_base: Path, \n                        report_md_filename: str = \"type_check_report.md\",\n                        project_root_path: Optional[Union[str, Path]] = None) -> str:\n        \"\"\"\n        Generate a markdown report of the type checking results.\n        \n        Args:\n            results: Dictionary mapping file paths to check results\n            output_dir_base: The base directory where type checking outputs (like this report) are saved.\n            report_md_filename: The specific name for the markdown report file.\n            project_root_path: Optional path to the project root for making file paths relative.\n            \n        Returns:\n            String summary of the report.\n        \"\"\"\n        logger.info(f\"Generating type check report: {report_md_filename} in {output_dir_base}\")\n        report_parts = [\"# GNN Type Checker Report\"]\n        valid_count = 0\n        invalid_count = 0\n\n        # Resolve project_root once\n        actual_project_root = None\n        if project_root_path:\n            actual_project_root = Path(project_root_path).resolve()\n\n        for file_path_str, result in results.items():\n            file_path_obj = Path(file_path_str).resolve()\n            display_path = file_path_str # Default to original string if not made relative\n            if actual_project_root:\n                try:\n                    display_path = str(file_path_obj.relative_to(actual_project_root))\n                except ValueError:\n                    display_path = file_path_obj.name # Fallback to filename if not in project root\n            \n            if result[\"is_valid\"]:\n                valid_count += 1\n                report_parts.append(f\"## {file_path_obj.name}: \u2705 VALID\")\n                report_parts.append(f\"Path: {display_path}\")\n                if result.get(\"warnings\"):\n                    report_parts.append(\"Warnings:\")\n                    for warning in result[\"warnings\"]:\n                        report_parts.append(f\"  - {warning}\")\n            else:\n                invalid_count += 1\n                report_parts.append(f\"## {file_path_obj.name}: \u274c INVALID\")\n                report_parts.append(f\"Path: {display_path}\")\n                if result.get(\"errors\"):\n                    report_parts.append(\"Errors:\")\n                    for error in result[\"errors\"]:\n                        report_parts.append(f\"  - {error}\")\n                if result.get(\"warnings\"):\n                    report_parts.append(\"Warnings:\")\n                    for warning in result[\"warnings\"]:\n                        report_parts.append(f\"  - {warning}\")\n            report_parts.append(\"\")  # Add a blank line for spacing\n\n        summary = f\"Checked {len(results)} files, {valid_count} valid, {invalid_count} invalid\"\n        report_parts.append(summary)\n        report_parts.append(\"\")\n\n        full_report_str = \"\\n\".join(report_parts)\n        \n        report_path = output_dir_base / report_md_filename\n        report_path.parent.mkdir(parents=True, exist_ok=True)\n        with open(report_path, 'w') as f:\n            f.write(full_report_str)\n            \n        logger.info(f\"Successfully wrote GNN type check report to: {report_path}\")\n        return full_report_str",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "_generate_html_report",
        "type": "method",
        "start_line": 390,
        "end_line": 525,
        "code": "def _generate_html_report(self, results: Dict[str, Dict[str, Any]], output_file: Path) -> None:\n        \"\"\"\n        Generate an HTML report with visualizations.\n        \n        Args:\n            results: Dictionary mapping file paths to check results\n            output_file: Path to save the HTML report\n        \"\"\"\n        import json\n        from pathlib import Path\n        \n        # Count error and warning types for visualization\n        error_types = {}\n        warning_types = {}\n        \n        for result in results.values():\n            for error in result[\"errors\"]:\n                error_type = error.split(\":\")[0] if \":\" in error else error\n                error_types[error_type] = error_types.get(error_type, 0) + 1\n            \n            for warning in result[\"warnings\"]:\n                warning_type = warning.split(\":\")[0] if \":\" in warning else warning\n                warning_types[warning_type] = warning_types.get(warning_type, 0) + 1\n        \n        # Create HTML content with embedded charts\n        html_content = f\"\"\"<!DOCTYPE html>\n        <html>\n        <head>\n            <title>GNN Type Checking Visualization</title>\n            <script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n            <style>\n                body {{ font-family: Arial, sans-serif; margin: 20px; }}\n                .chart-container {{ width: 600px; height: 400px; margin-bottom: 30px; }}\n                .summary {{ margin-bottom: 20px; }}\n            </style>\n        </head>\n        <body>\n            <h1>GNN Type Checking Visualization</h1>\n            \n            <div class=\"summary\">\n                <h2>Summary</h2>\n                <p>Total files: {len(results)}</p>\n                <p>Valid files: {sum(1 for r in results.values() if r[\"is_valid\"])}</p>\n                <p>Invalid files: {sum(1 for r in results.values() if not r[\"is_valid\"])}</p>\n                <p>Total errors: {sum(len(r[\"errors\"]) for r in results.values())}</p>\n                <p>Total warnings: {sum(len(r[\"warnings\"]) for r in results.values())}</p>\n            </div>\n            \n            <div class=\"chart-container\">\n                <h2>File Validity</h2>\n                <canvas id=\"validityChart\"></canvas>\n            </div>\n            \n            <div class=\"chart-container\">\n                <h2>Error Types</h2>\n                <canvas id=\"errorsChart\"></canvas>\n            </div>\n            \n            <div class=\"chart-container\">\n                <h2>Warning Types</h2>\n                <canvas id=\"warningsChart\"></canvas>\n            </div>\n            \n            <script>\n                // Validity pie chart\n                const validityCtx = document.getElementById('validityChart').getContext('2d');\n                new Chart(validityCtx, {{\n                    type: 'pie',\n                    data: {{\n                        labels: ['Valid', 'Invalid'],\n                        datasets: [{{\n                            data: [\n                                {sum(1 for r in results.values() if r[\"is_valid\"])}, \n                                {sum(1 for r in results.values() if not r[\"is_valid\"])}\n                            ],\n                            backgroundColor: ['rgba(75, 192, 192, 0.2)', 'rgba(255, 99, 132, 0.2)'],\n                            borderColor: ['rgba(75, 192, 192, 1)', 'rgba(255, 99, 132, 1)'],\n                            borderWidth: 1\n                        }}]\n                    }}\n                }});\n                \n                // Error types chart\n                const errorsCtx = document.getElementById('errorsChart').getContext('2d');\n                new Chart(errorsCtx, {{\n                    type: 'bar',\n                    data: {{\n                        labels: {json.dumps(list(error_types.keys()))},\n                        datasets: [{{\n                            label: 'Count',\n                            data: {json.dumps(list(error_types.values()))},\n                            backgroundColor: 'rgba(255, 99, 132, 0.2)',\n                            borderColor: 'rgba(255, 99, 132, 1)',\n                            borderWidth: 1\n                        }}]\n                    }},\n                    options: {{\n                        scales: {{\n                            y: {{\n                                beginAtZero: true\n                            }}\n                        }}\n                    }}\n                }});\n                \n                // Warning types chart\n                const warningsCtx = document.getElementById('warningsChart').getContext('2d');\n                new Chart(warningsCtx, {{\n                    type: 'bar',\n                    data: {{\n                        labels: {json.dumps(list(warning_types.keys()))},\n                        datasets: [{{\n                            label: 'Count',\n                            data: {json.dumps(list(warning_types.values()))},\n                            backgroundColor: 'rgba(255, 206, 86, 0.2)',\n                            borderColor: 'rgba(255, 206, 86, 1)',\n                            borderWidth: 1\n                        }}]\n                    }},\n                    options: {{\n                        scales: {{\n                            y: {{\n                                beginAtZero: true\n                            }}\n                        }}\n                    }}\n                }});\n            </script>\n        </body>\n        </html>\n        \"\"\"\n        \n        # Save HTML report\n        with open(output_file, 'w') as f:\n            f.write(html_content)\n        logger.info(f\"Successfully wrote HTML report to: {output_file}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      },
      {
        "name": "generate_json_data",
        "type": "method",
        "start_line": 527,
        "end_line": 552,
        "code": "def generate_json_data(self, results: Dict[str, Dict[str, Any]], output_file: Path) -> None:\n        \"\"\"\n        Generate JSON data for resource estimator and general use.\n        \n        Args:\n            results: Dictionary mapping file paths to check results\n            output_file: Path to save the JSON data\n        \"\"\"\n        import json\n        \n        # Prepare data for resource estimator\n        json_data = {\n            \"type_check_results\": results,\n            \"summary\": {\n                \"total_files\": len(results),\n                \"valid_files\": sum(1 for r in results.values() if r[\"is_valid\"]),\n                \"invalid_files\": sum(1 for r in results.values() if not r[\"is_valid\"]),\n                \"total_errors\": sum(len(r[\"errors\"]) for r in results.values()),\n                \"total_warnings\": sum(len(r[\"warnings\"]) for r in results.values())\n            }\n        }\n        \n        # Save JSON data\n        with open(output_file, 'w') as f:\n            json.dump(json_data, f, indent=2)\n        logger.info(f\"Successfully wrote JSON data to: {output_file}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/checker.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/cli.py": [
      {
        "name": "main",
        "type": "function",
        "start_line": 18,
        "end_line": 138,
        "code": "def main(cmd_args=None):\n    \"\"\"\n    Main function to run the type checker from command line.\n    \n    Args:\n        cmd_args: Command line arguments (if None, sys.argv[1:] is used)\n        \n    Returns:\n        Exit code (0 for success, 1 for errors)\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"GNN Type Checker\")\n    parser.add_argument(\"input_path\", help=\"Path to GNN file or directory\")\n    parser.add_argument(\"-r\", \"--report-file\", default=\"type_check_report.md\",\n                        help=\"Filename for the main type checking report (markdown). Default: type_check_report.md\")\n    parser.add_argument(\"--recursive\", action=\"store_true\", help=\"Recursively process directories\")\n    parser.add_argument(\"--strict\", action=\"store_true\", help=\"Enable strict type checking mode\")\n    parser.add_argument(\"--estimate-resources\", action=\"store_true\", help=\"Estimate computational resources for the GNN models\")\n    parser.add_argument(\"-o\", \"--output-dir\", required=True,\n                        help=\"Base directory to save all output files (type checker reports, resource reports, etc.).\")\n    parser.add_argument(\"--project-root\", help=\"Absolute path to the project root, for relative path generation in reports\")\n    \n    parsed_args = parser.parse_args(cmd_args)\n    \n    # The caller (4_gnn_type_checker.py or user via CLI) is responsible for configuring logging levels.\n    # This script just uses the logger.\n\n    actual_output_dir = Path(parsed_args.output_dir).resolve()\n    try:\n        actual_output_dir.mkdir(parents=True, exist_ok=True)\n    except OSError as e:\n        logger.error(f\"Failed to create output directory {actual_output_dir}: {e}\")\n        return 1 # Critical failure\n\n    markdown_report_name = Path(parsed_args.report_file).name # Use only the filename part\n\n    logger.info(f\"GNN Type Checker CLI starting...\")\n    logger.info(f\"  Input path: {parsed_args.input_path}\")\n    logger.info(f\"  Output directory: {actual_output_dir}\")\n    logger.info(f\"  Main report filename: {markdown_report_name}\")\n    logger.debug(f\"  Recursive: {parsed_args.recursive}, Strict: {parsed_args.strict}, Estimate Resources: {parsed_args.estimate_resources}\")\n    if parsed_args.project_root:\n        logger.debug(f\"  Project root for relative paths: {parsed_args.project_root}\")\n\n    checker = GNNTypeChecker(strict_mode=parsed_args.strict)\n    input_path_obj = Path(parsed_args.input_path)\n    results = {}\n    \n    try:\n        if input_path_obj.is_file():\n            is_valid, errors, warnings = checker.check_file(str(input_path_obj))\n            results = {str(input_path_obj): {\"is_valid\": is_valid, \"errors\": errors, \"warnings\": warnings}}\n        elif input_path_obj.is_dir():\n            results = checker.check_directory(str(input_path_obj), recursive=parsed_args.recursive)\n        else:\n            logger.error(f\"Input path {parsed_args.input_path} is not a valid file or directory.\")\n            return 1\n    except Exception as e_check:\n        logger.error(f\"An error occurred during GNN checking phase: {e_check}\", exc_info=True)\n        return 1\n\n    try:\n        report_summary_text = checker.generate_report(results, actual_output_dir, report_md_filename=markdown_report_name, project_root_path=parsed_args.project_root)\n        logger.info(\"\\n--- Type Check Report Summary ---\")\n        for line in report_summary_text.splitlines(): # Log line by line to respect logger formatting\n            logger.info(line)\n        logger.info(\"--- End of Type Check Report Summary ---\")\n        logger.info(f\"Main type check report saved in: {actual_output_dir / markdown_report_name}\")\n        \n        # Generate and save the detailed JSON data\n        json_output_dir = actual_output_dir / \"resources\"\n        json_output_dir.mkdir(parents=True, exist_ok=True)\n        type_check_data_json_path = json_output_dir / \"type_check_data.json\"\n        checker.generate_json_data(results, type_check_data_json_path) # Call the new public method\n        logger.info(f\"Detailed JSON data saved in: {type_check_data_json_path}\")\n\n    except Exception as e_report:\n        logger.error(f\"An error occurred during report generation for type checking: {e_report}\", exc_info=True)\n        # Decide if this is fatal; type checking might have finished.\n        # For now, let's say if report fails, the step has an issue.\n        # The `results` are still available if an error happened here.\n\n    if parsed_args.estimate_resources:\n        logger.info(\"\\nEstimating computational resources...\")\n        resource_estimator_output_base_dir = actual_output_dir / \"resource_estimates\"\n        try:\n            resource_estimator_output_base_dir.mkdir(parents=True, exist_ok=True)\n        except OSError as e_res_dir:\n            logger.error(f\"Failed to create resource estimates output directory {resource_estimator_output_base_dir}: {e_res_dir}\")\n            # Don't fail the whole script if only this sub-dir creation fails, but log it.\n\n        type_check_data_json_path = actual_output_dir / \"resources\" / \"type_check_data.json\"\n        estimator = GNNResourceEstimator(type_check_data=str(type_check_data_json_path) if type_check_data_json_path.exists() else None)\n        \n        try:\n            if input_path_obj.is_file():\n                result = estimator.estimate_from_file(str(input_path_obj))\n                estimator.results = {str(input_path_obj): result} # Store for report generation\n            elif input_path_obj.is_dir():\n                estimator.estimate_from_directory(str(input_path_obj), recursive=parsed_args.recursive)\n            # else case already handled above for main checker\n\n            resource_report_summary_text = estimator.generate_report(str(resource_estimator_output_base_dir), project_root_path=parsed_args.project_root)\n            logger.info(\"\\n--- Resource Estimation Report Summary ---\")\n            summary_lines = resource_report_summary_text.split('\\n')[:5] # Show first 5 lines\n            for r_line in summary_lines:\n                 logger.info(r_line)\n            logger.info(f\"Resource estimation reports (markdown, JSON, HTML) saved in: {resource_estimator_output_base_dir}\")\n            logger.info(\"--- End of Resource Estimation Report Summary ---\")\n        except Exception as e_est:\n            logger.error(f\"An error occurred during resource estimation: {e_est}\", exc_info=True)\n            # Resource estimation failure doesn't necessarily mean the type check failed.\n            # The overall exit code depends on type check errors.\n\n    # Determine final exit code based on type checking results\n    has_type_errors = any(not r.get(\"is_valid\", True) for r in results.values())\n    if has_type_errors:\n        logger.error(\"Type checking found errors in one or more GNN files.\")\n        return 1\n    else:\n        logger.info(\"Type checking completed. No errors found.\")\n        return 0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/cli.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn_type_checker/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/ontology/mcp.py": [
      {
        "name": "get_mcp_interface",
        "type": "function",
        "start_line": 14,
        "end_line": 26,
        "code": "def get_mcp_interface():\n    \"\"\"\n    Returns the MCP interface for the Ontology module.\n    \"\"\"\n    return {\n        \"status\": \"Ontology module MCP active\",\n        \"capabilities\": [\n            \"parse_gnn_ontology_section\",\n            \"load_defined_ontology_terms\",\n            \"validate_annotations\",\n            \"generate_ontology_report_for_file\"\n        ]\n    }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/ontology/mcp.py"
      },
      {
        "name": "parse_gnn_ontology_section",
        "type": "function",
        "start_line": 28,
        "end_line": 83,
        "code": "def parse_gnn_ontology_section(gnn_file_content: str, verbose: bool = False) -> dict:\n    \"\"\"\n    Parses the 'ActInfOntologyAnnotation' section from GNN file content.\n\n    Args:\n        gnn_file_content: The string content of a GNN file.\n        verbose: If True, prints detailed parsing information.\n\n    Returns:\n        A dictionary mapping model variables to ontological terms.\n        Returns an empty dictionary if the section is not found or is malformed.\n    \"\"\"\n    annotations = {}\n    try:\n        # Regex to find the ActInfOntologyAnnotation section and capture its content\n        match = re.search(r\"^## ActInfOntologyAnnotation\\s*$\\n(.*?)(?:^## \\S+|^\\Z)\", gnn_file_content, re.MULTILINE | re.DOTALL)\n        if not match:\n            logger.debug(\"'ActInfOntologyAnnotation' section not found.\")\n            return annotations\n\n        section_content = match.group(1).strip()\n        if not section_content:\n            logger.debug(\"'ActInfOntologyAnnotation' section is empty.\")\n            return annotations\n\n        lines = section_content.split('\\n')\n        for i, line in enumerate(lines):\n            line = line.strip()\n            if not line or line.startswith('#'):  # Skip empty lines or comments within the section\n                continue\n            if '=' in line:\n                parts = line.split('=', 1)\n                key = parts[0].strip()\n                value_full = parts[1].strip()\n                \n                # Strip comments from the value\n                if '#' in value_full:\n                    value = value_full.split('#', 1)[0].strip()\n                else:\n                    value = value_full\n                    \n                if key and value:\n                    annotations[key] = value\n                else:\n                    logger.debug(f\"Malformed line {i+1} in ActInfOntologyAnnotation: '{line}' - skipping.\")\n            else:\n                logger.debug(f\"Line {i+1} in ActInfOntologyAnnotation does not contain '=': '{line}' - skipping.\")\n        \n        logger.debug(f\"Parsed annotations: {annotations}\")\n            \n    except Exception as e:\n        logger.error(f\"Error parsing ActInfOntologyAnnotation section: {e}\", exc_info=True)\n        # Fallback to empty dict on any parsing error\n        return {}\n        \n    return annotations",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/ontology/mcp.py"
      },
      {
        "name": "load_defined_ontology_terms",
        "type": "function",
        "start_line": 85,
        "end_line": 126,
        "code": "def load_defined_ontology_terms(ontology_terms_path: str, verbose: bool = False) -> dict:\n    \"\"\"\n    Loads defined ontological terms from a JSON file.\n    The JSON file should contain an object where keys are term names\n    and values can be descriptions or other metadata.\n\n    Args:\n        ontology_terms_path: Path to the JSON file containing ontology terms.\n        verbose: If True, prints loading information.\n\n    Returns:\n        A dictionary of defined ontology terms (term: description/metadata).\n        Returns an empty dictionary if the file cannot be loaded or parsed.\n    \"\"\"\n    defined_terms = {}\n    try:\n        # Ensure the path is treated as absolute if it's not already.\n        # This helps if the CWD is unexpected.\n        # However, the path from the log ('src/ontology/act_inf_ontology_terms.json')\n        # is likely relative to the project root.\n        # For now, let's rely on the path being correctly resolved by the caller (8_ontology.py)\n        \n        logger.debug(f\"Attempting to load ontology terms from: {os.path.abspath(ontology_terms_path)}\")\n\n        with open(ontology_terms_path, 'r', encoding='utf-8-sig') as f: # Changed encoding\n            data = json.load(f)\n        if isinstance(data, dict):\n            defined_terms = data\n            logger.debug(f\"Loaded {len(defined_terms)} ontology terms from {ontology_terms_path}.\")\n        else:\n            logger.error(f\"Ontology terms file {ontology_terms_path} does not contain a root JSON object. Data type: {type(data)}\")\n            return {}\n    except FileNotFoundError:\n        logger.error(f\"Ontology terms file not found: {ontology_terms_path} (Absolute: {os.path.abspath(ontology_terms_path)})\")\n        return {}\n    except json.JSONDecodeError as e:\n        logger.error(f\"Error decoding JSON from {ontology_terms_path} (Absolute: {os.path.abspath(ontology_terms_path)}): {e}\", exc_info=True)\n        return {}\n    except Exception as e:\n        logger.error(f\"An unexpected error occurred while loading ontology terms from {ontology_terms_path} (Absolute: {os.path.abspath(ontology_terms_path)}): {e}\", exc_info=True)\n        return {}\n    return defined_terms",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/ontology/mcp.py"
      },
      {
        "name": "validate_annotations",
        "type": "function",
        "start_line": 128,
        "end_line": 166,
        "code": "def validate_annotations(parsed_annotations: dict, defined_terms: dict, verbose: bool = False) -> dict:\n    \"\"\"\n    Validates parsed GNN annotations against a set of defined ontological terms.\n\n    Args:\n        parsed_annotations: Dict of {model_var: ontology_term} from GNN file.\n        defined_terms: Dict of {ontology_term: description} loaded from a definition file.\n                            Only the keys of defined_terms are used for validation.\n        verbose: If True, prints validation details.\n\n    Returns:\n        A dictionary with validation results:\n        {\n            \"valid_mappings\": {model_var: ontology_term, ...},\n            \"invalid_terms\": {model_var: ontology_term, ...} // Terms not in defined_terms\n            \"unmapped_model_vars\": [] // Model vars in parsed_annotations with no ontology term (should not happen with current parser)\n        }\n    \"\"\"\n    results = {\n        \"valid_mappings\": {},\n        \"invalid_terms\": {},\n        \"unmapped_model_vars\": [] # Should be empty with current parse_gnn_ontology_section\n    }\n    defined_term_keys = set(defined_terms.keys())\n\n    for model_var, ontology_term in parsed_annotations.items():\n        if not ontology_term: # Should not happen if parser ensures value exists\n             results[\"unmapped_model_vars\"].append(model_var)\n             logger.debug(f\"Model variable '{model_var}' has no ontology term mapped.\")\n             continue\n\n        if ontology_term in defined_term_keys:\n            results[\"valid_mappings\"][model_var] = ontology_term\n        else:\n            results[\"invalid_terms\"][model_var] = ontology_term\n            logger.debug(f\"Ontology term '{ontology_term}' (for model var '{model_var}') is not in the defined set of terms.\")\n    \n    logger.debug(f\"Validation complete. Valid: {len(results['valid_mappings'])}, Invalid: {len(results['invalid_terms'])}\")\n    return results",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/ontology/mcp.py"
      },
      {
        "name": "generate_ontology_report_for_file",
        "type": "function",
        "start_line": 168,
        "end_line": 195,
        "code": "def generate_ontology_report_for_file(gnn_file_path: str, parsed_annotations: dict, validation_results: dict = None) -> str:\n    \"\"\"\n    Generates a markdown formatted report string for a single GNN file's ontology annotations.\n    \"\"\"\n    report_parts = [f\"### Ontological Annotations for `{gnn_file_path}`\\n\"]\n    \n    if not parsed_annotations:\n        report_parts.append(\"- No `ActInfOntologyAnnotation` section found or section was empty.\\n\")\n        return \"\".join(report_parts)\n\n    report_parts.append(\"#### Mappings:\\n\")\n    for var, term in parsed_annotations.items():\n        report_parts.append(f\"- `{var}` -> `{term}`\")\n        if validation_results and validation_results.get(\"invalid_terms\", {}).get(var) == term:\n            report_parts.append(\" (**INVALID TERM**)\")\n        report_parts.append(\"\\n\")\n    \n    if validation_results:\n        invalid_count = len(validation_results.get(\"invalid_terms\", {}))\n        if invalid_count > 0:\n            report_parts.append(f\"\\n**Validation Summary**: {invalid_count} unrecognized ontological term(s) found.\\n\")\n            # for var, term in validation_results[\"invalid_terms\"].items():\n            #     report_parts.append(f\"  - Model variable `{var}` uses unrecognized term `{term}`.\\n\")\n        else:\n            report_parts.append(\"\\n**Validation Summary**: All ontological terms are recognized.\\n\")\n            \n    report_parts.append(\"\\n---\\n\")\n    return \"\".join(report_parts)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/ontology/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/ontology/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/execute/mcp.py": [
      {
        "name": "register_tools",
        "type": "function",
        "start_line": 14,
        "end_line": 39,
        "code": "def register_tools(mcp_instance):\n    \"\"\"\n    Registers MCP tools related to execution tasks with the MCP instance.\n\n    Args:\n        mcp_instance: The main MCP instance to register tools with.\n    \"\"\"\n    logger.info(\"Registering MCP tools for 'execute' module (placeholder)...\")\n    # Example of how a tool might be registered:\n    #\n    # def example_execution_tool(params: dict) -> dict:\n    # \"\"\"An example execution tool that might be exposed via MCP.\"\"\"\n    #     logger.info(f\"Example execution tool called with params: {params}\")\n    #     # ... actual execution logic ...\n    # return {\"status\": \"success\", \"result\": \"executed example task\"}\n    #\n    # mcp_instance.register_tool(\n    #     name=\"execute.example_task\",\n    #     func=example_execution_tool,\n    #     description=\"Runs an example execution task.\",\n    #     schema=MCPToolSchema(\n    #         parameters={\"type\": \"object\", \"properties\": {\"param1\": {\"type\": \"string\"}}},\n    #         returns={\"type\": \"object\", \"properties\": {\"status\": {\"type\": \"string\"}}}\n    #     )\n    # )\n    logger.info(\"No specific execution tools registered at this time.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/execute/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/execute/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/execute/pymdp_runner.py": [
      {
        "name": "run_pymdp_scripts",
        "type": "function",
        "start_line": 16,
        "end_line": 186,
        "code": "def run_pymdp_scripts(pipeline_output_dir: str, recursive_search: bool, verbose: bool) -> bool:\n    \"\"\"\n    Finds and executes all .py files in the PyMDP rendered scripts directory.\n    Logs stdout/stderr for each script to a dedicated log directory.\n\n    Args:\n        pipeline_output_dir: The root output directory of the GNN pipeline.\n        recursive_search: Whether to search for PyMDP scripts recursively in their base directory.\n        verbose: If True, sets subprocess output to be more verbose.\n\n    Returns:\n        True if all found scripts executed successfully, False otherwise.\n    \"\"\"\n    pipeline_output_path = Path(pipeline_output_dir).resolve()\n    rendered_pymdp_base_dir = pipeline_output_path / \"gnn_rendered_simulators\" / \"pymdp\"\n    \n    # Define base directory for execution logs from this step\n    step_10_log_dir_base = pipeline_output_path / \"pymdp_execute_logs\"\n    try:\n        step_10_log_dir_base.mkdir(parents=True, exist_ok=True)\n        logger.info(f\"Execution logs for Step 10 will be stored in: {step_10_log_dir_base}\")\n    except OSError as e:\n        logger.error(f\"Could not create base log directory {step_10_log_dir_base}: {e}\")\n        # Proceeding without dedicated file logs if base dir creation fails, but log an error.\n        # Alternatively, could return False here. For now, attempt to continue.\n\n    logger.info(f\"Searching for PyMDP scripts to execute in: {rendered_pymdp_base_dir}\")\n    if not rendered_pymdp_base_dir.is_dir():\n        logger.warning(f\"PyMDP rendered scripts directory not found: {rendered_pymdp_base_dir}\")\n        logger.warning(\"This might be expected if no PyMDP models were rendered in step 9.\")\n        return True # Not a failure of this step, just no scripts to run.\n\n    glob_pattern = \"**/*.py\" if recursive_search else \"*.py\"\n    pymdp_scripts = list(rendered_pymdp_base_dir.glob(glob_pattern))\n\n    if not pymdp_scripts:\n        logger.info(f\"No PyMDP scripts (matching '{glob_pattern}') found in {rendered_pymdp_base_dir}.\")\n        return True # No scripts to run is not an error for this runner.\n\n    logger.info(f\"Found {len(pymdp_scripts)} PyMDP script(s) to execute.\")\n\n    all_executions_successful = True\n    overall_summary = []\n\n    # Determine the python executable to use (prefer venv if available)\n    python_executable = sys.executable # Default to current Python\n    project_root = Path(__file__).resolve().parent.parent # src/\n    venv_python = project_root / \".venv\" / \"bin\" / \"python\"\n    if venv_python.exists():\n        python_executable = str(venv_python)\n        logger.info(f\"Using Python executable from virtual environment: {python_executable}\")\n    else:\n        logger.info(f\"Using system Python executable: {python_executable}\")\n\n    for script_path in pymdp_scripts:\n        script_stem = script_path.stem\n        script_log_dir = step_10_log_dir_base / script_stem\n        try:\n            script_log_dir.mkdir(parents=True, exist_ok=True)\n        except OSError as e:\n            logger.error(f\"Could not create log directory {script_log_dir} for {script_path.name}: {e}. Logs will not be saved to files for this script.\")\n            # Fallback: don't use script_log_dir for this script if creation fails\n            current_script_log_dir = None \n        else:\n            current_script_log_dir = script_log_dir\n\n        logger.info(f\"  Executing PyMDP script: {script_path.relative_to(pipeline_output_path)}\")\n        stdout_path = current_script_log_dir / \"stdout.log\" if current_script_log_dir else None\n        stderr_path = current_script_log_dir / \"stderr.log\" if current_script_log_dir else None\n        log_file_info = f\" (Logs: {current_script_log_dir})\" if current_script_log_dir else \" (File logging disabled due to dir error)\"\n\n        try:\n            # Scripts are run with their own directory as CWD to handle relative paths within the script if any.\n            run_cwd = script_path.parent\n            env = os.environ.copy()\n            # Ensure PYTHONPATH includes project root and venv site-packages for consistency\n            project_root_str = str(project_root)\n            venv_site_packages_path = str(project_root / \".venv\" / \"lib\" / f\"python{sys.version_info.major}.{sys.version_info.minor}\" / \"site-packages\")\n            \n            current_python_path = env.get(\"PYTHONPATH\", \"\")\n            path_parts = {project_root_str, venv_site_packages_path}\n            if current_python_path:\n                path_parts.update(current_python_path.split(os.pathsep))\n            \n            env[\"PYTHONPATH\"] = os.pathsep.join(sorted(list(path_parts)))\n\n            if verbose:\n                logger.debug(f\"      Using PYTHONPATH for subprocess: {env['PYTHONPATH']}\")\n\n            process = subprocess.run(\n                [python_executable, str(script_path.name)],\n                capture_output=True,\n                text=True,\n                check=False, # Don't raise exception on non-zero exit, we handle it\n                cwd=run_cwd,\n                env=env\n            )\n\n            # Save stdout and stderr to files\n            stdout_log_path = script_log_dir / \"stdout.log\"\n            stderr_log_path = script_log_dir / \"stderr.log\"\n            try:\n                with open(stdout_log_path, \"w\", encoding='utf-8') as f_out:\n                    f_out.write(process.stdout if process.stdout else \"\")\n                if verbose: logger.debug(f\"      Stdout successfully written to {stdout_log_path}\")\n                with open(stderr_log_path, \"w\", encoding='utf-8') as f_err:\n                    f_err.write(process.stderr if process.stderr else \"\")\n                if verbose: logger.debug(f\"      Stderr successfully written to {stderr_log_path}\")\n            except IOError as e:\n                logger.error(f\"    \u274c Error writing log files for {script_path.name} to {script_log_dir}: {e}\")\n                # Continue, but this script's logs might be missing\n\n            script_summary_data = {\n                \"status\": \"Unknown\", \n                \"log_dir\": str(script_log_dir),\n                \"stdout_preview\": process.stdout[:300].strip() if process.stdout else \"\",\n                \"stderr_preview\": process.stderr.strip() if process.stderr else \"\"\n            }\n\n            if process.returncode == 0:\n                script_summary_data[\"status\"] = \"Success\"\n                logger.info(f\"    \u2705 Execution successful for: {script_path.name} (Logs: {script_log_dir})\")\n                if verbose:\n                    if process.stdout:\n                        logger.debug(f\"      Stdout Preview (see {stdout_log_path.name} for full):\\n{process.stdout[:300].strip()}...\")\n                    if process.stderr:\n                        logger.warning(f\"      Stderr Output from {script_path.name} (see {stderr_log_path.name} for full):\\n{process.stderr.strip()}\")\n            else:\n                script_summary_data[\"status\"] = \"Failure\"\n                logger.error(f\"    \u274c Execution FAILED for: {script_path.name} (Return Code: {process.returncode}, Logs: {script_log_dir})\")\n                all_executions_successful = False\n                # For failed scripts, log previews even if not verbose, as this is important diagnostic info from the runner's perspective.\n                if process.stdout:\n                    logger.error(f\"      Stdout from failed {script_path.name} (see {stdout_log_path.name} for full):\\n{process.stdout.strip()}\")\n                if process.stderr:\n                    logger.error(f\"      Stderr from failed {script_path.name} (see {stderr_log_path.name} for full):\\n{process.stderr.strip()}\")\n            \n            overall_summary.append((str(script_path.name), script_summary_data[\"status\"], script_summary_data[\"stdout_preview\"], script_summary_data[\"stderr_preview\"], str(script_log_dir)))\n        except Exception as e:\n            all_executions_successful = False\n            logger.error(f\"    \u274c Exception during execution of {script_path.name}: {e}{log_file_info}\", exc_info=verbose)\n            if current_script_log_dir: # Attempt to save exception to a file too\n                try:\n                    with open(current_script_log_dir / \"exception.log\", 'w') as f_exc:\n                        import traceback\n                        f_exc.write(f\"Exception: {e}\\n\")\n                        f_exc.write(traceback.format_exc())\n                except OSError as e_write:\n                    logger.error(f\"    Could not write exception log for {script_path.name}: {e_write}\")\n            overall_summary.append((str(script_path.name), \"Exception\", str(e), str(current_script_log_dir if current_script_log_dir else \"N/A\")))\n\n    logger.info(\"--- PyMDP Execution Summary ---\")\n    total_scripts = len(overall_summary)\n    successful_scripts = sum(1 for data in overall_summary if data[1] == \"Success\")\n    failed_scripts = total_scripts - successful_scripts\n\n    logger.info(f\"  Total scripts processed: {total_scripts}\")\n    logger.info(f\"  Successfully executed: {successful_scripts}\")\n    logger.info(f\"  Failed: {failed_scripts}\")\n\n    if verbose and failed_scripts > 0 : # Only print detailed summary of failures if verbose\n        logger.info(\"  Details of failed/warning executions:\")\n        for name, status, stdout_preview, stderr_preview, log_dir in overall_summary:\n            if status != \"Success\":\n                logger.warning(f\"    - Script: {name}\")\n                logger.warning(f\"      Status: {status}\")\n                logger.warning(f\"      Log Dir: {log_dir}\")\n                if stderr_preview: # Only show stderr preview from summary if it exists\n                     logger.warning(f\"      Stderr Preview: {stderr_preview[:300]}...\")\n\n    return all_executions_successful",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/execute/pymdp_runner.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py": [
      {
        "name": "make_section_id",
        "type": "function",
        "start_line": 129,
        "end_line": 131,
        "code": "def make_section_id(title: str) -> str:\n    \"\"\"Generates a URL-friendly ID from a title.\"\"\"\n    return title.lower().replace(\" \", \"-\").replace(\"/\", \"-\").replace(\":\", \"\").replace(\"(\", \"\").replace(\")\", \"\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "add_collapsible_section",
        "type": "function",
        "start_line": 133,
        "end_line": 140,
        "code": "def add_collapsible_section(f: IO[str], title: str, content_html: str, is_open: bool = False):\n    \"\"\"Adds a collapsible section to the HTML file.\"\"\"\n    section_id = make_section_id(title) # Although collapsible doesn't use ID for navigation, it's good practice\n    display_style = \"block\" if is_open else \"none\"\n    f.write(f'<button type=\"button\" class=\"collapsible\">{title}</button>\\n')\n    f.write(f'<div class=\"collapsible-content\" style=\"display: {display_style};\">\\n')\n    f.write(content_html)\n    f.write(\"</div>\\n\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "embed_image",
        "type": "function",
        "start_line": 142,
        "end_line": 153,
        "code": "def embed_image(file_path: Path, alt_text: Optional[str] = None) -> str:\n    \"\"\"Embeds an image into HTML using base64 encoding.\"\"\"\n    if not file_path.exists():\n        return f\"<p>Image not found: {file_path.as_posix()}</p>\"\n    try:\n        with open(file_path, \"rb\") as img_file:\n            encoded_string = base64.b64encode(img_file.read()).decode('utf-8')\n        alt = alt_text if alt_text else file_path.name\n        return f'<img src=\"data:image/{file_path.suffix.lstrip(\".\")};base64,{encoded_string}\" alt=\"{alt}\" loading=\"lazy\"><br><small>{file_path.name}</small>'\n    except Exception as e:\n        logger.error(f\"Error embedding image {file_path.as_posix()}: {e}\")\n        return f\"<p>Error embedding image {file_path.name}: {e}</p>\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "embed_markdown_file",
        "type": "function",
        "start_line": 155,
        "end_line": 165,
        "code": "def embed_markdown_file(file_path: Path) -> str:\n    \"\"\"Reads a markdown file and converts it to HTML.\"\"\"\n    if not file_path.exists():\n        return f\"<p>Markdown file not found: {file_path.as_posix()}</p>\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as md_file:\n            content = md_file.read()\n        return markdown.markdown(content, extensions=['fenced_code', 'tables', 'sane_lists'])\n    except Exception as e:\n        logger.error(f\"Error reading or converting markdown file {file_path.as_posix()}: {e}\")\n        return f\"<p>Error processing markdown file {file_path.name}: {e}</p>\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "embed_text_file",
        "type": "function",
        "start_line": 167,
        "end_line": 180,
        "code": "def embed_text_file(file_path: Path, max_lines: Optional[int] = 100) -> str:\n    \"\"\"Reads a text file and embeds its content in a <pre> tag.\"\"\"\n    if not file_path.exists():\n        return f\"<p>Text file not found: {file_path.as_posix()}</p>\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as txt_file:\n            lines = txt_file.readlines()\n        content = \"\".join(lines[:max_lines])\n        if len(lines) > max_lines:\n            content += f\"\\n... (file truncated, total lines: {len(lines)})\"\n        return f\"<pre class='log-output'><code>{content}</code></pre><small>{file_path.name}</small>\"\n    except Exception as e:\n        logger.error(f\"Error reading text file {file_path.as_posix()}: {e}\")\n        return f\"<p>Error processing text file {file_path.name}: {e}</p>\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "embed_json_file",
        "type": "function",
        "start_line": 182,
        "end_line": 192,
        "code": "def embed_json_file(file_path: Path) -> str:\n    \"\"\"Reads a JSON file and pretty-prints it in a <pre> tag.\"\"\"\n    if not file_path.exists():\n        return f\"<p>JSON file not found: {file_path.as_posix()}</p>\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as json_file:\n            data = json.load(json_file)\n        return f\"<pre class='log-output'><code>{json.dumps(data, indent=2)}</code></pre><small>{file_path.name}</small>\"\n    except Exception as e:\n        logger.error(f\"Error reading or parsing JSON file {file_path.as_posix()}: {e}\")\n        return f\"<p>Error processing JSON file {file_path.name}: {e}</p>\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "embed_html_file",
        "type": "function",
        "start_line": 194,
        "end_line": 236,
        "code": "def embed_html_file(file_path: Path) -> str:\n    \"\"\"Embeds an HTML file content directly or within an iframe if too complex.\"\"\"\n    if not file_path.exists():\n        return f\"<p>HTML file not found: {file_path.as_posix()}</p>\"\n    try:\n        # For simplicity, using iframe. Direct embedding might break styles.\n        # A more sophisticated approach would be to copy assets and adjust paths,\n        # or to parse and sanitize the HTML.\n        # Copy the HTML file and its associated directory (if one exists, e.g., for Plotly)\n        # to a subdirectory in the site output to ensure relative paths work.\n        \n        # Simplified: provide a link to open it, or try iframe for basic ones.\n        # This assumes the output HTML is in the same directory as the main report.\n        # For robust iframe, files need to be served or be in a predictable relative path.\n        # For now, let's just link to it, assuming it's a sibling or in a known relative path.\n        # Or, if we copy it to an 'assets' folder within the site output:\n        # Create a unique name for the asset\n        \n        # For now, let's assume direct embedding of simple HTML reports (e.g. from type checker)\n        # If a file is complex (e.g. has its own JS, complex CSS), an iframe pointing to a copied version is better.\n        # For this initial version, we'll link it.\n        \n        # Let's try to read and embed directly if it's simple.\n        # For complex HTML like plotly, it's better to copy to an assets dir and iframe.\n        # This will be improved if the user wants interactive plots directly embedded.\n        with open(file_path, 'r', encoding='utf-8') as html_f:\n            content = html_f.read()\n        # Basic check for complexity (very naive)\n        if \"<script\" in content.lower() or \"<link rel=\\\"stylesheet\\\"\" in content.lower():\n            # For complex HTML, provide a link. Or, copy to an assets folder and iframe.\n            # For this iteration, providing a link to the file (relative to the main output folder)\n            # This requires the user to navigate the output folder structure.\n            # A better way: copy to a \"site_assets\" folder and link relatively.\n            return (f'<p><a href=\"{file_path.name}\" target=\"_blank\" class=\"file-link\">View HTML Report: {file_path.name}</a> (Opens in new tab)</p>' +\n                    f'<p><em>Embedding complex HTML directly can be problematic. This report is linked.</em></p>' +\n                    f'<iframe src=\"{file_path.name}\" width=\"100%\" height=\"500px\" style=\"border:1px solid #ccc;\"></iframe>' +\n                    f'<small>Attempting to iframe: {file_path.name}. If it does not load correctly, please use the link above.</small>')\n        else: # Simple HTML\n            return content\n\n    except Exception as e:\n        logger.error(f\"Error processing HTML file {file_path.as_posix()}: {e}\")\n        return f\"<p>Error processing HTML file {file_path.name}: {e}</p>\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "process_directory_generic",
        "type": "function",
        "start_line": 238,
        "end_line": 311,
        "code": "def process_directory_generic(f: IO[str], dir_path: Path, base_output_dir: Path, title_prefix: str = \"\"):\n    \"\"\"Generic handler for directories: lists images, MDs, TXTs, JSONs, HTMLs.\"\"\"\n    if not dir_path.is_dir():\n        return\n\n    content_html = \"\"\n    images = []\n    md_files = []\n    txt_files = []\n    json_files = []\n    html_files = []\n    other_files = []\n\n    for item in sorted(dir_path.iterdir()):\n        if item.is_file():\n            if item.suffix.lower() in ['.png', '.jpg', '.jpeg', '.gif', '.svg']:\n                images.append(item)\n            elif item.suffix.lower() == '.md':\n                md_files.append(item)\n            elif item.suffix.lower() in ['.txt', '.log']:\n                txt_files.append(item)\n            elif item.suffix.lower() == '.json':\n                json_files.append(item)\n            elif item.suffix.lower() in ['.html', '.htm']:\n                html_files.append(item)\n            else:\n                other_files.append(item)\n    \n    if images:\n        content_html += \"<h3>Images</h3><div class='gallery'>\"\n        for img_path in images:\n            content_html += embed_image(img_path)\n        content_html += \"</div>\"\n\n    if md_files:\n        content_html += \"<h3>Markdown Reports</h3>\"\n        for md_path in md_files:\n            content_html += f\"<h4>{md_path.name}</h4>\"\n            content_html += embed_markdown_file(md_path)\n            \n    if html_files:\n        content_html += \"<h3>HTML Reports/Outputs</h3>\"\n        for html_path in html_files:\n            relative_html_path = html_path.relative_to(base_output_dir).as_posix()\n            content_html += f\"<h4>{html_path.name}</h4>\"\n            content_html += f'<p><a href=\"{relative_html_path}\" target=\"_blank\" class=\"file-link\">View standalone: {html_path.name}</a></p>'\n            # Sandbox iframe for security, allow-scripts and allow-same-origin for functionality if needed by the embedded HTML.\n            content_html += f'<iframe src=\"{relative_html_path}\" width=\"100%\" height=\"600px\" style=\"border:1px solid #ccc;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-forms\"></iframe>'\n\n    if json_files:\n        content_html += \"<h3>JSON Files</h3>\"\n        for json_path in json_files:\n            content_html += f\"<h4>{json_path.name}</h4>\"\n            content_html += embed_json_file(json_path)\n\n    if txt_files:\n        content_html += \"<h3>Text/Log Files</h3>\"\n        for txt_path in txt_files:\n            content_html += f\"<h4>{txt_path.name}</h4>\"\n            content_html += embed_text_file(txt_path)\n            \n    if other_files:\n        content_html += \"<h3>Other Files</h3><ul>\"\n        for other_path in other_files:\n            relative_other_path = other_path.relative_to(base_output_dir).as_posix()\n            content_html += f'<li><a href=\"{relative_other_path}\" class=\"file-link\" target=\"_blank\">{other_path.name}</a></li>'\n        content_html += \"</ul>\"\n\n    if content_html:\n        section_title = f\"{title_prefix}{dir_path.name}\"\n        f.write(f\"<div class='section' id='{make_section_id(section_title)}'>\\n\")\n        f.write(f\"<h2>{section_title}</h2>\\n\")\n        f.write(content_html)\n        f.write(\"</div>\\n\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_pipeline_summary_section",
        "type": "function",
        "start_line": 315,
        "end_line": 323,
        "code": "def _add_pipeline_summary_section(f: IO[str], output_dir: Path):\n    summary_json_path = output_dir / \"pipeline_execution_summary.json\"\n    if summary_json_path.exists():\n        f.write(f\"<div class='section' id='{make_section_id('Pipeline Execution Summary')}'>\\n\")\n        f.write(f\"<h2>Pipeline Execution Summary</h2>\\n\")\n        f.write(embed_json_file(summary_json_path))\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"Pipeline summary JSON not found: {summary_json_path.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_gnn_discovery_section",
        "type": "function",
        "start_line": 325,
        "end_line": 334,
        "code": "def _add_gnn_discovery_section(f: IO[str], output_dir: Path):\n    gnn_discovery_dir = output_dir / \"gnn_processing_step\"\n    gnn_discovery_report = gnn_discovery_dir / \"1_gnn_discovery_report.md\"\n    if gnn_discovery_report.exists():\n        f.write(f\"<div class='section' id='{make_section_id('GNN Discovery')}'>\\n\")\n        f.write(f\"<h2>GNN Discovery (Step 1)</h2>\\n\")\n        f.write(embed_markdown_file(gnn_discovery_report))\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"GNN Discovery report not found: {gnn_discovery_report.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_test_reports_section",
        "type": "function",
        "start_line": 336,
        "end_line": 346,
        "code": "def _add_test_reports_section(f: IO[str], output_dir: Path):\n    test_reports_dir = output_dir / \"test_reports\"\n    pytest_report_xml = test_reports_dir / \"pytest_report.xml\"\n    if pytest_report_xml.exists():\n        f.write(f\"<div class='section' id='{make_section_id('Test Reports')}'>\\n\")\n        f.write(f\"<h2>Test Reports (Step 3)</h2>\\n\")\n        content_html = embed_text_file(pytest_report_xml, max_lines=200)\n        add_collapsible_section(f, \"Pytest Report (pytest_report.xml - partial)\", content_html)\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"Pytest XML report not found: {pytest_report_xml.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_gnn_type_checker_section",
        "type": "function",
        "start_line": 348,
        "end_line": 372,
        "code": "def _add_gnn_type_checker_section(f: IO[str], output_dir: Path):\n    type_check_dir = output_dir / \"gnn_type_check\"\n    if type_check_dir.is_dir():\n        f.write(f\"<div class='section' id='{make_section_id('GNN Type Checker')}'>\\n\")\n        f.write(f\"<h2>GNN Type Checker (Step 4)</h2>\\n\")\n        \n        type_check_report_md = type_check_dir / \"type_check_report.md\"\n        if type_check_report_md.exists():\n            f.write(\"<h3>Type Check Report</h3>\")\n            f.write(embed_markdown_file(type_check_report_md))\n\n        resource_data_json = type_check_dir / \"resources\" / \"type_check_data.json\"\n        if resource_data_json.exists():\n                add_collapsible_section(f, \"Type Check Data (JSON)\", embed_json_file(resource_data_json))\n        \n        html_vis_dir = type_check_dir / \"resources\" / \"html_vis\"\n        if html_vis_dir.is_dir():\n            process_directory_generic(f, html_vis_dir, output_dir, title_prefix=\"Type Checker HTML Visualizations: \")\n\n        resource_estimates_dir = type_check_dir / \"resource_estimates\"\n        if resource_estimates_dir.is_dir():\n            process_directory_generic(f, resource_estimates_dir, output_dir, title_prefix=\"Resource Estimates: \")\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"GNN Type Checker directory not found: {type_check_dir.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_gnn_exports_section",
        "type": "function",
        "start_line": 374,
        "end_line": 397,
        "code": "def _add_gnn_exports_section(f: IO[str], output_dir: Path):\n    gnn_exports_dir = output_dir / \"gnn_exports\"\n    if gnn_exports_dir.is_dir():\n        f.write(f\"<div class='section' id='{make_section_id('GNN Exports')}'>\\n\")\n        f.write(f\"<h2>GNN Exports (Step 5)</h2>\\n\")\n        \n        export_step_report = gnn_exports_dir / \"5_export_step_report.md\"\n        if export_step_report.exists():\n            f.write(\"<h3>Export Step Report</h3>\")\n            f.write(embed_markdown_file(export_step_report))\n\n        for model_export_dir in sorted(gnn_exports_dir.iterdir()):\n            if model_export_dir.is_dir():\n                process_directory_generic(f, model_export_dir, output_dir, title_prefix=f\"Exports for {model_export_dir.name}: \")\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"GNN Exports directory not found: {gnn_exports_dir.as_posix()}\")\n\n    gnn_proc_summary_md = output_dir / \"gnn_processing_summary.md\"\n    if gnn_proc_summary_md.exists():\n        f.write(f\"<div class='section' id='{make_section_id('GNN Processing Summary')}'>\\n\")\n        f.write(f\"<h2>GNN Processing Summary (Overall File List)</h2>\\n\")\n        f.write(embed_markdown_file(gnn_proc_summary_md))\n        f.write(\"</div>\\n\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_visualizations_section",
        "type": "function",
        "start_line": 399,
        "end_line": 409,
        "code": "def _add_visualizations_section(f: IO[str], output_dir: Path):\n    viz_dir = output_dir / \"gnn_examples_visualization\"\n    if viz_dir.is_dir():\n        f.write(f\"<div class='section' id='{make_section_id('GNN Visualizations')}'>\\n\")\n        f.write(f\"<h2>GNN Visualizations (Step 6)</h2>\\n\")\n        for model_viz_dir in sorted(viz_dir.iterdir()):\n            if model_viz_dir.is_dir():\n                process_directory_generic(f, model_viz_dir, output_dir, title_prefix=f\"Visualizations for {model_viz_dir.name}: \")\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"GNN Visualizations directory not found: {viz_dir.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_mcp_report_section",
        "type": "function",
        "start_line": 411,
        "end_line": 420,
        "code": "def _add_mcp_report_section(f: IO[str], output_dir: Path):\n    mcp_report_dir = output_dir / \"mcp_processing_step\"\n    mcp_report_md = mcp_report_dir / \"7_mcp_integration_report.md\"\n    if mcp_report_md.exists():\n        f.write(f\"<div class='section' id='{make_section_id('MCP Integration Report')}'>\\n\")\n        f.write(f\"<h2>MCP Integration Report (Step 7)</h2>\\n\")\n        f.write(embed_markdown_file(mcp_report_md))\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"MCP Integration report not found: {mcp_report_md.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_ontology_processing_section",
        "type": "function",
        "start_line": 422,
        "end_line": 431,
        "code": "def _add_ontology_processing_section(f: IO[str], output_dir: Path):\n    ontology_dir = output_dir / \"ontology_processing\"\n    ontology_report_md = ontology_dir / \"ontology_processing_report.md\"\n    if ontology_report_md.exists():\n        f.write(f\"<div class='section' id='{make_section_id('Ontology Processing')}'>\\n\")\n        f.write(f\"<h2>Ontology Processing (Step 8)</h2>\\n\")\n        f.write(embed_markdown_file(ontology_report_md))\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"Ontology Processing report not found: {ontology_report_md.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_rendered_simulators_section",
        "type": "function",
        "start_line": 433,
        "end_line": 443,
        "code": "def _add_rendered_simulators_section(f: IO[str], output_dir: Path):\n    rendered_sim_dir = output_dir / \"gnn_rendered_simulators\"\n    if rendered_sim_dir.is_dir():\n        f.write(f\"<div class='section' id='{make_section_id('Rendered Simulators')}'>\\n\")\n        f.write(f\"<h2>Rendered Simulators (Step 9)</h2>\\n\")\n        for framework_dir in sorted(rendered_sim_dir.iterdir()): \n            if framework_dir.is_dir():\n                process_directory_generic(f, framework_dir, output_dir, title_prefix=f\"Simulators for {framework_dir.name}: \")\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"Rendered Simulators directory not found: {rendered_sim_dir.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_execution_logs_section",
        "type": "function",
        "start_line": 445,
        "end_line": 455,
        "code": "def _add_execution_logs_section(f: IO[str], output_dir: Path):\n    exec_logs_main_dir = output_dir / \"pymdp_execute_logs\"\n    if exec_logs_main_dir.is_dir():\n        f.write(f\"<div class='section' id='{make_section_id('Simulator Execution Logs')}'>\\n\")\n        f.write(f\"<h2>Simulator Execution Logs (Step 10)</h2>\\n\")\n        for model_exec_dir in sorted(exec_logs_main_dir.iterdir()):\n            if model_exec_dir.is_dir():\n                process_directory_generic(f, model_exec_dir, output_dir, title_prefix=f\"Execution Logs for {model_exec_dir.name}: \")\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"PyMDP Execute Logs directory not found: {exec_logs_main_dir.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_llm_outputs_section",
        "type": "function",
        "start_line": 457,
        "end_line": 467,
        "code": "def _add_llm_outputs_section(f: IO[str], output_dir: Path):\n    llm_dir = output_dir / \"llm_processing_step\"\n    if llm_dir.is_dir():\n        f.write(f\"<div class='section' id='{make_section_id('LLM Processing Outputs')}'>\\n\")\n        f.write(f\"<h2>LLM Processing Outputs (Step 11)</h2>\\n\")\n        for model_llm_dir in sorted(llm_dir.iterdir()):\n            if model_llm_dir.is_dir():\n                process_directory_generic(f, model_llm_dir, output_dir, title_prefix=f\"LLM Outputs for {model_llm_dir.name}: \")\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"LLM Processing directory not found: {llm_dir.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_pipeline_log_section",
        "type": "function",
        "start_line": 469,
        "end_line": 479,
        "code": "def _add_pipeline_log_section(f: IO[str], output_dir: Path):\n    pipeline_log_dir = output_dir / \"logs\"\n    pipeline_log_file = pipeline_log_dir / \"pipeline.log\"\n    if pipeline_log_file.exists():\n        f.write(f\"<div class='section' id='{make_section_id('Pipeline Log')}'>\\n\")\n        f.write(f\"<h2>Pipeline Log</h2>\\n\")\n        content_html = embed_text_file(pipeline_log_file, max_lines=500) \n        add_collapsible_section(f, \"pipeline.log (partial)\", content_html, is_open=False)\n        f.write(\"</div>\\n\")\n    else:\n        logger.warning(f\"Pipeline log file not found: {pipeline_log_file.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "_add_other_outputs_section",
        "type": "function",
        "start_line": 481,
        "end_line": 510,
        "code": "def _add_other_outputs_section(f: IO[str], output_dir: Path, site_output_file: Path):\n    f.write(f\"<div class='section' id='{make_section_id('Other Output Files')}'>\\n\")\n    f.write(\"<h2>Other Output Files/Directories</h2>\\n\")\n    other_content_html = \"\"\n    handled_items = {\n        \"pipeline_execution_summary.json\", \"gnn_processing_step\", \"test_reports\",\n        \"gnn_type_check\", \"gnn_exports\", \"gnn_processing_summary.md\",\n        \"gnn_examples_visualization\", \"mcp_processing_step\", \"ontology_processing\",\n        \"gnn_rendered_simulators\", \"pymdp_execute_logs\", \"llm_processing_step\", \"logs\",\n        site_output_file.name \n    }\n    found_other = False\n    items_list_html = \"<ul>\"\n    for item in sorted(output_dir.iterdir()):\n        if item.name not in handled_items:\n            found_other = True\n            relative_path = item.relative_to(output_dir).as_posix()\n            if item.is_file():\n                items_list_html += f'<li><a href=\"{relative_path}\" class=\"file-link\" target=\"_blank\">{item.name}</a></li>'\n            elif item.is_dir():\n                items_list_html += f\"<li><strong>{item.name}/</strong> (Directory - <a href='{relative_path}' class='file-link' target='_blank'>Browse</a>)</li>\" \n    items_list_html += \"</ul>\"\n    \n    if found_other:\n        other_content_html = items_list_html\n    else:\n        other_content_html = \"<p>No other top-level files or directories found or all were processed above.</p>\"\n    \n    f.write(other_content_html)\n    f.write(\"</div>\\n\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "generate_html_report",
        "type": "function",
        "start_line": 514,
        "end_line": 539,
        "code": "def generate_html_report(output_dir: Path, site_output_file: Path):\n    \"\"\"\n    Generates a single HTML file summarizing the contents of the output_dir.\n    \"\"\"\n    logger.info(f\"Starting HTML report generation for directory: {output_dir.as_posix()}\")\n    logger.info(f\"Output HTML will be saved to: {site_output_file.as_posix()}\")\n\n    with open(site_output_file, 'w', encoding='utf-8') as f:\n        f.write(HTML_START_TEMPLATE)\n\n        _add_pipeline_summary_section(f, output_dir)\n        _add_gnn_discovery_section(f, output_dir)\n        _add_test_reports_section(f, output_dir)\n        _add_gnn_type_checker_section(f, output_dir)\n        _add_gnn_exports_section(f, output_dir) # Also handles gnn_processing_summary.md internally\n        _add_visualizations_section(f, output_dir)\n        _add_mcp_report_section(f, output_dir)\n        _add_ontology_processing_section(f, output_dir)\n        _add_rendered_simulators_section(f, output_dir)\n        _add_execution_logs_section(f, output_dir)\n        _add_llm_outputs_section(f, output_dir)\n        _add_pipeline_log_section(f, output_dir)\n        _add_other_outputs_section(f, output_dir, site_output_file)\n\n        f.write(HTML_END_TEMPLATE)\n    logger.info(f\"\u2705 HTML report generated successfully: {site_output_file.as_posix()}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      },
      {
        "name": "main_site_generator",
        "type": "function",
        "start_line": 542,
        "end_line": 584,
        "code": "def main_site_generator():\n    \"\"\"\n    Main function to run the site generator.\n    Parses arguments for output directory and site HTML file path.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Generate an HTML summary site from GNN pipeline outputs.\")\n    parser.add_argument(\n        \"--output-dir\",\n        type=Path,\n        required=True,\n        help=\"The main output directory of the GNN pipeline (e.g., ../output or ./output).\"\n    )\n    parser.add_argument(\n        \"--site-output-file\",\n        type=Path,\n        required=True,\n        help=\"The path where the final HTML site file should be saved (e.g., output/gnn_pipeline_summary.html).\"\n    )\n    parser.add_argument(\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Enable verbose logging.\"\n    )\n    args = parser.parse_args()\n\n    if args.verbose:\n        logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        logger.setLevel(logging.DEBUG)\n    else:\n        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        logger.setLevel(logging.INFO)\n\n    resolved_output_dir = args.output_dir.resolve()\n    resolved_site_output_file = args.site_output_file.resolve()\n\n    if not resolved_output_dir.is_dir():\n        logger.error(f\"Output directory does not exist: {resolved_output_dir.as_posix()}\")\n        sys.exit(1) # Use sys.exit(1) for error exit code\n\n    resolved_site_output_file.parent.mkdir(parents=True, exist_ok=True)\n    \n    generate_html_report(resolved_output_dir, resolved_site_output_file)\n    sys.exit(0) # Success exit code",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/generator.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/mcp.py": [
      {
        "name": "GenerateSiteSchema",
        "type": "class",
        "start_line": 8,
        "end_line": 11,
        "code": "class GenerateSiteSchema(MCPSchema):\n    output_dir: Path\n    site_output_file: Path\n    verbose: bool = False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/mcp.py"
      },
      {
        "name": "GenerateSiteTool",
        "type": "class",
        "start_line": 13,
        "end_line": 53,
        "code": "class GenerateSiteTool(MCPTool):\n    name = \"generate_pipeline_summary_site\"\n    description = \"Generates a single HTML website summarizing all contents of the GNN pipeline output directory.\"\n    schema = GenerateSiteSchema\n\n    def handler(self, params: GenerateSiteSchema) -> MCPToolResponse:\n        logger.info(f\"MCP Tool '{self.name}' invoked with params: output_dir={params.output_dir}, site_output_file={params.site_output_file}\")\n        \n        # Configure generator logger level based on verbose flag from MCP params\n        if params.verbose:\n            generator_logger.setLevel(logging.DEBUG)\n        else:\n            generator_logger.setLevel(logging.INFO)\n        # Ensure console handler for generator_logger if not already present for MCP context\n        if not any(isinstance(h, logging.StreamHandler) for h in generator_logger.handlers):\n            ch = logging.StreamHandler()\n            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n            ch.setFormatter(formatter)\n            generator_logger.addHandler(ch)\n            generator_logger.propagate = False # Avoid double logging if root has handler\n\n        try:\n            resolved_output_dir = params.output_dir.resolve()\n            resolved_site_output_file = params.site_output_file.resolve()\n\n            if not resolved_output_dir.is_dir():\n                error_msg = f\"Output directory does not exist: {resolved_output_dir}\"\n                logger.error(error_msg)\n                return MCPToolResponse(status_code=400, message=error_msg, error=True)\n\n            resolved_site_output_file.parent.mkdir(parents=True, exist_ok=True)\n            \n            generate_html_report(resolved_output_dir, resolved_site_output_file)\n            \n            success_msg = f\"HTML site generated successfully at {resolved_site_output_file}\"\n            logger.info(success_msg)\n            return MCPToolResponse(status_code=200, message=success_msg, data={\"site_path\": str(resolved_site_output_file)})\n        except Exception as e:\n            error_msg = f\"Error during site generation: {str(e)}\"\n            logger.exception(error_msg) # Log full traceback\n            return MCPToolResponse(status_code=500, message=error_msg, error=True)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/mcp.py"
      },
      {
        "name": "handler",
        "type": "method",
        "start_line": 18,
        "end_line": 53,
        "code": "def handler(self, params: GenerateSiteSchema) -> MCPToolResponse:\n        logger.info(f\"MCP Tool '{self.name}' invoked with params: output_dir={params.output_dir}, site_output_file={params.site_output_file}\")\n        \n        # Configure generator logger level based on verbose flag from MCP params\n        if params.verbose:\n            generator_logger.setLevel(logging.DEBUG)\n        else:\n            generator_logger.setLevel(logging.INFO)\n        # Ensure console handler for generator_logger if not already present for MCP context\n        if not any(isinstance(h, logging.StreamHandler) for h in generator_logger.handlers):\n            ch = logging.StreamHandler()\n            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n            ch.setFormatter(formatter)\n            generator_logger.addHandler(ch)\n            generator_logger.propagate = False # Avoid double logging if root has handler\n\n        try:\n            resolved_output_dir = params.output_dir.resolve()\n            resolved_site_output_file = params.site_output_file.resolve()\n\n            if not resolved_output_dir.is_dir():\n                error_msg = f\"Output directory does not exist: {resolved_output_dir}\"\n                logger.error(error_msg)\n                return MCPToolResponse(status_code=400, message=error_msg, error=True)\n\n            resolved_site_output_file.parent.mkdir(parents=True, exist_ok=True)\n            \n            generate_html_report(resolved_output_dir, resolved_site_output_file)\n            \n            success_msg = f\"HTML site generated successfully at {resolved_site_output_file}\"\n            logger.info(success_msg)\n            return MCPToolResponse(status_code=200, message=success_msg, data={\"site_path\": str(resolved_site_output_file)})\n        except Exception as e:\n            error_msg = f\"Error during site generation: {str(e)}\"\n            logger.exception(error_msg) # Log full traceback\n            return MCPToolResponse(status_code=500, message=error_msg, error=True)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/site/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/test_gnn_type_checker.py": [
      {
        "name": "TestGNNTypeChecker",
        "type": "class",
        "start_line": 17,
        "end_line": 195,
        "code": "class TestGNNTypeChecker(unittest.TestCase):\n    \"\"\"Tests for the GNNTypeChecker class.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up the test environment.\"\"\"\n        self.checker = GNNTypeChecker()\n        \n        # Create a valid GNN file for testing\n        self.valid_gnn_content = \"\"\"# GNN Example: Valid Test Model\n# Format: Markdown representation of a Valid Test Model\n# Version: 1.0\n# This file is machine-readable\n\n## GNNSection\nTestModel\n\n## GNNVersionAndFlags\nGNN v1\n\n## ModelName\nValid Test Model\n\n## StateSpaceBlock\nx[2,1,type=float]      # Observable variable\ny[3,1,type=float]      # Hidden variable\n\n## Connections\nx-y                    # Bidirectional connection\n\n## InitialParameterization\nx={0.0,0.0}            # Initial values for x\ny={1.0,1.0,1.0}        # Initial values for y\n\n## Equations\nx = f(y)               # Simple equation\n\n## Time\nStatic\n\n## Footer\nValid Test Model\n\n## Signature\nNA\n\"\"\"\n        \n        # Create an invalid GNN file for testing\n        self.invalid_gnn_content = \"\"\"# GNN Example: Invalid Test Model\n# Format: Markdown representation of an Invalid Test Model\n# Version: 1.0\n# This file is machine-readable\n\n## GNNSection\nTestModel\n\n## GNNVersionAndFlags\nGNN v1\n\n## ModelName\nInvalid Test Model\n\n## StateSpaceBlock\nx[2,1,type=float]      # Observable variable\n\n## Connections\nx-y                    # Invalid connection to undefined variable y\n\n## InitialParameterization\nx={0.0,0.0}            # Initial values for x\n\n## Equations\nz = f(y)               # Invalid equation with undefined variables\n\n## Time\nInvalidTimeSpec        # Invalid time specification\n\n## Footer\nInvalid Test Model\n\n## Signature\nNA\n\"\"\"\n    \n    def test_check_valid_file(self):\n        \"\"\"Test checking a valid GNN file.\"\"\"\n        with NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:\n            f.write(self.valid_gnn_content)\n            temp_file = f.name\n        \n        try:\n            is_valid, errors, warnings = self.checker.check_file(temp_file)\n            \n            self.assertTrue(is_valid, f\"Expected valid file to pass checks, but got errors: {errors}\")\n            self.assertEqual(len(errors), 0, \"Expected no errors for valid file\")\n        finally:\n            os.unlink(temp_file)\n    \n    def test_check_invalid_file(self):\n        \"\"\"Test checking an invalid GNN file.\"\"\"\n        with NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:\n            f.write(self.invalid_gnn_content)\n            temp_file = f.name\n        \n        try:\n            is_valid, errors, warnings = self.checker.check_file(temp_file)\n            \n            self.assertFalse(is_valid, \"Expected invalid file to fail checks\")\n            self.assertGreater(len(errors), 0, \"Expected at least one error for invalid file\")\n            \n            # Check for specific errors\n            connection_error = any(\"Connection references undefined variable: y\" in error for error in errors)\n            time_error = any(\"Invalid time specification\" in error for error in errors)\n            \n            self.assertTrue(connection_error, \"Expected error about undefined variable in connection\")\n            self.assertTrue(time_error, \"Expected error about invalid time specification\")\n        finally:\n            os.unlink(temp_file)\n    \n    def test_check_directory(self):\n        \"\"\"Test checking a directory of GNN files.\"\"\"\n        with TemporaryDirectory() as temp_dir:\n            # Create a valid file\n            valid_path = os.path.join(temp_dir, \"valid.md\")\n            with open(valid_path, 'w') as f:\n                f.write(self.valid_gnn_content)\n            \n            # Create an invalid file\n            invalid_path = os.path.join(temp_dir, \"invalid.md\")\n            with open(invalid_path, 'w') as f:\n                f.write(self.invalid_gnn_content)\n            \n            # Check the directory\n            results = self.checker.check_directory(temp_dir)\n            \n            self.assertEqual(len(results), 2, \"Expected results for 2 files\")\n            self.assertTrue(results[valid_path][\"is_valid\"], \"Expected valid file to pass\")\n            self.assertFalse(results[invalid_path][\"is_valid\"], \"Expected invalid file to fail\")\n    \n    def test_generate_report(self):\n        \"\"\"Test generating a report from check results.\"\"\"\n        results = {\n            \"file1.md\": {\n                \"is_valid\": True,\n                \"errors\": [],\n                \"warnings\": [\"Warning 1\"]\n            },\n            \"file2.md\": {\n                \"is_valid\": False,\n                \"errors\": [\"Error 1\", \"Error 2\"],\n                \"warnings\": []\n            }\n        }\n        \n        with NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:\n            temp_file = f.name\n        \n        try:\n            # Get directory and filename from temp_file\n            temp_file_path = Path(temp_file)\n            output_dir = temp_file_path.parent\n            report_filename = temp_file_path.name\n            \n            report = self.checker.generate_report(results, output_dir_base=output_dir, report_md_filename=report_filename)\n            \n            # Check that the report was written to the file\n            self.assertTrue(os.path.exists(temp_file))\n            with open(temp_file, 'r') as f:\n                file_content = f.read()\n                self.assertEqual(file_content, report)\n            \n            # Check report content\n            self.assertIn(\"Checked 2 files, 1 valid, 1 invalid\", report)\n            self.assertIn(\"file1.md: \u2705 VALID\", report)\n            self.assertIn(\"file2.md: \u274c INVALID\", report)\n            self.assertIn(\"Warning 1\", report)\n            self.assertIn(\"Error 1\", report)\n            self.assertIn(\"Error 2\", report)\n        finally:\n            os.unlink(temp_file)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/test_gnn_type_checker.py"
      },
      {
        "name": "setUp",
        "type": "method",
        "start_line": 20,
        "end_line": 98,
        "code": "def setUp(self):\n        \"\"\"Set up the test environment.\"\"\"\n        self.checker = GNNTypeChecker()\n        \n        # Create a valid GNN file for testing\n        self.valid_gnn_content = \"\"\"# GNN Example: Valid Test Model\n# Format: Markdown representation of a Valid Test Model\n# Version: 1.0\n# This file is machine-readable\n\n## GNNSection\nTestModel\n\n## GNNVersionAndFlags\nGNN v1\n\n## ModelName\nValid Test Model\n\n## StateSpaceBlock\nx[2,1,type=float]      # Observable variable\ny[3,1,type=float]      # Hidden variable\n\n## Connections\nx-y                    # Bidirectional connection\n\n## InitialParameterization\nx={0.0,0.0}            # Initial values for x\ny={1.0,1.0,1.0}        # Initial values for y\n\n## Equations\nx = f(y)               # Simple equation\n\n## Time\nStatic\n\n## Footer\nValid Test Model\n\n## Signature\nNA\n\"\"\"\n        \n        # Create an invalid GNN file for testing\n        self.invalid_gnn_content = \"\"\"# GNN Example: Invalid Test Model\n# Format: Markdown representation of an Invalid Test Model\n# Version: 1.0\n# This file is machine-readable\n\n## GNNSection\nTestModel\n\n## GNNVersionAndFlags\nGNN v1\n\n## ModelName\nInvalid Test Model\n\n## StateSpaceBlock\nx[2,1,type=float]      # Observable variable\n\n## Connections\nx-y                    # Invalid connection to undefined variable y\n\n## InitialParameterization\nx={0.0,0.0}            # Initial values for x\n\n## Equations\nz = f(y)               # Invalid equation with undefined variables\n\n## Time\nInvalidTimeSpec        # Invalid time specification\n\n## Footer\nInvalid Test Model\n\n## Signature\nNA\n\"\"\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/test_gnn_type_checker.py"
      },
      {
        "name": "test_check_valid_file",
        "type": "method",
        "start_line": 100,
        "end_line": 112,
        "code": "def test_check_valid_file(self):\n        \"\"\"Test checking a valid GNN file.\"\"\"\n        with NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:\n            f.write(self.valid_gnn_content)\n            temp_file = f.name\n        \n        try:\n            is_valid, errors, warnings = self.checker.check_file(temp_file)\n            \n            self.assertTrue(is_valid, f\"Expected valid file to pass checks, but got errors: {errors}\")\n            self.assertEqual(len(errors), 0, \"Expected no errors for valid file\")\n        finally:\n            os.unlink(temp_file)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/test_gnn_type_checker.py"
      },
      {
        "name": "test_check_invalid_file",
        "type": "method",
        "start_line": 114,
        "end_line": 133,
        "code": "def test_check_invalid_file(self):\n        \"\"\"Test checking an invalid GNN file.\"\"\"\n        with NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:\n            f.write(self.invalid_gnn_content)\n            temp_file = f.name\n        \n        try:\n            is_valid, errors, warnings = self.checker.check_file(temp_file)\n            \n            self.assertFalse(is_valid, \"Expected invalid file to fail checks\")\n            self.assertGreater(len(errors), 0, \"Expected at least one error for invalid file\")\n            \n            # Check for specific errors\n            connection_error = any(\"Connection references undefined variable: y\" in error for error in errors)\n            time_error = any(\"Invalid time specification\" in error for error in errors)\n            \n            self.assertTrue(connection_error, \"Expected error about undefined variable in connection\")\n            self.assertTrue(time_error, \"Expected error about invalid time specification\")\n        finally:\n            os.unlink(temp_file)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/test_gnn_type_checker.py"
      },
      {
        "name": "test_check_directory",
        "type": "method",
        "start_line": 135,
        "end_line": 153,
        "code": "def test_check_directory(self):\n        \"\"\"Test checking a directory of GNN files.\"\"\"\n        with TemporaryDirectory() as temp_dir:\n            # Create a valid file\n            valid_path = os.path.join(temp_dir, \"valid.md\")\n            with open(valid_path, 'w') as f:\n                f.write(self.valid_gnn_content)\n            \n            # Create an invalid file\n            invalid_path = os.path.join(temp_dir, \"invalid.md\")\n            with open(invalid_path, 'w') as f:\n                f.write(self.invalid_gnn_content)\n            \n            # Check the directory\n            results = self.checker.check_directory(temp_dir)\n            \n            self.assertEqual(len(results), 2, \"Expected results for 2 files\")\n            self.assertTrue(results[valid_path][\"is_valid\"], \"Expected valid file to pass\")\n            self.assertFalse(results[invalid_path][\"is_valid\"], \"Expected invalid file to fail\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/test_gnn_type_checker.py"
      },
      {
        "name": "test_generate_report",
        "type": "method",
        "start_line": 155,
        "end_line": 195,
        "code": "def test_generate_report(self):\n        \"\"\"Test generating a report from check results.\"\"\"\n        results = {\n            \"file1.md\": {\n                \"is_valid\": True,\n                \"errors\": [],\n                \"warnings\": [\"Warning 1\"]\n            },\n            \"file2.md\": {\n                \"is_valid\": False,\n                \"errors\": [\"Error 1\", \"Error 2\"],\n                \"warnings\": []\n            }\n        }\n        \n        with NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:\n            temp_file = f.name\n        \n        try:\n            # Get directory and filename from temp_file\n            temp_file_path = Path(temp_file)\n            output_dir = temp_file_path.parent\n            report_filename = temp_file_path.name\n            \n            report = self.checker.generate_report(results, output_dir_base=output_dir, report_md_filename=report_filename)\n            \n            # Check that the report was written to the file\n            self.assertTrue(os.path.exists(temp_file))\n            with open(temp_file, 'r') as f:\n                file_content = f.read()\n                self.assertEqual(file_content, report)\n            \n            # Check report content\n            self.assertIn(\"Checked 2 files, 1 valid, 1 invalid\", report)\n            self.assertIn(\"file1.md: \u2705 VALID\", report)\n            self.assertIn(\"file2.md: \u274c INVALID\", report)\n            self.assertIn(\"Warning 1\", report)\n            self.assertIn(\"Error 1\", report)\n            self.assertIn(\"Error 2\", report)\n        finally:\n            os.unlink(temp_file)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/test_gnn_type_checker.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/mcp.py": [
      {
        "name": "run_type_checker_on_file",
        "type": "function",
        "start_line": 26,
        "end_line": 52,
        "code": "def run_type_checker_on_file(file_path: str) -> Dict[str, Any]:\n    \"\"\"\n    Run the GNN type checker on a file.\n    \n    Args:\n        file_path: Path to the GNN file to check\n        \n    Returns:\n        Dictionary containing type checker results\n    \"\"\"\n    try:\n        checker = GNNTypeChecker()\n        is_valid, errors, warnings = checker.check_file(file_path)\n        \n        return {\n            \"file_path\": file_path,\n            \"is_valid\": is_valid,\n            \"errors\": errors,\n            \"warnings\": warnings\n        }\n    except Exception as e:\n        logger.error(f\"Error in run_type_checker_on_file for {file_path}: {e}\", exc_info=True)\n        return {\n            \"file_path\": file_path,\n            \"success\": False,\n            \"error\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/mcp.py"
      },
      {
        "name": "run_type_checker_on_directory",
        "type": "function",
        "start_line": 54,
        "end_line": 103,
        "code": "def run_type_checker_on_directory(dir_path: str, report_file: Optional[str] = None) -> Dict[str, Any]:\n    \"\"\"\n    Run the GNN type checker on a directory of files.\n    \n    Args:\n        dir_path: Path to directory containing GNN files\n        report_file: Optional path to save the report\n        \n    Returns:\n        Dictionary containing type checker results\n    \"\"\"\n    try:\n        checker = GNNTypeChecker()\n        results = checker.check_directory(dir_path)\n        \n        # Generate report if requested\n        report = None\n        if report_file:\n            report = checker.generate_report(results, output_file=report_file)\n        \n        # Format results for output\n        formatted_results = {}\n        for file_path, result in results.items():\n            formatted_results[file_path] = {\n                \"is_valid\": result[\"is_valid\"],\n                \"error_count\": len(result[\"errors\"]),\n                \"warning_count\": len(result[\"warnings\"]),\n                \"errors\": result[\"errors\"],\n                \"warnings\": result[\"warnings\"]\n            }\n        \n        return {\n            \"directory_path\": dir_path,\n            \"report_file\": report_file if report_file else None,\n            \"results\": formatted_results,\n            \"summary\": {\n                \"total_files\": len(results),\n                \"valid_count\": sum(1 for r in results.values() if r[\"is_valid\"]),\n                \"invalid_count\": sum(1 for r in results.values() if not r[\"is_valid\"]),\n                \"total_errors\": sum(len(r[\"errors\"]) for r in results.values()),\n                \"total_warnings\": sum(len(r[\"warnings\"]) for r in results.values())\n            }\n        }\n    except Exception as e:\n        logger.error(f\"Error in run_type_checker_on_directory for {dir_path}: {e}\", exc_info=True)\n        return {\n            \"directory_path\": dir_path,\n            \"success\": False,\n            \"error\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/mcp.py"
      },
      {
        "name": "run_unit_tests",
        "type": "function",
        "start_line": 105,
        "end_line": 146,
        "code": "def run_unit_tests() -> Dict[str, Any]:\n    \"\"\"\n    Run the GNN unit tests.\n    \n    Returns:\n        Dictionary containing test results\n    \"\"\"\n    try:\n        # Create a test loader and runner\n        loader = unittest.TestLoader()\n        suite = loader.discover(os.path.dirname(__file__), pattern=\"test_*.py\")\n        \n        # Use a temporary file to capture test output\n        with tempfile.NamedTemporaryFile(mode='w+', delete=False) as temp_file:\n            # Create a text test runner that writes to the temp file\n            runner = unittest.TextTestRunner(stream=temp_file, verbosity=2)\n            result = runner.run(suite)\n            \n            # Rewind and read the output\n            temp_file.seek(0)\n            test_output = temp_file.read()\n        \n        # Clean up the temp file\n        os.unlink(temp_file.name)\n        \n        return {\n            \"success\": True,\n            \"ran\": result.testsRun,\n            \"failures\": len(result.failures),\n            \"errors\": len(result.errors),\n            \"skipped\": len(result.skipped),\n            \"was_successful\": result.wasSuccessful(),\n            \"failures_detail\": [{\"test\": t[0].id(), \"message\": t[1]} for t in result.failures],\n            \"errors_detail\": [{\"test\": t[0].id(), \"message\": t[1]} for t in result.errors],\n            \"output\": test_output\n        }\n    except Exception as e:\n        logger.error(f\"Error in run_unit_tests: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/mcp.py"
      },
      {
        "name": "get_test_report",
        "type": "function",
        "start_line": 150,
        "end_line": 180,
        "code": "def get_test_report(uri: str) -> Dict[str, Any]:\n    \"\"\"\n    Retrieve a test report by URI.\n    \n    Args:\n        uri: URI of the test report. Format: test-report://{report_file}\n        \n    Returns:\n        Dictionary containing the test report\n    \"\"\"\n    # Extract file path from URI\n    if not uri.startswith(\"test-report://\"):\n        error_msg = f\"Invalid URI format: {uri}\"\n        logger.error(f\"get_test_report: {error_msg}\")\n        raise ValueError(error_msg)\n    \n    file_path_str = uri[14:]  # Remove 'test-report://' prefix\n    file_path = Path(file_path_str)\n    \n    if not file_path.exists() or not file_path.is_file():\n        error_msg = f\"Report file does not exist: {file_path}\"\n        logger.error(f\"get_test_report: {error_msg}\")\n        raise ValueError(error_msg)\n    \n    # Read the report content\n    report_content = file_path.read_text()\n    \n    return {\n        \"file_path\": str(file_path),\n        \"content\": report_content\n    }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/mcp.py"
      },
      {
        "name": "register_tools",
        "type": "function",
        "start_line": 184,
        "end_line": 221,
        "code": "def register_tools(mcp):\n    \"\"\"Register test tools with the MCP.\"\"\"\n    \n    # Register test tools\n    mcp.register_tool(\n        \"run_gnn_type_checker\",\n        run_type_checker_on_file,\n        {\n            \"file_path\": {\"type\": \"string\", \"description\": \"Path to the GNN file to check\"}\n        },\n        \"Run the GNN type checker on a specific file (via test module).\"\n    )\n    \n    mcp.register_tool(\n        \"run_gnn_type_checker_on_directory\",\n        run_type_checker_on_directory,\n        {\n            \"dir_path\": {\"type\": \"string\", \"description\": \"Path to directory containing GNN files\"},\n            \"report_file\": {\"type\": \"string\", \"description\": \"Optional path to save the report\"}\n        },\n        \"Run the GNN type checker on all GNN files in a directory (via test module).\"\n    )\n    \n    mcp.register_tool(\n        \"run_gnn_unit_tests\",\n        run_unit_tests,\n        {},\n        \"Run the GNN unit tests and return results.\"\n    )\n    \n    # Register test resources\n    mcp.register_resource(\n        \"test-report://{report_file}\",\n        get_test_report,\n        \"Retrieve a test report by file path\"\n    )\n    \n    logger.info(\"Tests module MCP tools and resources registered.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/tests/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/structured_data_exporters.py": [
      {
        "name": "_pretty_print_xml",
        "type": "function",
        "start_line": 14,
        "end_line": 18,
        "code": "def _pretty_print_xml(element: ET.Element) -> str:\n    \"\"\"Return a pretty-printed XML string for the Element.\"\"\"\n    rough_string = ET.tostring(element, 'utf-8')\n    reparsed = minidom.parseString(rough_string)\n    return reparsed.toprettyxml(indent=\"  \")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/structured_data_exporters.py"
      },
      {
        "name": "_dict_to_xml",
        "type": "function",
        "start_line": 20,
        "end_line": 42,
        "code": "def _dict_to_xml(tag: str, d: Union[Dict[str, Any], List[Any], str, int, float, bool, None]) -> ET.Element:\n    \"\"\"Recursively convert a Python dictionary or list to an XML ET.Element.\"\"\"\n    elem = ET.Element(tag)\n    if isinstance(d, dict):\n        for key, val in d.items():\n            safe_key = re.sub(r'[^a-zA-Z0-9_.-]', '_', str(key)) # Allow . and - in tags if they are not first char\n            if not safe_key or not safe_key[0].isalpha() and safe_key[0] != '_':\n                safe_key = '_' + safe_key\n            # Replace special characters that are still problematic even if not first\n            safe_key = safe_key.replace(\"[\", \"_ob_\").replace(\"]\", \"_cb_\").replace(\"(\", \"_op_\").replace(\")\", \"_cp_\").replace(\"{\", \"_ocb_\").replace(\"}\", \"_ccb_\")\n            \n            child = _dict_to_xml(safe_key, val)\n            elem.append(child)\n    elif isinstance(d, list):\n        for i, item in enumerate(d):\n            item_tag = f\"{tag}_item\" \n            child = _dict_to_xml(item_tag, item)\n            elem.append(child)\n    elif d is None:\n        elem.text = \"\" \n    else:\n        elem.text = str(d)\n    return elem",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/structured_data_exporters.py"
      },
      {
        "name": "export_to_json_gnn",
        "type": "function",
        "start_line": 46,
        "end_line": 54,
        "code": "def export_to_json_gnn(gnn_model: dict, output_file_path: str):\n    \"\"\"Exports the GNN model dictionary to a JSON file.\"\"\"\n    try:\n        with open(output_file_path, 'w', encoding='utf-8') as f:\n            json.dump(gnn_model, f, indent=4, ensure_ascii=False)\n        logger.debug(f\"Successfully exported GNN model to JSON: {output_file_path}\")\n    except Exception as e:\n        logger.error(f\"Failed to export GNN model to JSON {output_file_path}: {e}\", exc_info=True)\n        raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/structured_data_exporters.py"
      },
      {
        "name": "export_to_xml_gnn",
        "type": "function",
        "start_line": 56,
        "end_line": 73,
        "code": "def export_to_xml_gnn(gnn_model: dict, output_file_path: str):\n    \"\"\"Exports the GNN model dictionary to an XML file.\"\"\"\n    try:\n        # Ensure the top-level GNN model dictionary has a root tag name if being converted directly\n        # For example, if gnn_model itself is the d in _dict_to_xml(tag, d)\n        root_tag_name = gnn_model.get(\"name\", \"gnn_model\").replace(\" \", \"_\")\n        safe_root_tag = re.sub(r'[^a-zA-Z0-9_.-]', '_', root_tag_name)\n        if not safe_root_tag or not safe_root_tag[0].isalpha() and safe_root_tag[0] != '_':\n            safe_root_tag = '_' + safe_root_tag\n\n        root_element = _dict_to_xml(safe_root_tag, gnn_model)\n        xml_string = _pretty_print_xml(root_element)\n        with open(output_file_path, 'w', encoding='utf-8') as f:\n            f.write(xml_string)\n        logger.debug(f\"Successfully exported GNN model to XML: {output_file_path}\")\n    except Exception as e:\n        logger.error(f\"Failed to export GNN model to XML {output_file_path}: {e}\", exc_info=True)\n        raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/structured_data_exporters.py"
      },
      {
        "name": "export_to_python_pickle",
        "type": "function",
        "start_line": 75,
        "end_line": 83,
        "code": "def export_to_python_pickle(gnn_model: dict, output_file_path: str):\n    \"\"\"Serializes the GNN model dictionary to a Python pickle file.\"\"\"\n    try:\n        with open(output_file_path, 'wb') as f:\n            pickle.dump(gnn_model, f)\n        logger.debug(f\"Successfully exported GNN model to Python pickle: {output_file_path}\")\n    except Exception as e:\n        logger.error(f\"Failed to export GNN model to Python pickle {output_file_path}: {e}\", exc_info=True)\n        raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/structured_data_exporters.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/text_exporters.py": [
      {
        "name": "export_to_plaintext_summary",
        "type": "function",
        "start_line": 8,
        "end_line": 62,
        "code": "def export_to_plaintext_summary(gnn_model: dict, output_file_path: str):\n    \"\"\"Exports a human-readable plain text summary of the GNN model.\"\"\"\n    try:\n        with open(output_file_path, 'w', encoding='utf-8') as f:\n            f.write(f\"GNN Model Summary: {gnn_model.get('name', gnn_model.get('metadata', {}).get('name', 'N/A'))}\\n\")\n            f.write(f\"Source File: {gnn_model.get('file_path', 'N/A')}\\n\\n\")\n\n            f.write(\"Metadata:\\n\")\n            for k, v in gnn_model.get('metadata', {}).items():\n                f.write(f\"  {k}: {v}\\n\")\n            f.write(\"\\n\")\n\n            f.write(f\"States ({len(gnn_model.get('states', []))}):\\n\")\n            for state in gnn_model.get('states', []):\n                f.write(f\"  - ID: {state.get('id')}\")\n                attrs = [f\"{k}={v}\" for k,v in state.items() if k!='id']\n                if attrs: f.write(f\" ({', '.join(attrs)})\")\n                f.write(\"\\n\")\n            f.write(\"\\n\")\n\n            f.write(f\"Initial Parameters ({len(gnn_model.get('initial_parameters', {}))}):\\n\")\n            for k, v in gnn_model.get('initial_parameters', {}).items():\n                 f.write(f\"  {k}: {v}\\n\") # v here is already parsed by _parse_matrix_string\n            f.write(\"\\n\")\n            \n            f.write(f\"General Parameters ({len(gnn_model.get('parameters', {}))}):\\n\")\n            for k, v in gnn_model.get('parameters', {}).items():\n                 f.write(f\"  {k}: {v}\\n\")\n            f.write(\"\\n\")\n            \n            f.write(f\"Observations ({len(gnn_model.get('observations', []))}):\\n\")\n            for obs in gnn_model.get('observations', []):\n                f.write(f\"  - ID: {obs.get('id')}\")\n                attrs = [f\"{k}={v}\" for k,v in obs.items() if k!='id']\n                if attrs: f.write(f\" ({', '.join(attrs)})\")\n                f.write(\"\\n\")\n            f.write(\"\\n\")\n\n            f.write(f\"Transitions ({len(gnn_model.get('transitions', []))}):\\n\")\n            for trans in gnn_model.get('transitions', []):\n                attr_str = \", \".join([f\"{k}={v}\" for k, v in trans.get('attributes', {}).items()])\n                f.write(f\"  - {trans.get('source')} -> {trans.get('target')}\")\n                if attr_str: f.write(f\" : {attr_str}\")\n                f.write(\"\\n\")\n            f.write(\"\\n\")\n\n            f.write(f\"Ontology Annotations ({len(gnn_model.get('ontology_annotations', {}))}):\\n\")\n            for k, v in gnn_model.get('ontology_annotations', {}).items():\n                f.write(f\"  {k} = {v}\\n\")\n            f.write(\"\\n\")\n\n        logger.debug(f\"Successfully exported GNN model to plain text summary: {output_file_path}\")\n    except Exception as e:\n        logger.error(f\"Failed to export GNN model to plain text summary {output_file_path}: {e}\", exc_info=True)\n        raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/text_exporters.py"
      },
      {
        "name": "export_to_plaintext_dsl",
        "type": "function",
        "start_line": 64,
        "end_line": 109,
        "code": "def export_to_plaintext_dsl(gnn_model: dict, output_file_path: str):\n    \"\"\"\n    Exports the GNN model back to a DSL-like format using the raw sections.\n    This aims to reconstruct the original .gnn.md file structure.\n    \"\"\"\n    try:\n        with open(output_file_path, 'w', encoding='utf-8') as f:\n            # A predefined section order might be better for consistency.\n            # For now, using a common order, then remaining raw_sections.\n            # This order is an example and might need refinement based on GNN standards.\n            preferred_order = [\n                \"GNNSection\", \"ImageFromPaper\", \"GNNVersionAndFlags\", \"ModelName\", \n                \"ModelAnnotation\", \"StateSpaceBlock\", \"ParameterBlock\", \n                \"InitialParameterization\", \"ObservationBlock\", \"Connections\", \n                \"TransitionBlock\", \"Equations\", \"Time\", \"ActInfOntologyAnnotation\",\n                \"ModelParameters\", \"Footer\", \"Signature\"\n            ]\n            \n            written_sections = set()\n            raw_sections = gnn_model.get('raw_sections', {})\n\n            for section_name in preferred_order:\n                if section_name in raw_sections:\n                    # Check for the special case of InitialParameterization_raw_content due to previous fix\n                    if section_name == \"InitialParameterization\" and \"InitialParameterization_raw_content\" in raw_sections:\n                        section_content = raw_sections[\"InitialParameterization_raw_content\"]\n                    else:\n                        section_content = raw_sections[section_name]\n                    \n                    f.write(f\"## {section_name}\\n\")\n                    f.write(f\"{section_content}\\n\\n\")\n                    written_sections.add(section_name)\n                    if section_name == \"InitialParameterization\": # also mark the _raw_content as written if used\n                         written_sections.add(\"InitialParameterization_raw_content\")\n                         written_sections.add(\"InitialParameterization_parsed_kv\") # mark helper keys as written\n\n            # Write any remaining sections not in preferred_order\n            for section_name, section_content in raw_sections.items():\n                if section_name not in written_sections:\n                    f.write(f\"## {section_name}\\n\")\n                    f.write(f\"{section_content}\\n\\n\")\n            \n        logger.debug(f\"Successfully exported GNN model to plain text DSL: {output_file_path}\")\n    except Exception as e:\n        logger.error(f\"Failed to export GNN model to plain text DSL {output_file_path}: {e}\", exc_info=True)\n        raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/text_exporters.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py": [
      {
        "name": "_handle_export",
        "type": "function",
        "start_line": 35,
        "end_line": 87,
        "code": "def _handle_export(\n    export_func: Callable[[Dict[str, Any], str], None], \n    gnn_file_path: str, \n    output_file_path: str, \n    format_name: str, \n    requires_nx: bool = False\n) -> Dict[str, Any]:\n    \"\"\"Generic helper to run an export function and handle common exceptions.\"\"\"\n    if _gnn_model_to_dict is None:\n        logger.error(f\"Export to {format_name} failed: _gnn_model_to_dict parser not available.\")\n        return {\n            \"success\": False,\n            \"input_file\": gnn_file_path,\n            \"output_file\": output_file_path,\n            \"error\": \"GNN parser (_gnn_model_to_dict) not available. Cannot perform export.\"\n        }\n        \n    if requires_nx and not GRAPH_EXPORTERS_HAVE_NETWORKX:\n        logger.error(f\"NetworkX library is not available. Cannot export to {format_name}.\")\n        return {\n            \"success\": False,\n            \"input_file\": gnn_file_path,\n            \"output_file\": output_file_path,\n            \"error\": f\"NetworkX library is required for {format_name} export but is not installed or available.\"\n        }\n        \n    try:\n        gnn_model = _gnn_model_to_dict(gnn_file_path)\n        if gnn_model is None: # Parser might return None on critical failure\n            raise ValueError(\"GNN parsing resulted in None, cannot proceed with export.\")\n            \n        export_func(gnn_model, output_file_path)\n        return {\n            \"success\": True,\n            \"input_file\": gnn_file_path,\n            \"output_file\": output_file_path,\n            \"message\": f\"Successfully exported GNN model from '{gnn_file_path}' to {format_name}: '{output_file_path}'\"\n        }\n    except FileNotFoundError as fnfe:\n        logger.error(f\"Input GNN file not found ('{gnn_file_path}') for {format_name} export: {fnfe}\")\n        return {\"success\": False, \"input_file\": gnn_file_path, \"error\": f\"Input file not found: {str(fnfe)}\"}\n    except ImportError as ie: \n        logger.error(f\"ImportError during {format_name} export for '{gnn_file_path}': {ie}\")\n        return {\"success\": False, \"input_file\": gnn_file_path, \"output_file\": output_file_path, \"error\": f\"Missing dependency for {format_name}: {str(ie)}\"}\n    except Exception as e:\n        logger.error(f\"Failed to export GNN to {format_name} for '{gnn_file_path}': {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"input_file\": gnn_file_path,\n            \"output_file\": output_file_path,\n            \"error_type\": type(e).__name__,\n            \"error_message\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py"
      },
      {
        "name": "export_gnn_to_json_mcp",
        "type": "function",
        "start_line": 89,
        "end_line": 90,
        "code": "def export_gnn_to_json_mcp(gnn_file_path: str, output_file_path: str) -> Dict[str, Any]:\n    return _handle_export(export_to_json_gnn, gnn_file_path, output_file_path, \"JSON\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py"
      },
      {
        "name": "export_gnn_to_xml_mcp",
        "type": "function",
        "start_line": 92,
        "end_line": 93,
        "code": "def export_gnn_to_xml_mcp(gnn_file_path: str, output_file_path: str) -> Dict[str, Any]:\n    return _handle_export(export_to_xml_gnn, gnn_file_path, output_file_path, \"XML\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py"
      },
      {
        "name": "export_gnn_to_plaintext_summary_mcp",
        "type": "function",
        "start_line": 95,
        "end_line": 96,
        "code": "def export_gnn_to_plaintext_summary_mcp(gnn_file_path: str, output_file_path: str) -> Dict[str, Any]:\n    return _handle_export(export_to_plaintext_summary, gnn_file_path, output_file_path, \"Plaintext Summary\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py"
      },
      {
        "name": "export_gnn_to_plaintext_dsl_mcp",
        "type": "function",
        "start_line": 98,
        "end_line": 99,
        "code": "def export_gnn_to_plaintext_dsl_mcp(gnn_file_path: str, output_file_path: str) -> Dict[str, Any]:\n    return _handle_export(export_to_plaintext_dsl, gnn_file_path, output_file_path, \"Plaintext DSL\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py"
      },
      {
        "name": "export_gnn_to_gexf_mcp",
        "type": "function",
        "start_line": 101,
        "end_line": 102,
        "code": "def export_gnn_to_gexf_mcp(gnn_file_path: str, output_file_path: str) -> Dict[str, Any]:\n    return _handle_export(export_to_gexf, gnn_file_path, output_file_path, \"GEXF\", requires_nx=True)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py"
      },
      {
        "name": "export_gnn_to_graphml_mcp",
        "type": "function",
        "start_line": 104,
        "end_line": 105,
        "code": "def export_gnn_to_graphml_mcp(gnn_file_path: str, output_file_path: str) -> Dict[str, Any]:\n    return _handle_export(export_to_graphml, gnn_file_path, output_file_path, \"GraphML\", requires_nx=True)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py"
      },
      {
        "name": "export_gnn_to_json_adjacency_list_mcp",
        "type": "function",
        "start_line": 107,
        "end_line": 108,
        "code": "def export_gnn_to_json_adjacency_list_mcp(gnn_file_path: str, output_file_path: str) -> Dict[str, Any]:\n    return _handle_export(export_to_json_adjacency_list, gnn_file_path, output_file_path, \"JSON Adjacency List\", requires_nx=True)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py"
      },
      {
        "name": "export_gnn_to_python_pickle_mcp",
        "type": "function",
        "start_line": 110,
        "end_line": 111,
        "code": "def export_gnn_to_python_pickle_mcp(gnn_file_path: str, output_file_path: str) -> Dict[str, Any]:\n    return _handle_export(export_to_python_pickle, gnn_file_path, output_file_path, \"Python Pickle\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py"
      },
      {
        "name": "register_tools",
        "type": "function",
        "start_line": 115,
        "end_line": 148,
        "code": "def register_tools(mcp_instance):\n    \"\"\"Registers all GNN export tools with the MCP instance.\"\"\"\n    \n    base_schema = {\n        \"gnn_file_path\": {\"type\": \"string\", \"description\": \"Path to the input GNN Markdown file (.gnn.md).\"},\n        \"output_file_path\": {\"type\": \"string\", \"description\": \"Path where the exported file will be saved.\"}\n    }\n\n    tools_to_register_spec = [\n        (\"export_gnn_to_json\", export_gnn_to_json_mcp, export_to_json_gnn, \"Exports a GNN model to JSON format.\", False),\n        (\"export_gnn_to_xml\", export_gnn_to_xml_mcp, export_to_xml_gnn, \"Exports a GNN model to XML format.\", False),\n        (\"export_gnn_to_plaintext_summary\", export_gnn_to_plaintext_summary_mcp, export_to_plaintext_summary, \"Exports a GNN model to a human-readable plain text summary.\", False),\n        (\"export_gnn_to_plaintext_dsl\", export_gnn_to_plaintext_dsl_mcp, export_to_plaintext_dsl, \"Exports a GNN model back to its GNN DSL plain text format.\", False),\n        (\"export_gnn_to_gexf\", export_gnn_to_gexf_mcp, export_to_gexf, \"Exports a GNN model to GEXF graph format (requires NetworkX).\", True),\n        (\"export_gnn_to_graphml\", export_gnn_to_graphml_mcp, export_to_graphml, \"Exports a GNN model to GraphML graph format (requires NetworkX).\", True),\n        (\"export_gnn_to_json_adjacency_list\", export_gnn_to_json_adjacency_list_mcp, export_to_json_adjacency_list, \"Exports a GNN model to JSON Adjacency List graph format (requires NetworkX).\", True),\n        (\"export_gnn_to_python_pickle\", export_gnn_to_python_pickle_mcp, export_to_python_pickle, \"Serializes a GNN model to a Python pickle file.\", False)\n    ]\n\n    for mcp_tool_name, mcp_wrapper_func, core_exporter_func, description, needs_nx_flag in tools_to_register_spec:\n        if core_exporter_func is None: # Check if the core function itself is None (due to import issues in specialized modules)\n             logger.warning(f\"Skipping registration of MCP tool '{mcp_tool_name}': Its underlying core export function was not imported correctly from its specialized module.\")\n             continue\n        if needs_nx_flag and not GRAPH_EXPORTERS_HAVE_NETWORKX:\n            logger.warning(f\"Skipping registration of MCP tool '{mcp_tool_name}': It requires NetworkX, which is not available.\")\n            continue\n\n        mcp_instance.register_tool(\n            name=mcp_tool_name,\n            func=mcp_wrapper_func,\n            schema=base_schema.copy(), \n            description=description\n        )\n    logger.info(\"Export module MCP tools registration process completed.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py": [
      {
        "name": "_ensure_path",
        "type": "function",
        "start_line": 42,
        "end_line": 43,
        "code": "def _ensure_path(path_str: str) -> Path:\n    return Path(path_str)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_strip_comments_from_multiline_str",
        "type": "function",
        "start_line": 45,
        "end_line": 56,
        "code": "def _strip_comments_from_multiline_str(m_str: str) -> str:\n    \"\"\"Removes Python-style comments from a multi-line string.\"\"\"\n    lines = []\n    for line in m_str.splitlines():\n        stripped_line = line.split('#', 1)[0].rstrip()\n        lines.append(stripped_line)\n    # Join and then remove lines that became empty AFTER comment stripping and rstrip\n    # but preserve structure for multiline arrays that might have legitimate empty lines (though uncommon)\n    # For ast.literal_eval, truly empty lines within a list/tuple definition are often problematic anyway\n    # So, filtering them out is usually safer if they are not part of string literals.\n    # A simple join and then re-strip should be fine for ast.literal_eval\n    return \"\\n\".join(lines).strip() # Final strip to remove leading/trailing empty lines from the whole block",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_parse_matrix_string",
        "type": "function",
        "start_line": 58,
        "end_line": 111,
        "code": "def _parse_matrix_string(matrix_str: str) -> Any:\n    \"\"\"Safely parses a string representation of a matrix after stripping comments.\"\"\"\n    \n    processed_str = _strip_comments_from_multiline_str(matrix_str)\n    # After stripping comments, processed_str might be empty or just whitespace\n    if not processed_str:\n        logger.debug(f\"Matrix string was empty after comment stripping (original: '{matrix_str}')\")\n        return matrix_str # Or perhaps None, or an empty list, depending on desired behavior\n\n    # Heuristic to convert GNN's common {{...}} or {(...)} for parameterization\n    # into valid Python literal strings, typically aiming for list-of-lists or list-of-tuples.\n    # This should happen AFTER comment stripping.\n    if processed_str.startswith(\"{\") and processed_str.endswith(\"}\"):\n        inner_content = processed_str[1:-1].strip()\n        # If it looks like a dict, leave it as is for ast.literal_eval\n        if ':' in inner_content and not (inner_content.startswith(\"(\") and inner_content.endswith(\")\")):\n            pass # Likely a dictionary, ast.literal_eval handles dicts with {}\n        else:\n            # Otherwise, assume GNN's { } means a list-like structure (set or list of items/tuples)\n            # Convert to [ ] for ast.literal_eval to parse as a list.\n            processed_str = \"[\" + inner_content + \"]\"\n\n    try:\n        parsed_value = ast.literal_eval(processed_str)\n        \n        def convert_structure(item):\n            if isinstance(item, set):\n                # Convert sets to sorted lists for deterministic output\n                try:\n                    return sorted(list(item))\n                except TypeError:\n                    # Cannot sort if items are of mixed uncomparable types (e.g. int and tuple)\n                    return list(item)\n            elif isinstance(item, list):\n                return [convert_structure(x) for x in item]\n            elif isinstance(item, tuple):\n                return tuple(convert_structure(x) for x in item)\n            elif isinstance(item, dict):\n                return {k: convert_structure(v) for k, v in item.items()}\n            return item\n\n        parsed_value = convert_structure(parsed_value)\n        \n        # If the original GNN was like D_f0={(1.0,0.0,0.0)} and became [[(1.0,0.0,0.0)]] due to {[()]} heuristic,\n        # and only contains one element that is a list/tuple, unwrap it.\n        if isinstance(parsed_value, list) and len(parsed_value) == 1 and isinstance(parsed_value[0], (list,tuple)) and processed_str.startswith('[(') and processed_str.endswith(')]'):\n            if processed_str.count('(') == 1 and processed_str.count(')') == 1 : # Check if it was a single tuple in original like {(...)}\n                 parsed_value = list(parsed_value[0]) # Convert the inner tuple to list\n\n        logger.debug(f\"Parsed matrix string (original: \\'{matrix_str}\\') to (processed for eval: \\'{processed_str}\\'): {parsed_value}\")\n        return parsed_value\n    except (ValueError, TypeError, SyntaxError, MemoryError, RecursionError) as e:\n        logger.warning(f\"Error parsing matrix string with ast.literal_eval (original: \\'{matrix_str}\\', processed for eval: \\'{processed_str}\\'). Error: {e}. Returning as raw string.\")\n        return matrix_str",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_parse_free_text_section",
        "type": "function",
        "start_line": 115,
        "end_line": 117,
        "code": "def _parse_free_text_section(section_content: str) -> str:\n    \"\"\"Parses section content as a block of free text.\"\"\"\n    return section_content.strip()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_parse_key_value_section",
        "type": "function",
        "start_line": 119,
        "end_line": 132,
        "code": "def _parse_key_value_section(section_content: str) -> dict:\n    \"\"\"Parses section content assuming key=value or key: value pairs per line.\"\"\"\n    data = {}\n    for line in section_content.strip().split('\\n'):\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            key, value = line.split('=', 1)\n            data[key.strip()] = value.strip()\n        elif ':' in line: # Alternative key-value\n            key, value = line.split(':', 1)\n            data[key.strip()] = value.strip()\n    return data",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_parse_state_line",
        "type": "function",
        "start_line": 134,
        "end_line": 169,
        "code": "def _parse_state_line(line: str) -> dict | None:\n    \"\"\"\n    Parses a line describing a state.\n    Example: s_t[2,1,type=float] name=\"Hidden State\" id_override=\"state1\"\n    \"\"\"\n    match = re.match(r\"^\\s*([a-zA-Z0-9_']+)\\s*(?:\\[(.*?)\\])?\\s*(?:type=([a-zA-Z0-9_]+))?\\s*(.*)$\", line)\n    if not match:\n        simple_line_content = line.split('#')[0].strip()\n        simple_match = re.match(r\"^\\s*([a-zA-Z0-9_']+)\\s*(.*)$\", simple_line_content)\n        if simple_match:\n            state_id_default = simple_match.group(1)\n            attributes_str = simple_match.group(2).strip() \n            dimensions = None\n            state_type = None\n        else:\n            logger.debug(f\"Could not parse state line: {line}\")\n            return None\n    else: \n        state_id_default = match.group(1)\n        dimensions = match.group(2)\n        state_type = match.group(3)\n        attributes_str = match.group(4).split('#')[0].strip()\n\n    attributes = {}\n    if dimensions:\n        attributes['dimensions'] = dimensions\n    if state_type:\n        attributes['type'] = state_type\n\n    for kv_match in re.finditer(r'([a-zA-Z0-9_]+)\\s*=\\s*\"([^\"]*)\"', attributes_str):\n        attributes[kv_match.group(1)] = kv_match.group(2)\n    \n    state_id = attributes.pop('id_override', state_id_default)\n    attributes['original_id'] = state_id_default\n\n    return {\"id\": state_id, **attributes}",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_parse_transition_line",
        "type": "function",
        "start_line": 171,
        "end_line": 216,
        "code": "def _parse_transition_line(line: str) -> dict | None:\n    \"\"\"\n    Parses a line describing a transition or connection.\n    Example: s1 -> s2 : probability=0.8, action=\"A1\" label=\"Transition X\"\n    Also handles: (s1, s2) -> (s3, s4)\n                  s1 > s2\n                  s1 - s2 (simple link)\n    Prime characters like s' are supported in IDs.\n    \"\"\"\n    # Non-verbose, single-line raw string regex pattern\n    pattern = r\"^\\s*(\\(?[a-zA-Z0-9_,'\\s]+\\)?|[a-zA-Z0-9_']+)\\s*([-><]+|-)\\s*(\\(?[a-zA-Z0-9_,'\\s]+\\)?|[a-zA-Z0-9_']+)\\s*(?::\\s*(.*))?$\"\n    match = re.match(pattern, line)\n\n    if not match:\n        logger.debug(f\"Could not parse transition/connection line: {line}\")\n        return None\n\n    source_str, operator, target_str, attrs_str = match.groups()\n\n    def clean_variable_list_str(s: str) -> List[str]:\n        s = s.strip()\n        if s.startswith('(') and s.endswith(')'):\n            s = s[1:-1] # Remove parentheses\n        return [v.strip() for v in s.split(',') if v.strip()]\n\n    sources = clean_variable_list_str(source_str)\n    targets = clean_variable_list_str(target_str)\n    \n    attributes = {}\n    if attrs_str:\n        # Regex to find key=\"value\" or key='value' or key=bare_value\n        # Handles escaped quotes within quoted values.\n        attr_pairs = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*)\\\\s*=\\\\s*(\"[^\"\\\\\\\\]*(?:\\\\\\\\.[^\"\\\\\\\\]*)*\"|\\'[^\\'\\\\\\\\]*(?:\\\\\\\\.[^\\'\\\\\\\\]*)*\\'|[^{},\\\\s]+)', attrs_str)\n        for key_attr, value_attr in attr_pairs: # Renamed to avoid conflict\n            key_attr = key_attr.strip()\n            value_attr = value_attr.strip()\n            # Attempt to evaluate if it looks like a string literal, to unescape and convert\n            if (value_attr.startswith('\"') and value_attr.endswith('\"')) or \\\n               (value_attr.startswith(\"'\") and value_attr.endswith(\"'\")): # Corrected\n                try:\n                    value_attr = ast.literal_eval(value_attr)\n                except Exception: # Broad exception to catch any ast.literal_eval issues\n                    logger.warning(f\"Could not ast.literal_eval attribute value '{value_attr}' for key '{key_attr}'. Keeping as raw quoted string.\")\n            attributes[key_attr] = value_attr\n        \n    return {\"sources\": sources, \"operator\": operator.strip(), \"targets\": targets, \"attributes\": attributes}",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_parse_list_items_section",
        "type": "function",
        "start_line": 218,
        "end_line": 228,
        "code": "def _parse_list_items_section(section_content: str, item_parser: callable) -> list:\n    \"\"\"Parses lines in a section using a specific item_parser for each line.\"\"\"\n    items = []\n    for line in section_content.strip().split('\\n'):\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        parsed_item = item_parser(line)\n        if parsed_item:\n            items.append(parsed_item)\n    return items",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_parse_ontology_annotations",
        "type": "function",
        "start_line": 230,
        "end_line": 248,
        "code": "def _parse_ontology_annotations(section_content: str) -> dict:\n    \"\"\"Parses ActInfOntologyAnnotation section (key=value pairs).\"\"\"\n    annotations = {}\n    lines = section_content.strip().split('\\n')\n    for i, line in enumerate(lines):\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n        if '=' in line:\n            parts = line.split('=', 1)\n            key = parts[0].strip()\n            value = parts[1].strip()\n            if key and value:\n                annotations[key] = value\n            else:\n                logger.debug(f\"Malformed line {i+1} in ontology annotation: '{line}' - skipping.\")\n        else:\n            logger.debug(f\"Line {i+1} in ontology annotation does not contain '=': '{line}' - skipping.\")\n    return annotations",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_parse_model_parameters_section",
        "type": "function",
        "start_line": 250,
        "end_line": 281,
        "code": "def _parse_model_parameters_section(section_content: str) -> dict:\n    \"\"\"Parses ModelParameters section, converting list-like strings to Python lists.\"\"\"\n    data = {}\n    for line in section_content.strip().split('\\n'):\n        line_stripped_comments = line.split('#', 1)[0].strip() # Remove comments before parsing\n        if not line_stripped_comments: # Skip empty or comment-only lines\n            continue\n        \n        match = re.match(r\"([\\\\w_]+):\\\\s*(\\\\[.*?\\\\])\", line_stripped_comments) # Regex for key: [list]\n        if match:\n            key = match.group(1).strip()\n            value_str = match.group(2).strip()\n            try:\n                value = ast.literal_eval(value_str) # ast.literal_eval is safer\n                if isinstance(value, list):\n                    data[key] = value\n                    logger.debug(f\"  Parsed ModelParameter (as list): {key} = {value}\")\n                else:\n                    logger.warning(f\"  ModelParameter '{key}' value '{value_str}' did not evaluate to a list. Storing as string.\")\n                    data[key] = value_str \n            except (ValueError, SyntaxError, TypeError) as e: \n                logger.warning(f\"  Could not parse ModelParameter value for '{key}' ('{value_str}') as list: {e}. Storing as string.\")\n                data[key] = value_str \n        elif ':' in line_stripped_comments: # General key: value fallback\n            key_part, value_part = line_stripped_comments.split(\":\", 1)\n            key = key_part.strip()\n            value = value_part.strip() \n            data[key] = value # Store as string, could attempt _parse_matrix_string if values can be complex\n            logger.debug(f\"  Parsed ModelParameter (as string): {key} = {value}\")\n        else:\n            logger.debug(f\"  Skipping malformed line in ModelParameters: {line}\")\n    return data",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_parse_initial_parameterization_section",
        "type": "function",
        "start_line": 283,
        "end_line": 340,
        "code": "def _parse_initial_parameterization_section(section_content: str) -> dict:\n    \"\"\"\n    Parses the InitialParameterization section.\n    Keys are parameter names (e.g., A_m0, D_f1).\n    Values are GNN matrix strings which are parsed into Python objects (lists/tuples).\n    Handles multi-line values for a single parameter.\n    \"\"\"\n    data = {}\n    current_key: Optional[str] = None\n    current_value_lines: List[str] = []\n    \n    for line_raw in section_content.split('\\n'):\n        # A new parameter key is expected to be at the start of a line (ignoring whitespace)\n        # and not be part of a comment.\n        stripped_line_for_key_check = line_raw.lstrip()\n        \n        is_new_key_line = False\n        if not stripped_line_for_key_check.startswith('#') and '=' in stripped_line_for_key_check:\n            # Try to match \"key = value\" where key is simple alphanumeric.\n            # This assumes the first '=' on such a line is the delimiter.\n            match = re.match(r\"^([a-zA-Z0-9_]+)\\\\s*=\\\\s*(.*)\", stripped_line_for_key_check)\n            if match:\n                is_new_key_line = True\n        \n        if is_new_key_line and match: # Confirm match is not None\n            # If there was a previous key, process its collected value lines\n            if current_key is not None and current_value_lines:\n                val_str_collected = \"\\n\".join(current_value_lines).strip() # Strip whole block\n                if val_str_collected: # only parse if non-empty after stripping\n                    data[current_key] = _parse_matrix_string(val_str_collected)\n                else:\n                    data[current_key] = \"\" # Or some indicator of empty value if appropriate\n                    logger.debug(f\"Collected value for '{current_key}' was empty after stripping comments.\")\n            \n            current_key = match.group(1).strip()\n            initial_value_part = match.group(2) # This is the rest of the line after \"key =\"\n            current_value_lines = [initial_value_part.strip()] # Start new value collection, strip this first part\n        elif current_key is not None:\n            # This line is a continuation of the previous key's value\n            # We append the raw line to preserve its original content (including leading whitespace)\n            # as _parse_matrix_string will handle comment stripping for the whole block later.\n            current_value_lines.append(line_raw) \n        else:\n            # This line is not a new key and there's no current_key being processed.\n            # It might be a full-line comment or a malformed line at the start of the section.\n            if not line_raw.strip().startswith('#') and line_raw.strip():\n                 logger.debug(f\"Skipping orphan/malformed line at start/between params in InitialParameterization: '{line_raw}'\")\n    \n    # Process the last collected parameter after the loop ends\n    if current_key is not None and current_value_lines:\n        val_str_collected = \"\\n\".join(current_value_lines).strip()\n        if val_str_collected:\n            data[current_key] = _parse_matrix_string(val_str_collected)\n        else:\n            data[current_key] = \"\"\n            logger.debug(f\"Collected value for '{current_key}' (last param) was empty after stripping comments.\")\n            \n    return data",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      },
      {
        "name": "_gnn_model_to_dict",
        "type": "function",
        "start_line": 369,
        "end_line": 473,
        "code": "def _gnn_model_to_dict(gnn_file_path_str: str) -> dict:\n    \"\"\"\n    Parses a GNN Markdown file into a structured dictionary.\n    The GNN file is expected to have sections like ## SectionName.\n    \"\"\"\n    gnn_file_path = Path(gnn_file_path_str)\n    if not gnn_file_path.is_file():\n        logger.error(f\"GNN file not found: {gnn_file_path_str}\")\n        raise FileNotFoundError(f\"GNN file not found: {gnn_file_path_str}\")\n\n    try:\n        content = gnn_file_path.read_text(encoding='utf-8')\n    except Exception as e:\n        logger.error(f\"Error reading GNN file {gnn_file_path_str}: {e}\")\n        raise\n\n    model = {\n        \"file_path\": str(gnn_file_path),\n        \"name\": gnn_file_path.stem, \n        \"metadata\": {},\n        \"states\": [], \n        \"parameters\": {}, \n        \"initial_parameters\": {}, \n        \"observations\": [], \n        \"transitions\": [], \n        \"ontology_annotations\": {},\n        \"equations_text\": \"\",\n        \"time_info\": {},\n        \"footer_text\": \"\",\n        \"signature\": {},\n        \"raw_sections\": {}, \n        \"other_sections\": {} \n    }\n\n    section_regex = r\"^##\\s*([A-Za-z0-9_\\s]+?)\\s*$(.*?)(?=^##\\s*[A-Za-z0-9_\\s]+?\\s*$|\\Z)\"\n    \n    parsed_section_names = set()\n\n    for match in re.finditer(section_regex, content, re.MULTILINE | re.DOTALL):\n        section_name_original = match.group(1).strip()\n        section_content_raw = match.group(2).strip()\n        \n        model[\"raw_sections\"][section_name_original] = section_content_raw\n        parsed_section_names.add(section_name_original)\n\n        parser_found = False\n        for known_parser_name, parser_func in SECTION_PARSERS.items():\n            if section_name_original.lower() == known_parser_name.lower():\n                try:\n                    parsed_data = parser_func(section_content_raw)\n                    if known_parser_name == \"ModelName\":\n                        model[\"name\"] = parsed_data \n                    elif known_parser_name == \"ModelAnnotation\":\n                        model[\"metadata\"][\"description\"] = parsed_data\n                    elif known_parser_name == \"StateSpaceBlock\":\n                        model[\"states\"] = parsed_data \n                    elif known_parser_name == \"ParameterBlock\": \n                        model[\"parameters\"] = parsed_data\n                    elif known_parser_name == \"Connections\" or known_parser_name == \"TransitionBlock\" or known_parser_name == \"transitions\":\n                        model[\"transitions\"].extend(parsed_data) \n                    elif known_parser_name == \"ActInfOntologyAnnotation\":\n                        model[\"ontology_annotations\"] = parsed_data\n                    elif known_parser_name == \"InitialParameterization\":\n                        model[\"initial_parameters\"] = parsed_data # 'parsed_data' is the direct result from _parse_initial_parameterization_section\n                        \n                        # Store the raw content for reference.\n                        model[\"raw_sections\"][\"InitialParameterization_raw_content\"] = section_content_raw\n                        # Optionally, if wanting to trace the output of the section parser specifically:\n                        # model[\"raw_sections\"][\"InitialParameterization_parsed_by_section_parser\"] = parsed_data\n                    elif known_parser_name == \"Time\":\n                        model[\"time_info\"] = parsed_data\n                        if \"type\" in parsed_data: \n                             model[\"metadata\"][\"time_type\"] = parsed_data[\"type\"]\n                    elif known_parser_name == \"ModelParameters\":\n                        model[\"ModelParameters\"] = parsed_data # Store the whole block\n                        # And also hoist specific known params to top level of model dict\n                        if isinstance(parsed_data, dict):\n                            for mp_key, mp_val in parsed_data.items():\n                                if mp_key in [\"num_hidden_states_factors\", \"num_obs_modalities\", \"num_control_factors\"]:\n                                    model[mp_key] = mp_val\n                    else: \n                        model[known_parser_name.lower().replace(\" \", \"_\")] = parsed_data\n                except Exception as e:\n                    logger.warning(f\"Error parsing section '{section_name_original}' with parser '{known_parser_name}': {e}\")\n                    model[\"other_sections\"][section_name_original] = section_content_raw\n                parser_found = True\n                break\n        \n        if not parser_found:\n            model[\"other_sections\"][section_name_original] = section_content_raw\n\n    # Post-processing to extract dimensions if ModelParameters didn't fully provide them\n    if not model.get(\"num_obs_modalities\"):\n        obs_modality_dims: List[Tuple[int, int]] = []\n        # ... (rest of dimension inference logic, if kept, would go here)\n        # For brevity, assuming ModelParameters is the primary source now\n    if not model.get(\"num_hidden_states_factors\"):\n        hidden_state_factor_dims_inferred: List[Tuple[int, int]] = []\n        # ... \n        if hidden_state_factor_dims_inferred: \n            model[\"num_hidden_states_factors\"] = [dim for _, dim in sorted(hidden_state_factor_dims_inferred)]\n    # ...\n\n    logger.debug(f\"_gnn_model_to_dict: Final model before return for {gnn_file_path_str}\")\n    return model",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/format_exporters.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/graph_exporters.py": [
      {
        "name": "_build_networkx_graph",
        "type": "function",
        "start_line": 16,
        "end_line": 50,
        "code": "def _build_networkx_graph(gnn_model: dict) -> 'nx.DiGraph | None':\n    \"\"\"Helper to build a NetworkX graph from the GNN model.\"\"\"\n    if not HAS_NETWORKX:\n        logger.error(\"NetworkX library is not available. Cannot build graph.\")\n        return None\n\n    graph = nx.DiGraph()\n    model_name = gnn_model.get('name', gnn_model.get('metadata', {}).get('name', 'GNN_Model'))\n    graph.graph['name'] = model_name\n\n    # Add states as nodes\n    for state_data in gnn_model.get('states', []):\n        node_id = state_data.get('id')\n        if node_id:\n            attributes = {k: v for k, v in state_data.items() if k != 'id'}\n            graph.add_node(node_id, **attributes)\n\n    # Add observations as nodes (if distinct from states)\n    for obs_data in gnn_model.get('observations', []):\n        node_id = obs_data.get('id')\n        if node_id and not graph.has_node(node_id): \n            attributes = {k: v for k, v in obs_data.items() if k != 'id'}\n            graph.add_node(node_id, **attributes)\n\n    # Add transitions as edges\n    for trans_data in gnn_model.get('transitions', []):\n        source = trans_data.get('source')\n        target = trans_data.get('target')\n        if source and target:\n            attributes = trans_data.get('attributes', {})\n            if not graph.has_node(source): graph.add_node(source, label=source)\n            if not graph.has_node(target): graph.add_node(target, label=target)\n            graph.add_edge(source, target, **attributes)\n            \n    return graph",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/graph_exporters.py"
      },
      {
        "name": "export_to_gexf",
        "type": "function",
        "start_line": 52,
        "end_line": 63,
        "code": "def export_to_gexf(gnn_model: dict, output_file_path: str):\n    \"\"\"Exports the GNN model graph to a GEXF file.\"\"\"\n    if not HAS_NETWORKX:\n        raise ImportError(\"NetworkX not available, GEXF export failed.\")\n    graph = _build_networkx_graph(gnn_model)\n    if graph is None: return # Error logged in _build_networkx_graph\n    try:\n        nx.write_gexf(graph, output_file_path)\n        logger.debug(f\"Successfully exported GNN model to GEXF: {output_file_path}\")\n    except Exception as e:\n        logger.error(f\"Failed to export GNN model to GEXF {output_file_path}: {e}\", exc_info=True)\n        raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/graph_exporters.py"
      },
      {
        "name": "export_to_graphml",
        "type": "function",
        "start_line": 65,
        "end_line": 76,
        "code": "def export_to_graphml(gnn_model: dict, output_file_path: str):\n    \"\"\"Exports the GNN model graph to a GraphML file.\"\"\"\n    if not HAS_NETWORKX:\n        raise ImportError(\"NetworkX not available, GraphML export failed.\")\n    graph = _build_networkx_graph(gnn_model)\n    if graph is None: return\n    try:\n        nx.write_graphml(graph, output_file_path)\n        logger.debug(f\"Successfully exported GNN model to GraphML: {output_file_path}\")\n    except Exception as e:\n        logger.error(f\"Failed to export GNN model to GraphML {output_file_path}: {e}\", exc_info=True)\n        raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/graph_exporters.py"
      },
      {
        "name": "export_to_json_adjacency_list",
        "type": "function",
        "start_line": 78,
        "end_line": 93,
        "code": "def export_to_json_adjacency_list(gnn_model: dict, output_file_path: str):\n    \"\"\"Exports the GNN model graph to a JSON adjacency list format.\"\"\"\n    if not HAS_NETWORKX:\n        raise ImportError(\"NetworkX not available, JSON adjacency list export failed.\")\n    graph = _build_networkx_graph(gnn_model)\n    if graph is None: return\n    try:\n        # Need to import json here as it's not a top-level import for this specific module\n        import json \n        adj_data = nx.readwrite.json_graph.adjacency_data(graph)\n        with open(output_file_path, 'w', encoding='utf-8') as f:\n            json.dump(adj_data, f, indent=4, ensure_ascii=False)\n        logger.debug(f\"Successfully exported GNN model to JSON adjacency list: {output_file_path}\")\n    except Exception as e:\n        logger.error(f\"Failed to export GNN model to JSON adjacency list {output_file_path}: {e}\", exc_info=True)\n        raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/export/graph_exporters.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/utils/logging_utils.py": [
      {
        "name": "setup_standalone_logging",
        "type": "function",
        "start_line": 6,
        "end_line": 45,
        "code": "def setup_standalone_logging(level=logging.INFO, logger_name=None):\n    '''\n    Configures basic logging for standalone script execution.\n\n    This function should be called only if no root handlers are already configured,\n    typically within an 'if __name__ == \"__main__\":' block of a script that\n    can also be run as part of a larger pipeline (which would configure logging).\n\n    Args:\n        level: The logging level to set (e.g., logging.INFO, logging.DEBUG).\n        logger_name: Optional. If provided, also get and set the level for this specific logger.\n                     Otherwise, only basicConfig is called for the root logger.\n    '''\n    if not logging.getLogger().hasHandlers():\n        logging.basicConfig(\n            level=level,\n            format=DEFAULT_LOG_FORMAT,\n            datefmt=DEFAULT_DATE_FORMAT,\n            stream=sys.stdout\n        )\n        # Get root logger to log that basicConfig was called by this utility\n        # This helps in tracing how logging was set up.\n        # Using a more specific logger name here to avoid confusion with the script's own __name__ logger\n        # if logger_name is the same as __name__ when __name__ is '__main__'.\n        config_logger_name = \"StandaloneLoggingSetup\"\n        if logger_name:\n            # e.g. MyScript.__main__.StandaloneLoggingSetup\n            config_logger_name = f\"{logger_name}.StandaloneLoggingSetup\"\n        \n        setup_logger = logging.getLogger(config_logger_name)\n        setup_logger.info(f\"Basic logging configured by setup_standalone_logging at level {logging.getLevelName(level)}.\")\n\n    # If a specific logger name is given, also set its level.\n    # This is useful if the script's main logger (e.g., logging.getLogger(__name__))\n    # needs its level set independently after basicConfig (or if basicConfig was skipped\n    # because handlers already existed).\n    if logger_name:\n        script_logger = logging.getLogger(logger_name)\n        script_logger.setLevel(level)\n        script_logger.debug(f\"Logger '{logger_name}' level set to {logging.getLevelName(level)} by setup_standalone_logging.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/utils/logging_utils.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/utils/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/utils.py": [
      {
        "name": "ensure_directory",
        "type": "function",
        "start_line": 9,
        "end_line": 21,
        "code": "def ensure_directory(directory: str or Path) -> Path:\n    \"\"\"\n    Ensure a directory exists, creating it if necessary.\n    \n    Args:\n        directory: Directory path (string or Path object)\n        \n    Returns:\n        Path object for the directory\n    \"\"\"\n    path = Path(directory)\n    path.mkdir(parents=True, exist_ok=True)\n    return path",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/utils.py"
      },
      {
        "name": "find_gnn_files",
        "type": "function",
        "start_line": 24,
        "end_line": 40,
        "code": "def find_gnn_files(directory: str or Path, recursive: bool = False) -> List[Path]:\n    \"\"\"\n    Find all GNN (.md) files in a directory.\n    \n    Args:\n        directory: Directory to search\n        recursive: Whether to search recursively\n        \n    Returns:\n        List of Path objects for GNN files\n    \"\"\"\n    path = Path(directory)\n    if not path.exists():\n        return []\n        \n    pattern = \"**/*.md\" if recursive else \"*.md\"\n    return list(path.glob(pattern))",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/utils.py"
      },
      {
        "name": "get_output_paths",
        "type": "function",
        "start_line": 43,
        "end_line": 62,
        "code": "def get_output_paths(base_output_dir: str or Path) -> Dict[str, Path]:\n    \"\"\"\n    Get standard output paths for the pipeline.\n    \n    Args:\n        base_output_dir: Base output directory\n        \n    Returns:\n        Dictionary of named output paths\n    \"\"\"\n    base_dir = ensure_directory(base_output_dir)\n    \n    # Create standard subdirectories\n    paths = {\n        \"base\": base_dir,\n        \"type_check\": ensure_directory(base_dir / \"gnn_type_check\"),\n        \"visualization\": ensure_directory(base_dir / \"gnn_examples_visualization\")\n    }\n    \n    return paths",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/utils.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/mcp.py": [
      {
        "name": "ensure_directory_exists_mcp",
        "type": "function",
        "start_line": 19,
        "end_line": 41,
        "code": "def ensure_directory_exists_mcp(directory_path: str) -> Dict[str, Any]:\n    \"\"\"\n    Ensure a directory exists, creating it if necessary. Exposed via MCP.\n    \n    Args:\n        directory_path: Directory path to ensure existence of.\n        \n    Returns:\n        Dictionary with operation status and path.\n    \"\"\"\n    try:\n        path_obj = ensure_directory(directory_path)\n        return {\n            \"success\": True,\n            \"path\": str(path_obj),\n            \"created\": not Path(directory_path).exists() # Check if it was created now or existed before\n        }\n    except Exception as e:\n        logger.error(f\"Error in ensure_directory_exists_mcp for {directory_path}: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/mcp.py"
      },
      {
        "name": "find_project_gnn_files_mcp",
        "type": "function",
        "start_line": 43,
        "end_line": 66,
        "code": "def find_project_gnn_files_mcp(search_directory: str, recursive: bool = False) -> Dict[str, Any]:\n    \"\"\"\n    Find all GNN (.md) files in a directory. Exposed via MCP.\n    \n    Args:\n        search_directory: Directory to search.\n        recursive: Whether to search recursively (default: False).\n        \n    Returns:\n        Dictionary with list of found file paths or an error.\n    \"\"\"\n    try:\n        files = find_gnn_files(search_directory, recursive)\n        return {\n            \"success\": True,\n            \"files\": [str(f) for f in files],\n            \"count\": len(files)\n        }\n    except Exception as e:\n        logger.error(f\"Error in find_project_gnn_files_mcp for {search_directory}: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/mcp.py"
      },
      {
        "name": "get_standard_output_paths_mcp",
        "type": "function",
        "start_line": 68,
        "end_line": 89,
        "code": "def get_standard_output_paths_mcp(base_output_directory: str) -> Dict[str, Any]:\n    \"\"\"\n    Get standard output paths for the pipeline. Exposed via MCP.\n    \n    Args:\n        base_output_directory: Base output directory.\n        \n    Returns:\n        Dictionary of named output paths or an error.\n    \"\"\"\n    try:\n        paths = get_output_paths(base_output_directory)\n        return {\n            \"success\": True,\n            \"paths\": {name: str(p) for name, p in paths.items()}\n        }\n    except Exception as e:\n        logger.error(f\"Error in get_standard_output_paths_mcp for {base_output_directory}: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/mcp.py"
      },
      {
        "name": "register_tools",
        "type": "function",
        "start_line": 92,
        "end_line": 123,
        "code": "def register_tools(mcp_instance): # Changed 'mcp' to 'mcp_instance' for clarity\n    \"\"\"Register setup utility tools with the MCP.\"\"\"\n    \n    mcp_instance.register_tool(\n        \"ensure_directory_exists\",\n        ensure_directory_exists_mcp,\n        {\n            \"directory_path\": {\"type\": \"string\", \"description\": \"Path of the directory to create if it doesn\\'t exist.\"}\n        },\n        \"Ensures a directory exists, creating it if necessary. Returns the absolute path.\"\n    )\n    \n    mcp_instance.register_tool(\n        \"find_project_gnn_files\",\n        find_project_gnn_files_mcp,\n        {\n            \"search_directory\": {\"type\": \"string\", \"description\": \"The directory to search for GNN (.md) files.\"},\n            \"recursive\": {\"type\": \"boolean\", \"description\": \"Set to true to search recursively. Defaults to false.\", \"optional\": True}\n        },\n        \"Finds all GNN (.md) files in a specified directory within the project.\"\n    )\n    \n    mcp_instance.register_tool(\n        \"get_standard_output_paths\",\n        get_standard_output_paths_mcp,\n        {\n            \"base_output_directory\": {\"type\": \"string\", \"description\": \"The base directory where output subdirectories will be managed.\"}\n        },\n        \"Gets a dictionary of standard output directory paths (e.g., for type_check, visualization), creating them if needed.\"\n    )\n    \n    logger.info(\"Setup module MCP tools registered.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/setup.py": [
      {
        "name": "run_command",
        "type": "function",
        "start_line": 40,
        "end_line": 82,
        "code": "def run_command(command: list[str], cwd: Path = PROJECT_ROOT, check: bool = True, verbose: bool = False) -> None:\n    \"\"\"\n    Runs a shell command and logs its output based on verbosity.\n\n    Args:\n        command: The command and its arguments as a list of strings.\n        cwd: The current working directory for the command.\n        check: If True, raises CalledProcessError if the command returns a non-zero exit code.\n        verbose: If True, enables detailed (DEBUG level) logging for this setup process.\n    \"\"\"\n    command_str_list = [str(c) for c in command]\n    if verbose:\n        logger.debug(f\"Running command: '{' '.join(command_str_list)}' in {cwd}\")\n    else:\n        logger.debug(f\"Running command: '{command_str_list[0]} ...' in {cwd}\")\n    \n    try:\n        process = subprocess.run(command_str_list, cwd=cwd, check=check, capture_output=True, text=True, errors='replace')\n        if verbose:\n            if process.stdout:\n                logger.debug(f\"Stdout:\\n{process.stdout.strip()}\")\n            if process.stderr:\n                logger.debug(f\"Stderr:\\n{process.stderr.strip()}\")\n        if not check and process.returncode != 0:\n            logger.warning(f\"Command returned non-zero exit code: {process.returncode}\")\n            if process.stdout:\n                logger.warning(f\"Stdout:\\n{process.stdout.strip()}\")\n            if process.stderr:\n                logger.warning(f\"Stderr:\\n{process.stderr.strip()}\")\n    except subprocess.CalledProcessError as e:\n        logger.error(f\"Error running command: '{' '.join(e.cmd)}'\")\n        logger.error(f\"Return code: {e.returncode}\")\n        if e.stdout:\n            logger.error(f\"Stdout:\\n{e.stdout.strip()}\")\n        if e.stderr:\n            logger.error(f\"Stderr:\\n{e.stderr.strip()}\")\n        if check:\n            raise\n    except FileNotFoundError as e:\n        logger.error(f\"Error: Command not found - {command_str_list[0]}. Ensure it is installed and in PATH.\")\n        logger.error(f\"Details: {e}\")\n        if check:\n            raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/setup.py"
      },
      {
        "name": "create_virtual_environment",
        "type": "function",
        "start_line": 84,
        "end_line": 100,
        "code": "def create_virtual_environment(verbose: bool = False) -> None:\n    \"\"\"\n    Creates a virtual environment if it doesn't already exist.\n\n    Args:\n        verbose: If True, enables detailed (DEBUG level) logging for this setup process.\n    \"\"\"\n    if not VENV_PATH.exists():\n        logger.info(f\"Creating virtual environment in {VENV_PATH}...\")\n        try:\n            run_command([sys.executable, \"-m\", \"venv\", VENV_DIR], cwd=PROJECT_ROOT, verbose=verbose)\n            logger.info(f\"Virtual environment created successfully at {VENV_PATH}\")\n        except Exception as e:\n            logger.error(f\"Failed to create virtual environment: {e}\", exc_info=verbose)\n            raise\n    else:\n        logger.info(f\"Virtual environment already exists at {VENV_PATH}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/setup.py"
      },
      {
        "name": "install_dependencies",
        "type": "function",
        "start_line": 102,
        "end_line": 138,
        "code": "def install_dependencies(verbose: bool = False) -> None:\n    \"\"\"\n    Installs or updates dependencies from the requirements.txt file\n    into the virtual environment.\n\n    Args:\n        verbose: If True, enables detailed (DEBUG level) logging for this setup process.\n    \"\"\"\n    if not REQUIREMENTS_PATH.exists():\n        logger.warning(f\"{REQUIREMENTS_PATH} not found. Skipping dependency installation from this file.\")\n        return\n\n    logger.info(f\"Attempting to install 'inferactively-pymdp' individually into {VENV_PATH}...\")\n    try:\n        if not VENV_PIP.exists():\n            logger.error(f\"Pip executable not found at {VENV_PIP}. Cannot install dependencies.\")\n            raise FileNotFoundError(f\"Pip not found at {VENV_PIP}\")\n        \n        run_command([str(VENV_PIP), \"install\", \"inferactively-pymdp\"], cwd=PROJECT_ROOT, check=False, verbose=verbose)\n        logger.debug(\"Individual installation attempt for 'inferactively-pymdp' completed.\")\n    except Exception as e:\n        logger.warning(f\"An error occurred during the individual installation of 'inferactively-pymdp': {e}\", exc_info=verbose)\n\n    logger.info(f\"Installing/updating dependencies from {REQUIREMENTS_PATH} into {VENV_PATH}...\")\n    try:\n        if not VENV_PIP.exists():\n            logger.error(f\"Pip executable not found at {VENV_PIP}. Cannot install dependencies.\")\n            raise FileNotFoundError(f\"Pip not found at {VENV_PIP}\")\n\n        run_command([str(VENV_PIP), \"install\", \"-r\", str(REQUIREMENTS_PATH)], cwd=PROJECT_ROOT, verbose=verbose)\n        logger.info(\"Dependencies from requirements.txt installed successfully.\")\n    except subprocess.CalledProcessError:\n        logger.error(\"Failed to install dependencies from requirements.txt.\")\n        raise\n    except Exception as e:\n        logger.error(f\"An unexpected error occurred during dependency installation from requirements.txt: {e}\", exc_info=verbose)\n        raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/setup.py"
      },
      {
        "name": "perform_full_setup",
        "type": "function",
        "start_line": 141,
        "end_line": 183,
        "code": "def perform_full_setup(verbose: bool = False):\n    \"\"\"\n    Performs the full setup: creates virtual environment and installs dependencies.\n    This function is intended to be called by other scripts.\n\n    Args:\n        verbose (bool): If True, enables detailed (DEBUG level) logging for this setup process.\n    \"\"\"\n    \n    # Configure logger for this module based on verbosity passed from caller\n    # This assumes that the caller (e.g., 2_setup.py) has already configured the root logger if necessary.\n    # We are setting the level for THIS logger instance.\n    log_level_to_set = logging.DEBUG if verbose else logging.INFO\n    logger.setLevel(log_level_to_set)\n    # If no handlers are configured on the root logger (e.g. running this script directly without a pre-configured root logger),\n    # add a basic one for this logger to output to console.\n    if not logging.getLogger().hasHandlers() and not logger.hasHandlers():\n        console_handler = logging.StreamHandler(sys.stdout)\n        console_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n        logger.addHandler(console_handler)\n        logger.propagate = False # Avoid double-logging if root also gets configured later\n\n    logger.info(f\"Starting environment setup (venv and dependencies) targeting {PROJECT_ROOT}...\")\n    logger.debug(f\"Verbose mode: {verbose}\")\n    logger.debug(f\"Project root: {PROJECT_ROOT}\")\n    logger.debug(f\"Venv path: {VENV_PATH}\")\n    logger.debug(f\"Requirements path: {REQUIREMENTS_PATH}\")\n    logger.debug(f\"Venv Python: {VENV_PYTHON}\")\n    logger.debug(f\"Venv Pip: {VENV_PIP}\")\n\n    try:\n        create_virtual_environment(verbose=verbose)\n        install_dependencies(verbose=verbose)\n        logger.info(f\"Environment setup completed successfully for {PROJECT_ROOT}.\")\n        logger.info(f\"To activate the virtual environment, navigate to {PROJECT_ROOT} and run:\")\n        if sys.platform == \"win32\":\n            logger.info(f\"  .\\\\{VENV_DIR}\\\\Scripts\\\\activate\")\n        else:\n            logger.info(f\"  source {VENV_DIR}/bin/activate\")\n        return 0 # Success\n    except Exception as e:\n        logger.error(f\"Environment setup failed: {e}\", exc_info=verbose)\n        return 1 # Failure",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/setup.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/setup/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn/mcp.py": [
      {
        "name": "get_gnn_documentation",
        "type": "function",
        "start_line": 15,
        "end_line": 62,
        "code": "def get_gnn_documentation(doc_name: Literal[\"file_structure\", \"punctuation\"]) -> Dict[str, Any]:\n    \"\"\"\n    Retrieve content of a GNN documentation file.\n    \n    Args:\n        doc_name: Name of the GNN document to retrieve. \n                  Allowed values: \"file_structure\", \"punctuation\".\n        \n    Returns:\n        Dictionary containing document content or an error.\n    \"\"\"\n    \n    base_path = Path(__file__).parent\n    \n    if doc_name == \"file_structure\":\n        file_to_read = base_path / \"gnn_file_structure.md\"\n    elif doc_name == \"punctuation\":\n        file_to_read = base_path / \"gnn_punctuation.md\"\n    else:\n        error_msg = f\"Invalid document name: {doc_name}. Allowed: 'file_structure', 'punctuation'.\"\n        logger.error(f\"get_gnn_documentation: {error_msg}\")\n        return {\n            \"success\": False,\n            \"error\": error_msg\n        }\n        \n    if not file_to_read.exists():\n        error_msg = f\"Documentation file not found: {file_to_read.name} (expected at {file_to_read.resolve()})\"\n        logger.error(f\"get_gnn_documentation: {error_msg}\")\n        return {\n            \"success\": False,\n            \"error\": error_msg\n        }\n        \n    try:\n        content = file_to_read.read_text()\n        return {\n            \"success\": True,\n            \"doc_name\": doc_name,\n            \"content\": content\n        }\n    except Exception as e:\n        error_msg = f\"Error reading {file_to_read.name}: {str(e)}\"\n        logger.error(f\"get_gnn_documentation: {error_msg}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": error_msg\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn/mcp.py"
      },
      {
        "name": "_retrieve_gnn_doc_resource",
        "type": "function",
        "start_line": 65,
        "end_line": 90,
        "code": "def _retrieve_gnn_doc_resource(uri: str) -> Dict[str, Any]:\n    \"\"\"\n    Retrieve GNN documentation resource by URI.\n    Example URI: gnn://documentation/file_structure\n    \"\"\"\n    if not uri.startswith(\"gnn://documentation/\"):\n        error_msg = f\"Invalid URI format for GNN documentation: {uri}\"\n        logger.error(f\"_retrieve_gnn_doc_resource: {error_msg}\")\n        raise ValueError(error_msg)\n    \n    doc_name_part = uri.replace(\"gnn://documentation/\", \"\")\n    \n    if doc_name_part not in [\"file_structure\", \"punctuation\"]:\n        error_msg = f\"Invalid document name in URI: {doc_name_part}\"\n        logger.error(f\"_retrieve_gnn_doc_resource: {error_msg}\")\n        raise ValueError(error_msg)\n        \n    # Type casting for Literal\n    doc_name_literal = doc_name_part # type: Literal[\"file_structure\", \"punctuation\"]\n    \n    result = get_gnn_documentation(doc_name=doc_name_literal)\n    if not result[\"success\"]:\n        error_msg = f\"Failed to retrieve document {doc_name_part}: {result.get('error', 'Unknown error')}\"\n        logger.error(f\"_retrieve_gnn_doc_resource: {error_msg}\")\n        raise ValueError(error_msg)\n    return result",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn/mcp.py"
      },
      {
        "name": "register_tools",
        "type": "function",
        "start_line": 94,
        "end_line": 115,
        "code": "def register_tools(mcp_instance): # Changed 'mcp' to 'mcp_instance' for clarity\n    \"\"\"Register GNN documentation tools and resources with the MCP.\"\"\"\n    \n    mcp_instance.register_tool(\n        \"get_gnn_documentation\",\n        get_gnn_documentation,\n        {\n            \"doc_name\": {\n                \"type\": \"string\", \n                \"description\": \"Name of the GNN document (e.g., 'file_structure', 'punctuation')\",\n                \"enum\": [\"file_structure\", \"punctuation\"] # Added enum for better schema\n            }\n        },\n        \"Retrieve the content of a GNN core documentation file (e.g., syntax, file structure).\"\n    )\n    \n    mcp_instance.register_resource(\n        \"gnn://documentation/{doc_name}\", # Using a more specific URI template\n        _retrieve_gnn_doc_resource,\n        \"Access GNN core documentation files like syntax and file structure definitions.\"\n    )\n    logger.info(\"GNN documentation module MCP tools and resources registered.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py": [
      {
        "name": "print_json",
        "type": "function",
        "start_line": 29,
        "end_line": 31,
        "code": "def print_json(data):\n    \"\"\"Prints JSON data with indentation.\"\"\"\n    print(json.dumps(data, indent=2, sort_keys=True))",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "read_server_output",
        "type": "function",
        "start_line": 33,
        "end_line": 38,
        "code": "def read_server_output(process, output_queue, error_queue):\n    \"\"\"Reads stdout from the server process and puts lines into a queue.\"\"\"\n    if process.stdout:\n        for line in iter(process.stdout.readline, ''):\n            output_queue.put(line)\n        process.stdout.close()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "read_server_errors",
        "type": "function",
        "start_line": 40,
        "end_line": 45,
        "code": "def read_server_errors(process, error_queue):\n    \"\"\"Reads stderr from the server process and puts lines into a queue.\"\"\"\n    if process.stderr:\n        for line in iter(process.stderr.readline, ''):\n            error_queue.put(line)\n        process.stderr.close()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "StdioMCPClient",
        "type": "class",
        "start_line": 47,
        "end_line": 141,
        "code": "class StdioMCPClient:\n    \"\"\"A simple client to interact with an MCP server over stdio.\"\"\"\n    def __init__(self, process):\n        self.process = process\n        self.request_id_counter = 1\n        self.response_timeout = 10 # seconds\n        self.server_stdout_queue = queue.Queue()\n        self.server_stderr_queue = queue.Queue()\n\n        self.stdout_thread = threading.Thread(\n            target=read_server_output, \n            args=(self.process, self.server_stdout_queue)\n        )\n        self.stderr_thread = threading.Thread(\n            target=read_server_errors,\n            args=(self.process, self.server_stderr_queue)\n        )\n        self.stdout_thread.daemon = True\n        self.stderr_thread.daemon = True\n        self.stdout_thread.start()\n        self.stderr_thread.start()\n\n    def _send_request(self, method: str, params: dict = None) -> dict:\n        if not self.process.stdin:\n            raise IOError(\"Server stdin is not available.\")\n\n        request_id = f\"inspector-{self.request_id_counter}\"\n        self.request_id_counter += 1\n        \n        rpc_request = {\n            \"jsonrpc\": \"2.0\",\n            \"method\": method,\n            \"id\": request_id\n        }\n        if params is not None:\n            rpc_request[\"params\"] = params\n\n        request_str = json.dumps(rpc_request)\n        print(f\"INSPECTOR -> SERVER: {request_str}\", file=sys.stderr)\n        self.process.stdin.write(request_str + '\\n')\n        self.process.stdin.flush()\n\n        # Wait for response\n        start_time = time.time()\n        while True:\n            if time.time() - start_time > self.response_timeout:\n                raise TimeoutError(f\"Timeout waiting for response to request ID {request_id}\")\n            \n            try:\n                # Check stderr first for server-side issues unrelated to this request\n                while not self.server_stderr_queue.empty():\n                    err_line = self.server_stderr_queue.get_nowait().strip()\n                    if err_line: # Only print if it's not an empty line\n                        print(f\"SERVER (stderr): {err_line}\", file=sys.stderr)\n\n                line = self.server_stdout_queue.get(timeout=0.1) # Check queue with timeout\n                print(f\"SERVER -> INSPECTOR: {line.strip()}\", file=sys.stderr)\n                response = json.loads(line)\n                if response.get(\"id\") == request_id:\n                    return response\n                else:\n                    # Might be a notification or unrelated message, log it and continue\n                    print(f\"INSPECTOR (info): Received unrelated message or notification: {response}\", file=sys.stderr)\n            except queue.Empty:\n                if self.process.poll() is not None: # Server process terminated\n                    raise ConnectionError(\"Server process terminated unexpectedly.\")\n                continue # Timeout, try again\n            except json.JSONDecodeError as e:\n                print(f\"INSPECTOR (error): Could not decode JSON from server: {line.strip()} - {e}\", file=sys.stderr)\n                # If it's a fatal error, we might not get a response with our ID.\n                # This could be part of a multi-line error dump from the server.\n                # For now, just log and continue waiting for our specific response ID.\n            except Exception as e:\n                print(f\"INSPECTOR (error): Unexpected error reading server response: {e}\", file=sys.stderr)\n                raise # Re-raise for now\n\n    def get_capabilities(self) -> dict:\n        # MCP standard often uses \"mcp/discover\" or similar, \n        # but GNN server's meta_mcp.py registers \"get_mcp_server_capabilities\"\n        return self._send_request(method=\"get_mcp_server_capabilities\")\n\n    def execute_tool(self, tool_name: str, tool_params: dict) -> dict:\n        # GNN MCP server expects tool name as method and params as params object\n        return self._send_request(method=tool_name, params=tool_params)\n\n    def get_resource(self, uri: str) -> dict:\n        # This might require a specific method name if not using raw URI as method\n        # For now, assuming a hypothetical \"resource/get\" method, or that resource URIs are tools.\n        # The GNN `cli.py` 'resource' command implies resource URIs are distinct.\n        # Let's assume a tool like `meta.get_resource_content` for now, or adjust if GNN MCP has a specific one.\n        # Based on GNN MCP spec, there isn't a generic \"get resource\" tool.\n        # Resources are typically outputs of other tools. This function might be less useful directly.\n        # For now, let's make it try to call the URI as if it were a tool (unlikely to work).\n        print(f\"INSPECTOR (warning): Direct resource GET not well-defined in GNN MCP. Trying URI as method.\", file=sys.stderr)\n        return self._send_request(method=uri) # This is a guess",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 49,
        "end_line": 67,
        "code": "def __init__(self, process):\n        self.process = process\n        self.request_id_counter = 1\n        self.response_timeout = 10 # seconds\n        self.server_stdout_queue = queue.Queue()\n        self.server_stderr_queue = queue.Queue()\n\n        self.stdout_thread = threading.Thread(\n            target=read_server_output, \n            args=(self.process, self.server_stdout_queue)\n        )\n        self.stderr_thread = threading.Thread(\n            target=read_server_errors,\n            args=(self.process, self.server_stderr_queue)\n        )\n        self.stdout_thread.daemon = True\n        self.stderr_thread.daemon = True\n        self.stdout_thread.start()\n        self.stderr_thread.start()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "_send_request",
        "type": "method",
        "start_line": 69,
        "end_line": 121,
        "code": "def _send_request(self, method: str, params: dict = None) -> dict:\n        if not self.process.stdin:\n            raise IOError(\"Server stdin is not available.\")\n\n        request_id = f\"inspector-{self.request_id_counter}\"\n        self.request_id_counter += 1\n        \n        rpc_request = {\n            \"jsonrpc\": \"2.0\",\n            \"method\": method,\n            \"id\": request_id\n        }\n        if params is not None:\n            rpc_request[\"params\"] = params\n\n        request_str = json.dumps(rpc_request)\n        print(f\"INSPECTOR -> SERVER: {request_str}\", file=sys.stderr)\n        self.process.stdin.write(request_str + '\\n')\n        self.process.stdin.flush()\n\n        # Wait for response\n        start_time = time.time()\n        while True:\n            if time.time() - start_time > self.response_timeout:\n                raise TimeoutError(f\"Timeout waiting for response to request ID {request_id}\")\n            \n            try:\n                # Check stderr first for server-side issues unrelated to this request\n                while not self.server_stderr_queue.empty():\n                    err_line = self.server_stderr_queue.get_nowait().strip()\n                    if err_line: # Only print if it's not an empty line\n                        print(f\"SERVER (stderr): {err_line}\", file=sys.stderr)\n\n                line = self.server_stdout_queue.get(timeout=0.1) # Check queue with timeout\n                print(f\"SERVER -> INSPECTOR: {line.strip()}\", file=sys.stderr)\n                response = json.loads(line)\n                if response.get(\"id\") == request_id:\n                    return response\n                else:\n                    # Might be a notification or unrelated message, log it and continue\n                    print(f\"INSPECTOR (info): Received unrelated message or notification: {response}\", file=sys.stderr)\n            except queue.Empty:\n                if self.process.poll() is not None: # Server process terminated\n                    raise ConnectionError(\"Server process terminated unexpectedly.\")\n                continue # Timeout, try again\n            except json.JSONDecodeError as e:\n                print(f\"INSPECTOR (error): Could not decode JSON from server: {line.strip()} - {e}\", file=sys.stderr)\n                # If it's a fatal error, we might not get a response with our ID.\n                # This could be part of a multi-line error dump from the server.\n                # For now, just log and continue waiting for our specific response ID.\n            except Exception as e:\n                print(f\"INSPECTOR (error): Unexpected error reading server response: {e}\", file=sys.stderr)\n                raise # Re-raise for now",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "get_capabilities",
        "type": "method",
        "start_line": 123,
        "end_line": 126,
        "code": "def get_capabilities(self) -> dict:\n        # MCP standard often uses \"mcp/discover\" or similar, \n        # but GNN server's meta_mcp.py registers \"get_mcp_server_capabilities\"\n        return self._send_request(method=\"get_mcp_server_capabilities\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "execute_tool",
        "type": "method",
        "start_line": 128,
        "end_line": 130,
        "code": "def execute_tool(self, tool_name: str, tool_params: dict) -> dict:\n        # GNN MCP server expects tool name as method and params as params object\n        return self._send_request(method=tool_name, params=tool_params)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "get_resource",
        "type": "method",
        "start_line": 132,
        "end_line": 141,
        "code": "def get_resource(self, uri: str) -> dict:\n        # This might require a specific method name if not using raw URI as method\n        # For now, assuming a hypothetical \"resource/get\" method, or that resource URIs are tools.\n        # The GNN `cli.py` 'resource' command implies resource URIs are distinct.\n        # Let's assume a tool like `meta.get_resource_content` for now, or adjust if GNN MCP has a specific one.\n        # Based on GNN MCP spec, there isn't a generic \"get resource\" tool.\n        # Resources are typically outputs of other tools. This function might be less useful directly.\n        # For now, let's make it try to call the URI as if it were a tool (unlikely to work).\n        print(f\"INSPECTOR (warning): Direct resource GET not well-defined in GNN MCP. Trying URI as method.\", file=sys.stderr)\n        return self._send_request(method=uri) # This is a guess",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "handle_list_capabilities",
        "type": "function",
        "start_line": 145,
        "end_line": 154,
        "code": "def handle_list_capabilities(client: StdioMCPClient, args):\n    \"\"\"Handles the 'list-capabilities' command.\"\"\"\n    print(\"Inspector: Requesting server capabilities...\", file=sys.stderr)\n    try:\n        response = client.get_capabilities()\n        print_json(response)\n    except Exception as e:\n        print(f\"Error getting capabilities: {e}\", file=sys.stderr)\n        if hasattr(e, '__cause__') and e.__cause__:\n             print(f\"Cause: {e.__cause__}\", file=sys.stderr)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "handle_execute_tool",
        "type": "function",
        "start_line": 156,
        "end_line": 170,
        "code": "def handle_execute_tool(client: StdioMCPClient, args):\n    \"\"\"Handles the 'execute-tool' command.\"\"\"\n    tool_name = args.tool_name\n    try:\n        tool_params = json.loads(args.params) if args.params else {}\n    except json.JSONDecodeError as e:\n        print(f\"Error: Invalid JSON in --params: {e}\", file=sys.stderr)\n        return\n\n    print(f\"Inspector: Executing tool '{tool_name}' with params: {tool_params}\", file=sys.stderr)\n    try:\n        response = client.execute_tool(tool_name, tool_params)\n        print_json(response)\n    except Exception as e:\n        print(f\"Error executing tool '{tool_name}': {e}\", file=sys.stderr)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "handle_get_resource",
        "type": "function",
        "start_line": 172,
        "end_line": 180,
        "code": "def handle_get_resource(client: StdioMCPClient, args):\n    \"\"\"Handles the 'get-resource' command.\"\"\"\n    uri = args.uri\n    print(f\"Inspector: Attempting to get resource '{uri}'...\", file=sys.stderr)\n    try:\n        response = client.get_resource(uri) # This might not work as expected with GNN MCP\n        print_json(response)\n    except Exception as e:\n        print(f\"Error getting resource '{uri}': {e}\", file=sys.stderr)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 184,
        "end_line": 327,
        "code": "def main():\n    # This is the primary parser for the inspector tool itself.\n    parser = argparse.ArgumentParser(\n        description=\"GNN MCP Inspector. Launches and interacts with a GNN MCP server.\",\n        epilog=f\"Example: python {sys.argv[0]} --server-cmd \\\"python src/mcp/cli.py server --transport stdio\\\" list-capabilities\"\n    )\n    parser.add_argument(\n        \"--server-cmd\",\n        help=\"Full command string to start the GNN MCP server. \"\n             \"Example: 'python src/mcp/cli.py server --transport stdio'. \"\n             \"If not provided, defaults to stdio server via configured MCP_CLI_PATH.\",\n        default=f\"{PYTHON_EXECUTABLE} {MCP_CLI_PATH} server --transport stdio\"\n    )\n    parser.add_argument(\"--verbose\", action=\"store_true\", help=\"Print verbose output from inspector and server.\")\n\n    subparsers = parser.add_subparsers(dest=\"inspector_command\", title=\"Inspector Commands\", required=True)\n\n    # List Capabilities\n    list_parser = subparsers.add_parser(\"list-capabilities\", help=\"List all tools and resources from the server.\")\n    list_parser.set_defaults(func=handle_list_capabilities)\n\n    # Execute Tool\n    exec_parser = subparsers.add_parser(\"execute-tool\", help=\"Execute a specific tool on the server.\")\n    exec_parser.add_argument(\"tool_name\", help=\"The name of the tool to execute (e.g., meta.get_server_status).\")\n    exec_parser.add_argument(\"--params\", help=\"JSON string of parameters for the tool (e.g., '{\\\"key\\\": \\\"value\\\"}').\", default=\"{}\")\n    exec_parser.set_defaults(func=handle_execute_tool)\n    \n    # Get Resource (Experimental for GNN MCP) - Currently commented out as per previous structure\n    # resource_parser = subparsers.add_parser(\"get-resource\", help=\"Attempt to retrieve a resource by URI (experimental).\")\n    # resource_parser.add_argument(\"uri\", help=\"The URI of the resource.\")\n    # resource_parser.set_defaults(func=handle_get_resource)\n\n    args = parser.parse_args()\n\n    server_cmd_str = args.server_cmd\n    print(f\"Inspector: Using server command: {server_cmd_str}\", file=sys.stderr)\n    \n    # Prepare server command for subprocess\n    # shlex.split is good for this if the command is a single string.\n    # If it's already a list, use that.\n    if isinstance(server_cmd_str, str):\n        server_cmd_list = shlex.split(server_cmd_str)\n    else: # Assuming it could be pre-split if not default\n        server_cmd_list = server_cmd_str\n\n    if not Path(server_cmd_list[1]).is_file() and server_cmd_list[0] == PYTHON_EXECUTABLE : # Check if script path exists\n         print(f\"Inspector Error: MCP CLI script not found at {server_cmd_list[1]}\", file=sys.stderr)\n         print(f\"Please ensure GNN_PROJECT_ROOT is correct or provide full path in --server-cmd.\", file=sys.stderr)\n         sys.exit(1)\n    \n    if args.verbose:\n        if \"--verbose\" not in server_cmd_list and \"server\" in server_cmd_list : # Add verbose to server if not present\n            try:\n                server_idx = server_cmd_list.index(\"server\")\n                server_cmd_list.insert(server_idx, \"--verbose\") # GNN MCP CLI uses -v or --verbose at main level\n            except ValueError:\n                 # 'server' command not found, maybe it's a direct script call.\n                 # For simplicity, we assume the main CLI is used.\n                 pass # Don't add verbose if we can't find where to put it.\n        print(f\"Inspector: Augmented server command for verbose: {' '.join(server_cmd_list)}\", file=sys.stderr)\n\n\n    server_process = None\n    client = None\n    try:\n        print(f\"Inspector: Starting GNN MCP server process...\", file=sys.stderr)\n        server_process = subprocess.Popen(\n            server_cmd_list,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE, # Capture server's stderr separately\n            text=True, # Work with text streams\n            cwd=GNN_PROJECT_ROOT # Run from project root\n        )\n        \n        # Give server a moment to start, especially if it logs to stderr/stdout on startup\n        time.sleep(1 if \"stdio\" in server_cmd_str else 3) # Longer for http potentially\n\n        if server_process.poll() is not None:\n            print(f\"Inspector Error: Server process terminated prematurely (exit code {server_process.returncode}).\", file=sys.stderr)\n            print(\"--- Server stderr (if any) ---\", file=sys.stderr)\n            if server_process.stderr:\n                 for line in server_process.stderr: print(line.strip(), file=sys.stderr)\n            print(\"-----------------------------\", file=sys.stderr)\n            sys.exit(1)\n\n        print(\"Inspector: Server process started. Initializing client...\", file=sys.stderr)\n        # For now, only StdioMCPClient is implemented as it's simpler to manage process I/O.\n        # An HTTP client would use `requests` and connect to the server's host/port.\n        if \"stdio\" in server_cmd_str:\n            client = StdioMCPClient(server_process)\n        elif \"http\" in server_cmd_str:\n            # HTTP client would be different. For now, raise error if HTTP is specified.\n            # TODO: Implement an HTTP client similar to StdioMCPClient if needed.\n            print(\"Inspector Error: HTTP client mode for inspector is not yet fully implemented.\", file=sys.stderr)\n            print(\"Please use stdio transport for the server with this inspector version.\", file=sys.stderr)\n            sys.exit(1)\n        else:\n            print(\"Inspector Error: Could not determine server transport from command. Assuming stdio.\", file=sys.stderr)\n            client = StdioMCPClient(server_process)\n\n\n        # Execute the inspector command\n        if hasattr(args, 'func'):\n            args.func(client, args)\n\n    except FileNotFoundError:\n        print(f\"Inspector Error: Could not find server command '{server_cmd_list[0]}'. Is it in PATH or path correct?\", file=sys.stderr)\n    except ConnectionError as e:\n        print(f\"Inspector Error: Connection to server failed: {e}\", file=sys.stderr)\n    except TimeoutError as e:\n        print(f\"Inspector Error: Timeout communicating with server: {e}\", file=sys.stderr)\n    except Exception as e:\n        print(f\"Inspector: An unexpected error occurred: {e}\", file=sys.stderr)\n        print(f\"Details: {type(e).__name__}: {e.args}\", file=sys.stderr)\n\n    finally:\n        if server_process:\n            print(\"Inspector: Shutting down server process...\", file=sys.stderr)\n            if server_process.stdin:\n                server_process.stdin.close() # Signal EOF to server if it's reading stdin\n            \n            # Give threads a chance to process remaining output\n            if client and client.stdout_thread.is_alive(): client.stdout_thread.join(timeout=0.5)\n            if client and client.stderr_thread.is_alive(): client.stderr_thread.join(timeout=0.5)\n\n            if server_process.poll() is None: # If still running\n                server_process.terminate()\n                try:\n                    server_process.wait(timeout=2) # Wait for termination\n                except subprocess.TimeoutExpired:\n                    print(\"Inspector: Server did not terminate gracefully, killing.\", file=sys.stderr)\n                    server_process.kill()\n            print(\"Inspector: Server process shut down.\", file=sys.stderr)\n            \n            # Drain any remaining output from queues (after threads might have exited)\n            if client:\n                print(\"--- Remaining Server Stdout ---\", file=sys.stderr)\n                while not client.server_stdout_queue.empty():\n                    print(client.server_stdout_queue.get_nowait().strip(), file=sys.stderr)\n                print(\"--- Remaining Server Stderr ---\", file=sys.stderr)\n                while not client.server_stderr_queue.empty():\n                    print(client.server_stderr_queue.get_nowait().strip(), file=sys.stderr)\n                print(\"-----------------------------\", file=sys.stderr)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/npx_inspector.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py": [
      {
        "name": "StdioServer",
        "type": "class",
        "start_line": 22,
        "end_line": 210,
        "code": "class StdioServer:\n    \"\"\"A Model Context Protocol server implementation using stdio transport.\"\"\"\n    \n    def __init__(self):\n        self.running = False\n        self.request_queue = queue.Queue()\n        self.response_queue = queue.Queue()\n        self.next_id = 1\n        self.pending_requests = {}\n        \n    def start(self):\n        \"\"\"Start the server.\"\"\"\n        self.running = True\n        \n        # Initialize MCP\n        initialize()\n        \n        # Start reader and writer threads\n        reader_thread = threading.Thread(target=self._reader_thread)\n        writer_thread = threading.Thread(target=self._writer_thread)\n        processor_thread = threading.Thread(target=self._processor_thread)\n        \n        reader_thread.daemon = True\n        writer_thread.daemon = True\n        processor_thread.daemon = True\n        \n        reader_thread.start()\n        writer_thread.start()\n        processor_thread.start()\n        \n        # Wait for threads to exit\n        try:\n            while self.running:\n                reader_thread.join(0.1)\n                if not reader_thread.is_alive():\n                    self.running = False\n        except KeyboardInterrupt:\n            self.running = False\n        \n        writer_thread.join()\n        processor_thread.join()\n    \n    def _reader_thread(self):\n        \"\"\"Thread that reads messages from stdin.\"\"\"\n        try:\n            while self.running:\n                line = sys.stdin.readline()\n                if not line:\n                    logger.info(\"End of input, stopping server\")\n                    self.running = False\n                    break\n                \n                try:\n                    message = json.loads(line)\n                    self.request_queue.put(message)\n                except json.JSONDecodeError:\n                    logger.error(f\"Invalid JSON message: {line}\")\n        except Exception as e:\n            logger.error(f\"Error in reader thread: {str(e)}\")\n            self.running = False\n    \n    def _processor_thread(self):\n        \"\"\"Thread that processes messages from the request queue.\"\"\"\n        try:\n            while self.running:\n                try:\n                    message = self.request_queue.get(timeout=0.1)\n                except queue.Empty:\n                    continue\n                \n                try:\n                    self._process_message(message)\n                except Exception as e:\n                    logger.error(f\"Error processing message: {str(e)}\")\n                    traceback.print_exc()\n                \n                self.request_queue.task_done()\n        except Exception as e:\n            logger.error(f\"Error in processor thread: {str(e)}\")\n            self.running = False\n    \n    def _writer_thread(self):\n        \"\"\"Thread that writes messages to stdout.\"\"\"\n        try:\n            while self.running:\n                try:\n                    message = self.response_queue.get(timeout=0.1)\n                except queue.Empty:\n                    continue\n                \n                try:\n                    json_str = json.dumps(message)\n                    sys.stdout.write(json_str + \"\\n\")\n                    sys.stdout.flush()\n                except Exception as e:\n                    logger.error(f\"Error writing message: {str(e)}\")\n                \n                self.response_queue.task_done()\n        except Exception as e:\n            logger.error(f\"Error in writer thread: {str(e)}\")\n            self.running = False\n    \n    def _process_message(self, message: Dict[str, Any]):\n        \"\"\"Process an incoming message.\"\"\"\n        if not isinstance(message, dict):\n            logger.error(f\"Invalid message format: {message}\")\n            return\n        \n        # Check for JSON-RPC message\n        if \"jsonrpc\" in message and message[\"jsonrpc\"] == \"2.0\":\n            self._process_jsonrpc(message)\n        else:\n            logger.error(f\"Unsupported message format: {message}\")\n    \n    def _process_jsonrpc(self, message: Dict[str, Any]):\n        \"\"\"Process a JSON-RPC message.\"\"\"\n        if \"method\" not in message:\n            self._send_error(message.get(\"id\"), -32600, \"Invalid Request\")\n            return\n        \n        method = message[\"method\"]\n        params = message.get(\"params\", {})\n        \n        # Handle standard methods\n        if method == \"mcp.capabilities\":\n            self._handle_capabilities(message[\"id\"])\n        elif method == \"mcp.tool.execute\":\n            self._handle_execute_tool(message[\"id\"], params)\n        elif method == \"mcp.resource.get\":\n            self._handle_get_resource(message[\"id\"], params)\n        else:\n            self._send_error(message.get(\"id\"), -32601, f\"Method not found: {method}\")\n    \n    def _handle_capabilities(self, request_id: str):\n        \"\"\"Handle capabilities request.\"\"\"\n        capabilities = mcp_instance.get_capabilities()\n        self._send_result(request_id, capabilities)\n    \n    def _handle_execute_tool(self, request_id: str, params: Dict[str, Any]):\n        \"\"\"Handle tool execution request.\"\"\"\n        if \"name\" not in params or \"params\" not in params:\n            self._send_error(request_id, -32602, \"Invalid params for tool execution\")\n            return\n        \n        tool_name = params[\"name\"]\n        tool_params = params[\"params\"]\n        \n        try:\n            result = mcp_instance.execute_tool(tool_name, tool_params)\n            self._send_result(request_id, result)\n        except Exception as e:\n            logger.error(f\"Error executing tool {tool_name}: {str(e)}\")\n            self._send_error(request_id, -32603, f\"Internal error: {str(e)}\")\n    \n    def _handle_get_resource(self, request_id: str, params: Dict[str, Any]):\n        \"\"\"Handle resource retrieval request.\"\"\"\n        if \"uri\" not in params:\n            self._send_error(request_id, -32602, \"Invalid params for resource retrieval\")\n            return\n        \n        uri = params[\"uri\"]\n        \n        try:\n            result = mcp_instance.get_resource(uri)\n            self._send_result(request_id, result)\n        except Exception as e:\n            logger.error(f\"Error retrieving resource {uri}: {str(e)}\")\n            self._send_error(request_id, -32603, f\"Internal error: {str(e)}\")\n    \n    def _send_result(self, request_id: str, result: Any):\n        \"\"\"Send a successful result response.\"\"\"\n        response = {\n            \"jsonrpc\": \"2.0\",\n            \"id\": request_id,\n            \"result\": result\n        }\n        self.response_queue.put(response)\n    \n    def _send_error(self, request_id: Optional[str], code: int, message: str):\n        \"\"\"Send an error response.\"\"\"\n        response = {\n            \"jsonrpc\": \"2.0\",\n            \"id\": request_id,\n            \"error\": {\n                \"code\": code,\n                \"message\": message\n            }\n        }\n        self.response_queue.put(response)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 25,
        "end_line": 30,
        "code": "def __init__(self):\n        self.running = False\n        self.request_queue = queue.Queue()\n        self.response_queue = queue.Queue()\n        self.next_id = 1\n        self.pending_requests = {}",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "start",
        "type": "method",
        "start_line": 32,
        "end_line": 62,
        "code": "def start(self):\n        \"\"\"Start the server.\"\"\"\n        self.running = True\n        \n        # Initialize MCP\n        initialize()\n        \n        # Start reader and writer threads\n        reader_thread = threading.Thread(target=self._reader_thread)\n        writer_thread = threading.Thread(target=self._writer_thread)\n        processor_thread = threading.Thread(target=self._processor_thread)\n        \n        reader_thread.daemon = True\n        writer_thread.daemon = True\n        processor_thread.daemon = True\n        \n        reader_thread.start()\n        writer_thread.start()\n        processor_thread.start()\n        \n        # Wait for threads to exit\n        try:\n            while self.running:\n                reader_thread.join(0.1)\n                if not reader_thread.is_alive():\n                    self.running = False\n        except KeyboardInterrupt:\n            self.running = False\n        \n        writer_thread.join()\n        processor_thread.join()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "_reader_thread",
        "type": "method",
        "start_line": 64,
        "end_line": 81,
        "code": "def _reader_thread(self):\n        \"\"\"Thread that reads messages from stdin.\"\"\"\n        try:\n            while self.running:\n                line = sys.stdin.readline()\n                if not line:\n                    logger.info(\"End of input, stopping server\")\n                    self.running = False\n                    break\n                \n                try:\n                    message = json.loads(line)\n                    self.request_queue.put(message)\n                except json.JSONDecodeError:\n                    logger.error(f\"Invalid JSON message: {line}\")\n        except Exception as e:\n            logger.error(f\"Error in reader thread: {str(e)}\")\n            self.running = False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "_processor_thread",
        "type": "method",
        "start_line": 83,
        "end_line": 101,
        "code": "def _processor_thread(self):\n        \"\"\"Thread that processes messages from the request queue.\"\"\"\n        try:\n            while self.running:\n                try:\n                    message = self.request_queue.get(timeout=0.1)\n                except queue.Empty:\n                    continue\n                \n                try:\n                    self._process_message(message)\n                except Exception as e:\n                    logger.error(f\"Error processing message: {str(e)}\")\n                    traceback.print_exc()\n                \n                self.request_queue.task_done()\n        except Exception as e:\n            logger.error(f\"Error in processor thread: {str(e)}\")\n            self.running = False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "_writer_thread",
        "type": "method",
        "start_line": 103,
        "end_line": 122,
        "code": "def _writer_thread(self):\n        \"\"\"Thread that writes messages to stdout.\"\"\"\n        try:\n            while self.running:\n                try:\n                    message = self.response_queue.get(timeout=0.1)\n                except queue.Empty:\n                    continue\n                \n                try:\n                    json_str = json.dumps(message)\n                    sys.stdout.write(json_str + \"\\n\")\n                    sys.stdout.flush()\n                except Exception as e:\n                    logger.error(f\"Error writing message: {str(e)}\")\n                \n                self.response_queue.task_done()\n        except Exception as e:\n            logger.error(f\"Error in writer thread: {str(e)}\")\n            self.running = False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "_process_message",
        "type": "method",
        "start_line": 124,
        "end_line": 134,
        "code": "def _process_message(self, message: Dict[str, Any]):\n        \"\"\"Process an incoming message.\"\"\"\n        if not isinstance(message, dict):\n            logger.error(f\"Invalid message format: {message}\")\n            return\n        \n        # Check for JSON-RPC message\n        if \"jsonrpc\" in message and message[\"jsonrpc\"] == \"2.0\":\n            self._process_jsonrpc(message)\n        else:\n            logger.error(f\"Unsupported message format: {message}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "_process_jsonrpc",
        "type": "method",
        "start_line": 136,
        "end_line": 153,
        "code": "def _process_jsonrpc(self, message: Dict[str, Any]):\n        \"\"\"Process a JSON-RPC message.\"\"\"\n        if \"method\" not in message:\n            self._send_error(message.get(\"id\"), -32600, \"Invalid Request\")\n            return\n        \n        method = message[\"method\"]\n        params = message.get(\"params\", {})\n        \n        # Handle standard methods\n        if method == \"mcp.capabilities\":\n            self._handle_capabilities(message[\"id\"])\n        elif method == \"mcp.tool.execute\":\n            self._handle_execute_tool(message[\"id\"], params)\n        elif method == \"mcp.resource.get\":\n            self._handle_get_resource(message[\"id\"], params)\n        else:\n            self._send_error(message.get(\"id\"), -32601, f\"Method not found: {method}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "_handle_capabilities",
        "type": "method",
        "start_line": 155,
        "end_line": 158,
        "code": "def _handle_capabilities(self, request_id: str):\n        \"\"\"Handle capabilities request.\"\"\"\n        capabilities = mcp_instance.get_capabilities()\n        self._send_result(request_id, capabilities)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "_handle_execute_tool",
        "type": "method",
        "start_line": 160,
        "end_line": 174,
        "code": "def _handle_execute_tool(self, request_id: str, params: Dict[str, Any]):\n        \"\"\"Handle tool execution request.\"\"\"\n        if \"name\" not in params or \"params\" not in params:\n            self._send_error(request_id, -32602, \"Invalid params for tool execution\")\n            return\n        \n        tool_name = params[\"name\"]\n        tool_params = params[\"params\"]\n        \n        try:\n            result = mcp_instance.execute_tool(tool_name, tool_params)\n            self._send_result(request_id, result)\n        except Exception as e:\n            logger.error(f\"Error executing tool {tool_name}: {str(e)}\")\n            self._send_error(request_id, -32603, f\"Internal error: {str(e)}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "_handle_get_resource",
        "type": "method",
        "start_line": 176,
        "end_line": 189,
        "code": "def _handle_get_resource(self, request_id: str, params: Dict[str, Any]):\n        \"\"\"Handle resource retrieval request.\"\"\"\n        if \"uri\" not in params:\n            self._send_error(request_id, -32602, \"Invalid params for resource retrieval\")\n            return\n        \n        uri = params[\"uri\"]\n        \n        try:\n            result = mcp_instance.get_resource(uri)\n            self._send_result(request_id, result)\n        except Exception as e:\n            logger.error(f\"Error retrieving resource {uri}: {str(e)}\")\n            self._send_error(request_id, -32603, f\"Internal error: {str(e)}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "_send_result",
        "type": "method",
        "start_line": 191,
        "end_line": 198,
        "code": "def _send_result(self, request_id: str, result: Any):\n        \"\"\"Send a successful result response.\"\"\"\n        response = {\n            \"jsonrpc\": \"2.0\",\n            \"id\": request_id,\n            \"result\": result\n        }\n        self.response_queue.put(response)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "_send_error",
        "type": "method",
        "start_line": 200,
        "end_line": 210,
        "code": "def _send_error(self, request_id: Optional[str], code: int, message: str):\n        \"\"\"Send an error response.\"\"\"\n        response = {\n            \"jsonrpc\": \"2.0\",\n            \"id\": request_id,\n            \"error\": {\n                \"code\": code,\n                \"message\": message\n            }\n        }\n        self.response_queue.put(response)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      },
      {
        "name": "start_stdio_server",
        "type": "function",
        "start_line": 212,
        "end_line": 215,
        "code": "def start_stdio_server():\n    \"\"\"Start an MCP server using stdio transport.\"\"\"\n    server = StdioServer()\n    server.start()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_stdio.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py": [
      {
        "name": "MCPError",
        "type": "class",
        "start_line": 13,
        "end_line": 18,
        "code": "class MCPError(Exception):\n    \"\"\"Base class for MCP related errors.\"\"\"\n    def __init__(self, message, code=-32000, data=None):\n        super().__init__(message)\n        self.code = code\n        self.data = data",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 15,
        "end_line": 18,
        "code": "def __init__(self, message, code=-32000, data=None):\n        super().__init__(message)\n        self.code = code\n        self.data = data",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "MCPToolNotFoundError",
        "type": "class",
        "start_line": 20,
        "end_line": 22,
        "code": "class MCPToolNotFoundError(MCPError):\n    def __init__(self, tool_name):\n        super().__init__(f\"Tool '{tool_name}' not found.\", code=-32601, data=f\"Tool '{tool_name}' not found.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 21,
        "end_line": 22,
        "code": "def __init__(self, tool_name):\n        super().__init__(f\"Tool '{tool_name}' not found.\", code=-32601, data=f\"Tool '{tool_name}' not found.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "MCPResourceNotFoundError",
        "type": "class",
        "start_line": 24,
        "end_line": 27,
        "code": "class MCPResourceNotFoundError(MCPError):\n    def __init__(self, uri):\n        # Or a custom code, but -32601 (Method not found) can also be used if resources are accessed like methods\n        super().__init__(f\"Resource '{uri}' not found.\", code=-32601, data=f\"Resource '{uri}' not found.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 25,
        "end_line": 27,
        "code": "def __init__(self, uri):\n        # Or a custom code, but -32601 (Method not found) can also be used if resources are accessed like methods\n        super().__init__(f\"Resource '{uri}' not found.\", code=-32601, data=f\"Resource '{uri}' not found.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "MCPInvalidParamsError",
        "type": "class",
        "start_line": 29,
        "end_line": 31,
        "code": "class MCPInvalidParamsError(MCPError):\n    def __init__(self, message, details=None):\n        super().__init__(message, code=-32602, data=details)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 30,
        "end_line": 31,
        "code": "def __init__(self, message, details=None):\n        super().__init__(message, code=-32602, data=details)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "MCPToolExecutionError",
        "type": "class",
        "start_line": 33,
        "end_line": 35,
        "code": "class MCPToolExecutionError(MCPError):\n    def __init__(self, tool_name, original_exception):\n        super().__init__(f\"Error executing tool '{tool_name}': {original_exception}\", code=-32000, data=str(original_exception))",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 34,
        "end_line": 35,
        "code": "def __init__(self, tool_name, original_exception):\n        super().__init__(f\"Error executing tool '{tool_name}': {original_exception}\", code=-32000, data=str(original_exception))",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "MCPSDKNotFoundError",
        "type": "class",
        "start_line": 37,
        "end_line": 39,
        "code": "class MCPSDKNotFoundError(MCPError): # This was already defined, ensuring it inherits from MCPError\n    def __init__(self, message=\"MCP SDK not found or failed to initialize.\"):\n        super().__init__(message, code=-32001, data=message) # Example custom server error code",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 38,
        "end_line": 39,
        "code": "def __init__(self, message=\"MCP SDK not found or failed to initialize.\"):\n        super().__init__(message, code=-32001, data=message) # Example custom server error code",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "MCPTool",
        "type": "class",
        "start_line": 61,
        "end_line": 68,
        "code": "class MCPTool:\n    \"\"\"Represents an MCP tool that can be executed.\"\"\"\n    \n    def __init__(self, name: str, func: Callable, schema: Dict, description: str):\n        self.name = name\n        self.func = func\n        self.schema = schema\n        self.description = description",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 64,
        "end_line": 68,
        "code": "def __init__(self, name: str, func: Callable, schema: Dict, description: str):\n        self.name = name\n        self.func = func\n        self.schema = schema\n        self.description = description",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "MCPResource",
        "type": "class",
        "start_line": 70,
        "end_line": 76,
        "code": "class MCPResource:\n    \"\"\"Represents an MCP resource that can be accessed.\"\"\"\n    \n    def __init__(self, uri_template: str, retriever: Callable, description: str):\n        self.uri_template = uri_template\n        self.retriever = retriever\n        self.description = description",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 73,
        "end_line": 76,
        "code": "def __init__(self, uri_template: str, retriever: Callable, description: str):\n        self.uri_template = uri_template\n        self.retriever = retriever\n        self.description = description",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "MCP",
        "type": "class",
        "start_line": 78,
        "end_line": 268,
        "code": "class MCP:\n    \"\"\"Main Model Context Protocol implementation.\"\"\"\n    \n    def __init__(self):\n        self.tools: Dict[str, MCPTool] = {}\n        self.resources: Dict[str, MCPResource] = {}\n        self.modules: Dict[str, Any] = {}\n        self._modules_discovered = False # Flag to track if discovery has run\n        # Note: The _MCP_SDK_CONFIG_STATUS is module-level, not instance-level,\n        # as SDK availability is a system-wide concern for this MCP setup.\n        \n    def discover_modules(self) -> bool:\n        \"\"\"Discover and load MCP modules from other directories.\n\n        Returns:\n            bool: True if all modules loaded successfully, False otherwise.\n        \"\"\"\n        if self._modules_discovered:\n            logger.debug(\"MCP modules already discovered. Skipping redundant discovery.\")\n            # Return True assuming previous discovery's success state is what matters,\n            # or we'd need to store the previous result. For now, if it ran, assume it was handled.\n            # To be more precise, one might store the result of the first discovery.\n            # However, the function is meant to load modules into self.modules and register tools,\n            # which should not be redone.\n            return True # Or reflect stored status if available and needed.\n\n        root_dir = Path(__file__).parent.parent\n        logger.debug(f\"Discovering MCP modules in {root_dir}\")\n        all_modules_loaded_successfully = True\n        \n        for directory in root_dir.iterdir():\n            if not directory.is_dir() or directory.name.startswith('_'):\n                continue\n                \n            mcp_file = directory / \"mcp.py\"\n            if not mcp_file.exists():\n                logger.debug(f\"No MCP module found in {directory}\")\n                continue\n                \n            module_name = f\"src.{directory.name}.mcp\"\n            try:\n                # Add parent directory to path if needed\n                if str(root_dir.parent) not in sys.path:\n                    sys.path.append(str(root_dir.parent))\n                \n                module = importlib.import_module(module_name)\n                logger.debug(f\"Loaded MCP module: {module_name}\")\n                \n                # Special handling for llm module initialization\n                if module_name == \"src.llm.mcp\":\n                    if hasattr(module, \"initialize_llm_module\") and callable(module.initialize_llm_module):\n                        logger.debug(f\"Calling initialize_llm_module for {module_name}\")\n                        module.initialize_llm_module(self) # Pass MCP instance\n                    else:\n                        logger.warning(f\"Module {module_name} does not have a callable initialize_llm_module function.\")\n\n                # Register tools and resources from the module\n                if hasattr(module, \"register_tools\") and callable(module.register_tools):\n                    module.register_tools(self)\n                \n                self.modules[directory.name] = module\n            except Exception as e:\n                logger.error(f\"Failed to load MCP module {module_name}: {str(e)}\")\n                all_modules_loaded_successfully = False\n\n        self._modules_discovered = True # Set flag after successful completion of first discovery\n        return all_modules_loaded_successfully\n    \n    def register_tool(self, name: str, func: Callable, schema: Dict, description: str):\n        \"\"\"Register a new tool with the MCP.\"\"\"\n        if name in self.tools:\n            logger.warning(f\"Tool '{name}' already registered. Overwriting.\")\n        \n        self.tools[name] = MCPTool(name, func, schema, description)\n        logger.debug(f\"Registered tool: {name}\")\n        \n    def register_resource(self, uri_template: str, retriever: Callable, description: str):\n        \"\"\"Register a new resource with the MCP.\"\"\"\n        if uri_template in self.resources:\n            logger.warning(f\"Resource '{uri_template}' already registered. Overwriting.\")\n            \n        self.resources[uri_template] = MCPResource(uri_template, retriever, description)\n        logger.debug(f\"Registered resource: {uri_template}\")\n    \n    def execute_tool(self, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute a registered tool with the given parameters.\"\"\"\n        logger.debug(f\"Attempting to execute tool: {tool_name} with params: {params}\")\n        if tool_name not in self.tools:\n            logger.error(f\"Tool not found: {tool_name}\")\n            raise MCPToolNotFoundError(tool_name)\n            \n        tool = self.tools[tool_name]\n        \n        # Basic schema validation (can be enhanced with a proper JSON schema validator)\n        # For simplicity, this example just checks for required parameters.\n        # A real implementation should use a library like jsonschema for full validation.\n        if tool.schema and tool.schema.get('properties'):\n            required_params = tool.schema.get('required', [])\n            for param_name in required_params:\n                if param_name not in params:\n                    err_msg = f\"Missing required parameter for {tool_name}: {param_name}\"\n                    logger.error(err_msg)\n                    raise MCPInvalidParamsError(err_msg, details={\"missing_parameter\": param_name})\n            # Optional: Add type checking here based on schema if not using full jsonschema validation\n            for param_name, param_value in params.items():\n                if param_name in tool.schema['properties']:\n                    expected_type_str = tool.schema['properties'][param_name].get('type')\n                    # Basic type mapping - extend as needed\n                    type_map = {\n                        'string': str,\n                        'integer': int,\n                        'number': (int, float),\n                        'boolean': bool,\n                        'array': list,\n                        'object': dict\n                    }\n                    if expected_type_str and expected_type_str in type_map:\n                        expected_type = type_map[expected_type_str]\n                        if not isinstance(param_value, expected_type):\n                            err_msg = f\"Invalid type for parameter '{param_name}' in tool '{tool_name}'. Expected {expected_type_str}, got {type(param_value).__name__}.\"\n                            logger.error(err_msg)\n                            raise MCPInvalidParamsError(err_msg, details={ \"parameter\": param_name, \"expected_type\": expected_type_str, \"actual_type\": type(param_value).__name__})\n        \n        try:\n            # The actual tool function (tool.func) is responsible for its own logic.\n            # It should return a dictionary or JSON-serializable data.\n            result_data = tool.func(**params)\n            logger.info(f\"Tool {tool_name} executed successfully.\")\n            # The MCP spec usually expects the result of the tool directly.\n            # The client then wraps this in a JSON-RPC response if it's an MCP client.\n            # If this mcp.py is part of a server that forms the full JSON-RPC response,\n            # then it might return just `result_data`.\n            # The previous code `return {\"result\": result_data}` implies this method might be\n            # called by something that expects the *full* JSON-RPC `result` field content.\n            # However, the method is `execute_tool`, not `handle_execute_tool_rpc_request`.\n            # For clarity and adhering to what a tool execution means, it should return the tool's direct output.\n            # The JSON-RPC formatting ({\"jsonrpc\": ..., \"result\": ..., \"id\": ...}) should be handled by the transport layer.\n            return result_data # Return the direct result of the tool function\n        except MCPError: # Re-raise MCP-specific errors directly\n            raise\n        except Exception as e:\n            logger.error(f\"Unhandled error during execution of tool {tool_name}: {e}\", exc_info=True)\n            raise MCPToolExecutionError(tool_name, e)\n    \n    def get_resource(self, uri: str) -> Dict[str, Any]:\n        \"\"\"Retrieve a resource by URI.\"\"\"\n        logger.debug(f\"Attempting to retrieve resource: {uri}\")\n        # Basic implementation - would need more sophisticated URI template matching\n        for template, resource in self.resources.items():\n            # This is a very simplified matching logic. \n            # A robust solution would use URI template libraries or regex.\n            # Example: if uri matches template pattern (e.g. using re or a template library)\n            if template == uri or (template.endswith('{}') and uri.startswith(template[:-2])) or (template.endswith('{id}') and uri.startswith(template[:-4])) :\n                try:\n                    # The retriever function should return the resource content directly.\n                    resource_content = resource.retriever(uri=uri) # Pass the actual URI to the retriever\n                    logger.info(f\"Resource {uri} retrieved successfully.\")\n                    # Similar to execute_tool, return the direct content of the resource.\n                    # The JSON-RPC formatting should be handled by the transport layer.\n                    return resource_content\n                except MCPError: # Re-raise MCP-specific errors\n                    raise\n                except Exception as e:\n                    logger.error(f\"Error retrieving resource {uri} via retriever for template {template}: {e}\", exc_info=True)\n                    # Treat retriever failure like a tool execution failure\n                    raise MCPToolExecutionError(f\"resource_retriever_for_{template}\", e) # Use template as a quasi-toolname\n                    \n        logger.warning(f\"Resource with URI '{uri}' not found after checking all templates.\")\n        raise MCPResourceNotFoundError(uri)\n    \n    def get_capabilities(self) -> Dict[str, Any]:\n        \"\"\"Return the capabilities of this MCP instance.\"\"\"\n        tools = {}\n        for name, tool in self.tools.items():\n            tools[name] = {\n                \"schema\": tool.schema,\n                \"description\": tool.description\n            }\n            \n        resources = {}\n        for uri_template, resource in self.resources.items():\n            resources[uri_template] = {\n                \"description\": resource.description\n            }\n            \n        return {\n            \"tools\": tools,\n            \"resources\": resources,\n            \"version\": \"1.0.0\",\n            \"name\": \"GeneralizedNotationNotation MCP\"\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 81,
        "end_line": 87,
        "code": "def __init__(self):\n        self.tools: Dict[str, MCPTool] = {}\n        self.resources: Dict[str, MCPResource] = {}\n        self.modules: Dict[str, Any] = {}\n        self._modules_discovered = False # Flag to track if discovery has run\n        # Note: The _MCP_SDK_CONFIG_STATUS is module-level, not instance-level,\n        # as SDK availability is a system-wide concern for this MCP setup.",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "discover_modules",
        "type": "method",
        "start_line": 89,
        "end_line": 144,
        "code": "def discover_modules(self) -> bool:\n        \"\"\"Discover and load MCP modules from other directories.\n\n        Returns:\n            bool: True if all modules loaded successfully, False otherwise.\n        \"\"\"\n        if self._modules_discovered:\n            logger.debug(\"MCP modules already discovered. Skipping redundant discovery.\")\n            # Return True assuming previous discovery's success state is what matters,\n            # or we'd need to store the previous result. For now, if it ran, assume it was handled.\n            # To be more precise, one might store the result of the first discovery.\n            # However, the function is meant to load modules into self.modules and register tools,\n            # which should not be redone.\n            return True # Or reflect stored status if available and needed.\n\n        root_dir = Path(__file__).parent.parent\n        logger.debug(f\"Discovering MCP modules in {root_dir}\")\n        all_modules_loaded_successfully = True\n        \n        for directory in root_dir.iterdir():\n            if not directory.is_dir() or directory.name.startswith('_'):\n                continue\n                \n            mcp_file = directory / \"mcp.py\"\n            if not mcp_file.exists():\n                logger.debug(f\"No MCP module found in {directory}\")\n                continue\n                \n            module_name = f\"src.{directory.name}.mcp\"\n            try:\n                # Add parent directory to path if needed\n                if str(root_dir.parent) not in sys.path:\n                    sys.path.append(str(root_dir.parent))\n                \n                module = importlib.import_module(module_name)\n                logger.debug(f\"Loaded MCP module: {module_name}\")\n                \n                # Special handling for llm module initialization\n                if module_name == \"src.llm.mcp\":\n                    if hasattr(module, \"initialize_llm_module\") and callable(module.initialize_llm_module):\n                        logger.debug(f\"Calling initialize_llm_module for {module_name}\")\n                        module.initialize_llm_module(self) # Pass MCP instance\n                    else:\n                        logger.warning(f\"Module {module_name} does not have a callable initialize_llm_module function.\")\n\n                # Register tools and resources from the module\n                if hasattr(module, \"register_tools\") and callable(module.register_tools):\n                    module.register_tools(self)\n                \n                self.modules[directory.name] = module\n            except Exception as e:\n                logger.error(f\"Failed to load MCP module {module_name}: {str(e)}\")\n                all_modules_loaded_successfully = False\n\n        self._modules_discovered = True # Set flag after successful completion of first discovery\n        return all_modules_loaded_successfully",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "register_tool",
        "type": "method",
        "start_line": 146,
        "end_line": 152,
        "code": "def register_tool(self, name: str, func: Callable, schema: Dict, description: str):\n        \"\"\"Register a new tool with the MCP.\"\"\"\n        if name in self.tools:\n            logger.warning(f\"Tool '{name}' already registered. Overwriting.\")\n        \n        self.tools[name] = MCPTool(name, func, schema, description)\n        logger.debug(f\"Registered tool: {name}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "register_resource",
        "type": "method",
        "start_line": 154,
        "end_line": 160,
        "code": "def register_resource(self, uri_template: str, retriever: Callable, description: str):\n        \"\"\"Register a new resource with the MCP.\"\"\"\n        if uri_template in self.resources:\n            logger.warning(f\"Resource '{uri_template}' already registered. Overwriting.\")\n            \n        self.resources[uri_template] = MCPResource(uri_template, retriever, description)\n        logger.debug(f\"Registered resource: {uri_template}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "execute_tool",
        "type": "method",
        "start_line": 162,
        "end_line": 220,
        "code": "def execute_tool(self, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute a registered tool with the given parameters.\"\"\"\n        logger.debug(f\"Attempting to execute tool: {tool_name} with params: {params}\")\n        if tool_name not in self.tools:\n            logger.error(f\"Tool not found: {tool_name}\")\n            raise MCPToolNotFoundError(tool_name)\n            \n        tool = self.tools[tool_name]\n        \n        # Basic schema validation (can be enhanced with a proper JSON schema validator)\n        # For simplicity, this example just checks for required parameters.\n        # A real implementation should use a library like jsonschema for full validation.\n        if tool.schema and tool.schema.get('properties'):\n            required_params = tool.schema.get('required', [])\n            for param_name in required_params:\n                if param_name not in params:\n                    err_msg = f\"Missing required parameter for {tool_name}: {param_name}\"\n                    logger.error(err_msg)\n                    raise MCPInvalidParamsError(err_msg, details={\"missing_parameter\": param_name})\n            # Optional: Add type checking here based on schema if not using full jsonschema validation\n            for param_name, param_value in params.items():\n                if param_name in tool.schema['properties']:\n                    expected_type_str = tool.schema['properties'][param_name].get('type')\n                    # Basic type mapping - extend as needed\n                    type_map = {\n                        'string': str,\n                        'integer': int,\n                        'number': (int, float),\n                        'boolean': bool,\n                        'array': list,\n                        'object': dict\n                    }\n                    if expected_type_str and expected_type_str in type_map:\n                        expected_type = type_map[expected_type_str]\n                        if not isinstance(param_value, expected_type):\n                            err_msg = f\"Invalid type for parameter '{param_name}' in tool '{tool_name}'. Expected {expected_type_str}, got {type(param_value).__name__}.\"\n                            logger.error(err_msg)\n                            raise MCPInvalidParamsError(err_msg, details={ \"parameter\": param_name, \"expected_type\": expected_type_str, \"actual_type\": type(param_value).__name__})\n        \n        try:\n            # The actual tool function (tool.func) is responsible for its own logic.\n            # It should return a dictionary or JSON-serializable data.\n            result_data = tool.func(**params)\n            logger.info(f\"Tool {tool_name} executed successfully.\")\n            # The MCP spec usually expects the result of the tool directly.\n            # The client then wraps this in a JSON-RPC response if it's an MCP client.\n            # If this mcp.py is part of a server that forms the full JSON-RPC response,\n            # then it might return just `result_data`.\n            # The previous code `return {\"result\": result_data}` implies this method might be\n            # called by something that expects the *full* JSON-RPC `result` field content.\n            # However, the method is `execute_tool`, not `handle_execute_tool_rpc_request`.\n            # For clarity and adhering to what a tool execution means, it should return the tool's direct output.\n            # The JSON-RPC formatting ({\"jsonrpc\": ..., \"result\": ..., \"id\": ...}) should be handled by the transport layer.\n            return result_data # Return the direct result of the tool function\n        except MCPError: # Re-raise MCP-specific errors directly\n            raise\n        except Exception as e:\n            logger.error(f\"Unhandled error during execution of tool {tool_name}: {e}\", exc_info=True)\n            raise MCPToolExecutionError(tool_name, e)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "get_resource",
        "type": "method",
        "start_line": 222,
        "end_line": 246,
        "code": "def get_resource(self, uri: str) -> Dict[str, Any]:\n        \"\"\"Retrieve a resource by URI.\"\"\"\n        logger.debug(f\"Attempting to retrieve resource: {uri}\")\n        # Basic implementation - would need more sophisticated URI template matching\n        for template, resource in self.resources.items():\n            # This is a very simplified matching logic. \n            # A robust solution would use URI template libraries or regex.\n            # Example: if uri matches template pattern (e.g. using re or a template library)\n            if template == uri or (template.endswith('{}') and uri.startswith(template[:-2])) or (template.endswith('{id}') and uri.startswith(template[:-4])) :\n                try:\n                    # The retriever function should return the resource content directly.\n                    resource_content = resource.retriever(uri=uri) # Pass the actual URI to the retriever\n                    logger.info(f\"Resource {uri} retrieved successfully.\")\n                    # Similar to execute_tool, return the direct content of the resource.\n                    # The JSON-RPC formatting should be handled by the transport layer.\n                    return resource_content\n                except MCPError: # Re-raise MCP-specific errors\n                    raise\n                except Exception as e:\n                    logger.error(f\"Error retrieving resource {uri} via retriever for template {template}: {e}\", exc_info=True)\n                    # Treat retriever failure like a tool execution failure\n                    raise MCPToolExecutionError(f\"resource_retriever_for_{template}\", e) # Use template as a quasi-toolname\n                    \n        logger.warning(f\"Resource with URI '{uri}' not found after checking all templates.\")\n        raise MCPResourceNotFoundError(uri)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "get_capabilities",
        "type": "method",
        "start_line": 248,
        "end_line": 268,
        "code": "def get_capabilities(self) -> Dict[str, Any]:\n        \"\"\"Return the capabilities of this MCP instance.\"\"\"\n        tools = {}\n        for name, tool in self.tools.items():\n            tools[name] = {\n                \"schema\": tool.schema,\n                \"description\": tool.description\n            }\n            \n        resources = {}\n        for uri_template, resource in self.resources.items():\n            resources[uri_template] = {\n                \"description\": resource.description\n            }\n            \n        return {\n            \"tools\": tools,\n            \"resources\": resources,\n            \"version\": \"1.0.0\",\n            \"name\": \"GeneralizedNotationNotation MCP\"\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      },
      {
        "name": "initialize",
        "type": "function",
        "start_line": 276,
        "end_line": 365,
        "code": "def initialize(halt_on_missing_sdk: bool = True, force_proceed_flag: bool = False) -> Tuple[MCP, bool, bool]:\n    \"\"\"\n    Initialize the MCP by discovering modules and checking SDK status.\n\n    Args:\n        halt_on_missing_sdk: If True (default), raises MCPSDKNotFoundError if the SDK is missing.\n        force_proceed_flag: If True, proceeds even if SDK is missing and halt_on_missing_sdk is True.\n                            (e.g., controlled by a command-line argument like --proceed-without-mcp-sdk)\n\n    Returns:\n        A tuple: (mcp_instance: MCP, sdk_found: bool, all_modules_loaded: bool)\n    \n    Raises:\n        MCPSDKNotFoundError: If SDK is not found, halt_on_missing_sdk is True, and force_proceed_flag is False.\n    \"\"\"\n    global _critical_mcp_warning_issued\n    \n    # Perform module discovery first, as this populates the mcp_instance\n    all_modules_loaded = mcp_instance.discover_modules()\n\n    # With the simplified approach, sdk_found is always True.\n    # The check for _MCP_SDK_CONFIG_STATUS[\"found\"] can be simplified or removed\n    # if we are certain that the project's internal MCP is always sufficient.\n    # For now, we'll keep the structure but ensure \"found\" is true.\n    sdk_found = _MCP_SDK_CONFIG_STATUS[\"found\"] # This will be True\n\n    if not sdk_found: # This block should ideally not be entered anymore.\n        if not _critical_mcp_warning_issued:\n            consequences_details = _MCP_SDK_CONFIG_STATUS['details']\n            consequences = f\"\"\"\nThe Model Context Protocol (MCP) SDK was not found or failed to initialize correctly.\nAs a result, core MCP functionalities will be severely limited or non-operational.\nThis will affect capabilities such as, but not limited to:\n  - Running GNN type checks via MCP.\n  - Estimating GNN computational resources via MCP.\n  - Exporting GNN models and reports to various formats via MCP.\n  - Utilizing setup utilities (e.g., finding project files, managing directories) via MCP.\n  - Executing GNN tests and accessing test reports via MCP.\n  - Generating GNN model visualizations via MCP.\n  - Accessing GNN core documentation and ontology terms via MCP.\n  - Full functionality of the MCP server itself (e.g., self-reflection tools).\n\nPipeline steps or client applications relying on these MCP functions may fail,\nproduce incomplete results, or operate with dummy/fallback implementations.\nIt is strongly recommended to install or correct the MCP SDK for full functionality.\nCurrent SDK status details: {consequences_details}\n\"\"\"\n            \n            banner = (\n                \"\\n\" + \"=\"*80 +\n                \"\\n\" + \"!!! CRITICAL MCP SDK WARNING !!!\".center(80) +\n                \"\\n\" + \"=\"*80\n            )\n            \n            logger.critical(banner)\n            logger.critical(consequences)\n            logger.critical(\"=\"*80 + \"\\n\")\n            _critical_mcp_warning_issued = True\n\n        if halt_on_missing_sdk and not force_proceed_flag:\n            error_message = (\n                \"MCP SDK is critical for full functionality and was not found or failed to load. \"\n                \"Pipeline is configured to halt. To proceed with limited MCP capabilities, \"\n                \"use a flag like --proceed-without-mcp-sdk (if available in the calling script) \"\n                \"or adjust pipeline configuration.\"\n            )\n            logger.error(error_message)\n            raise MCPSDKNotFoundError(error_message)\n        elif force_proceed_flag:\n            logger.warning(\n                \"Proceeding without a fully functional MCP SDK due to explicit override. \"\n                \"MCP features will be limited or non-operational.\"\n            )\n        else: # Not configured to halt, but SDK is missing\n             logger.warning(\n                \"MCP SDK not found or failed to load, but pipeline is configured to continue. \"\n                \"MCP functionalities will be impaired or non-operational.\"\n            )\n    elif sdk_found and _critical_mcp_warning_issued:\n        # If SDK was previously thought missing, but now found (e.g. re-init with fix)\n        logger.info(\"MCP SDK appears to be available now.\")\n        _critical_mcp_warning_issued = False\n    elif sdk_found: # This is the expected path now\n        logger.info(f\"MCP system initialized using project's internal MCP components. SDK Status: {_MCP_SDK_CONFIG_STATUS['details']}\")\n        _critical_mcp_warning_issued = False # Ensure warning flag is reset if it was ever set\n\n\n    # The calling script (e.g., 7_mcp.py) might log its own \"initialized successfully\" message.\n    # This function now returns sdk_found so the caller can be more accurate.\n    return mcp_instance, sdk_found, all_modules_loaded",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py": [
      {
        "name": "TestMCPCore",
        "type": "class",
        "start_line": 36,
        "end_line": 126,
        "code": "class TestMCPCore(unittest.TestCase):\n    \"\"\"Test the core MCP functionality.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up a fresh MCP instance for each test.\"\"\"\n        self.mcp = MCP()\n    \n    def test_tool_registration(self):\n        \"\"\"Test registering and retrieving tools.\"\"\"\n        # Define a simple test tool\n        def test_tool(param1: str, param2: int) -> dict:\n            return {\"result\": f\"{param1}_{param2}\"}\n        \n        # Register the tool\n        self.mcp.register_tool(\n            \"test_tool\",\n            test_tool,\n            {\n                \"param1\": {\"type\": \"string\"},\n                \"param2\": {\"type\": \"integer\"}\n            },\n            \"Test tool description\"\n        )\n        \n        # Check that the tool was registered correctly\n        self.assertIn(\"test_tool\", self.mcp.tools)\n        \n        # Execute the tool\n        result = self.mcp.execute_tool(\"test_tool\", {\"param1\": \"test\", \"param2\": 42})\n        self.assertEqual(result[\"result\"][\"result\"], \"test_42\")\n        \n        # Check tool capability listing\n        capabilities = self.mcp.get_capabilities()\n        self.assertIn(\"test_tool\", capabilities[\"tools\"])\n        self.assertEqual(capabilities[\"tools\"][\"test_tool\"][\"description\"], \"Test tool description\")\n    \n    def test_resource_registration(self):\n        \"\"\"Test registering and retrieving resources.\"\"\"\n        # Define a simple test resource retriever\n        def test_resource(uri: str) -> dict:\n            return {\"uri\": uri, \"content\": \"test_content\"}\n        \n        # Register the resource\n        self.mcp.register_resource(\n            \"test://{id}\",\n            test_resource,\n            \"Test resource description\"\n        )\n        \n        # Check that the resource was registered correctly\n        self.assertIn(\"test://{id}\", self.mcp.resources)\n        \n        # Get the resource\n        result = self.mcp.get_resource(\"test://123\")\n        self.assertEqual(result[\"content\"][\"uri\"], \"test://123\")\n        self.assertEqual(result[\"content\"][\"content\"], \"test_content\")\n        \n        # Check resource capability listing\n        capabilities = self.mcp.get_capabilities()\n        self.assertIn(\"test://{id}\", capabilities[\"resources\"])\n        self.assertEqual(capabilities[\"resources\"][\"test://{id}\"][\"description\"], \"Test resource description\")\n    \n    def test_module_discovery(self):\n        \"\"\"Test the module discovery mechanism.\"\"\"\n        # Create a mock module with register_tools function\n        mock_module = MagicMock()\n        \n        # Use patch to replace the importlib.import_module function\n        with patch('importlib.import_module', return_value=mock_module) as mock_import:\n            # Create a temporary directory with a mcp.py file\n            with tempfile.TemporaryDirectory() as temp_dir:\n                temp_dir_path = Path(temp_dir)\n                \n                # Create the mcp.py file\n                mcp_file = temp_dir_path / \"mcp.py\"\n                mcp_file.write_text(\"def register_tools(mcp): pass\")\n                \n                # Mock Path.iterdir() to return our temp directory\n                with patch('pathlib.Path.iterdir', return_value=[temp_dir_path]) as mock_iterdir:\n                    # Mock Path.is_dir() to return True\n                    with patch.object(temp_dir_path, 'is_dir', return_value=True) as mock_is_dir:\n                        # Mock Path.name to return a non-underscore name\n                        with patch.object(temp_dir_path, 'name', 'test_module') as mock_name:\n                            # Run module discovery\n                            self.mcp.discover_modules()\n                            \n                            # Verify that importlib.import_module was called with the right module name\n                            mock_import.assert_called_once()\n                            \n                            # Verify that register_tools was called\n                            mock_module.register_tools.assert_called_once_with(self.mcp)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "setUp",
        "type": "method",
        "start_line": 39,
        "end_line": 41,
        "code": "def setUp(self):\n        \"\"\"Set up a fresh MCP instance for each test.\"\"\"\n        self.mcp = MCP()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "test_tool_registration",
        "type": "method",
        "start_line": 43,
        "end_line": 70,
        "code": "def test_tool_registration(self):\n        \"\"\"Test registering and retrieving tools.\"\"\"\n        # Define a simple test tool\n        def test_tool(param1: str, param2: int) -> dict:\n            return {\"result\": f\"{param1}_{param2}\"}\n        \n        # Register the tool\n        self.mcp.register_tool(\n            \"test_tool\",\n            test_tool,\n            {\n                \"param1\": {\"type\": \"string\"},\n                \"param2\": {\"type\": \"integer\"}\n            },\n            \"Test tool description\"\n        )\n        \n        # Check that the tool was registered correctly\n        self.assertIn(\"test_tool\", self.mcp.tools)\n        \n        # Execute the tool\n        result = self.mcp.execute_tool(\"test_tool\", {\"param1\": \"test\", \"param2\": 42})\n        self.assertEqual(result[\"result\"][\"result\"], \"test_42\")\n        \n        # Check tool capability listing\n        capabilities = self.mcp.get_capabilities()\n        self.assertIn(\"test_tool\", capabilities[\"tools\"])\n        self.assertEqual(capabilities[\"tools\"][\"test_tool\"][\"description\"], \"Test tool description\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "test_resource_registration",
        "type": "method",
        "start_line": 72,
        "end_line": 96,
        "code": "def test_resource_registration(self):\n        \"\"\"Test registering and retrieving resources.\"\"\"\n        # Define a simple test resource retriever\n        def test_resource(uri: str) -> dict:\n            return {\"uri\": uri, \"content\": \"test_content\"}\n        \n        # Register the resource\n        self.mcp.register_resource(\n            \"test://{id}\",\n            test_resource,\n            \"Test resource description\"\n        )\n        \n        # Check that the resource was registered correctly\n        self.assertIn(\"test://{id}\", self.mcp.resources)\n        \n        # Get the resource\n        result = self.mcp.get_resource(\"test://123\")\n        self.assertEqual(result[\"content\"][\"uri\"], \"test://123\")\n        self.assertEqual(result[\"content\"][\"content\"], \"test_content\")\n        \n        # Check resource capability listing\n        capabilities = self.mcp.get_capabilities()\n        self.assertIn(\"test://{id}\", capabilities[\"resources\"])\n        self.assertEqual(capabilities[\"resources\"][\"test://{id}\"][\"description\"], \"Test resource description\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "test_module_discovery",
        "type": "method",
        "start_line": 98,
        "end_line": 126,
        "code": "def test_module_discovery(self):\n        \"\"\"Test the module discovery mechanism.\"\"\"\n        # Create a mock module with register_tools function\n        mock_module = MagicMock()\n        \n        # Use patch to replace the importlib.import_module function\n        with patch('importlib.import_module', return_value=mock_module) as mock_import:\n            # Create a temporary directory with a mcp.py file\n            with tempfile.TemporaryDirectory() as temp_dir:\n                temp_dir_path = Path(temp_dir)\n                \n                # Create the mcp.py file\n                mcp_file = temp_dir_path / \"mcp.py\"\n                mcp_file.write_text(\"def register_tools(mcp): pass\")\n                \n                # Mock Path.iterdir() to return our temp directory\n                with patch('pathlib.Path.iterdir', return_value=[temp_dir_path]) as mock_iterdir:\n                    # Mock Path.is_dir() to return True\n                    with patch.object(temp_dir_path, 'is_dir', return_value=True) as mock_is_dir:\n                        # Mock Path.name to return a non-underscore name\n                        with patch.object(temp_dir_path, 'name', 'test_module') as mock_name:\n                            # Run module discovery\n                            self.mcp.discover_modules()\n                            \n                            # Verify that importlib.import_module was called with the right module name\n                            mock_import.assert_called_once()\n                            \n                            # Verify that register_tools was called\n                            mock_module.register_tools.assert_called_once_with(self.mcp)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "TestMCPCLI",
        "type": "class",
        "start_line": 129,
        "end_line": 168,
        "code": "class TestMCPCLI(unittest.TestCase):\n    \"\"\"Test the MCP CLI functionality.\"\"\"\n    \n    def test_list_capabilities(self):\n        \"\"\"Test listing capabilities through the CLI.\"\"\"\n        # Mock stdout to capture output\n        with patch('sys.stdout', new_callable=io.StringIO) as mock_stdout:\n            # Mock import_mcp to return a mock MCP instance\n            mock_mcp = MagicMock()\n            mock_mcp.get_capabilities.return_value = {\n                \"tools\": {\"test_tool\": {\"description\": \"Test tool\"}},\n                \"resources\": {\"test://uri\": {\"description\": \"Test resource\"}},\n                \"version\": \"1.0.0\",\n                \"name\": \"Test MCP\"\n            }\n            \n            mock_init = MagicMock()\n            \n            with patch('src.mcp.cli.import_mcp', return_value=(mock_mcp, mock_init)) as mock_import:\n                # Create mock args\n                mock_args = MagicMock()\n                \n                # Import the CLI module\n                from src.mcp.cli import list_capabilities\n                \n                # Run list_capabilities\n                list_capabilities(mock_args)\n                \n                # Verify import_mcp was called\n                mock_import.assert_called_once()\n                \n                # Verify get_capabilities was called\n                mock_mcp.get_capabilities.assert_called_once()\n                \n                # Check output\n                output = mock_stdout.getvalue()\n                self.assertIn(\"test_tool\", output)\n                self.assertIn(\"Test tool\", output)\n                self.assertIn(\"test://uri\", output)\n                self.assertIn(\"Test resource\", output)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "test_list_capabilities",
        "type": "method",
        "start_line": 132,
        "end_line": 168,
        "code": "def test_list_capabilities(self):\n        \"\"\"Test listing capabilities through the CLI.\"\"\"\n        # Mock stdout to capture output\n        with patch('sys.stdout', new_callable=io.StringIO) as mock_stdout:\n            # Mock import_mcp to return a mock MCP instance\n            mock_mcp = MagicMock()\n            mock_mcp.get_capabilities.return_value = {\n                \"tools\": {\"test_tool\": {\"description\": \"Test tool\"}},\n                \"resources\": {\"test://uri\": {\"description\": \"Test resource\"}},\n                \"version\": \"1.0.0\",\n                \"name\": \"Test MCP\"\n            }\n            \n            mock_init = MagicMock()\n            \n            with patch('src.mcp.cli.import_mcp', return_value=(mock_mcp, mock_init)) as mock_import:\n                # Create mock args\n                mock_args = MagicMock()\n                \n                # Import the CLI module\n                from src.mcp.cli import list_capabilities\n                \n                # Run list_capabilities\n                list_capabilities(mock_args)\n                \n                # Verify import_mcp was called\n                mock_import.assert_called_once()\n                \n                # Verify get_capabilities was called\n                mock_mcp.get_capabilities.assert_called_once()\n                \n                # Check output\n                output = mock_stdout.getvalue()\n                self.assertIn(\"test_tool\", output)\n                self.assertIn(\"Test tool\", output)\n                self.assertIn(\"test://uri\", output)\n                self.assertIn(\"Test resource\", output)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "TestMCPServers",
        "type": "class",
        "start_line": 171,
        "end_line": 245,
        "code": "class TestMCPServers(unittest.TestCase):\n    \"\"\"Test the MCP server implementations.\"\"\"\n    \n    def test_http_server(self):\n        \"\"\"Test the HTTP server implementation.\"\"\"\n        # This test would start an actual HTTP server, send requests, and check responses\n        # For simplicity in a test environment, I'll just verify the server classes exist\n        \n        # Import the HTTP server\n        from src.mcp.server_http import MCPHTTPServer, MCPHTTPHandler\n        \n        # Create server with mock MCP instance\n        mock_mcp = MagicMock()\n        mock_mcp.get_capabilities.return_value = {\"tools\": {}, \"resources\": {}}\n        \n        with patch('src.mcp.server_http.initialize') as mock_init:\n            with patch('src.mcp.server_http.mcp_instance', mock_mcp):\n                # Mock HTTPServer to prevent actual server start\n                with patch('src.mcp.server_http.HTTPServer') as mock_http_server:\n                    # Mock threading.Thread to prevent actual thread start\n                    with patch('threading.Thread') as mock_thread:\n                        # Create server instance\n                        server = MCPHTTPServer(host=\"localhost\", port=8080)\n                        \n                        # Try to start the server (should be mocked)\n                        with patch.object(server, '_server_thread') as mock_server_thread:\n                            # Stop immediately\n                            with patch.object(server, 'running', False):\n                                server.start()\n                                \n                                # Verify that initialize was called\n                                mock_init.assert_called_once()\n                                \n                                # Verify that HTTPServer was created\n                                mock_http_server.assert_called_once()\n                                \n                                # Verify that Thread was created\n                                mock_thread.assert_called_once()\n    \n    def test_stdio_server(self):\n        \"\"\"Test the stdio server implementation.\"\"\"\n        # Similar to HTTP server test, verify the server class exists\n        \n        # Import the stdio server\n        from src.mcp.server_stdio import StdioServer\n        \n        # Create server with mock MCP instance\n        mock_mcp = MagicMock()\n        mock_mcp.get_capabilities.return_value = {\"tools\": {}, \"resources\": {}}\n        \n        with patch('src.mcp.server_stdio.initialize') as mock_init:\n            with patch('src.mcp.server_stdio.mcp_instance', mock_mcp):\n                # Mock sys.stdin and sys.stdout\n                with patch('sys.stdin') as mock_stdin:\n                    with patch('sys.stdout') as mock_stdout:\n                        # Mock queue.Queue to prevent actual queue operations\n                        with patch('queue.Queue') as mock_queue:\n                            # Mock threading.Thread to prevent actual thread start\n                            with patch('threading.Thread') as mock_thread:\n                                # Create server instance\n                                server = StdioServer()\n                                \n                                # Try to start the server (should be mocked)\n                                with patch.object(server, '_reader_thread') as mock_reader_thread:\n                                    with patch.object(server, '_writer_thread') as mock_writer_thread:\n                                        with patch.object(server, '_processor_thread') as mock_processor_thread:\n                                            # Stop immediately\n                                            with patch.object(server, 'running', False):\n                                                server.start()\n                                                \n                                                # Verify that initialize was called\n                                                mock_init.assert_called_once()\n                                                \n                                                # Verify that Thread was created at least once\n                                                self.assertGreater(mock_thread.call_count, 0)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "test_http_server",
        "type": "method",
        "start_line": 174,
        "end_line": 208,
        "code": "def test_http_server(self):\n        \"\"\"Test the HTTP server implementation.\"\"\"\n        # This test would start an actual HTTP server, send requests, and check responses\n        # For simplicity in a test environment, I'll just verify the server classes exist\n        \n        # Import the HTTP server\n        from src.mcp.server_http import MCPHTTPServer, MCPHTTPHandler\n        \n        # Create server with mock MCP instance\n        mock_mcp = MagicMock()\n        mock_mcp.get_capabilities.return_value = {\"tools\": {}, \"resources\": {}}\n        \n        with patch('src.mcp.server_http.initialize') as mock_init:\n            with patch('src.mcp.server_http.mcp_instance', mock_mcp):\n                # Mock HTTPServer to prevent actual server start\n                with patch('src.mcp.server_http.HTTPServer') as mock_http_server:\n                    # Mock threading.Thread to prevent actual thread start\n                    with patch('threading.Thread') as mock_thread:\n                        # Create server instance\n                        server = MCPHTTPServer(host=\"localhost\", port=8080)\n                        \n                        # Try to start the server (should be mocked)\n                        with patch.object(server, '_server_thread') as mock_server_thread:\n                            # Stop immediately\n                            with patch.object(server, 'running', False):\n                                server.start()\n                                \n                                # Verify that initialize was called\n                                mock_init.assert_called_once()\n                                \n                                # Verify that HTTPServer was created\n                                mock_http_server.assert_called_once()\n                                \n                                # Verify that Thread was created\n                                mock_thread.assert_called_once()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "test_stdio_server",
        "type": "method",
        "start_line": 210,
        "end_line": 245,
        "code": "def test_stdio_server(self):\n        \"\"\"Test the stdio server implementation.\"\"\"\n        # Similar to HTTP server test, verify the server class exists\n        \n        # Import the stdio server\n        from src.mcp.server_stdio import StdioServer\n        \n        # Create server with mock MCP instance\n        mock_mcp = MagicMock()\n        mock_mcp.get_capabilities.return_value = {\"tools\": {}, \"resources\": {}}\n        \n        with patch('src.mcp.server_stdio.initialize') as mock_init:\n            with patch('src.mcp.server_stdio.mcp_instance', mock_mcp):\n                # Mock sys.stdin and sys.stdout\n                with patch('sys.stdin') as mock_stdin:\n                    with patch('sys.stdout') as mock_stdout:\n                        # Mock queue.Queue to prevent actual queue operations\n                        with patch('queue.Queue') as mock_queue:\n                            # Mock threading.Thread to prevent actual thread start\n                            with patch('threading.Thread') as mock_thread:\n                                # Create server instance\n                                server = StdioServer()\n                                \n                                # Try to start the server (should be mocked)\n                                with patch.object(server, '_reader_thread') as mock_reader_thread:\n                                    with patch.object(server, '_writer_thread') as mock_writer_thread:\n                                        with patch.object(server, '_processor_thread') as mock_processor_thread:\n                                            # Stop immediately\n                                            with patch.object(server, 'running', False):\n                                                server.start()\n                                                \n                                                # Verify that initialize was called\n                                                mock_init.assert_called_once()\n                                                \n                                                # Verify that Thread was created at least once\n                                                self.assertGreater(mock_thread.call_count, 0)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "TestIntegration",
        "type": "class",
        "start_line": 248,
        "end_line": 329,
        "code": "class TestIntegration(unittest.TestCase):\n    \"\"\"Test integration with other modules.\"\"\"\n    \n    def test_visualization_integration(self):\n        \"\"\"Test integration with the visualization module.\"\"\"\n        # Skip if visualization module doesn't exist\n        try:\n            importlib.import_module(\"src.visualization.mcp\")\n        except ImportError:\n            self.skipTest(\"Visualization module not found\")\n        \n        # Create MCP instance and discover modules\n        mcp = MCP()\n        \n        # Mock Path.iterdir to return a fixed set of directories\n        mock_dirs = []\n        visualization_dir = MagicMock()\n        visualization_dir.is_dir.return_value = True\n        visualization_dir.name = \"visualization\"\n        \n        # Mock visualization_dir / \"mcp.py\" to exist\n        visualization_mcp_file = MagicMock()\n        visualization_mcp_file.exists.return_value = True\n        \n        # Make Path / return the mcp file\n        visualization_dir.__truediv__.return_value = visualization_mcp_file\n        \n        mock_dirs.append(visualization_dir)\n        \n        with patch('pathlib.Path.iterdir', return_value=mock_dirs):\n            # Mock importlib.import_module to return real visualization.mcp module\n            with patch('importlib.import_module', return_value=importlib.import_module(\"src.visualization.mcp\")):\n                # Discover modules\n                mcp.discover_modules()\n                \n                # Check that visualization tools were registered\n                self.assertIn(\"visualize_gnn_file\", mcp.tools)\n                self.assertIn(\"visualize_gnn_directory\", mcp.tools)\n                self.assertIn(\"parse_gnn_file\", mcp.tools)\n                \n                # Check that visualization resources were registered\n                self.assertIn(\"visualization://{output_directory}\", mcp.resources)\n    \n    def test_tests_integration(self):\n        \"\"\"Test integration with the tests module.\"\"\"\n        # Skip if tests module doesn't exist\n        try:\n            importlib.import_module(\"src.tests.mcp\")\n        except ImportError:\n            self.skipTest(\"Tests module not found\")\n        \n        # Create MCP instance and discover modules\n        mcp = MCP()\n        \n        # Mock Path.iterdir to return a fixed set of directories\n        mock_dirs = []\n        tests_dir = MagicMock()\n        tests_dir.is_dir.return_value = True\n        tests_dir.name = \"tests\"\n        \n        # Mock tests_dir / \"mcp.py\" to exist\n        tests_mcp_file = MagicMock()\n        tests_mcp_file.exists.return_value = True\n        \n        # Make Path / return the mcp file\n        tests_dir.__truediv__.return_value = tests_mcp_file\n        \n        mock_dirs.append(tests_dir)\n        \n        with patch('pathlib.Path.iterdir', return_value=mock_dirs):\n            # Mock importlib.import_module to return real tests.mcp module\n            with patch('importlib.import_module', return_value=importlib.import_module(\"src.tests.mcp\")):\n                # Discover modules\n                mcp.discover_modules()\n                \n                # Check that tests tools were registered\n                self.assertIn(\"run_gnn_type_checker\", mcp.tools)\n                self.assertIn(\"run_gnn_type_checker_on_directory\", mcp.tools)\n                self.assertIn(\"run_gnn_unit_tests\", mcp.tools)\n                \n                # Check that tests resources were registered\n                self.assertIn(\"test-report://{report_file}\", mcp.resources)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "test_visualization_integration",
        "type": "method",
        "start_line": 251,
        "end_line": 289,
        "code": "def test_visualization_integration(self):\n        \"\"\"Test integration with the visualization module.\"\"\"\n        # Skip if visualization module doesn't exist\n        try:\n            importlib.import_module(\"src.visualization.mcp\")\n        except ImportError:\n            self.skipTest(\"Visualization module not found\")\n        \n        # Create MCP instance and discover modules\n        mcp = MCP()\n        \n        # Mock Path.iterdir to return a fixed set of directories\n        mock_dirs = []\n        visualization_dir = MagicMock()\n        visualization_dir.is_dir.return_value = True\n        visualization_dir.name = \"visualization\"\n        \n        # Mock visualization_dir / \"mcp.py\" to exist\n        visualization_mcp_file = MagicMock()\n        visualization_mcp_file.exists.return_value = True\n        \n        # Make Path / return the mcp file\n        visualization_dir.__truediv__.return_value = visualization_mcp_file\n        \n        mock_dirs.append(visualization_dir)\n        \n        with patch('pathlib.Path.iterdir', return_value=mock_dirs):\n            # Mock importlib.import_module to return real visualization.mcp module\n            with patch('importlib.import_module', return_value=importlib.import_module(\"src.visualization.mcp\")):\n                # Discover modules\n                mcp.discover_modules()\n                \n                # Check that visualization tools were registered\n                self.assertIn(\"visualize_gnn_file\", mcp.tools)\n                self.assertIn(\"visualize_gnn_directory\", mcp.tools)\n                self.assertIn(\"parse_gnn_file\", mcp.tools)\n                \n                # Check that visualization resources were registered\n                self.assertIn(\"visualization://{output_directory}\", mcp.resources)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "test_tests_integration",
        "type": "method",
        "start_line": 291,
        "end_line": 329,
        "code": "def test_tests_integration(self):\n        \"\"\"Test integration with the tests module.\"\"\"\n        # Skip if tests module doesn't exist\n        try:\n            importlib.import_module(\"src.tests.mcp\")\n        except ImportError:\n            self.skipTest(\"Tests module not found\")\n        \n        # Create MCP instance and discover modules\n        mcp = MCP()\n        \n        # Mock Path.iterdir to return a fixed set of directories\n        mock_dirs = []\n        tests_dir = MagicMock()\n        tests_dir.is_dir.return_value = True\n        tests_dir.name = \"tests\"\n        \n        # Mock tests_dir / \"mcp.py\" to exist\n        tests_mcp_file = MagicMock()\n        tests_mcp_file.exists.return_value = True\n        \n        # Make Path / return the mcp file\n        tests_dir.__truediv__.return_value = tests_mcp_file\n        \n        mock_dirs.append(tests_dir)\n        \n        with patch('pathlib.Path.iterdir', return_value=mock_dirs):\n            # Mock importlib.import_module to return real tests.mcp module\n            with patch('importlib.import_module', return_value=importlib.import_module(\"src.tests.mcp\")):\n                # Discover modules\n                mcp.discover_modules()\n                \n                # Check that tests tools were registered\n                self.assertIn(\"run_gnn_type_checker\", mcp.tools)\n                self.assertIn(\"run_gnn_type_checker_on_directory\", mcp.tools)\n                self.assertIn(\"run_gnn_unit_tests\", mcp.tools)\n                \n                # Check that tests resources were registered\n                self.assertIn(\"test-report://{report_file}\", mcp.resources)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      },
      {
        "name": "run_all_tests",
        "type": "function",
        "start_line": 332,
        "end_line": 378,
        "code": "def run_all_tests():\n    \"\"\"Run all MCP tests and generate a report.\"\"\"\n    # Create a test suite\n    test_suite = unittest.TestSuite()\n    \n    # Add test cases\n    test_suite.addTest(unittest.makeSuite(TestMCPCore))\n    test_suite.addTest(unittest.makeSuite(TestMCPCLI))\n    test_suite.addTest(unittest.makeSuite(TestMCPServers))\n    test_suite.addTest(unittest.makeSuite(TestIntegration))\n    \n    # Create a test runner\n    test_runner = unittest.TextTestRunner(verbosity=2)\n    \n    # Run the tests\n    test_result = test_runner.run(test_suite)\n    \n    # Generate a report\n    report = {\n        \"total_tests\": test_result.testsRun,\n        \"failures\": len(test_result.failures),\n        \"errors\": len(test_result.errors),\n        \"skipped\": len(test_result.skipped),\n        \"success\": test_result.wasSuccessful()\n    }\n    \n    # Print the report\n    print(\"\\n\\n===== MCP TEST REPORT =====\")\n    print(f\"Total tests: {report['total_tests']}\")\n    print(f\"Failures: {report['failures']}\")\n    print(f\"Errors: {report['errors']}\")\n    print(f\"Skipped: {report['skipped']}\")\n    print(f\"Success: {'Yes' if report['success'] else 'No'}\")\n    \n    if report['failures'] > 0:\n        print(\"\\nFailures:\")\n        for failure in test_result.failures:\n            print(f\"- {failure[0]}: {failure[1][:200]}...\")\n    \n    if report['errors'] > 0:\n        print(\"\\nErrors:\")\n        for error in test_result.errors:\n            print(f\"- {error[0]}: {error[1][:200]}...\")\n    \n    print(\"===========================\\n\")\n    \n    return report",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/test_mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py": [
      {
        "name": "MCPHTTPHandler",
        "type": "class",
        "start_line": 22,
        "end_line": 154,
        "code": "class MCPHTTPHandler(BaseHTTPRequestHandler):\n    \"\"\"HTTP request handler for MCP.\"\"\"\n    \n    def do_POST(self):\n        \"\"\"Handle POST requests.\"\"\"\n        # Parse path\n        parsed_path = urllib.parse.urlparse(self.path)\n        \n        # Check content length\n        content_length = int(self.headers.get('Content-Length', 0))\n        if content_length <= 0:\n            self._send_error(400, \"Missing request body\")\n            return\n        \n        # Read and parse request body\n        try:\n            request_body = self.rfile.read(content_length)\n            request = json.loads(request_body)\n        except json.JSONDecodeError:\n            self._send_error(400, \"Invalid JSON request\")\n            return\n        \n        # Process JSON-RPC message\n        if \"jsonrpc\" in request and request[\"jsonrpc\"] == \"2.0\":\n            self._handle_jsonrpc(request)\n        else:\n            self._send_error(400, \"Invalid request format\")\n    \n    def _handle_jsonrpc(self, request: Dict[str, Any]):\n        \"\"\"Process a JSON-RPC message.\"\"\"\n        if \"method\" not in request:\n            self._send_jsonrpc_error(request.get(\"id\"), -32600, \"Invalid Request\")\n            return\n        \n        method = request[\"method\"]\n        params = request.get(\"params\", {})\n        \n        # Handle standard methods\n        try:\n            if method == \"mcp.capabilities\":\n                self._handle_capabilities(request.get(\"id\"))\n            elif method == \"mcp.tool.execute\":\n                self._handle_execute_tool(request.get(\"id\"), params)\n            elif method == \"mcp.resource.get\":\n                self._handle_get_resource(request.get(\"id\"), params)\n            else:\n                self._send_jsonrpc_error(request.get(\"id\"), -32601, f\"Method not found: {method}\")\n        except Exception as e:\n            logger.error(f\"Error handling method {method}: {str(e)}\")\n            traceback.print_exc()\n            self._send_jsonrpc_error(request.get(\"id\"), -32603, f\"Internal error: {str(e)}\")\n    \n    def _handle_capabilities(self, request_id: Optional[str]):\n        \"\"\"Handle capabilities request.\"\"\"\n        capabilities = mcp_instance.get_capabilities()\n        self._send_jsonrpc_result(request_id, capabilities)\n    \n    def _handle_execute_tool(self, request_id: Optional[str], params: Dict[str, Any]):\n        \"\"\"Handle tool execution request.\"\"\"\n        if \"name\" not in params or \"params\" not in params:\n            self._send_jsonrpc_error(request_id, -32602, \"Invalid params for tool execution\")\n            return\n        \n        tool_name = params[\"name\"]\n        tool_params = params[\"params\"]\n        \n        try:\n            result = mcp_instance.execute_tool(tool_name, tool_params)\n            self._send_jsonrpc_result(request_id, result)\n        except Exception as e:\n            logger.error(f\"Error executing tool {tool_name}: {str(e)}\")\n            self._send_jsonrpc_error(request_id, -32603, f\"Internal error: {str(e)}\")\n    \n    def _handle_get_resource(self, request_id: Optional[str], params: Dict[str, Any]):\n        \"\"\"Handle resource retrieval request.\"\"\"\n        if \"uri\" not in params:\n            self._send_jsonrpc_error(request_id, -32602, \"Invalid params for resource retrieval\")\n            return\n        \n        uri = params[\"uri\"]\n        \n        try:\n            result = mcp_instance.get_resource(uri)\n            self._send_jsonrpc_result(request_id, result)\n        except Exception as e:\n            logger.error(f\"Error retrieving resource {uri}: {str(e)}\")\n            self._send_jsonrpc_error(request_id, -32603, f\"Internal error: {str(e)}\")\n    \n    def _send_jsonrpc_result(self, request_id: Optional[str], result: Any):\n        \"\"\"Send a successful JSON-RPC response.\"\"\"\n        response = {\n            \"jsonrpc\": \"2.0\",\n            \"id\": request_id,\n            \"result\": result\n        }\n        self._send_json_response(200, response)\n    \n    def _send_jsonrpc_error(self, request_id: Optional[str], code: int, message: str):\n        \"\"\"Send a JSON-RPC error response.\"\"\"\n        response = {\n            \"jsonrpc\": \"2.0\",\n            \"id\": request_id,\n            \"error\": {\n                \"code\": code,\n                \"message\": message\n            }\n        }\n        self._send_json_response(200, response)\n    \n    def _send_json_response(self, status_code: int, data: Any):\n        \"\"\"Send a JSON response.\"\"\"\n        self.send_response(status_code)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        \n        response_body = json.dumps(data).encode('utf-8')\n        self.wfile.write(response_body)\n    \n    def _send_error(self, status_code: int, message: str):\n        \"\"\"Send an HTTP error response.\"\"\"\n        self.send_response(status_code)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        \n        error_body = json.dumps({\n            \"error\": message\n        }).encode('utf-8')\n        \n        self.wfile.write(error_body)\n    \n    def log_message(self, format, *args):\n        \"\"\"Override log_message to use our logger.\"\"\"\n        logger.info(\"%s - - [%s] %s\" % (self.client_address[0], self.log_date_time_string(), format % args))",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "do_POST",
        "type": "method",
        "start_line": 25,
        "end_line": 48,
        "code": "def do_POST(self):\n        \"\"\"Handle POST requests.\"\"\"\n        # Parse path\n        parsed_path = urllib.parse.urlparse(self.path)\n        \n        # Check content length\n        content_length = int(self.headers.get('Content-Length', 0))\n        if content_length <= 0:\n            self._send_error(400, \"Missing request body\")\n            return\n        \n        # Read and parse request body\n        try:\n            request_body = self.rfile.read(content_length)\n            request = json.loads(request_body)\n        except json.JSONDecodeError:\n            self._send_error(400, \"Invalid JSON request\")\n            return\n        \n        # Process JSON-RPC message\n        if \"jsonrpc\" in request and request[\"jsonrpc\"] == \"2.0\":\n            self._handle_jsonrpc(request)\n        else:\n            self._send_error(400, \"Invalid request format\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "_handle_jsonrpc",
        "type": "method",
        "start_line": 50,
        "end_line": 72,
        "code": "def _handle_jsonrpc(self, request: Dict[str, Any]):\n        \"\"\"Process a JSON-RPC message.\"\"\"\n        if \"method\" not in request:\n            self._send_jsonrpc_error(request.get(\"id\"), -32600, \"Invalid Request\")\n            return\n        \n        method = request[\"method\"]\n        params = request.get(\"params\", {})\n        \n        # Handle standard methods\n        try:\n            if method == \"mcp.capabilities\":\n                self._handle_capabilities(request.get(\"id\"))\n            elif method == \"mcp.tool.execute\":\n                self._handle_execute_tool(request.get(\"id\"), params)\n            elif method == \"mcp.resource.get\":\n                self._handle_get_resource(request.get(\"id\"), params)\n            else:\n                self._send_jsonrpc_error(request.get(\"id\"), -32601, f\"Method not found: {method}\")\n        except Exception as e:\n            logger.error(f\"Error handling method {method}: {str(e)}\")\n            traceback.print_exc()\n            self._send_jsonrpc_error(request.get(\"id\"), -32603, f\"Internal error: {str(e)}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "_handle_capabilities",
        "type": "method",
        "start_line": 74,
        "end_line": 77,
        "code": "def _handle_capabilities(self, request_id: Optional[str]):\n        \"\"\"Handle capabilities request.\"\"\"\n        capabilities = mcp_instance.get_capabilities()\n        self._send_jsonrpc_result(request_id, capabilities)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "_handle_execute_tool",
        "type": "method",
        "start_line": 79,
        "end_line": 93,
        "code": "def _handle_execute_tool(self, request_id: Optional[str], params: Dict[str, Any]):\n        \"\"\"Handle tool execution request.\"\"\"\n        if \"name\" not in params or \"params\" not in params:\n            self._send_jsonrpc_error(request_id, -32602, \"Invalid params for tool execution\")\n            return\n        \n        tool_name = params[\"name\"]\n        tool_params = params[\"params\"]\n        \n        try:\n            result = mcp_instance.execute_tool(tool_name, tool_params)\n            self._send_jsonrpc_result(request_id, result)\n        except Exception as e:\n            logger.error(f\"Error executing tool {tool_name}: {str(e)}\")\n            self._send_jsonrpc_error(request_id, -32603, f\"Internal error: {str(e)}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "_handle_get_resource",
        "type": "method",
        "start_line": 95,
        "end_line": 108,
        "code": "def _handle_get_resource(self, request_id: Optional[str], params: Dict[str, Any]):\n        \"\"\"Handle resource retrieval request.\"\"\"\n        if \"uri\" not in params:\n            self._send_jsonrpc_error(request_id, -32602, \"Invalid params for resource retrieval\")\n            return\n        \n        uri = params[\"uri\"]\n        \n        try:\n            result = mcp_instance.get_resource(uri)\n            self._send_jsonrpc_result(request_id, result)\n        except Exception as e:\n            logger.error(f\"Error retrieving resource {uri}: {str(e)}\")\n            self._send_jsonrpc_error(request_id, -32603, f\"Internal error: {str(e)}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "_send_jsonrpc_result",
        "type": "method",
        "start_line": 110,
        "end_line": 117,
        "code": "def _send_jsonrpc_result(self, request_id: Optional[str], result: Any):\n        \"\"\"Send a successful JSON-RPC response.\"\"\"\n        response = {\n            \"jsonrpc\": \"2.0\",\n            \"id\": request_id,\n            \"result\": result\n        }\n        self._send_json_response(200, response)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "_send_jsonrpc_error",
        "type": "method",
        "start_line": 119,
        "end_line": 129,
        "code": "def _send_jsonrpc_error(self, request_id: Optional[str], code: int, message: str):\n        \"\"\"Send a JSON-RPC error response.\"\"\"\n        response = {\n            \"jsonrpc\": \"2.0\",\n            \"id\": request_id,\n            \"error\": {\n                \"code\": code,\n                \"message\": message\n            }\n        }\n        self._send_json_response(200, response)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "_send_json_response",
        "type": "method",
        "start_line": 131,
        "end_line": 138,
        "code": "def _send_json_response(self, status_code: int, data: Any):\n        \"\"\"Send a JSON response.\"\"\"\n        self.send_response(status_code)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        \n        response_body = json.dumps(data).encode('utf-8')\n        self.wfile.write(response_body)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "_send_error",
        "type": "method",
        "start_line": 140,
        "end_line": 150,
        "code": "def _send_error(self, status_code: int, message: str):\n        \"\"\"Send an HTTP error response.\"\"\"\n        self.send_response(status_code)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        \n        error_body = json.dumps({\n            \"error\": message\n        }).encode('utf-8')\n        \n        self.wfile.write(error_body)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "log_message",
        "type": "method",
        "start_line": 152,
        "end_line": 154,
        "code": "def log_message(self, format, *args):\n        \"\"\"Override log_message to use our logger.\"\"\"\n        logger.info(\"%s - - [%s] %s\" % (self.client_address[0], self.log_date_time_string(), format % args))",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "MCPHTTPServer",
        "type": "class",
        "start_line": 156,
        "end_line": 206,
        "code": "class MCPHTTPServer:\n    \"\"\"HTTP server for MCP.\"\"\"\n    \n    def __init__(self, host: str = \"127.0.0.1\", port: int = 8080):\n        self.host = host\n        self.port = port\n        self.server = None\n        self.server_thread = None\n        self.running = False\n    \n    def start(self):\n        \"\"\"Start the HTTP server.\"\"\"\n        # Initialize MCP\n        initialize()\n        \n        # Create and start server\n        self.server = HTTPServer((self.host, self.port), MCPHTTPHandler)\n        self.running = True\n        \n        logger.info(f\"Starting MCP HTTP server on {self.host}:{self.port}\")\n        \n        # Run server in a separate thread\n        self.server_thread = threading.Thread(target=self._server_thread)\n        self.server_thread.daemon = True\n        self.server_thread.start()\n        \n        # Wait for Ctrl+C\n        try:\n            while self.running:\n                self.server_thread.join(0.1)\n                if not self.server_thread.is_alive():\n                    self.running = False\n        except KeyboardInterrupt:\n            logger.info(\"Keyboard interrupt received, stopping server\")\n            self.stop()\n    \n    def _server_thread(self):\n        \"\"\"Thread function that runs the HTTP server.\"\"\"\n        try:\n            self.server.serve_forever()\n        except Exception as e:\n            logger.error(f\"Error in HTTP server: {str(e)}\")\n            self.running = False\n    \n    def stop(self):\n        \"\"\"Stop the HTTP server.\"\"\"\n        if self.server:\n            logger.info(\"Stopping HTTP server\")\n            self.server.shutdown()\n            self.server.server_close()\n            self.running = False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 159,
        "end_line": 164,
        "code": "def __init__(self, host: str = \"127.0.0.1\", port: int = 8080):\n        self.host = host\n        self.port = port\n        self.server = None\n        self.server_thread = None\n        self.running = False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "start",
        "type": "method",
        "start_line": 166,
        "end_line": 190,
        "code": "def start(self):\n        \"\"\"Start the HTTP server.\"\"\"\n        # Initialize MCP\n        initialize()\n        \n        # Create and start server\n        self.server = HTTPServer((self.host, self.port), MCPHTTPHandler)\n        self.running = True\n        \n        logger.info(f\"Starting MCP HTTP server on {self.host}:{self.port}\")\n        \n        # Run server in a separate thread\n        self.server_thread = threading.Thread(target=self._server_thread)\n        self.server_thread.daemon = True\n        self.server_thread.start()\n        \n        # Wait for Ctrl+C\n        try:\n            while self.running:\n                self.server_thread.join(0.1)\n                if not self.server_thread.is_alive():\n                    self.running = False\n        except KeyboardInterrupt:\n            logger.info(\"Keyboard interrupt received, stopping server\")\n            self.stop()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "_server_thread",
        "type": "method",
        "start_line": 192,
        "end_line": 198,
        "code": "def _server_thread(self):\n        \"\"\"Thread function that runs the HTTP server.\"\"\"\n        try:\n            self.server.serve_forever()\n        except Exception as e:\n            logger.error(f\"Error in HTTP server: {str(e)}\")\n            self.running = False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "stop",
        "type": "method",
        "start_line": 200,
        "end_line": 206,
        "code": "def stop(self):\n        \"\"\"Stop the HTTP server.\"\"\"\n        if self.server:\n            logger.info(\"Stopping HTTP server\")\n            self.server.shutdown()\n            self.server.server_close()\n            self.running = False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      },
      {
        "name": "start_http_server",
        "type": "function",
        "start_line": 208,
        "end_line": 211,
        "code": "def start_http_server(host: str = \"127.0.0.1\", port: int = 8080):\n    \"\"\"Start an MCP server using HTTP transport.\"\"\"\n    server = MCPHTTPServer(host, port)\n    server.start()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/server_http.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/meta_mcp.py": [
      {
        "name": "get_mcp_server_status",
        "type": "function",
        "start_line": 19,
        "end_line": 50,
        "code": "def get_mcp_server_status(mcp_instance_ref) -> Dict[str, Any]:\n    \"\"\"\n    Get the current status of the MCP server itself.\n    \n    Args:\n        mcp_instance_ref: A reference to the MCP instance running the server.\n                          This is passed by the registration mechanism.\n                          \n    Returns:\n        Dictionary server status information.\n    \"\"\"\n    uptime_seconds = time.time() - SERVER_START_TIME\n    uptime_str = time.strftime(\"%H:%M:%S\", time.gmtime(uptime_seconds))\n    \n    loaded_modules = list(mcp_instance_ref.modules.keys())\n    tool_count = len(mcp_instance_ref.tools)\n    resource_count = len(mcp_instance_ref.resources)\n    \n    return {\n        \"success\": True,\n        \"server_name\": mcp_instance_ref.get_capabilities().get(\"name\", \"Unknown GNN MCP Server\"),\n        \"server_version\": mcp_instance_ref.get_capabilities().get(\"version\", \"Unknown\"),\n        \"status\": \"running\",\n        \"start_time_unix\": SERVER_START_TIME,\n        \"uptime_seconds\": uptime_seconds,\n        \"uptime_formatted\": uptime_str,\n        \"loaded_modules_count\": len(loaded_modules),\n        \"loaded_modules\": loaded_modules,\n        \"registered_tools_count\": tool_count,\n        \"registered_resources_count\": resource_count,\n        # In a real scenario, you might add request counts, error rates etc.\n    }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/meta_mcp.py"
      },
      {
        "name": "get_mcp_auth_status",
        "type": "function",
        "start_line": 52,
        "end_line": 68,
        "code": "def get_mcp_auth_status(mcp_instance_ref) -> Dict[str, Any]:\n    \"\"\"\n    Get the authentication status of the MCP server.\n    \n    Args:\n        mcp_instance_ref: A reference to the MCP instance.\n        \n    Returns:\n        Dictionary with authentication status.\n    \"\"\"\n    # Currently, no specific auth is implemented beyond transport (stdio, http local)\n    return {\n        \"success\": True,\n        \"authentication_type\": \"none_implemented\",\n        \"access_level\": \"unrestricted_local_access\",\n        \"description\": \"Server does not implement explicit authentication. Relies on transport security.\"\n    }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/meta_mcp.py"
      },
      {
        "name": "get_mcp_encryption_status",
        "type": "function",
        "start_line": 70,
        "end_line": 87,
        "code": "def get_mcp_encryption_status(mcp_instance_ref) -> Dict[str, Any]:\n    \"\"\"\n    Get the encryption status of the MCP server connections.\n    \n    Args:\n        mcp_instance_ref: A reference to the MCP instance.\n\n    Returns:\n        Dictionary with encryption status.\n    \"\"\"\n    # Currently, stdio is unencrypted by default. HTTP is unencrypted by default.\n    # HTTPS would need to be explicitly configured.\n    return {\n        \"success\": True,\n        \"stdio_transport_encryption\": \"none (plaintext)\",\n        \"http_transport_encryption\": \"none (plaintext, HTTPS not configured by default)\",\n        \"data_at_rest_encryption\": \"not_applicable (server is stateless or relies on filesystem)\"\n    }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/meta_mcp.py"
      },
      {
        "name": "register_tools",
        "type": "function",
        "start_line": 90,
        "end_line": 132,
        "code": "def register_tools(mcp_instance): # This mcp_instance IS the main server's MCP instance\n    \"\"\"Register MCP meta-tools with the MCP server itself.\"\"\"\n    \n    # To call these tools, the mcp_instance needs to be passed. \n    # The MCP standard doesn't have a built-in way for a tool to get a reference to its host server.\n    # So, we'll wrap the tool functions to pass the mcp_instance.\n    \n    def get_status_wrapper():\n        return get_mcp_server_status(mcp_instance)\n        \n    def get_auth_wrapper():\n        return get_mcp_auth_status(mcp_instance)\n        \n    def get_encryption_wrapper():\n        return get_mcp_encryption_status(mcp_instance)\n        \n    mcp_instance.register_tool(\n        \"get_mcp_server_capabilities\", # Renaming from get_capabilities to avoid direct name clash if called by tool name\n        mcp_instance.get_capabilities, # Directly register the existing method\n        {},\n        \"Retrieves the full capabilities description of this MCP server, including all tools and resources.\"\n    )\n    \n    mcp_instance.register_tool(\n        \"get_mcp_server_status\",\n        get_status_wrapper, \n        {},\n        \"Provides the current operational status of the MCP server, including uptime and loaded modules.\"\n    )\n    \n    mcp_instance.register_tool(\n        \"get_mcp_server_auth_status\",\n        get_auth_wrapper,\n        {},\n        \"Describes the current authentication mechanisms and status of the MCP server.\"\n    )\n    \n    mcp_instance.register_tool(\n        \"get_mcp_server_encryption_status\",\n        get_encryption_wrapper,\n        {},\n        \"Describes the current encryption status for server transport and data handling.\"\n    )",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/meta_mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/cli.py": [
      {
        "name": "import_mcp",
        "type": "function",
        "start_line": 13,
        "end_line": 28,
        "code": "def import_mcp():\n    \"\"\"Import the MCP module dynamically.\"\"\"\n    try:\n        from . import mcp_instance, initialize\n        return mcp_instance, initialize\n    except ImportError:\n        # Try to import from path\n        mcp_path = Path(__file__).parent / \"mcp.py\"\n        if not mcp_path.exists():\n            raise ImportError(\"MCP module not found\")\n            \n        spec = importlib.util.spec_from_file_location(\"mcp\", mcp_path)\n        mcp_module = importlib.util.module_from_spec(spec)\n        spec.loader.exec_module(mcp_module)\n        \n        return mcp_module.mcp_instance, mcp_module.initialize",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/cli.py"
      },
      {
        "name": "list_capabilities",
        "type": "function",
        "start_line": 30,
        "end_line": 36,
        "code": "def list_capabilities(args):\n    \"\"\"List all available MCP capabilities.\"\"\"\n    mcp_instance, initialize = import_mcp()\n    initialize()\n    \n    capabilities = mcp_instance.get_capabilities()\n    print(json.dumps(capabilities, indent=2))",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/cli.py"
      },
      {
        "name": "execute_tool",
        "type": "function",
        "start_line": 38,
        "end_line": 56,
        "code": "def execute_tool(args):\n    \"\"\"Execute an MCP tool with the given parameters.\"\"\"\n    mcp_instance, initialize = import_mcp()\n    initialize()\n    \n    params = {}\n    if args.params:\n        try:\n            params = json.loads(args.params)\n        except json.JSONDecodeError:\n            logger.error(\"Invalid JSON parameters\")\n            sys.exit(1)\n    \n    try:\n        result = mcp_instance.execute_tool(args.tool_name, params)\n        print(json.dumps(result, indent=2))\n    except Exception as e:\n        logger.error(f\"Error executing tool: {str(e)}\")\n        sys.exit(1)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/cli.py"
      },
      {
        "name": "get_resource",
        "type": "function",
        "start_line": 58,
        "end_line": 68,
        "code": "def get_resource(args):\n    \"\"\"Retrieve an MCP resource.\"\"\"\n    mcp_instance, initialize = import_mcp()\n    initialize()\n    \n    try:\n        result = mcp_instance.get_resource(args.uri)\n        print(json.dumps(result, indent=2))\n    except Exception as e:\n        logger.error(f\"Error retrieving resource: {str(e)}\")\n        sys.exit(1)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/cli.py"
      },
      {
        "name": "start_server",
        "type": "function",
        "start_line": 70,
        "end_line": 88,
        "code": "def start_server(args):\n    \"\"\"Start the MCP server.\"\"\"\n    try:\n        # Import specific server implementation based on transport type\n        if args.transport == \"stdio\":\n            from .server_stdio import start_stdio_server\n            start_stdio_server()\n        elif args.transport == \"http\":\n            from .server_http import start_http_server\n            start_http_server(args.host, args.port)\n        else:\n            logger.error(f\"Unsupported transport: {args.transport}\")\n            sys.exit(1)\n    except ImportError as e:\n        logger.error(f\"Failed to import server implementation: {str(e)}\")\n        sys.exit(1)\n    except Exception as e:\n        logger.error(f\"Error starting server: {str(e)}\")\n        sys.exit(1)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/cli.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 90,
        "end_line": 122,
        "code": "def main():\n    parser = argparse.ArgumentParser(description=\"Model Context Protocol CLI\")\n    subparsers = parser.add_subparsers(dest=\"command\", help=\"Command to execute\")\n    \n    # List capabilities\n    list_parser = subparsers.add_parser(\"list\", help=\"List available capabilities\")\n    list_parser.set_defaults(func=list_capabilities)\n    \n    # Execute tool\n    execute_parser = subparsers.add_parser(\"execute\", help=\"Execute a tool\")\n    execute_parser.add_argument(\"tool_name\", help=\"Name of the tool to execute\")\n    execute_parser.add_argument(\"--params\", help=\"JSON parameters for the tool\")\n    execute_parser.set_defaults(func=execute_tool)\n    \n    # Get resource\n    resource_parser = subparsers.add_parser(\"resource\", help=\"Get a resource\")\n    resource_parser.add_argument(\"uri\", help=\"URI of the resource to retrieve\")\n    resource_parser.set_defaults(func=get_resource)\n    \n    # Start server\n    server_parser = subparsers.add_parser(\"server\", help=\"Start MCP server\")\n    server_parser.add_argument(\"--transport\", choices=[\"stdio\", \"http\"], default=\"stdio\",\n                              help=\"Transport mechanism to use\")\n    server_parser.add_argument(\"--host\", default=\"127.0.0.1\", help=\"Host for HTTP server\")\n    server_parser.add_argument(\"--port\", type=int, default=8080, help=\"Port for HTTP server\")\n    server_parser.set_defaults(func=start_server)\n    \n    args = parser.parse_args()\n    if not hasattr(args, \"func\"):\n        parser.print_help()\n        sys.exit(1)\n    \n    args.func(args)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/cli.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/mcp/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/matrix_visualizer.py": [
      {
        "name": "MatrixVisualizer",
        "type": "class",
        "start_line": 14,
        "end_line": 254,
        "code": "class MatrixVisualizer:\n    \"\"\"\n    A class for visualizing matrices extracted from GNN models.\n    \n    This visualizer provides methods to create heatmaps and other\n    visualizations of matrices in the model.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the matrix visualizer.\"\"\"\n        pass\n    \n    def visualize_all_matrices(self, parsed_data: Dict[str, Any], output_dir: Path) -> List[str]:\n        \"\"\"\n        Generate visualizations for all matrices in the model.\n        \n        Args:\n            parsed_data: Parsed GNN model data\n            output_dir: Directory to save visualizations\n            \n        Returns:\n            List of paths to saved visualization files\n        \"\"\"\n        saved_files = []\n        \n        # Extract matrices from InitialParameterization\n        if 'InitialParameterization' in parsed_data:\n            matrices = self._extract_matrices(parsed_data['InitialParameterization'])\n            \n            # Create individual heatmaps\n            for matrix_name, matrix_data in matrices.items():\n                file_path = self.create_heatmap(matrix_name, matrix_data, output_dir)\n                if file_path:\n                    saved_files.append(file_path)\n            \n            # Create combined matrix visualization\n            if matrices:\n                combined_path = self.create_combined_matrix_visualization(matrices, output_dir)\n                if combined_path:\n                    saved_files.append(combined_path)\n        \n        return saved_files\n    \n    def _extract_matrices(self, init_params: str) -> Dict[str, List[List[float]]]:\n        \"\"\"\n        Extract matrices from the InitialParameterization section.\n        \n        Args:\n            init_params: Raw content of the InitialParameterization section\n            \n        Returns:\n            Dictionary mapping matrix names to their data\n        \"\"\"\n        matrices = {}\n        \n        # Look for patterns like A_\u03c01={...}, B={...}, etc.\n        matrix_pattern = r'(\\w+(?:_\\w+)?)\\s*=\\s*{([^}]*)}'\n        \n        for match in re.finditer(matrix_pattern, init_params, re.DOTALL):\n            matrix_name = match.group(1)\n            matrix_content = match.group(2).strip()\n            \n            # Parse matrix content\n            # Look for row patterns like (0.1,0.2,0.3,0.4)\n            rows = []\n            for row_match in re.finditer(r'\\((.*?)\\)', matrix_content):\n                try:\n                    row_values = [float(val.strip()) for val in row_match.group(1).split(',')]\n                    rows.append(row_values)\n                except ValueError:\n                    # Skip rows with non-numeric values\n                    continue\n            \n            if rows:\n                matrices[matrix_name] = rows\n        \n        return matrices\n    \n    def create_heatmap(self, matrix_name: str, matrix_data: List[List[float]], \n                       output_dir: Path) -> str:\n        \"\"\"\n        Create a heatmap visualization for a matrix.\n        \n        Args:\n            matrix_name: Name of the matrix\n            matrix_data: 2D list of matrix values\n            output_dir: Directory to save visualization\n            \n        Returns:\n            Path to saved visualization file, or empty string if failed\n        \"\"\"\n        try:\n            # Convert to numpy array for heatmap\n            matrix_array = np.array(matrix_data)\n            \n            # Create heatmap visualization\n            plt.figure(figsize=(10, 8))\n            ax = plt.subplot(111)\n            \n            # Create heatmap\n            im = ax.imshow(matrix_array, cmap='viridis')\n            \n            # Add colorbar\n            cbar = plt.colorbar(im)\n            cbar.set_label('Value')\n            \n            # Add labels and title\n            plt.title(f'Matrix: {matrix_name}', fontsize=14, fontweight='bold')\n            \n            # Add row and column labels if available\n            # Row labels on y-axis\n            if matrix_array.shape[0] <= 10:  # Only add labels for reasonably sized matrices\n                row_labels = [str(i) for i in range(matrix_array.shape[0])]\n                ax.set_yticks(np.arange(matrix_array.shape[0]))\n                ax.set_yticklabels(row_labels)\n            \n            # Column labels on x-axis\n            if matrix_array.shape[1] <= 10:\n                col_labels = [str(i) for i in range(matrix_array.shape[1])]\n                ax.set_xticks(np.arange(matrix_array.shape[1]))\n                ax.set_xticklabels(col_labels)\n            \n            # Add grid to make it easier to read values\n            ax.set_xticks(np.arange(-.5, matrix_array.shape[1], 1), minor=True)\n            ax.set_yticks(np.arange(-.5, matrix_array.shape[0], 1), minor=True)\n            ax.grid(which=\"minor\", color=\"black\", linestyle='-', linewidth=1, alpha=0.2)\n            \n            # Add text annotations with the values\n            if matrix_array.shape[0] <= 10 and matrix_array.shape[1] <= 10:\n                for i in range(matrix_array.shape[0]):\n                    for j in range(matrix_array.shape[1]):\n                        ax.text(j, i, f\"{matrix_array[i, j]:.2f}\", \n                               ha=\"center\", va=\"center\", \n                               color=\"black\" if matrix_array[i, j] > 0.5 else \"white\")\n            \n            # Save figure\n            matrix_filename = f\"matrix_{matrix_name.replace('_', '')}.png\"\n            output_path = output_dir / matrix_filename\n            plt.tight_layout()\n            plt.savefig(output_path, dpi=150)\n            plt.close()\n            \n            print(f\"Matrix visualization saved to {output_path}\")\n            return str(output_path)\n        except Exception as e:\n            print(f\"Error creating heatmap for matrix {matrix_name}: {e}\")\n            return \"\"\n            \n    def create_combined_matrix_visualization(self, matrices: Dict[str, List[List[float]]], \n                                            output_dir: Path) -> str:\n        \"\"\"\n        Create a combined visualization of all matrices.\n        \n        Args:\n            matrices: Dictionary of matrix names to matrix data\n            output_dir: Directory to save visualization\n            \n        Returns:\n            Path to saved visualization file, or empty string if failed\n        \"\"\"\n        if not matrices:\n            return \"\"\n            \n        try:\n            # Calculate grid size based on number of matrices\n            num_matrices = len(matrices)\n            grid_size = int(np.ceil(np.sqrt(num_matrices)))\n            \n            # Create a figure with subplots\n            fig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size * 5, grid_size * 4))\n            \n            # Make axes a 2D array even if it's a single subplot\n            if num_matrices == 1:\n                axes = np.array([[axes]])\n            elif grid_size == 1:\n                axes = np.array([axes])\n            \n            # Flatten axes for easy iteration\n            axes_flat = axes.flatten()\n            \n            # Plot each matrix in its own subplot\n            for i, (matrix_name, matrix_data) in enumerate(matrices.items()):\n                if i >= len(axes_flat):\n                    break\n                    \n                # Get current axis\n                ax = axes_flat[i]\n                \n                # Convert to numpy array\n                matrix_array = np.array(matrix_data)\n                \n                # Create heatmap\n                im = ax.imshow(matrix_array, cmap='viridis')\n                \n                # Add matrix name as title\n                ax.set_title(matrix_name, fontsize=12)\n                \n                # Add row and column labels if matrix is small enough\n                if matrix_array.shape[0] <= 8 and matrix_array.shape[1] <= 8:\n                    # Row labels\n                    ax.set_yticks(np.arange(matrix_array.shape[0]))\n                    ax.set_yticklabels([str(i) for i in range(matrix_array.shape[0])])\n                    \n                    # Column labels\n                    ax.set_xticks(np.arange(matrix_array.shape[1]))\n                    ax.set_xticklabels([str(i) for i in range(matrix_array.shape[1])])\n                    \n                    # Add grid\n                    ax.set_xticks(np.arange(-.5, matrix_array.shape[1], 1), minor=True)\n                    ax.set_yticks(np.arange(-.5, matrix_array.shape[0], 1), minor=True)\n                    ax.grid(which=\"minor\", color=\"black\", linestyle='-', linewidth=0.5, alpha=0.2)\n                    \n                    # Add text annotations with values\n                    for y in range(matrix_array.shape[0]):\n                        for x in range(matrix_array.shape[1]):\n                            ax.text(x, y, f\"{matrix_array[y, x]:.2f}\", \n                                  ha=\"center\", va=\"center\", fontsize=8,\n                                  color=\"black\" if matrix_array[y, x] > 0.5 else \"white\")\n            \n            # Hide unused subplots\n            for j in range(i+1, len(axes_flat)):\n                axes_flat[j].axis('off')\n            \n            # Add a common colorbar\n            cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n            fig.colorbar(im, cax=cbar_ax)\n            \n            # Add overall title\n            fig.suptitle('All Model Matrices', fontsize=16, fontweight='bold')\n            \n            # Save figure\n            output_path = output_dir / 'combined_matrices.png'\n            plt.tight_layout()  # Make room for colorbar and title\n            plt.savefig(output_path, dpi=150, bbox_inches='tight')\n            plt.close()\n            \n            print(f\"Combined matrix visualization saved to {output_path}\")\n            return str(output_path)\n        except Exception as e:\n            print(f\"Error creating combined matrix visualization: {e}\")\n            return \"\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/matrix_visualizer.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 22,
        "end_line": 24,
        "code": "def __init__(self):\n        \"\"\"Initialize the matrix visualizer.\"\"\"\n        pass",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/matrix_visualizer.py"
      },
      {
        "name": "visualize_all_matrices",
        "type": "method",
        "start_line": 26,
        "end_line": 55,
        "code": "def visualize_all_matrices(self, parsed_data: Dict[str, Any], output_dir: Path) -> List[str]:\n        \"\"\"\n        Generate visualizations for all matrices in the model.\n        \n        Args:\n            parsed_data: Parsed GNN model data\n            output_dir: Directory to save visualizations\n            \n        Returns:\n            List of paths to saved visualization files\n        \"\"\"\n        saved_files = []\n        \n        # Extract matrices from InitialParameterization\n        if 'InitialParameterization' in parsed_data:\n            matrices = self._extract_matrices(parsed_data['InitialParameterization'])\n            \n            # Create individual heatmaps\n            for matrix_name, matrix_data in matrices.items():\n                file_path = self.create_heatmap(matrix_name, matrix_data, output_dir)\n                if file_path:\n                    saved_files.append(file_path)\n            \n            # Create combined matrix visualization\n            if matrices:\n                combined_path = self.create_combined_matrix_visualization(matrices, output_dir)\n                if combined_path:\n                    saved_files.append(combined_path)\n        \n        return saved_files",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/matrix_visualizer.py"
      },
      {
        "name": "_extract_matrices",
        "type": "method",
        "start_line": 57,
        "end_line": 90,
        "code": "def _extract_matrices(self, init_params: str) -> Dict[str, List[List[float]]]:\n        \"\"\"\n        Extract matrices from the InitialParameterization section.\n        \n        Args:\n            init_params: Raw content of the InitialParameterization section\n            \n        Returns:\n            Dictionary mapping matrix names to their data\n        \"\"\"\n        matrices = {}\n        \n        # Look for patterns like A_\u03c01={...}, B={...}, etc.\n        matrix_pattern = r'(\\w+(?:_\\w+)?)\\s*=\\s*{([^}]*)}'\n        \n        for match in re.finditer(matrix_pattern, init_params, re.DOTALL):\n            matrix_name = match.group(1)\n            matrix_content = match.group(2).strip()\n            \n            # Parse matrix content\n            # Look for row patterns like (0.1,0.2,0.3,0.4)\n            rows = []\n            for row_match in re.finditer(r'\\((.*?)\\)', matrix_content):\n                try:\n                    row_values = [float(val.strip()) for val in row_match.group(1).split(',')]\n                    rows.append(row_values)\n                except ValueError:\n                    # Skip rows with non-numeric values\n                    continue\n            \n            if rows:\n                matrices[matrix_name] = rows\n        \n        return matrices",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/matrix_visualizer.py"
      },
      {
        "name": "create_heatmap",
        "type": "method",
        "start_line": 92,
        "end_line": 160,
        "code": "def create_heatmap(self, matrix_name: str, matrix_data: List[List[float]], \n                       output_dir: Path) -> str:\n        \"\"\"\n        Create a heatmap visualization for a matrix.\n        \n        Args:\n            matrix_name: Name of the matrix\n            matrix_data: 2D list of matrix values\n            output_dir: Directory to save visualization\n            \n        Returns:\n            Path to saved visualization file, or empty string if failed\n        \"\"\"\n        try:\n            # Convert to numpy array for heatmap\n            matrix_array = np.array(matrix_data)\n            \n            # Create heatmap visualization\n            plt.figure(figsize=(10, 8))\n            ax = plt.subplot(111)\n            \n            # Create heatmap\n            im = ax.imshow(matrix_array, cmap='viridis')\n            \n            # Add colorbar\n            cbar = plt.colorbar(im)\n            cbar.set_label('Value')\n            \n            # Add labels and title\n            plt.title(f'Matrix: {matrix_name}', fontsize=14, fontweight='bold')\n            \n            # Add row and column labels if available\n            # Row labels on y-axis\n            if matrix_array.shape[0] <= 10:  # Only add labels for reasonably sized matrices\n                row_labels = [str(i) for i in range(matrix_array.shape[0])]\n                ax.set_yticks(np.arange(matrix_array.shape[0]))\n                ax.set_yticklabels(row_labels)\n            \n            # Column labels on x-axis\n            if matrix_array.shape[1] <= 10:\n                col_labels = [str(i) for i in range(matrix_array.shape[1])]\n                ax.set_xticks(np.arange(matrix_array.shape[1]))\n                ax.set_xticklabels(col_labels)\n            \n            # Add grid to make it easier to read values\n            ax.set_xticks(np.arange(-.5, matrix_array.shape[1], 1), minor=True)\n            ax.set_yticks(np.arange(-.5, matrix_array.shape[0], 1), minor=True)\n            ax.grid(which=\"minor\", color=\"black\", linestyle='-', linewidth=1, alpha=0.2)\n            \n            # Add text annotations with the values\n            if matrix_array.shape[0] <= 10 and matrix_array.shape[1] <= 10:\n                for i in range(matrix_array.shape[0]):\n                    for j in range(matrix_array.shape[1]):\n                        ax.text(j, i, f\"{matrix_array[i, j]:.2f}\", \n                               ha=\"center\", va=\"center\", \n                               color=\"black\" if matrix_array[i, j] > 0.5 else \"white\")\n            \n            # Save figure\n            matrix_filename = f\"matrix_{matrix_name.replace('_', '')}.png\"\n            output_path = output_dir / matrix_filename\n            plt.tight_layout()\n            plt.savefig(output_path, dpi=150)\n            plt.close()\n            \n            print(f\"Matrix visualization saved to {output_path}\")\n            return str(output_path)\n        except Exception as e:\n            print(f\"Error creating heatmap for matrix {matrix_name}: {e}\")\n            return \"\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/matrix_visualizer.py"
      },
      {
        "name": "create_combined_matrix_visualization",
        "type": "method",
        "start_line": 162,
        "end_line": 254,
        "code": "def create_combined_matrix_visualization(self, matrices: Dict[str, List[List[float]]], \n                                            output_dir: Path) -> str:\n        \"\"\"\n        Create a combined visualization of all matrices.\n        \n        Args:\n            matrices: Dictionary of matrix names to matrix data\n            output_dir: Directory to save visualization\n            \n        Returns:\n            Path to saved visualization file, or empty string if failed\n        \"\"\"\n        if not matrices:\n            return \"\"\n            \n        try:\n            # Calculate grid size based on number of matrices\n            num_matrices = len(matrices)\n            grid_size = int(np.ceil(np.sqrt(num_matrices)))\n            \n            # Create a figure with subplots\n            fig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size * 5, grid_size * 4))\n            \n            # Make axes a 2D array even if it's a single subplot\n            if num_matrices == 1:\n                axes = np.array([[axes]])\n            elif grid_size == 1:\n                axes = np.array([axes])\n            \n            # Flatten axes for easy iteration\n            axes_flat = axes.flatten()\n            \n            # Plot each matrix in its own subplot\n            for i, (matrix_name, matrix_data) in enumerate(matrices.items()):\n                if i >= len(axes_flat):\n                    break\n                    \n                # Get current axis\n                ax = axes_flat[i]\n                \n                # Convert to numpy array\n                matrix_array = np.array(matrix_data)\n                \n                # Create heatmap\n                im = ax.imshow(matrix_array, cmap='viridis')\n                \n                # Add matrix name as title\n                ax.set_title(matrix_name, fontsize=12)\n                \n                # Add row and column labels if matrix is small enough\n                if matrix_array.shape[0] <= 8 and matrix_array.shape[1] <= 8:\n                    # Row labels\n                    ax.set_yticks(np.arange(matrix_array.shape[0]))\n                    ax.set_yticklabels([str(i) for i in range(matrix_array.shape[0])])\n                    \n                    # Column labels\n                    ax.set_xticks(np.arange(matrix_array.shape[1]))\n                    ax.set_xticklabels([str(i) for i in range(matrix_array.shape[1])])\n                    \n                    # Add grid\n                    ax.set_xticks(np.arange(-.5, matrix_array.shape[1], 1), minor=True)\n                    ax.set_yticks(np.arange(-.5, matrix_array.shape[0], 1), minor=True)\n                    ax.grid(which=\"minor\", color=\"black\", linestyle='-', linewidth=0.5, alpha=0.2)\n                    \n                    # Add text annotations with values\n                    for y in range(matrix_array.shape[0]):\n                        for x in range(matrix_array.shape[1]):\n                            ax.text(x, y, f\"{matrix_array[y, x]:.2f}\", \n                                  ha=\"center\", va=\"center\", fontsize=8,\n                                  color=\"black\" if matrix_array[y, x] > 0.5 else \"white\")\n            \n            # Hide unused subplots\n            for j in range(i+1, len(axes_flat)):\n                axes_flat[j].axis('off')\n            \n            # Add a common colorbar\n            cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n            fig.colorbar(im, cax=cbar_ax)\n            \n            # Add overall title\n            fig.suptitle('All Model Matrices', fontsize=16, fontweight='bold')\n            \n            # Save figure\n            output_path = output_dir / 'combined_matrices.png'\n            plt.tight_layout()  # Make room for colorbar and title\n            plt.savefig(output_path, dpi=150, bbox_inches='tight')\n            plt.close()\n            \n            print(f\"Combined matrix visualization saved to {output_path}\")\n            return str(output_path)\n        except Exception as e:\n            print(f\"Error creating combined matrix visualization: {e}\")\n            return \"\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/matrix_visualizer.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/__main__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/mcp.py": [
      {
        "name": "visualize_file",
        "type": "function",
        "start_line": 20,
        "end_line": 46,
        "code": "def visualize_file(file_path: str, output_dir: Optional[str] = None) -> Dict[str, Any]:\n    \"\"\"\n    Visualize a GNN file through MCP.\n    \n    Args:\n        file_path: Path to the GNN file to visualize\n        output_dir: Optional output directory to save visualizations\n        \n    Returns:\n        Dictionary containing visualization results\n    \"\"\"\n    try:\n        visualizer = GNNVisualizer(output_dir=output_dir)\n        output_path = visualizer.visualize_file(file_path)\n        \n        return {\n            \"success\": True,\n            \"output_directory\": output_path,\n            \"file_path\": file_path\n        }\n    except Exception as e:\n        logger.error(f\"Error in visualize_file for {file_path}: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e),\n            \"file_path\": file_path\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/mcp.py"
      },
      {
        "name": "visualize_directory",
        "type": "function",
        "start_line": 48,
        "end_line": 74,
        "code": "def visualize_directory(dir_path: str, output_dir: Optional[str] = None) -> Dict[str, Any]:\n    \"\"\"\n    Visualize all GNN files in a directory through MCP.\n    \n    Args:\n        dir_path: Path to directory containing GNN files\n        output_dir: Optional output directory to save visualizations\n        \n    Returns:\n        Dictionary containing visualization results\n    \"\"\"\n    try:\n        visualizer = GNNVisualizer(output_dir=output_dir)\n        output_path = visualizer.visualize_directory(dir_path)\n        \n        return {\n            \"success\": True,\n            \"output_directory\": output_path,\n            \"directory_path\": dir_path\n        }\n    except Exception as e:\n        logger.error(f\"Error in visualize_directory for {dir_path}: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e),\n            \"directory_path\": dir_path\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/mcp.py"
      },
      {
        "name": "parse_gnn_file",
        "type": "function",
        "start_line": 76,
        "end_line": 109,
        "code": "def parse_gnn_file(file_path: str) -> Dict[str, Any]:\n    \"\"\"\n    Parse a GNN file without visualization through MCP.\n    \n    Args:\n        file_path: Path to the GNN file to parse\n        \n    Returns:\n        Dictionary containing parsed GNN data\n    \"\"\"\n    try:\n        parser = GNNParser()\n        parsed_data = parser.parse_file(file_path)\n        \n        # Convert to serializable format\n        serializable_data = {}\n        for k, v in parsed_data.items():\n            if k not in ['Variables', 'Edges']:  # Skip complex objects\n                serializable_data[k] = str(v)\n            else:\n                serializable_data[k] = f\"{len(v)} items\"\n        \n        return {\n            \"success\": True,\n            \"parsed_data\": serializable_data,\n            \"file_path\": file_path\n        }\n    except Exception as e:\n        logger.error(f\"Error in parse_gnn_file for {file_path}: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e),\n            \"file_path\": file_path\n        }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/mcp.py"
      },
      {
        "name": "get_visualization_results",
        "type": "function",
        "start_line": 113,
        "end_line": 150,
        "code": "def get_visualization_results(uri: str) -> Dict[str, Any]:\n    \"\"\"\n    Retrieve visualization results by URI.\n    \n    Args:\n        uri: URI of the visualization results. Format: visualization://{output_directory}\n        \n    Returns:\n        Dictionary containing visualization results\n    \"\"\"\n    # Extract directory path from URI\n    if not uri.startswith(\"visualization://\"):\n        error_msg = f\"Invalid URI format: {uri}\"\n        logger.error(f\"get_visualization_results: {error_msg}\")\n        raise ValueError(error_msg)\n    \n    dir_path_str = uri[16:]  # Remove 'visualization://' prefix\n    dir_path = Path(dir_path_str)\n    \n    if not dir_path.exists() or not dir_path.is_dir():\n        error_msg = f\"Directory does not exist: {dir_path}\"\n        logger.error(f\"get_visualization_results: {error_msg}\")\n        raise ValueError(error_msg)\n    \n    # Collect visualization files\n    visualization_files = []\n    for file_path in dir_path.glob(\"*\"):\n        if file_path.is_file():\n            visualization_files.append({\n                \"name\": file_path.name,\n                \"path\": str(file_path),\n                \"size\": file_path.stat().st_size\n            })\n    \n    return {\n        \"directory\": str(dir_path),\n        \"files\": visualization_files\n    }",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/mcp.py"
      },
      {
        "name": "register_tools",
        "type": "function",
        "start_line": 154,
        "end_line": 194,
        "code": "def register_tools(mcp):\n    \"\"\"Register visualization tools with the MCP.\"\"\"\n    \n    # Register visualization tools\n    mcp.register_tool(\n        \"visualize_gnn_file\",\n        visualize_file,\n        {\n            \"file_path\": {\"type\": \"string\", \"description\": \"Path to the GNN file to visualize\"},\n            \"output_dir\": {\"type\": \"string\", \"description\": \"Optional output directory\"}\n        },\n        \"Generate visualizations for a specific GNN file.\"\n    )\n    \n    mcp.register_tool(\n        \"visualize_gnn_directory\",\n        visualize_directory,\n        {\n            \"dir_path\": {\"type\": \"string\", \"description\": \"Path to directory containing GNN files\"},\n            \"output_dir\": {\"type\": \"string\", \"description\": \"Optional output directory\"}\n        },\n        \"Visualize all GNN files in a directory\"\n    )\n    \n    mcp.register_tool(\n        \"parse_gnn_file\",\n        parse_gnn_file,\n        {\n            \"file_path\": {\"type\": \"string\", \"description\": \"Path to the GNN file to parse\"}\n        },\n        \"Parse a GNN file without visualization\"\n    )\n    \n    # Register visualization resources\n    mcp.register_resource(\n        \"visualization://{output_directory}\",\n        get_visualization_results,\n        \"Retrieve visualization results by output directory\"\n    )\n    \n    logger.info(\"Visualization module MCP tools and resources registered.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py": [
      {
        "name": "GNNVisualizer",
        "type": "class",
        "start_line": 24,
        "end_line": 505,
        "code": "class GNNVisualizer:\n    \"\"\"\n    Visualizer for GNN models.\n    \n    This class provides methods to visualize GNN models from parsed GNN files.\n    It generates various visualizations of the model's state space, connections,\n    and other properties.\n    \"\"\"\n    \n    def __init__(self, output_dir: Optional[str] = None, project_root: Optional[Union[str, Path]] = None):\n        \"\"\"\n        Initialize the GNN visualizer.\n        \n        Args:\n            output_dir: Directory where output visualizations will be saved.\n                        If None, creates a timestamped directory in the current working directory.\n            project_root: Optional path to the project root for making file paths relative.\n        \"\"\"\n        self.parser = GNNParser()\n        self.matrix_visualizer = MatrixVisualizer()\n        self.ontology_visualizer = OntologyVisualizer()\n        \n        # Create timestamped output directory if not provided\n        if output_dir is None:\n            # Default to project_root/output\n            # Assumes script is run from a subdirectory of the project root (e.g. src/)\n            # or that current working directory is project root.\n            # Path.cwd() will be /path/to/GeneralizedNotationNotation/src\n            # Path.cwd().parent will be /path/to/GeneralizedNotationNotation\n            project_root_output_dir = Path.cwd().parent / 'output'\n            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            # Keep timestamp for uniqueness if multiple runs without specific output dir\n            output_dir = project_root_output_dir / f'gnn_visualization_{timestamp}'\n        \n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        \n        self.project_root = Path(project_root).resolve() if project_root else None\n        \n    def visualize_file(self, file_path: str) -> str:\n        \"\"\"\n        Generate visualizations for a GNN file.\n        \n        Args:\n            file_path: Path to the GNN file to visualize\n            \n        Returns:\n            Path to the directory containing generated visualizations\n        \"\"\"\n        try:\n            # Parse the GNN file\n            parsed_data = self.parser.parse_file(file_path)\n            \n            # Create subdirectory for this file\n            file_name = Path(file_path).stem\n            file_output_dir = self.output_dir / file_name\n            file_output_dir.mkdir(exist_ok=True)\n            \n            # Generate and save model metadata\n            self._save_model_metadata(parsed_data, file_output_dir)\n            \n            # Generate basic text-based visualizations regardless of parsing success\n            self._create_basic_text_visualization(parsed_data, file_path, file_output_dir)\n            \n            # Generate different visualizations if we have parsed structured data\n            print(f\"Checking for variables in {file_path}...\")\n            if 'Variables' in parsed_data:\n                print(f\"Found {len(parsed_data['Variables'])} variables: {list(parsed_data['Variables'].keys())}\")\n                self._visualize_state_space(parsed_data, file_output_dir)\n            else:\n                print(f\"No variables found in {file_path}\")\n                # Write available sections\n                print(f\"Available sections: {list(parsed_data.keys())}\")\n                \n                # Try to extract state space from the StateSpaceBlock\n                if 'StateSpaceBlock' in parsed_data:\n                    print(f\"StateSpaceBlock content: {parsed_data['StateSpaceBlock'][:100]}...\")\n                    self._process_state_space_and_visualize(parsed_data, file_output_dir)\n            \n            print(f\"Checking for edges in {file_path}...\")\n            if 'Edges' in parsed_data:\n                print(f\"Found {len(parsed_data['Edges'])} edges\")\n                self._visualize_connections(parsed_data, file_output_dir)\n            else:\n                print(f\"No edges found in {file_path}\")\n                # Try to extract connections from the Connections section\n                if 'Connections' in parsed_data:\n                    print(f\"Connections content: {parsed_data['Connections'][:100]}...\")\n                    self._process_connections_and_visualize(parsed_data, file_output_dir)\n            \n            # Generate matrix visualizations\n            if 'InitialParameterization' in parsed_data:\n                print(f\"[GNNVisualizer] Found 'InitialParameterization' section for {file_name}. Attempting matrix visualization.\")\n                if parsed_data['InitialParameterization'].strip(): # Check if content is not just whitespace\n                    self.matrix_visualizer.visualize_all_matrices(parsed_data, file_output_dir)\n                else:\n                    print(f\"[GNNVisualizer] 'InitialParameterization' section for {file_name} is empty. Skipping matrix visualization.\")\n            else:\n                print(f\"[GNNVisualizer] 'InitialParameterization' section NOT FOUND for {file_name}. Skipping matrix visualization.\")\n            \n            # Generate ontology visualizations\n            if 'ActInfOntologyAnnotation' in parsed_data:\n                print(f\"[GNNVisualizer] Found 'ActInfOntologyAnnotation' section for {file_name}. Attempting ontology visualization.\")\n                if parsed_data['ActInfOntologyAnnotation'].strip(): # Check if content is not just whitespace\n                    self.ontology_visualizer.visualize_ontology(parsed_data, file_output_dir)\n                else:\n                    print(f\"[GNNVisualizer] 'ActInfOntologyAnnotation' section for {file_name} is empty. Skipping ontology visualization.\")\n            else:\n                print(f\"[GNNVisualizer] 'ActInfOntologyAnnotation' section NOT FOUND for {file_name}. Skipping ontology visualization.\")\n            \n            if 'Variables' in parsed_data and 'Edges' in parsed_data:\n                self._visualize_combined(parsed_data, file_output_dir)\n            \n            return str(file_output_dir)\n        except Exception as e:\n            # Create a subdirectory even for failed files\n            file_name = Path(file_path).stem\n            file_output_dir = self.output_dir / file_name\n            file_output_dir.mkdir(exist_ok=True)\n            \n            # Create a basic report of the error\n            with open(file_output_dir / 'parsing_error.txt', 'w') as f:\n                f.write(f\"Error parsing {file_path}: {str(e)}\\n\")\n            \n            # Create a basic text visualization\n            self._create_basic_text_visualization({}, file_path, file_output_dir)\n            \n            # Re-raise the exception for higher-level handling\n            raise\n    \n    def _process_state_space_and_visualize(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Process state space and generate visualization.\"\"\"\n        try:\n            # Process state space\n            self.parser._process_state_space(parsed_data)\n            \n            # Visualize if we have variables\n            if 'Variables' in parsed_data and parsed_data['Variables']:\n                print(f\"Successfully processed state space, found {len(parsed_data['Variables'])} variables\")\n                self._visualize_state_space(parsed_data, output_dir)\n        except Exception as e:\n            print(f\"Error processing state space: {e}\")\n    \n    def _process_connections_and_visualize(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Process connections and generate visualization.\"\"\"\n        try:\n            # Process connections\n            self.parser._process_connections(parsed_data)\n            \n            # Visualize if we have edges\n            if 'Edges' in parsed_data and parsed_data['Edges']:\n                print(f\"Successfully processed connections, found {len(parsed_data['Edges'])} edges\")\n                self._visualize_connections(parsed_data, output_dir)\n        except Exception as e:\n            print(f\"Error processing connections: {e}\")\n    \n    def visualize_directory(self, dir_path: str) -> str:\n        \"\"\"\n        Generate visualizations for all GNN files in a directory.\n        \n        Args:\n            dir_path: Path to directory containing GNN files\n            \n        Returns:\n            Path to the directory containing all generated visualizations\n        \"\"\"\n        dir_path = Path(dir_path)\n        \n        # Process all markdown files in the directory\n        for file_path in dir_path.glob('*.md'):\n            try:\n                self.visualize_file(str(file_path))\n            except Exception as e:\n                print(f\"Error processing {file_path}: {e}\")\n        \n        return str(self.output_dir)\n    \n    def _create_basic_text_visualization(self, parsed_data: Dict[str, Any], file_path: str, output_dir: Path) -> None:\n        \"\"\"Create a simple text-based visualization of the file.\"\"\"\n        # Read the raw file content\n        raw_file_content = Path(file_path).read_text()\n        \n        # Determine display path for the report\n        display_file_path = Path(file_path).name # Default to just name\n        if self.project_root:\n            try:\n                display_file_path = Path(file_path).resolve().relative_to(self.project_root)\n            except ValueError:\n                # Keep as name if not under project_root for some reason\n                pass \n\n        # Create a simple text report\n        with open(output_dir / 'file_content.md', 'w') as f:\n            f.write(f\"# GNN File: {display_file_path}\\\\n\\\\n\")\n            f.write(\"## Raw File Content\\\\n\\\\n\")\n            f.write(\"```\\\\n\")\n            f.write(raw_file_content)\n            f.write(\"\\\\n```\\\\n\\\\n\")\n            \n            # Add parsed sections if available\n            if parsed_data:\n                f.write(\"## Parsed Sections\\n\\n\")\n                for section, content in parsed_data.items():\n                    if section not in ['Variables', 'Edges']:  # Skip processed sections\n                        f.write(f\"### {section}\\n\\n\")\n                        f.write(\"```\\n\")\n                        f.write(str(content))\n                        f.write(\"\\n```\\n\\n\")\n    \n    def _save_model_metadata(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Save model metadata as JSON for reference.\"\"\"\n        # Extract relevant metadata\n        metadata = {\n            'ModelName': parsed_data.get('ModelName', ''),\n            'ModelAnnotation': parsed_data.get('ModelAnnotation', ''),\n            'GNNVersionAndFlags': parsed_data.get('GNNVersionAndFlags', ''),\n            'Time': parsed_data.get('Time', ''),\n            'ActInfOntologyAnnotation': parsed_data.get('ActInfOntologyAnnotation', '')\n        }\n        \n        # Save as JSON\n        with open(output_dir / 'model_metadata.json', 'w') as f:\n            json.dump(metadata, f, indent=2)\n            \n        # Also save full parsed data for reference\n        with open(output_dir / 'full_model_data.json', 'w') as f:\n            # Convert to serializable format\n            try:\n                serializable_data = {}\n                for k, v in parsed_data.items():\n                    if k not in ['Variables', 'Edges']:  # Skip complex objects\n                        serializable_data[k] = str(v)\n                json.dump(serializable_data, f, indent=2)\n            except Exception as e:\n                # Fallback to simple format\n                json.dump({\"error\": f\"Failed to serialize data: {str(e)}\"}, f)\n    \n    def _visualize_state_space(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Generate visualization of the state space variables.\"\"\"\n        if 'Variables' not in parsed_data or not parsed_data['Variables']:\n            return\n            \n        variables = parsed_data['Variables']\n        \n        # Create figure and table\n        fig, ax = plt.subplots(figsize=(10, max(5, len(variables) * 0.5)))\n        ax.axis('tight')\n        ax.axis('off')\n        \n        # Prepare table data\n        table_data = []\n        for var_name, var_info in variables.items():\n            dimensions = 'x'.join(str(d) for d in var_info.get('dimensions', [])) if var_info.get('dimensions') else ''\n            var_type = var_info.get('type', '') or ''\n            comment = var_info.get('comment', '') or ''\n            table_data.append([var_name, dimensions, var_type, comment])\n        \n        # Create the table\n        if table_data:\n            table = ax.table(\n                cellText=table_data,\n                colLabels=['Variable', 'Dimensions', 'Type', 'Description'],\n                loc='center',\n                cellLoc='left',\n                colWidths=[0.15, 0.15, 0.15, 0.55]\n            )\n            \n            # Style the table\n            table.auto_set_font_size(False)\n            table.set_fontsize(10)\n            table.scale(1, 1.5)\n        else:\n            ax.text(0.5, 0.5, \"No state space variables found\", \n                    horizontalalignment='center', verticalalignment='center',\n                    fontsize=12)\n        \n        # Add title\n        plt.title('State Space Variables', fontsize=14, fontweight='bold', pad=20)\n        \n        # Save figure\n        plt.tight_layout()\n        plt.savefig(output_dir / 'state_space.png', dpi=150, bbox_inches='tight')\n        plt.close()\n        \n        print(f\"State space visualization saved to {output_dir / 'state_space.png'}\")\n    \n    def _visualize_connections(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Generate visualization of the connections/edges in the model.\"\"\"\n        if 'Edges' not in parsed_data or not parsed_data['Edges']:\n            return\n            \n        edges = parsed_data['Edges']\n        \n        # Create directed graph\n        G = nx.DiGraph()\n        \n        try:\n            # Add nodes and edges\n            for edge in edges:\n                source = edge.get('source', '')\n                target = edge.get('target', '')\n                if not source or not target:\n                    continue\n                    \n                directed = edge.get('directed', True)\n                constraint = edge.get('constraint', None)\n                comment = edge.get('comment', None)\n                \n                G.add_node(source)\n                G.add_node(target)\n                \n                if directed:\n                    G.add_edge(source, target, constraint=constraint, comment=comment)\n                else:\n                    # For undirected edges in a directed graph, add edges in both directions\n                    G.add_edge(source, target, constraint=constraint, comment=comment)\n                    G.add_edge(target, source, constraint=constraint, comment=comment)\n            \n            # Create figure\n            plt.figure(figsize=(12, 10))\n            \n            if G.number_of_nodes() > 0:\n                # Set node positions using spring layout\n                pos = nx.spring_layout(G, seed=42)\n                \n                # Draw nodes\n                nx.draw_networkx_nodes(G, pos, node_size=700, node_color='lightblue', alpha=0.8)\n                \n                # Draw edges\n                nx.draw_networkx_edges(G, pos, width=1.5, alpha=0.7, arrowsize=20)\n                \n                # Draw labels\n                nx.draw_networkx_labels(G, pos, font_size=12, font_family='sans-serif')\n                \n                # Add edge labels for constraints\n                edge_labels = {(edge.get('source', ''), edge.get('target', '')): edge.get('constraint', '') \n                              for edge in edges if edge.get('constraint')}\n                if edge_labels:\n                    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n            else:\n                plt.text(0.5, 0.5, \"No connections found\", \n                        horizontalalignment='center', verticalalignment='center',\n                        fontsize=14)\n            \n            # Set title\n            plt.title('Model Connections', fontsize=14, fontweight='bold')\n            \n            # Remove axis\n            plt.axis('off')\n            \n            # Save figure\n            plt.tight_layout()\n            plt.savefig(output_dir / 'connections.png', dpi=150, bbox_inches='tight')\n            plt.close()\n            \n            print(f\"Connections visualization saved to {output_dir / 'connections.png'}\")\n        except Exception as e:\n            # Create error text figure if visualization fails\n            plt.figure(figsize=(10, 5))\n            plt.text(0.5, 0.5, f\"Error generating connections visualization: {str(e)}\", \n                    horizontalalignment='center', verticalalignment='center',\n                    fontsize=12, wrap=True)\n            plt.axis('off')\n            plt.savefig(output_dir / 'connections_error.png', dpi=150)\n            plt.close()\n    \n    def _visualize_combined(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Generate a combined visualization of the model.\"\"\"\n        try:\n            # Create a comprehensive visualization that combines state space and connections\n            if 'Variables' not in parsed_data or not parsed_data['Variables'] or 'Edges' not in parsed_data or not parsed_data['Edges']:\n                return\n                \n            variables = parsed_data['Variables']\n            edges = parsed_data['Edges']\n            \n            # Create figure with two subplots\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n            \n            # Left subplot: Variable details\n            ax1.axis('tight')\n            ax1.axis('off')\n            \n            # Prepare table data\n            table_data = []\n            for var_name, var_info in variables.items():\n                dimensions = 'x'.join(str(d) for d in var_info.get('dimensions', [])) if var_info.get('dimensions') else ''\n                var_type = var_info.get('type', '') or ''\n                table_data.append([var_name, dimensions, var_type])\n            \n            # Create the table\n            if table_data:\n                table = ax1.table(\n                    cellText=table_data,\n                    colLabels=['Variable', 'Dimensions', 'Type'],\n                    loc='center',\n                    cellLoc='left'\n                )\n                \n                # Style the table\n                table.auto_set_font_size(False)\n                table.set_fontsize(10)\n                table.scale(1, 1.5)\n            else:\n                ax1.text(0.5, 0.5, \"No state space variables found\", \n                        horizontalalignment='center', verticalalignment='center',\n                        fontsize=12)\n            \n            ax1.set_title('State Space Variables', fontsize=14, fontweight='bold')\n            \n            # Right subplot: Connections graph\n            ax2.axis('off')\n            \n            # Create directed graph\n            G = nx.DiGraph()\n            \n            # Add nodes and edges\n            valid_edges = []\n            for edge in edges:\n                source = edge.get('source', '')\n                target = edge.get('target', '')\n                if not source or not target:\n                    continue\n                    \n                G.add_node(source)\n                G.add_node(target)\n                G.add_edge(source, target, directed=edge.get('directed', True))\n                valid_edges.append(edge)\n            \n            if G.number_of_nodes() > 0:\n                # Set node positions using spring layout\n                pos = nx.spring_layout(G, seed=42)\n                \n                # Draw nodes\n                nx.draw_networkx_nodes(G, pos, ax=ax2, node_size=700, node_color='lightblue', alpha=0.8)\n                \n                # Draw edges with different styles for directed and undirected\n                directed_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get('directed', True)]\n                undirected_edges = [(u, v) for u, v, d in G.edges(data=True) if not d.get('directed', True)]\n                \n                if directed_edges:\n                    nx.draw_networkx_edges(G, pos, ax=ax2, edgelist=directed_edges, \n                                        width=1.5, alpha=0.7, arrowsize=20)\n                if undirected_edges:\n                    nx.draw_networkx_edges(G, pos, ax=ax2, edgelist=undirected_edges, \n                                        width=1.5, alpha=0.7, arrowstyle='-')\n                \n                # Draw labels\n                nx.draw_networkx_labels(G, pos, ax=ax2, font_size=12, font_family='sans-serif')\n            else:\n                ax2.text(0.5, 0.5, \"No connections found\", \n                        horizontalalignment='center', verticalalignment='center',\n                        fontsize=14)\n            \n            ax2.set_title('Model Connections', fontsize=14, fontweight='bold')\n            \n            # Set overall title\n            model_name = self._extract_model_name(parsed_data)\n            fig.suptitle(model_name, fontsize=16, fontweight='bold')\n            \n            # Save figure\n            plt.tight_layout(rect=[0, 0, 1, 0.95])  # Make room for suptitle\n            plt.savefig(output_dir / 'combined_visualization.png', dpi=150, bbox_inches='tight')\n            plt.close()\n            \n            print(f\"Combined visualization saved to {output_dir / 'combined_visualization.png'}\")\n        except Exception as e:\n            # Create error text figure if visualization fails\n            plt.figure(figsize=(10, 5))\n            plt.text(0.5, 0.5, f\"Error generating combined visualization: {str(e)}\", \n                    horizontalalignment='center', verticalalignment='center',\n                    fontsize=12, wrap=True)\n            plt.axis('off')\n            plt.savefig(output_dir / 'combined_visualization_error.png', dpi=150)\n            plt.close()\n        \n    def _extract_model_name(self, parsed_data: Dict[str, Any]) -> str:\n        \"\"\"Extract a clean model name from the parsed data.\"\"\"\n        if 'ModelName' in parsed_data and parsed_data['ModelName']:\n            # Remove Markdown formatting and clean up\n            return parsed_data['ModelName'].replace('#', '').strip()\n        return \"GNN Model\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 33,
        "end_line": 61,
        "code": "def __init__(self, output_dir: Optional[str] = None, project_root: Optional[Union[str, Path]] = None):\n        \"\"\"\n        Initialize the GNN visualizer.\n        \n        Args:\n            output_dir: Directory where output visualizations will be saved.\n                        If None, creates a timestamped directory in the current working directory.\n            project_root: Optional path to the project root for making file paths relative.\n        \"\"\"\n        self.parser = GNNParser()\n        self.matrix_visualizer = MatrixVisualizer()\n        self.ontology_visualizer = OntologyVisualizer()\n        \n        # Create timestamped output directory if not provided\n        if output_dir is None:\n            # Default to project_root/output\n            # Assumes script is run from a subdirectory of the project root (e.g. src/)\n            # or that current working directory is project root.\n            # Path.cwd() will be /path/to/GeneralizedNotationNotation/src\n            # Path.cwd().parent will be /path/to/GeneralizedNotationNotation\n            project_root_output_dir = Path.cwd().parent / 'output'\n            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            # Keep timestamp for uniqueness if multiple runs without specific output dir\n            output_dir = project_root_output_dir / f'gnn_visualization_{timestamp}'\n        \n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        \n        self.project_root = Path(project_root).resolve() if project_root else None",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "visualize_file",
        "type": "method",
        "start_line": 63,
        "end_line": 152,
        "code": "def visualize_file(self, file_path: str) -> str:\n        \"\"\"\n        Generate visualizations for a GNN file.\n        \n        Args:\n            file_path: Path to the GNN file to visualize\n            \n        Returns:\n            Path to the directory containing generated visualizations\n        \"\"\"\n        try:\n            # Parse the GNN file\n            parsed_data = self.parser.parse_file(file_path)\n            \n            # Create subdirectory for this file\n            file_name = Path(file_path).stem\n            file_output_dir = self.output_dir / file_name\n            file_output_dir.mkdir(exist_ok=True)\n            \n            # Generate and save model metadata\n            self._save_model_metadata(parsed_data, file_output_dir)\n            \n            # Generate basic text-based visualizations regardless of parsing success\n            self._create_basic_text_visualization(parsed_data, file_path, file_output_dir)\n            \n            # Generate different visualizations if we have parsed structured data\n            print(f\"Checking for variables in {file_path}...\")\n            if 'Variables' in parsed_data:\n                print(f\"Found {len(parsed_data['Variables'])} variables: {list(parsed_data['Variables'].keys())}\")\n                self._visualize_state_space(parsed_data, file_output_dir)\n            else:\n                print(f\"No variables found in {file_path}\")\n                # Write available sections\n                print(f\"Available sections: {list(parsed_data.keys())}\")\n                \n                # Try to extract state space from the StateSpaceBlock\n                if 'StateSpaceBlock' in parsed_data:\n                    print(f\"StateSpaceBlock content: {parsed_data['StateSpaceBlock'][:100]}...\")\n                    self._process_state_space_and_visualize(parsed_data, file_output_dir)\n            \n            print(f\"Checking for edges in {file_path}...\")\n            if 'Edges' in parsed_data:\n                print(f\"Found {len(parsed_data['Edges'])} edges\")\n                self._visualize_connections(parsed_data, file_output_dir)\n            else:\n                print(f\"No edges found in {file_path}\")\n                # Try to extract connections from the Connections section\n                if 'Connections' in parsed_data:\n                    print(f\"Connections content: {parsed_data['Connections'][:100]}...\")\n                    self._process_connections_and_visualize(parsed_data, file_output_dir)\n            \n            # Generate matrix visualizations\n            if 'InitialParameterization' in parsed_data:\n                print(f\"[GNNVisualizer] Found 'InitialParameterization' section for {file_name}. Attempting matrix visualization.\")\n                if parsed_data['InitialParameterization'].strip(): # Check if content is not just whitespace\n                    self.matrix_visualizer.visualize_all_matrices(parsed_data, file_output_dir)\n                else:\n                    print(f\"[GNNVisualizer] 'InitialParameterization' section for {file_name} is empty. Skipping matrix visualization.\")\n            else:\n                print(f\"[GNNVisualizer] 'InitialParameterization' section NOT FOUND for {file_name}. Skipping matrix visualization.\")\n            \n            # Generate ontology visualizations\n            if 'ActInfOntologyAnnotation' in parsed_data:\n                print(f\"[GNNVisualizer] Found 'ActInfOntologyAnnotation' section for {file_name}. Attempting ontology visualization.\")\n                if parsed_data['ActInfOntologyAnnotation'].strip(): # Check if content is not just whitespace\n                    self.ontology_visualizer.visualize_ontology(parsed_data, file_output_dir)\n                else:\n                    print(f\"[GNNVisualizer] 'ActInfOntologyAnnotation' section for {file_name} is empty. Skipping ontology visualization.\")\n            else:\n                print(f\"[GNNVisualizer] 'ActInfOntologyAnnotation' section NOT FOUND for {file_name}. Skipping ontology visualization.\")\n            \n            if 'Variables' in parsed_data and 'Edges' in parsed_data:\n                self._visualize_combined(parsed_data, file_output_dir)\n            \n            return str(file_output_dir)\n        except Exception as e:\n            # Create a subdirectory even for failed files\n            file_name = Path(file_path).stem\n            file_output_dir = self.output_dir / file_name\n            file_output_dir.mkdir(exist_ok=True)\n            \n            # Create a basic report of the error\n            with open(file_output_dir / 'parsing_error.txt', 'w') as f:\n                f.write(f\"Error parsing {file_path}: {str(e)}\\n\")\n            \n            # Create a basic text visualization\n            self._create_basic_text_visualization({}, file_path, file_output_dir)\n            \n            # Re-raise the exception for higher-level handling\n            raise",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "_process_state_space_and_visualize",
        "type": "method",
        "start_line": 154,
        "end_line": 165,
        "code": "def _process_state_space_and_visualize(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Process state space and generate visualization.\"\"\"\n        try:\n            # Process state space\n            self.parser._process_state_space(parsed_data)\n            \n            # Visualize if we have variables\n            if 'Variables' in parsed_data and parsed_data['Variables']:\n                print(f\"Successfully processed state space, found {len(parsed_data['Variables'])} variables\")\n                self._visualize_state_space(parsed_data, output_dir)\n        except Exception as e:\n            print(f\"Error processing state space: {e}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "_process_connections_and_visualize",
        "type": "method",
        "start_line": 167,
        "end_line": 178,
        "code": "def _process_connections_and_visualize(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Process connections and generate visualization.\"\"\"\n        try:\n            # Process connections\n            self.parser._process_connections(parsed_data)\n            \n            # Visualize if we have edges\n            if 'Edges' in parsed_data and parsed_data['Edges']:\n                print(f\"Successfully processed connections, found {len(parsed_data['Edges'])} edges\")\n                self._visualize_connections(parsed_data, output_dir)\n        except Exception as e:\n            print(f\"Error processing connections: {e}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "visualize_directory",
        "type": "method",
        "start_line": 180,
        "end_line": 199,
        "code": "def visualize_directory(self, dir_path: str) -> str:\n        \"\"\"\n        Generate visualizations for all GNN files in a directory.\n        \n        Args:\n            dir_path: Path to directory containing GNN files\n            \n        Returns:\n            Path to the directory containing all generated visualizations\n        \"\"\"\n        dir_path = Path(dir_path)\n        \n        # Process all markdown files in the directory\n        for file_path in dir_path.glob('*.md'):\n            try:\n                self.visualize_file(str(file_path))\n            except Exception as e:\n                print(f\"Error processing {file_path}: {e}\")\n        \n        return str(self.output_dir)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "_create_basic_text_visualization",
        "type": "method",
        "start_line": 201,
        "end_line": 231,
        "code": "def _create_basic_text_visualization(self, parsed_data: Dict[str, Any], file_path: str, output_dir: Path) -> None:\n        \"\"\"Create a simple text-based visualization of the file.\"\"\"\n        # Read the raw file content\n        raw_file_content = Path(file_path).read_text()\n        \n        # Determine display path for the report\n        display_file_path = Path(file_path).name # Default to just name\n        if self.project_root:\n            try:\n                display_file_path = Path(file_path).resolve().relative_to(self.project_root)\n            except ValueError:\n                # Keep as name if not under project_root for some reason\n                pass \n\n        # Create a simple text report\n        with open(output_dir / 'file_content.md', 'w') as f:\n            f.write(f\"# GNN File: {display_file_path}\\\\n\\\\n\")\n            f.write(\"## Raw File Content\\\\n\\\\n\")\n            f.write(\"```\\\\n\")\n            f.write(raw_file_content)\n            f.write(\"\\\\n```\\\\n\\\\n\")\n            \n            # Add parsed sections if available\n            if parsed_data:\n                f.write(\"## Parsed Sections\\n\\n\")\n                for section, content in parsed_data.items():\n                    if section not in ['Variables', 'Edges']:  # Skip processed sections\n                        f.write(f\"### {section}\\n\\n\")\n                        f.write(\"```\\n\")\n                        f.write(str(content))\n                        f.write(\"\\n```\\n\\n\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "_save_model_metadata",
        "type": "method",
        "start_line": 233,
        "end_line": 259,
        "code": "def _save_model_metadata(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Save model metadata as JSON for reference.\"\"\"\n        # Extract relevant metadata\n        metadata = {\n            'ModelName': parsed_data.get('ModelName', ''),\n            'ModelAnnotation': parsed_data.get('ModelAnnotation', ''),\n            'GNNVersionAndFlags': parsed_data.get('GNNVersionAndFlags', ''),\n            'Time': parsed_data.get('Time', ''),\n            'ActInfOntologyAnnotation': parsed_data.get('ActInfOntologyAnnotation', '')\n        }\n        \n        # Save as JSON\n        with open(output_dir / 'model_metadata.json', 'w') as f:\n            json.dump(metadata, f, indent=2)\n            \n        # Also save full parsed data for reference\n        with open(output_dir / 'full_model_data.json', 'w') as f:\n            # Convert to serializable format\n            try:\n                serializable_data = {}\n                for k, v in parsed_data.items():\n                    if k not in ['Variables', 'Edges']:  # Skip complex objects\n                        serializable_data[k] = str(v)\n                json.dump(serializable_data, f, indent=2)\n            except Exception as e:\n                # Fallback to simple format\n                json.dump({\"error\": f\"Failed to serialize data: {str(e)}\"}, f)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "_visualize_state_space",
        "type": "method",
        "start_line": 261,
        "end_line": 308,
        "code": "def _visualize_state_space(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Generate visualization of the state space variables.\"\"\"\n        if 'Variables' not in parsed_data or not parsed_data['Variables']:\n            return\n            \n        variables = parsed_data['Variables']\n        \n        # Create figure and table\n        fig, ax = plt.subplots(figsize=(10, max(5, len(variables) * 0.5)))\n        ax.axis('tight')\n        ax.axis('off')\n        \n        # Prepare table data\n        table_data = []\n        for var_name, var_info in variables.items():\n            dimensions = 'x'.join(str(d) for d in var_info.get('dimensions', [])) if var_info.get('dimensions') else ''\n            var_type = var_info.get('type', '') or ''\n            comment = var_info.get('comment', '') or ''\n            table_data.append([var_name, dimensions, var_type, comment])\n        \n        # Create the table\n        if table_data:\n            table = ax.table(\n                cellText=table_data,\n                colLabels=['Variable', 'Dimensions', 'Type', 'Description'],\n                loc='center',\n                cellLoc='left',\n                colWidths=[0.15, 0.15, 0.15, 0.55]\n            )\n            \n            # Style the table\n            table.auto_set_font_size(False)\n            table.set_fontsize(10)\n            table.scale(1, 1.5)\n        else:\n            ax.text(0.5, 0.5, \"No state space variables found\", \n                    horizontalalignment='center', verticalalignment='center',\n                    fontsize=12)\n        \n        # Add title\n        plt.title('State Space Variables', fontsize=14, fontweight='bold', pad=20)\n        \n        # Save figure\n        plt.tight_layout()\n        plt.savefig(output_dir / 'state_space.png', dpi=150, bbox_inches='tight')\n        plt.close()\n        \n        print(f\"State space visualization saved to {output_dir / 'state_space.png'}\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "_visualize_connections",
        "type": "method",
        "start_line": 310,
        "end_line": 388,
        "code": "def _visualize_connections(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Generate visualization of the connections/edges in the model.\"\"\"\n        if 'Edges' not in parsed_data or not parsed_data['Edges']:\n            return\n            \n        edges = parsed_data['Edges']\n        \n        # Create directed graph\n        G = nx.DiGraph()\n        \n        try:\n            # Add nodes and edges\n            for edge in edges:\n                source = edge.get('source', '')\n                target = edge.get('target', '')\n                if not source or not target:\n                    continue\n                    \n                directed = edge.get('directed', True)\n                constraint = edge.get('constraint', None)\n                comment = edge.get('comment', None)\n                \n                G.add_node(source)\n                G.add_node(target)\n                \n                if directed:\n                    G.add_edge(source, target, constraint=constraint, comment=comment)\n                else:\n                    # For undirected edges in a directed graph, add edges in both directions\n                    G.add_edge(source, target, constraint=constraint, comment=comment)\n                    G.add_edge(target, source, constraint=constraint, comment=comment)\n            \n            # Create figure\n            plt.figure(figsize=(12, 10))\n            \n            if G.number_of_nodes() > 0:\n                # Set node positions using spring layout\n                pos = nx.spring_layout(G, seed=42)\n                \n                # Draw nodes\n                nx.draw_networkx_nodes(G, pos, node_size=700, node_color='lightblue', alpha=0.8)\n                \n                # Draw edges\n                nx.draw_networkx_edges(G, pos, width=1.5, alpha=0.7, arrowsize=20)\n                \n                # Draw labels\n                nx.draw_networkx_labels(G, pos, font_size=12, font_family='sans-serif')\n                \n                # Add edge labels for constraints\n                edge_labels = {(edge.get('source', ''), edge.get('target', '')): edge.get('constraint', '') \n                              for edge in edges if edge.get('constraint')}\n                if edge_labels:\n                    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n            else:\n                plt.text(0.5, 0.5, \"No connections found\", \n                        horizontalalignment='center', verticalalignment='center',\n                        fontsize=14)\n            \n            # Set title\n            plt.title('Model Connections', fontsize=14, fontweight='bold')\n            \n            # Remove axis\n            plt.axis('off')\n            \n            # Save figure\n            plt.tight_layout()\n            plt.savefig(output_dir / 'connections.png', dpi=150, bbox_inches='tight')\n            plt.close()\n            \n            print(f\"Connections visualization saved to {output_dir / 'connections.png'}\")\n        except Exception as e:\n            # Create error text figure if visualization fails\n            plt.figure(figsize=(10, 5))\n            plt.text(0.5, 0.5, f\"Error generating connections visualization: {str(e)}\", \n                    horizontalalignment='center', verticalalignment='center',\n                    fontsize=12, wrap=True)\n            plt.axis('off')\n            plt.savefig(output_dir / 'connections_error.png', dpi=150)\n            plt.close()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "_visualize_combined",
        "type": "method",
        "start_line": 390,
        "end_line": 498,
        "code": "def _visualize_combined(self, parsed_data: Dict[str, Any], output_dir: Path) -> None:\n        \"\"\"Generate a combined visualization of the model.\"\"\"\n        try:\n            # Create a comprehensive visualization that combines state space and connections\n            if 'Variables' not in parsed_data or not parsed_data['Variables'] or 'Edges' not in parsed_data or not parsed_data['Edges']:\n                return\n                \n            variables = parsed_data['Variables']\n            edges = parsed_data['Edges']\n            \n            # Create figure with two subplots\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n            \n            # Left subplot: Variable details\n            ax1.axis('tight')\n            ax1.axis('off')\n            \n            # Prepare table data\n            table_data = []\n            for var_name, var_info in variables.items():\n                dimensions = 'x'.join(str(d) for d in var_info.get('dimensions', [])) if var_info.get('dimensions') else ''\n                var_type = var_info.get('type', '') or ''\n                table_data.append([var_name, dimensions, var_type])\n            \n            # Create the table\n            if table_data:\n                table = ax1.table(\n                    cellText=table_data,\n                    colLabels=['Variable', 'Dimensions', 'Type'],\n                    loc='center',\n                    cellLoc='left'\n                )\n                \n                # Style the table\n                table.auto_set_font_size(False)\n                table.set_fontsize(10)\n                table.scale(1, 1.5)\n            else:\n                ax1.text(0.5, 0.5, \"No state space variables found\", \n                        horizontalalignment='center', verticalalignment='center',\n                        fontsize=12)\n            \n            ax1.set_title('State Space Variables', fontsize=14, fontweight='bold')\n            \n            # Right subplot: Connections graph\n            ax2.axis('off')\n            \n            # Create directed graph\n            G = nx.DiGraph()\n            \n            # Add nodes and edges\n            valid_edges = []\n            for edge in edges:\n                source = edge.get('source', '')\n                target = edge.get('target', '')\n                if not source or not target:\n                    continue\n                    \n                G.add_node(source)\n                G.add_node(target)\n                G.add_edge(source, target, directed=edge.get('directed', True))\n                valid_edges.append(edge)\n            \n            if G.number_of_nodes() > 0:\n                # Set node positions using spring layout\n                pos = nx.spring_layout(G, seed=42)\n                \n                # Draw nodes\n                nx.draw_networkx_nodes(G, pos, ax=ax2, node_size=700, node_color='lightblue', alpha=0.8)\n                \n                # Draw edges with different styles for directed and undirected\n                directed_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get('directed', True)]\n                undirected_edges = [(u, v) for u, v, d in G.edges(data=True) if not d.get('directed', True)]\n                \n                if directed_edges:\n                    nx.draw_networkx_edges(G, pos, ax=ax2, edgelist=directed_edges, \n                                        width=1.5, alpha=0.7, arrowsize=20)\n                if undirected_edges:\n                    nx.draw_networkx_edges(G, pos, ax=ax2, edgelist=undirected_edges, \n                                        width=1.5, alpha=0.7, arrowstyle='-')\n                \n                # Draw labels\n                nx.draw_networkx_labels(G, pos, ax=ax2, font_size=12, font_family='sans-serif')\n            else:\n                ax2.text(0.5, 0.5, \"No connections found\", \n                        horizontalalignment='center', verticalalignment='center',\n                        fontsize=14)\n            \n            ax2.set_title('Model Connections', fontsize=14, fontweight='bold')\n            \n            # Set overall title\n            model_name = self._extract_model_name(parsed_data)\n            fig.suptitle(model_name, fontsize=16, fontweight='bold')\n            \n            # Save figure\n            plt.tight_layout(rect=[0, 0, 1, 0.95])  # Make room for suptitle\n            plt.savefig(output_dir / 'combined_visualization.png', dpi=150, bbox_inches='tight')\n            plt.close()\n            \n            print(f\"Combined visualization saved to {output_dir / 'combined_visualization.png'}\")\n        except Exception as e:\n            # Create error text figure if visualization fails\n            plt.figure(figsize=(10, 5))\n            plt.text(0.5, 0.5, f\"Error generating combined visualization: {str(e)}\", \n                    horizontalalignment='center', verticalalignment='center',\n                    fontsize=12, wrap=True)\n            plt.axis('off')\n            plt.savefig(output_dir / 'combined_visualization_error.png', dpi=150)\n            plt.close()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      },
      {
        "name": "_extract_model_name",
        "type": "method",
        "start_line": 500,
        "end_line": 505,
        "code": "def _extract_model_name(self, parsed_data: Dict[str, Any]) -> str:\n        \"\"\"Extract a clean model name from the parsed data.\"\"\"\n        if 'ModelName' in parsed_data and parsed_data['ModelName']:\n            # Remove Markdown formatting and clean up\n            return parsed_data['ModelName'].replace('#', '').strip()\n        return \"GNN Model\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/visualizer.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/ontology_visualizer.py": [
      {
        "name": "OntologyVisualizer",
        "type": "class",
        "start_line": 12,
        "end_line": 120,
        "code": "class OntologyVisualizer:\n    \"\"\"\n    A class for visualizing ontology annotations extracted from GNN models.\n    \n    This visualizer provides methods to create table-based and other\n    visualizations of ontology mappings.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the ontology visualizer.\"\"\"\n        pass\n    \n    def visualize_ontology(self, parsed_data: Dict[str, Any], output_dir: Path) -> str:\n        \"\"\"\n        Generate visualization of the ontology annotations.\n        \n        Args:\n            parsed_data: Parsed GNN model data\n            output_dir: Directory to save visualization\n            \n        Returns:\n            Path to saved visualization file, or empty string if failed\n        \"\"\"\n        if 'ActInfOntologyAnnotation' not in parsed_data:\n            return \"\"\n            \n        ontology = parsed_data['ActInfOntologyAnnotation']\n        \n        # Extract ontology mappings\n        mappings = self._extract_ontology_mappings(ontology)\n        \n        if not mappings:\n            return \"\"\n            \n        # Create visualization\n        try:\n            return self._create_ontology_table(mappings, output_dir)\n        except Exception as e:\n            print(f\"Error creating ontology visualization: {e}\")\n            return \"\"\n    \n    def _extract_ontology_mappings(self, ontology_content: str) -> List[Tuple[str, str]]:\n        \"\"\"\n        Extract variable-concept mappings from ontology content.\n        \n        Args:\n            ontology_content: Raw content of the ActInfOntologyAnnotation section\n            \n        Returns:\n            List of (variable, concept) tuples\n        \"\"\"\n        mappings = []\n        \n        for line in ontology_content.split('\\n'):\n            line = line.strip()\n            if not line or '=' not in line:\n                continue\n                \n            parts = line.split('=', 1)\n            if len(parts) == 2:\n                variable = parts[0].strip()\n                concept = parts[1].strip()\n                mappings.append((variable, concept))\n        \n        return mappings\n    \n    def _create_ontology_table(self, mappings: List[Tuple[str, str]], output_dir: Path) -> str:\n        \"\"\"\n        Create a table visualization of ontology mappings.\n        \n        Args:\n            mappings: List of (variable, concept) tuples\n            output_dir: Directory to save visualization\n            \n        Returns:\n            Path to saved visualization file\n        \"\"\"\n        # Create figure\n        plt.figure(figsize=(10, max(5, len(mappings) * 0.5)))\n        ax = plt.subplot(111)\n        ax.axis('tight')\n        ax.axis('off')\n        \n        # Create table\n        table_data = [[var, concept] for var, concept in mappings]\n        table = ax.table(\n            cellText=table_data,\n            colLabels=['Variable', 'Ontological Concept'],\n            loc='center',\n            cellLoc='left',\n            colWidths=[0.3, 0.7]\n        )\n        \n        # Style the table\n        table.auto_set_font_size(False)\n        table.set_fontsize(10)\n        table.scale(1, 1.5)\n        \n        # Add title\n        plt.title('Ontological Annotations', fontsize=14, fontweight='bold', pad=20)\n        \n        # Save figure\n        output_path = output_dir / 'ontology_annotations.png'\n        plt.tight_layout()\n        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n        plt.close()\n        \n        print(f\"Ontology visualization saved to {output_path}\")\n        return str(output_path)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/ontology_visualizer.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 20,
        "end_line": 22,
        "code": "def __init__(self):\n        \"\"\"Initialize the ontology visualizer.\"\"\"\n        pass",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/ontology_visualizer.py"
      },
      {
        "name": "visualize_ontology",
        "type": "method",
        "start_line": 24,
        "end_line": 51,
        "code": "def visualize_ontology(self, parsed_data: Dict[str, Any], output_dir: Path) -> str:\n        \"\"\"\n        Generate visualization of the ontology annotations.\n        \n        Args:\n            parsed_data: Parsed GNN model data\n            output_dir: Directory to save visualization\n            \n        Returns:\n            Path to saved visualization file, or empty string if failed\n        \"\"\"\n        if 'ActInfOntologyAnnotation' not in parsed_data:\n            return \"\"\n            \n        ontology = parsed_data['ActInfOntologyAnnotation']\n        \n        # Extract ontology mappings\n        mappings = self._extract_ontology_mappings(ontology)\n        \n        if not mappings:\n            return \"\"\n            \n        # Create visualization\n        try:\n            return self._create_ontology_table(mappings, output_dir)\n        except Exception as e:\n            print(f\"Error creating ontology visualization: {e}\")\n            return \"\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/ontology_visualizer.py"
      },
      {
        "name": "_extract_ontology_mappings",
        "type": "method",
        "start_line": 53,
        "end_line": 76,
        "code": "def _extract_ontology_mappings(self, ontology_content: str) -> List[Tuple[str, str]]:\n        \"\"\"\n        Extract variable-concept mappings from ontology content.\n        \n        Args:\n            ontology_content: Raw content of the ActInfOntologyAnnotation section\n            \n        Returns:\n            List of (variable, concept) tuples\n        \"\"\"\n        mappings = []\n        \n        for line in ontology_content.split('\\n'):\n            line = line.strip()\n            if not line or '=' not in line:\n                continue\n                \n            parts = line.split('=', 1)\n            if len(parts) == 2:\n                variable = parts[0].strip()\n                concept = parts[1].strip()\n                mappings.append((variable, concept))\n        \n        return mappings",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/ontology_visualizer.py"
      },
      {
        "name": "_create_ontology_table",
        "type": "method",
        "start_line": 78,
        "end_line": 120,
        "code": "def _create_ontology_table(self, mappings: List[Tuple[str, str]], output_dir: Path) -> str:\n        \"\"\"\n        Create a table visualization of ontology mappings.\n        \n        Args:\n            mappings: List of (variable, concept) tuples\n            output_dir: Directory to save visualization\n            \n        Returns:\n            Path to saved visualization file\n        \"\"\"\n        # Create figure\n        plt.figure(figsize=(10, max(5, len(mappings) * 0.5)))\n        ax = plt.subplot(111)\n        ax.axis('tight')\n        ax.axis('off')\n        \n        # Create table\n        table_data = [[var, concept] for var, concept in mappings]\n        table = ax.table(\n            cellText=table_data,\n            colLabels=['Variable', 'Ontological Concept'],\n            loc='center',\n            cellLoc='left',\n            colWidths=[0.3, 0.7]\n        )\n        \n        # Style the table\n        table.auto_set_font_size(False)\n        table.set_fontsize(10)\n        table.scale(1, 1.5)\n        \n        # Add title\n        plt.title('Ontological Annotations', fontsize=14, fontweight='bold', pad=20)\n        \n        # Save figure\n        output_path = output_dir / 'ontology_annotations.png'\n        plt.tight_layout()\n        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n        plt.close()\n        \n        print(f\"Ontology visualization saved to {output_path}\")\n        return str(output_path)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/ontology_visualizer.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/run_visualization.py": [
      {
        "name": "main",
        "type": "function",
        "start_line": 21,
        "end_line": 75,
        "code": "def main():\n    \"\"\"Run the visualization on GNN examples.\"\"\"\n    parser = argparse.ArgumentParser(description='Generate visualizations for GNN examples.')\n    parser.add_argument('--input', '-i', type=str, default=str(parent_dir / 'gnn' / 'examples'),\n                        help='Directory containing GNN example files')\n    parser.add_argument('--output', '-o', type=str, default=str(parent_dir.parent / 'output' / 'gnn_examples_visualization'),\n                        help='Directory to save visualizations')\n    parser.add_argument('--recursive', '-r', action='store_true',\n                        help='Recursively process all subdirectories')\n    args = parser.parse_args()\n    \n    print(f\"Processing GNN examples from {args.input}\")\n    print(f\"Saving visualizations to {args.output}\")\n    \n    # Create visualizer\n    visualizer = GNNVisualizer(output_dir=args.output)\n    \n    # Process examples\n    input_path = Path(args.input)\n    \n    if input_path.is_file() and input_path.suffix.lower() == '.md':\n        # If input is a single file\n        md_files = [input_path]\n        print(f\"Processing single file: {input_path}\")\n    else:\n        # If input is a directory\n        if not input_path.exists():\n            print(f\"Error: Input path {input_path} does not exist\")\n            return 1\n        \n        # Find all markdown files\n        if args.recursive:\n            md_files = list(input_path.glob('**/*.md'))\n        else:\n            md_files = list(input_path.glob('*.md'))\n        \n        if not md_files:\n            print(f\"No Markdown files found in {input_path}\")\n            return 1\n    \n    print(f\"Found {len(md_files)} Markdown files\")\n    \n    # Process each file\n    success_count = 0\n    for md_file in md_files:\n        print(f\"\\nProcessing {md_file}...\")\n        try:\n            output_dir = visualizer.visualize_file(str(md_file))\n            print(f\"Visualizations saved to {output_dir}\")\n            success_count += 1\n        except Exception as e:\n            print(f\"Error processing {md_file}: {e}\")\n    \n    print(f\"\\nProcessed {len(md_files)} files, {success_count} succeeded\")\n    return 0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/run_visualization.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/cli.py": [
      {
        "name": "parse_args",
        "type": "function",
        "start_line": 15,
        "end_line": 46,
        "code": "def parse_args(args: Optional[List[str]] = None) -> argparse.Namespace:\n    \"\"\"Parse command-line arguments.\"\"\"\n    parser = argparse.ArgumentParser(\n        description='Generate visualizations for GNN models.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    \n    # Input options\n    parser.add_argument(\n        'input',\n        help='Path to a GNN file or directory containing GNN files'\n    )\n    \n    # Output directory\n    parser.add_argument(\n        '-o', '--output-dir',\n        help='Directory to save visualizations. If not provided, creates a timestamped directory in ../output.',\n        default='../output'  # Defaults to output folder in the parent of current scripts (e.g. project_root/output)\n    )\n    \n    # Visualization options\n    parser.add_argument(\n        '--recursive',\n        help='Recursively process directories',\n        action='store_true'\n    )\n    parser.add_argument(\n        '--project-root',\n        help='Absolute path to the project root, for relative path generation in reports'\n    )\n    \n    return parser.parse_args(args)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/cli.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 49,
        "end_line": 82,
        "code": "def main(args: Optional[List[str]] = None) -> int:\n    \"\"\"Main entry point for GNN visualization CLI.\"\"\"\n    parsed_args = parse_args(args)\n    \n    # Create visualizer\n    visualizer = GNNVisualizer(output_dir=parsed_args.output_dir, project_root=parsed_args.project_root)\n    \n    # Get input path\n    input_path = Path(parsed_args.input)\n    \n    # Process input\n    if input_path.is_file():\n        # Single file\n        output_dir = visualizer.visualize_file(str(input_path))\n        print(f\"Visualizations generated in {output_dir}\")\n    elif input_path.is_dir():\n        # Directory\n        if parsed_args.recursive:\n            # Process all md files recursively\n            for file_path in input_path.glob('**/*.md'):\n                try:\n                    visualizer.visualize_file(str(file_path))\n                except Exception as e:\n                    print(f\"Error processing {file_path}: {e}\")\n            print(f\"Visualizations generated in {visualizer.output_dir}\")\n        else:\n            # Process only md files in the top directory\n            output_dir = visualizer.visualize_directory(str(input_path))\n            print(f\"Visualizations generated in {output_dir}\")\n    else:\n        print(f\"Error: Input path '{input_path}' does not exist\")\n        return 1\n    \n    return 0",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/cli.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/parser.py": [
      {
        "name": "GNNParser",
        "type": "class",
        "start_line": 17,
        "end_line": 260,
        "code": "class GNNParser:\n    \"\"\"Parser for GNN files in various formats.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the GNN parser.\"\"\"\n        self.sections = {}\n        \n    def parse_file(self, file_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Parse a GNN file and return the structured content.\n        \n        Args:\n            file_path: Path to the GNN file to parse\n            \n        Returns:\n            Dictionary containing parsed GNN sections\n        \"\"\"\n        path = Path(file_path)\n        content = path.read_text()\n        \n        # Determine file format based on file content\n        if \"GNNSection,\" in content:\n            return self._parse_csv_format(file_path, content)\n        else:\n            return self._parse_markdown_format(content)\n    \n    def _parse_csv_format(self, file_path: str, content: str) -> Dict[str, Any]:\n        \"\"\"Parse GNN file in CSV format.\"\"\"\n        sections = {}\n        \n        # Extract header comments\n        header_lines = []\n        content_lines = content.splitlines()\n        line_index = 0\n        \n        while line_index < len(content_lines) and (content_lines[line_index].startswith('#') or not content_lines[line_index].strip()):\n            if content_lines[line_index].startswith('#'):\n                header_lines.append(content_lines[line_index])\n            line_index += 1\n        \n        # Add header information to sections\n        if header_lines:\n            sections['ModelName'] = header_lines[0].replace('#', '').strip()\n            if len(header_lines) > 1:\n                sections['ModelAnnotation'] = '\\n'.join([h.replace('#', '').strip() for h in header_lines[1:]])\n        \n        # Re-parse the raw file content to extract all sections\n        self._extract_gnn_csv_sections(content, sections)\n        \n        # Process state space and connections\n        logger.debug(f\"Before processing, StateSpaceBlock length: {len(sections.get('StateSpaceBlock', ''))}\")\n        self._process_state_space(sections)\n        self._process_connections(sections)\n        \n        return sections\n    \n    def _extract_gnn_csv_sections(self, content: str, sections: Dict[str, Any]) -> None:\n        \"\"\"Extract sections from GNN CSV format, handling quoted multiline values.\"\"\"\n        # Extract each section with its quoted content\n        section_pattern = r'(\\w+),(?:\"([^\"]*)\"|(.*?)(?=\\n\\w+,|\\Z))'\n        \n        for match in re.finditer(section_pattern, content, re.DOTALL):\n            section_name = match.group(1)\n            # Get the content from either the quoted group or unquoted group\n            section_content = match.group(2) if match.group(2) is not None else match.group(3)\n            \n            if section_content is not None:\n                # Clean up the section content\n                if section_name in ['StateSpaceBlock', 'Connections', 'InitialParameterization',\n                                    'Equations', 'Time', 'ActInfOntologyAnnotation']:\n                    # Remove leading markdown header if present\n                    if section_content.startswith('## '):\n                        section_content = section_content.split('\\n', 1)[1] if '\\n' in section_content else ''\n                \n                sections[section_name] = section_content.strip()\n    \n    def _parse_markdown_format(self, content: str) -> Dict[str, Any]:\n        \"\"\"Parse GNN file in Markdown format.\"\"\"\n        lines = content.splitlines()\n        sections: Dict[str, Any] = {}\n        current_section_name: str | None = None\n        current_section_content: List[str] = []\n        \n        # Preserve header comments (lines starting with # not followed by ##)\n        header_comments = []\n        line_idx = 0\n        while line_idx < len(lines) and lines[line_idx].startswith('#') and not lines[line_idx].startswith('##'):\n            header_comments.append(lines[line_idx])\n            line_idx +=1\n        if header_comments:\n            sections['_HeaderComments'] = \"\\n\".join(header_comments)\n\n        # Heuristic for ModelName and ModelAnnotation if not explicitly sectioned early\n        # This is based on the observation that the first few non-comment, non-section lines might be these.\n        if lines[0].startswith('# ') and not lines[0].startswith('## '):\n            potential_model_name = lines[0][2:].strip()\n            if 'ModelName' not in sections:\n                 sections['ModelName'] = potential_model_name\n\n        for line in lines[line_idx:]:\n            stripped_line = line.strip()\n            if stripped_line.startswith('## '):\n                if current_section_name and current_section_content:\n                    sections[current_section_name] = '\\n'.join(current_section_content).strip()\n                \n                current_section_name = stripped_line[3:].strip()\n                current_section_content = []\n                # Handle cases where section name might have a colon (as seen in gnn_file_structure.md)\n                if ':' in current_section_name:\n                    current_section_name = current_section_name.split(':',1)[0].strip()\n\n            elif current_section_name:\n                current_section_content.append(line)\n        \n        # Save the last section\n        if current_section_name and current_section_content:\n            sections[current_section_name] = '\\n'.join(current_section_content).strip()\n        \n        # Process specific GNN sections for structured data\n        self._process_state_space(sections)\n        self._process_connections(sections)\n        \n        # Attempt to populate ModelName from header if not found as a section\n        if 'ModelName' not in sections and '_HeaderComments' in sections:\n            header_lines = sections['_HeaderComments'].split('\\n')\n            if header_lines and header_lines[0].startswith('# GNN Example: '):\n                sections['ModelName'] = header_lines[0].replace('# GNN Example: ', '').strip()\n            elif header_lines and header_lines[0].startswith('# '):\n                 sections['ModelName'] = header_lines[0][2:].strip()\n\n        return sections\n    \n    def _process_state_space(self, sections: Dict[str, Any]) -> None:\n        \"\"\"Process the StateSpaceBlock to extract variables and their dimensions.\"\"\"\n        if 'StateSpaceBlock' not in sections:\n            logger.debug(\"StateSpaceBlock section not found\")\n            return\n            \n        state_space_content = sections['StateSpaceBlock']\n        variables = {}\n        \n        logger.debug(\"Processing state space block...\")\n        \n        lines = state_space_content.split('\\n')\n        for line in lines:\n            line = line.strip()\n            if not line or line.startswith('##'): # Ignore empty lines or sub-headers within content\n                continue\n                \n            # First, check if there's a comment in the line\n            comment = \"\"\n            hash_index = line.find('#')\n            if hash_index != -1:\n                comment = line[hash_index+1:].strip()\n                line = line[:hash_index].strip()  # Remove the comment part for cleaner regex matching\n            \n            # Match the variable definition\n            match = re.match(r'(\\w+(?:\\^\\w+)?(?:_\\w+)?)\\s*\\[([^\\]]+)\\]', line)\n            if not match:\n                match = re.match(r'(\\w+(?:\\^\\w+)?(?:_\\w+)?)\\s*([\\w,=\\[\\]]+)', line)\n            \n            if match:\n                var_name = match.group(1)\n                dimensions_str = match.group(2)\n                \n                logger.debug(f\"Found variable: {var_name}, dimensions: {dimensions_str}, comment: {comment}\")\n                \n                dimensions = []\n                var_type = None\n                \n                # Handle simple dimension strings like \"len(\u03c0)\" or \"[2]\"\n                if re.fullmatch(r'len\\(\\w+\\)', dimensions_str) or re.fullmatch(r'\\[\\d+\\]', dimensions_str):\n                    dimensions.append(dimensions_str) # Keep as string for such cases\n                else:\n                    for dim_part in dimensions_str.split(','):\n                        dim_part = dim_part.strip()\n                        if 'type=' in dim_part:\n                            var_type = dim_part.split('=')[1]\n                        else:\n                            try:\n                                dimensions.append(int(dim_part))\n                            except ValueError:\n                                dimensions.append(dim_part) # Keep as string if not int\n                \n                variables[var_name] = {\n                    'dimensions': dimensions,\n                    'type': var_type,\n                    'comment': comment\n                }\n        \n        if variables:\n            logger.debug(f\"Extracted {len(variables)} variables with comments: {[(k, v.get('comment', '')) for k, v in variables.items()]}\")\n            sections['Variables'] = variables\n        else:\n            logger.debug(\"No variables could be extracted from state space\")\n    \n    def _process_connections(self, sections: Dict[str, Any]) -> None:\n        \"\"\"Process the Connections section to extract graph structure.\"\"\"\n        if 'Connections' not in sections:\n            return\n            \n        connections_content = sections['Connections']\n        edges = []\n        \n        pattern = r'(\\w+(?:\\^\\w+)?(?:_\\w+)?(?:\\+\\d+)?)\\s*([>\\-])\\s*(\\w+(?:\\^\\w+)?(?:_\\w+)?(?:\\+\\d+)?)\\s*(?:=\\s*([^#]*))?(?:#(.*))?'\n        \n        lines = connections_content.split('\\n')\n        for line in lines:\n            line = line.strip()\n            if not line or line.startswith('##'): # Ignore empty lines or sub-headers\n                continue\n                \n            match = re.match(pattern, line)\n            if match:\n                source = match.group(1)\n                edge_type = match.group(2)\n                target = match.group(3)\n                constraint = match.group(4).strip() if match.group(4) else None\n                comment = match.group(5).strip() if match.group(5) else None\n                \n                logger.debug(f\"Found edge: {source} {edge_type} {target}\")\n                \n                edges.append({\n                    'source': source,\n                    'target': target,\n                    'directed': edge_type == '>',\n                    'constraint': constraint,\n                    'comment': comment\n                })\n        \n        if edges:\n            sections['Edges'] = edges\n    \n    def extract_sections(self, file_path: str) -> Dict[str, str]:\n        \"\"\"\n        Extract all sections from a GNN file without detailed parsing.\n        \n        Args:\n            file_path: Path to the GNN file\n            \n        Returns:\n            Dictionary with section names as keys and their raw content as values\n        \"\"\"\n        return self.parse_file(file_path)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/parser.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 20,
        "end_line": 22,
        "code": "def __init__(self):\n        \"\"\"Initialize the GNN parser.\"\"\"\n        self.sections = {}",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/parser.py"
      },
      {
        "name": "parse_file",
        "type": "method",
        "start_line": 24,
        "end_line": 41,
        "code": "def parse_file(self, file_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Parse a GNN file and return the structured content.\n        \n        Args:\n            file_path: Path to the GNN file to parse\n            \n        Returns:\n            Dictionary containing parsed GNN sections\n        \"\"\"\n        path = Path(file_path)\n        content = path.read_text()\n        \n        # Determine file format based on file content\n        if \"GNNSection,\" in content:\n            return self._parse_csv_format(file_path, content)\n        else:\n            return self._parse_markdown_format(content)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/parser.py"
      },
      {
        "name": "_parse_csv_format",
        "type": "method",
        "start_line": 43,
        "end_line": 71,
        "code": "def _parse_csv_format(self, file_path: str, content: str) -> Dict[str, Any]:\n        \"\"\"Parse GNN file in CSV format.\"\"\"\n        sections = {}\n        \n        # Extract header comments\n        header_lines = []\n        content_lines = content.splitlines()\n        line_index = 0\n        \n        while line_index < len(content_lines) and (content_lines[line_index].startswith('#') or not content_lines[line_index].strip()):\n            if content_lines[line_index].startswith('#'):\n                header_lines.append(content_lines[line_index])\n            line_index += 1\n        \n        # Add header information to sections\n        if header_lines:\n            sections['ModelName'] = header_lines[0].replace('#', '').strip()\n            if len(header_lines) > 1:\n                sections['ModelAnnotation'] = '\\n'.join([h.replace('#', '').strip() for h in header_lines[1:]])\n        \n        # Re-parse the raw file content to extract all sections\n        self._extract_gnn_csv_sections(content, sections)\n        \n        # Process state space and connections\n        logger.debug(f\"Before processing, StateSpaceBlock length: {len(sections.get('StateSpaceBlock', ''))}\")\n        self._process_state_space(sections)\n        self._process_connections(sections)\n        \n        return sections",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/parser.py"
      },
      {
        "name": "_extract_gnn_csv_sections",
        "type": "method",
        "start_line": 73,
        "end_line": 91,
        "code": "def _extract_gnn_csv_sections(self, content: str, sections: Dict[str, Any]) -> None:\n        \"\"\"Extract sections from GNN CSV format, handling quoted multiline values.\"\"\"\n        # Extract each section with its quoted content\n        section_pattern = r'(\\w+),(?:\"([^\"]*)\"|(.*?)(?=\\n\\w+,|\\Z))'\n        \n        for match in re.finditer(section_pattern, content, re.DOTALL):\n            section_name = match.group(1)\n            # Get the content from either the quoted group or unquoted group\n            section_content = match.group(2) if match.group(2) is not None else match.group(3)\n            \n            if section_content is not None:\n                # Clean up the section content\n                if section_name in ['StateSpaceBlock', 'Connections', 'InitialParameterization',\n                                    'Equations', 'Time', 'ActInfOntologyAnnotation']:\n                    # Remove leading markdown header if present\n                    if section_content.startswith('## '):\n                        section_content = section_content.split('\\n', 1)[1] if '\\n' in section_content else ''\n                \n                sections[section_name] = section_content.strip()",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/parser.py"
      },
      {
        "name": "_parse_markdown_format",
        "type": "method",
        "start_line": 93,
        "end_line": 147,
        "code": "def _parse_markdown_format(self, content: str) -> Dict[str, Any]:\n        \"\"\"Parse GNN file in Markdown format.\"\"\"\n        lines = content.splitlines()\n        sections: Dict[str, Any] = {}\n        current_section_name: str | None = None\n        current_section_content: List[str] = []\n        \n        # Preserve header comments (lines starting with # not followed by ##)\n        header_comments = []\n        line_idx = 0\n        while line_idx < len(lines) and lines[line_idx].startswith('#') and not lines[line_idx].startswith('##'):\n            header_comments.append(lines[line_idx])\n            line_idx +=1\n        if header_comments:\n            sections['_HeaderComments'] = \"\\n\".join(header_comments)\n\n        # Heuristic for ModelName and ModelAnnotation if not explicitly sectioned early\n        # This is based on the observation that the first few non-comment, non-section lines might be these.\n        if lines[0].startswith('# ') and not lines[0].startswith('## '):\n            potential_model_name = lines[0][2:].strip()\n            if 'ModelName' not in sections:\n                 sections['ModelName'] = potential_model_name\n\n        for line in lines[line_idx:]:\n            stripped_line = line.strip()\n            if stripped_line.startswith('## '):\n                if current_section_name and current_section_content:\n                    sections[current_section_name] = '\\n'.join(current_section_content).strip()\n                \n                current_section_name = stripped_line[3:].strip()\n                current_section_content = []\n                # Handle cases where section name might have a colon (as seen in gnn_file_structure.md)\n                if ':' in current_section_name:\n                    current_section_name = current_section_name.split(':',1)[0].strip()\n\n            elif current_section_name:\n                current_section_content.append(line)\n        \n        # Save the last section\n        if current_section_name and current_section_content:\n            sections[current_section_name] = '\\n'.join(current_section_content).strip()\n        \n        # Process specific GNN sections for structured data\n        self._process_state_space(sections)\n        self._process_connections(sections)\n        \n        # Attempt to populate ModelName from header if not found as a section\n        if 'ModelName' not in sections and '_HeaderComments' in sections:\n            header_lines = sections['_HeaderComments'].split('\\n')\n            if header_lines and header_lines[0].startswith('# GNN Example: '):\n                sections['ModelName'] = header_lines[0].replace('# GNN Example: ', '').strip()\n            elif header_lines and header_lines[0].startswith('# '):\n                 sections['ModelName'] = header_lines[0][2:].strip()\n\n        return sections",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/parser.py"
      },
      {
        "name": "_process_state_space",
        "type": "method",
        "start_line": 149,
        "end_line": 211,
        "code": "def _process_state_space(self, sections: Dict[str, Any]) -> None:\n        \"\"\"Process the StateSpaceBlock to extract variables and their dimensions.\"\"\"\n        if 'StateSpaceBlock' not in sections:\n            logger.debug(\"StateSpaceBlock section not found\")\n            return\n            \n        state_space_content = sections['StateSpaceBlock']\n        variables = {}\n        \n        logger.debug(\"Processing state space block...\")\n        \n        lines = state_space_content.split('\\n')\n        for line in lines:\n            line = line.strip()\n            if not line or line.startswith('##'): # Ignore empty lines or sub-headers within content\n                continue\n                \n            # First, check if there's a comment in the line\n            comment = \"\"\n            hash_index = line.find('#')\n            if hash_index != -1:\n                comment = line[hash_index+1:].strip()\n                line = line[:hash_index].strip()  # Remove the comment part for cleaner regex matching\n            \n            # Match the variable definition\n            match = re.match(r'(\\w+(?:\\^\\w+)?(?:_\\w+)?)\\s*\\[([^\\]]+)\\]', line)\n            if not match:\n                match = re.match(r'(\\w+(?:\\^\\w+)?(?:_\\w+)?)\\s*([\\w,=\\[\\]]+)', line)\n            \n            if match:\n                var_name = match.group(1)\n                dimensions_str = match.group(2)\n                \n                logger.debug(f\"Found variable: {var_name}, dimensions: {dimensions_str}, comment: {comment}\")\n                \n                dimensions = []\n                var_type = None\n                \n                # Handle simple dimension strings like \"len(\u03c0)\" or \"[2]\"\n                if re.fullmatch(r'len\\(\\w+\\)', dimensions_str) or re.fullmatch(r'\\[\\d+\\]', dimensions_str):\n                    dimensions.append(dimensions_str) # Keep as string for such cases\n                else:\n                    for dim_part in dimensions_str.split(','):\n                        dim_part = dim_part.strip()\n                        if 'type=' in dim_part:\n                            var_type = dim_part.split('=')[1]\n                        else:\n                            try:\n                                dimensions.append(int(dim_part))\n                            except ValueError:\n                                dimensions.append(dim_part) # Keep as string if not int\n                \n                variables[var_name] = {\n                    'dimensions': dimensions,\n                    'type': var_type,\n                    'comment': comment\n                }\n        \n        if variables:\n            logger.debug(f\"Extracted {len(variables)} variables with comments: {[(k, v.get('comment', '')) for k, v in variables.items()]}\")\n            sections['Variables'] = variables\n        else:\n            logger.debug(\"No variables could be extracted from state space\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/parser.py"
      },
      {
        "name": "_process_connections",
        "type": "method",
        "start_line": 213,
        "end_line": 248,
        "code": "def _process_connections(self, sections: Dict[str, Any]) -> None:\n        \"\"\"Process the Connections section to extract graph structure.\"\"\"\n        if 'Connections' not in sections:\n            return\n            \n        connections_content = sections['Connections']\n        edges = []\n        \n        pattern = r'(\\w+(?:\\^\\w+)?(?:_\\w+)?(?:\\+\\d+)?)\\s*([>\\-])\\s*(\\w+(?:\\^\\w+)?(?:_\\w+)?(?:\\+\\d+)?)\\s*(?:=\\s*([^#]*))?(?:#(.*))?'\n        \n        lines = connections_content.split('\\n')\n        for line in lines:\n            line = line.strip()\n            if not line or line.startswith('##'): # Ignore empty lines or sub-headers\n                continue\n                \n            match = re.match(pattern, line)\n            if match:\n                source = match.group(1)\n                edge_type = match.group(2)\n                target = match.group(3)\n                constraint = match.group(4).strip() if match.group(4) else None\n                comment = match.group(5).strip() if match.group(5) else None\n                \n                logger.debug(f\"Found edge: {source} {edge_type} {target}\")\n                \n                edges.append({\n                    'source': source,\n                    'target': target,\n                    'directed': edge_type == '>',\n                    'constraint': constraint,\n                    'comment': comment\n                })\n        \n        if edges:\n            sections['Edges'] = edges",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/parser.py"
      },
      {
        "name": "extract_sections",
        "type": "method",
        "start_line": 250,
        "end_line": 260,
        "code": "def extract_sections(self, file_path: str) -> Dict[str, str]:\n        \"\"\"\n        Extract all sections from a GNN file without detailed parsing.\n        \n        Args:\n            file_path: Path to the GNN file\n            \n        Returns:\n            Dictionary with section names as keys and their raw content as values\n        \"\"\"\n        return self.parse_file(file_path)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/visualization/parser.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py": [
      {
        "name": "MCPTool",
        "type": "class",
        "start_line": 35,
        "end_line": 37,
        "code": "class MCPTool:\n        def __init__(self, name: str, func: Callable, schema: Dict, description: str):\n            pass # Minimal placeholder",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 36,
        "end_line": 37,
        "code": "def __init__(self, name: str, func: Callable, schema: Dict, description: str):\n            pass # Minimal placeholder",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      },
      {
        "name": "RenderGnnInput",
        "type": "class",
        "start_line": 44,
        "end_line": 58,
        "code": "class RenderGnnInput(BaseModel):\n    gnn_specification: Union[Dict[str, Any], str] = Field(\n        description=\"The GNN specification itself as a dictionary, or a string URI/path to a GNN spec file (e.g., JSON).\"\n    )\n    target_format: Literal[\"pymdp\", \"rxinfer\"] = Field(\n        description=\"The target format to render the GNN specification to.\"\n    )\n    output_filename_base: Optional[str] = Field(\n        None,\n        description=\"Optional desired base name for the output file (e.g., 'my_model'). Extension is added automatically. If None, derived from GNN spec name or input file name.\"\n    )\n    render_options: Optional[Dict[str, Any]] = Field(\n        None, \n        description=\"Optional dictionary of specific options for the chosen renderer (e.g., data_bindings for RxInfer).\"\n    )",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      },
      {
        "name": "RenderGnnOutput",
        "type": "class",
        "start_line": 60,
        "end_line": 70,
        "code": "class RenderGnnOutput(BaseModel):\n    success: bool = Field(description=\"Whether the rendering was successful.\")\n    message: str = Field(description=\"A message describing the outcome of the rendering process.\")\n    artifact_uri: Optional[str] = Field(\n        None, \n        description=\"URI to the generated rendered file, if successful and file was saved.\"\n    )\n    rendered_content_preview: Optional[str] = Field(\n        None,\n        description=\"A preview of the rendered content (e.g., first N lines). May be null if content is large or not applicable.\"\n    )",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      },
      {
        "name": "ListRenderTargetsInput",
        "type": "class",
        "start_line": 72,
        "end_line": 73,
        "code": "class ListRenderTargetsInput(BaseModel):\n    pass",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      },
      {
        "name": "ListRenderTargetsOutput",
        "type": "class",
        "start_line": 75,
        "end_line": 76,
        "code": "class ListRenderTargetsOutput(BaseModel):\n    targets: List[str] = Field(description=\"A list of supported rendering target formats.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      },
      {
        "name": "handle_render_gnn_spec",
        "type": "function",
        "start_line": 84,
        "end_line": 150,
        "code": "async def handle_render_gnn_spec(input_data: RenderGnnInput) -> RenderGnnOutput:\n    \"\"\"Handles a request to render a GNN specification to a target format.\"\"\"\n    logger.info(f\"MCP Tool: Received request to render GNN to {input_data.target_format}\")\n\n    gnn_spec_dict: Optional[Dict[str, Any]] = None\n\n    if isinstance(input_data.gnn_specification, dict):\n        gnn_spec_dict = input_data.gnn_specification\n        logger.debug(\"Received GNN specification directly as a dictionary.\")\n    elif isinstance(input_data.gnn_specification, str):\n        gnn_file_path = Path(input_data.gnn_specification)\n        logger.debug(f\"Attempting to load GNN specification from path: {gnn_file_path}\")\n        if not gnn_file_path.is_file():\n            return RenderGnnOutput(success=False, message=f\"GNN specification file not found: {gnn_file_path}\")\n        try:\n            with open(gnn_file_path, 'r', encoding='utf-8') as f:\n                gnn_spec_dict = json.load(f)\n            logger.info(f\"Successfully loaded GNN specification from {gnn_file_path}\")\n        except json.JSONDecodeError as e:\n            return RenderGnnOutput(success=False, message=f\"Error decoding JSON from {gnn_file_path}: {e}\")\n        except Exception as e:\n            return RenderGnnOutput(success=False, message=f\"Failed to read GNN file {gnn_file_path}: {e}\")\n    else:\n        return RenderGnnOutput(success=False, message=\"Invalid gnn_specification type. Must be dict or str path.\")\n\n    if gnn_spec_dict is None:\n         return RenderGnnOutput(success=False, message=\"Could not obtain GNN specification dictionary.\")\n\n    temp_dir = Path(tempfile.mkdtemp(prefix=\"gnn_render_mcp_\"))\n    \n    filename_base = input_data.output_filename_base\n    if not filename_base:\n        filename_base = gnn_spec_dict.get(\"name\", \"rendered_gnn_model\")\n        filename_base = filename_base.replace(\" \", \"_\").lower()\n    \n    file_extension = \".py\" if input_data.target_format == \"pymdp\" else \".jl\"\n    output_script_name = f\"{filename_base}{file_extension}\"\n    temp_output_path = temp_dir / output_script_name\n\n    logger.info(f\"Rendering to temporary file: {temp_output_path}\")\n\n    success, message, artifacts = render_gnn_spec(\n        gnn_spec=gnn_spec_dict,\n        output_script_path=temp_output_path,\n        target_format=input_data.target_format,\n        render_options=input_data.render_options or {}\n    )\n\n    if success:\n        artifact_uri = temp_output_path.as_uri() if artifacts else None\n        content_preview = None\n        try:\n            with open(temp_output_path, 'r', encoding='utf-8') as f:\n                lines = [next(f) for _ in range(20)]\n                content_preview = \"\".join(lines) + (\"... (truncated)\" if len(lines) == 20 else \"\")\n        except Exception as e:\n            logger.warning(f\"Could not read rendered file for preview: {e}\")\n        \n        return RenderGnnOutput(\n            success=True, \n            message=message, \n            artifact_uri=artifact_uri,\n            rendered_content_preview=content_preview\n        )\n    else:\n        logger.error(f\"MCP Tool: Rendering GNN failed. Message from renderer: {message}\")\n        return RenderGnnOutput(success=False, message=message)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      },
      {
        "name": "handle_render_gnn_spec",
        "type": "function",
        "start_line": 84,
        "end_line": 150,
        "code": "async def handle_render_gnn_spec(input_data: RenderGnnInput) -> RenderGnnOutput:\n    \"\"\"Handles a request to render a GNN specification to a target format.\"\"\"\n    logger.info(f\"MCP Tool: Received request to render GNN to {input_data.target_format}\")\n\n    gnn_spec_dict: Optional[Dict[str, Any]] = None\n\n    if isinstance(input_data.gnn_specification, dict):\n        gnn_spec_dict = input_data.gnn_specification\n        logger.debug(\"Received GNN specification directly as a dictionary.\")\n    elif isinstance(input_data.gnn_specification, str):\n        gnn_file_path = Path(input_data.gnn_specification)\n        logger.debug(f\"Attempting to load GNN specification from path: {gnn_file_path}\")\n        if not gnn_file_path.is_file():\n            return RenderGnnOutput(success=False, message=f\"GNN specification file not found: {gnn_file_path}\")\n        try:\n            with open(gnn_file_path, 'r', encoding='utf-8') as f:\n                gnn_spec_dict = json.load(f)\n            logger.info(f\"Successfully loaded GNN specification from {gnn_file_path}\")\n        except json.JSONDecodeError as e:\n            return RenderGnnOutput(success=False, message=f\"Error decoding JSON from {gnn_file_path}: {e}\")\n        except Exception as e:\n            return RenderGnnOutput(success=False, message=f\"Failed to read GNN file {gnn_file_path}: {e}\")\n    else:\n        return RenderGnnOutput(success=False, message=\"Invalid gnn_specification type. Must be dict or str path.\")\n\n    if gnn_spec_dict is None:\n         return RenderGnnOutput(success=False, message=\"Could not obtain GNN specification dictionary.\")\n\n    temp_dir = Path(tempfile.mkdtemp(prefix=\"gnn_render_mcp_\"))\n    \n    filename_base = input_data.output_filename_base\n    if not filename_base:\n        filename_base = gnn_spec_dict.get(\"name\", \"rendered_gnn_model\")\n        filename_base = filename_base.replace(\" \", \"_\").lower()\n    \n    file_extension = \".py\" if input_data.target_format == \"pymdp\" else \".jl\"\n    output_script_name = f\"{filename_base}{file_extension}\"\n    temp_output_path = temp_dir / output_script_name\n\n    logger.info(f\"Rendering to temporary file: {temp_output_path}\")\n\n    success, message, artifacts = render_gnn_spec(\n        gnn_spec=gnn_spec_dict,\n        output_script_path=temp_output_path,\n        target_format=input_data.target_format,\n        render_options=input_data.render_options or {}\n    )\n\n    if success:\n        artifact_uri = temp_output_path.as_uri() if artifacts else None\n        content_preview = None\n        try:\n            with open(temp_output_path, 'r', encoding='utf-8') as f:\n                lines = [next(f) for _ in range(20)]\n                content_preview = \"\".join(lines) + (\"... (truncated)\" if len(lines) == 20 else \"\")\n        except Exception as e:\n            logger.warning(f\"Could not read rendered file for preview: {e}\")\n        \n        return RenderGnnOutput(\n            success=True, \n            message=message, \n            artifact_uri=artifact_uri,\n            rendered_content_preview=content_preview\n        )\n    else:\n        logger.error(f\"MCP Tool: Rendering GNN failed. Message from renderer: {message}\")\n        return RenderGnnOutput(success=False, message=message)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      },
      {
        "name": "handle_list_render_targets",
        "type": "function",
        "start_line": 152,
        "end_line": 156,
        "code": "async def handle_list_render_targets() -> ListRenderTargetsOutput:\n    \"\"\"Lists the supported rendering target formats.\"\"\"\n    logger.info(\"MCP Tool: Received request to list render targets.\")\n    supported_targets = [\"pymdp\", \"rxinfer\"]\n    return ListRenderTargetsOutput(targets=supported_targets)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      },
      {
        "name": "handle_list_render_targets",
        "type": "function",
        "start_line": 152,
        "end_line": 156,
        "code": "async def handle_list_render_targets() -> ListRenderTargetsOutput:\n    \"\"\"Lists the supported rendering target formats.\"\"\"\n    logger.info(\"MCP Tool: Received request to list render targets.\")\n    supported_targets = [\"pymdp\", \"rxinfer\"]\n    return ListRenderTargetsOutput(targets=supported_targets)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      },
      {
        "name": "register_tools",
        "type": "function",
        "start_line": 160,
        "end_line": 187,
        "code": "def register_tools(mcp_instance_param): # Name changed to avoid conflict if mcp_instance is imported\n    \"\"\"\n    Registers the rendering tools with the provided MCP instance.\n    This function will be called by the main MCP module during discovery.\n    \"\"\"\n    \n    # Note on schemas: Pydantic models (RenderGnnInput, ListRenderTargetsOutput)\n    # can be converted to JSON Schema for MCP. The MCP registration might handle this\n    # automatically if it supports Pydantic, or a manual conversion step might be needed.\n    # For simplicity here, we'll pass the Pydantic model itself, assuming the\n    # MCP framework can derive or is given the schema.\n    # If MCPTool expects a dict schema: input_schema=RenderGnnInput.schema()\n\n    mcp_instance_param.register_tool(\n        name=\"render_gnn_specification\",\n        func=handle_render_gnn_spec,\n        schema=RenderGnnInput.model_json_schema(),\n        description=\"Renders a GNN (Generalized Notation Notation) specification into an executable format for a target modeling environment like PyMDP or RxInfer.jl.\"\n    )\n    \n    mcp_instance_param.register_tool(\n        name=\"list_render_targets\",\n        func=handle_list_render_targets,\n        schema=ListRenderTargetsInput.model_json_schema(),\n        description=\"Lists the available target formats for GNN rendering (e.g., pymdp, rxinfer).\"\n    )\n    \n    logger.info(\"Render module MCP tools registered.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp_utils.py": [
      {
        "name": "_numpy_array_to_string",
        "type": "function",
        "start_line": 8,
        "end_line": 22,
        "code": "def _numpy_array_to_string(arr: np.ndarray, indent=8) -> str:\n    \"\"\"Converts a NumPy array to a string representation for Python script, with proper indentation.\"\"\"\n    if arr is None:\n        return \"None\"\n    if arr.ndim == 0: # Scalar\n        return str(arr.item())\n    if arr.ndim == 1:\n        list_str = np.array2string(arr, separator=', ', prefix=' ' * indent)\n    else:\n        list_str = np.array2string(arr, separator=', ', prefix=' ' * indent)\n        list_str = list_str.replace('\\n', '\\n' + ' ' * indent)\n    list_str = re.sub(r'\\[\\s+', '[', list_str)\n    list_str = re.sub(r'\\s+\\]', ']', list_str)\n    list_str = re.sub(r'\\s+,', ',', list_str)\n    return f\"np.array({list_str})\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp_utils.py"
      },
      {
        "name": "format_list_recursive",
        "type": "function",
        "start_line": 24,
        "end_line": 45,
        "code": "def format_list_recursive(data_list: list, current_indent: int, item_formatter: callable) -> str:\n    \"\"\"Formats a potentially nested list of items (like NumPy arrays) into a string for Python script.\"\"\"\n    lines = []\n    base_indent_str = ' ' * current_indent\n    item_indent_str = ' ' * (current_indent + 4)\n    \n    if not any(isinstance(item, list) for item in data_list):\n        formatted_items = [item_formatter(item, current_indent + 4) for item in data_list]\n        if len(formatted_items) > 3: \n            lines.append(\"[\")\n            for fi in formatted_items:\n                lines.append(item_indent_str + fi + \",\")\n            lines.append(base_indent_str + \"]\")\n        else:\n            lines.append(\"[\" + \", \".join(formatted_items) + \"]\")\n    else: \n        lines.append(\"[\")\n        for item in data_list:\n            if isinstance(item, np.ndarray):\n                lines.append(item_indent_str + item_formatter(item, current_indent + 4) + \",\")\n        lines.append(base_indent_str + \"]\")\n    return '\\n'.join(lines)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp_utils.py"
      },
      {
        "name": "generate_pymdp_matrix_definition",
        "type": "function",
        "start_line": 47,
        "end_line": 124,
        "code": "def generate_pymdp_matrix_definition(\n    matrix_name: str,\n    data: Any, \n    is_object_array: bool = False,\n    num_modalities_or_factors: Optional[int] = None, \n    is_vector: bool = False\n) -> str:\n    \"\"\"\n    Generates Python code for a PyMDP matrix (A, B, C, D, etc.).\n    Handles single matrices, lists of matrices (object arrays), and vectors.\n    If data is already a string (e.g. \"pymdp.utils.get_A_likelihood_identity(...)\"), use it directly.\n    \"\"\"\n    lines = []\n    indent_str = \"    \" \n\n    if data is None:\n        if is_object_array: \n            logger.debug(f\"Data for object array {matrix_name} is None, defaulting to np.array([], dtype=object).\")\n            lines.append(f\"{matrix_name} = np.array([], dtype=object)\")\n        else: \n            logger.debug(f\"Data for non-object array {matrix_name} is None, setting to None.\")\n            lines.append(f\"{matrix_name} = None\")\n        return '\\n'.join(lines)\n    \n    if isinstance(data, str) and (\"pymdp.\" in data or \"np.\" in data or \"utils.\" in data or \"maths.\" in data):\n        lines.append(f\"{matrix_name} = {data}\")\n        return '\\n'.join(lines)\n\n    if is_object_array and isinstance(data, list):\n        valid_arr_items = [item for item in data if item is not None]\n\n        if not valid_arr_items:\n            logger.debug(f\"All items for object array {matrix_name} were None or filtered out. Defaulting {matrix_name} to np.array([], dtype=object).\")\n            lines.append(f\"{matrix_name} = np.array([], dtype=object)\")\n            return '\\n'.join(lines)\n\n        array_strs = []\n        for i, arr_item in enumerate(valid_arr_items):\n            if not isinstance(arr_item, np.ndarray):\n                try:\n                    arr_item = np.array(arr_item)\n                except Exception as e:\n                    logger.error(f\"Object array {matrix_name}: Could not convert non-None item at index {i} (value: {arr_item}) to np.array: {e}. Skipping this item.\")\n                    continue \n            array_strs.append(_numpy_array_to_string(arr_item, indent=8))\n        \n        if not array_strs: \n            logger.debug(f\"All non-None items for object array {matrix_name} failed string conversion or were skipped. Defaulting {matrix_name} to np.array([], dtype=object).\")\n            lines.append(f\"{matrix_name} = np.array([], dtype=object)\")\n            return '\\n'.join(lines)\n\n        actual_num_elements = len(array_strs)\n        lines.append(f\"{matrix_name} = [ # Object array for {actual_num_elements} modalities/factors\")\n        for arr_s in array_strs:\n            lines.append(indent_str + indent_str + arr_s + \",\")\n        lines.append(indent_str + \"]\")\n        \n        if actual_num_elements > 0:\n             lines.append(f\"{matrix_name} = np.array({matrix_name}, dtype=object)\")\n\n    elif isinstance(data, (list, tuple)) and not is_object_array:\n        try:\n            np_array = np.array(data)\n            lines.append(f\"{matrix_name} = {_numpy_array_to_string(np_array, indent=4)}\")\n        except ValueError as e:\n            logger.error(f\"Could not convert data for matrix '{matrix_name}' to numpy array: {e}. Assigning None.\", exc_info=True)\n            lines.append(f\"# ERROR: Could not convert {matrix_name} data to numpy array: {e}\")\n            lines.append(f\"# Raw data: {data}\")\n            lines.append(f\"{matrix_name} = None\")\n            \n    elif isinstance(data, np.ndarray) and not is_object_array:\n        lines.append(f\"{matrix_name} = {_numpy_array_to_string(data, indent=4)}\")\n    else:\n        logger.warning(f\"Data for matrix '{matrix_name}' is of unexpected type: {type(data)}. Assigning as is or None.\")\n        lines.append(f\"# Note: Data for {matrix_name} is of unexpected type: {type(data)}. Assigning as is or None.\")\n        lines.append(f\"{matrix_name} = {data if data is not None else 'None'}\")\n\n    return '\\n'.join(lines)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp_utils.py"
      },
      {
        "name": "generate_pymdp_agent_instantiation",
        "type": "function",
        "start_line": 126,
        "end_line": 176,
        "code": "def generate_pymdp_agent_instantiation(\n    agent_name: str,\n    model_params: Dict[str, str], \n    control_params: Optional[Dict[str, Any]] = None, \n    learning_params: Optional[Dict[str, Any]] = None, \n    algorithm_params: Optional[Dict[str, Any]] = None,\n    policy_len: Optional[int] = None,\n    control_fac_idx_list: Optional[List[int]] = None, \n    use_utility: Optional[bool] = None, \n    use_states_info_gain: Optional[bool] = None, \n    use_param_info_gain: Optional[bool] = None, \n    action_selection: Optional[str] = None, \n    action_names: Optional[Dict[int, List[str]]] = None, \n    qs_initial: Optional[Union[List[np.ndarray], str]] = None\n) -> str:\n    \"\"\"Generates the Agent instantiation code string.\"\"\"\n    # Note: This function assumes 'Agent' is available in the scope where the generated code runs.\n    lines = [f\"{agent_name} = Agent(\"]\n    indent = \"    \"\n\n    if model_params:\n        for key, value_var_name in model_params.items():\n            lines.append(f\"{indent}{key}={value_var_name},\")\n\n    if control_fac_idx_list is not None:\n        lines.append(f\"{indent}control_fac_idx={control_fac_idx_list},\")\n    if policy_len is not None: lines.append(f\"{indent}policy_len={policy_len},\")\n    if use_utility is not None: lines.append(f\"{indent}use_utility={use_utility},\")\n    if use_states_info_gain is not None: lines.append(f\"{indent}use_states_info_gain={use_states_info_gain},\")\n    if use_param_info_gain is not None: lines.append(f\"{indent}use_param_info_gain={use_param_info_gain},\")\n    if action_selection is not None: lines.append(f\"{indent}action_selection='{action_selection}',\")\n    if action_names is not None: lines.append(f\"{indent}action_names={action_names},\")\n    if qs_initial is not None:\n        if isinstance(qs_initial, str):\n            lines.append(f\"{indent}qs_initial={qs_initial},\")\n        else: \n            lines.append(f\"{indent}qs_initial={repr(qs_initial)},\")\n\n    if learning_params:\n        for key, value in learning_params.items():\n            lines.append(f\"{indent}{key}={repr(value)},\")\n\n    if algorithm_params:\n        for key, value in algorithm_params.items():\n            lines.append(f\"{indent}{key}={repr(value)},\")\n\n    if lines[-1].endswith(\",\"):\n        lines[-1] = lines[-1][:-1]\n    \n    lines.append(\")\")\n    return \"\\n\".join(lines)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp_utils.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py": [
      {
        "name": "_parse_active_inference_matrix_str",
        "type": "function",
        "start_line": 22,
        "end_line": 66,
        "code": "def _parse_active_inference_matrix_str(val_str: str) -> str:\n    \"\"\"\n    Parses matrix strings like '{(0.5),(0.5)}' or '{(\".9\",\".1\"),(\".2\",\".8\")}'\n    into Julia-compatible array/matrix strings like '[0.5, 0.5]' or '[0.9 0.1; 0.2 0.8]'.\n    Handles basic cases found in GNN examples.\n    \"\"\"\n    val_str = val_str.strip()\n    if not val_str.startswith(\"{\") or not val_str.endswith(\"}\"):\n        logger.debug(f\"Matrix string '{val_str}' not in expected {{...}} format. Returning as is.\")\n        return val_str\n\n    content = val_str[1:-1].strip() # Remove outer {} and trim\n\n    # Case 1: Tuples defining rows e.g. { (v1,v2), (v3,v4) } or { (v1), (v2) }\n    if content.startswith(\"(\") and content.endswith(\")\"):\n        # Split rows. Need to be careful with nested structures if they were allowed.\n        # Assuming simple (v,v),(v,v) or (v),(v)\n        # This simplistic split works if rows are separated by \"),(\n        raw_rows = content.split(\"),(\")\n        parsed_rows_str = []\n        for i, r_str in enumerate(raw_rows):\n            r_str_cleaned = r_str.replace(\"(\", \"\").replace(\")\", \"\").strip()\n            elements = [elem.strip() for elem in r_str_cleaned.split(',')]\n            parsed_rows_str.append(\" \".join(elements)) # Julia elements in a row are space-separated\n        \n        if not parsed_rows_str:\n            return \"[]\"\n        \n        # Heuristic: if each \"row\" has one element, and there are multiple such rows, format as Julia vector\n        is_likely_col_vector = all(len(r.split()) == 1 for r in parsed_rows_str)\n        if is_likely_col_vector and len(parsed_rows_str) > 1:\n            return \"[\" + \", \".join(e.strip() for e in parsed_rows_str) + \"]\"\n        # Otherwise, format as Julia matrix (rows separated by ;)\n        return \"[\" + \"; \".join(parsed_rows_str) + \"]\"\n        \n    # Case 2: Simple comma-separated list e.g. {v1,v2,v3}\n    elif ',' in content and not '(' in content:\n        elements = [elem.strip() for elem in content.split(',')]\n        return \"[\" + \", \".join(elements) + \"]\"\n    # Case 3: Single value e.g. {v1}\n    elif not ',' in content and not '(' in content:\n        return content # Return as scalar string, RxInfer might take it as is or it needs type.\n\n    logger.warning(f\"Could not parse matrix string '{val_str}' into Julia array/matrix. Original: '{content}'\")\n    return val_str # Fallback",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_format_params",
        "type": "function",
        "start_line": 68,
        "end_line": 82,
        "code": "def _format_params(params: Dict[str, Any]) -> str:\n    \"\"\"Formats a dictionary of parameters into a Julia named tuple string.\"\"\"\n    if not params:\n        return \"\"\n    formatted_params = []\n    for k, v in params.items():\n        if isinstance(v, bool):\n            formatted_params.append(f\"{k} = {str(v).lower()}\")\n        elif isinstance(v, str) and not (v.startswith(\"(\") or v.startswith(\"[\") or v.isidentifier()):\n            escaped_v = v.replace('\"', '\\\\\"') # Escape double quotes for Julia string literals\n            formatted_params.append(f'{k} = \"{escaped_v}\"')\n        else:\n            # For numbers, expressions, or already formatted parts (like variable names)\n            formatted_params.append(f\"{k} = {v}\")\n    return \", \".join(formatted_params)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "generate_julia_variable_declaration",
        "type": "function",
        "start_line": 84,
        "end_line": 106,
        "code": "def generate_julia_variable_declaration(\n    var_name: str,\n    distribution: str,\n    params: Dict[str, Any],\n    is_observed: bool,\n    is_vectorized: bool = False,\n    observed_data_name: Optional[str] = None\n) -> str:\n    \"\"\"\n    Generates a Julia line for a variable declaration in RxInfer.\n    e.g., `\u03b2 ~ Normal(mean = 0.0, variance = 1.0)`\n    or    `y .~ Normal(mean = x * \u03b2 + intercept, variance = \u03c3\u00b2)`\n    \"\"\"\n    operator = \". ~\" if is_vectorized else \"~\"\n    params_str = _format_params(params)\n\n    if is_observed and observed_data_name:\n        return f\"    {observed_data_name} {operator} {distribution}({params_str})\"\n    elif not is_observed:\n        return f\"    {var_name} {operator} {distribution}({params_str})\"\n    else:\n        logger.warning(f\"Attempted to generate observed variable '{var_name}' without proper data handling in declaration.\")\n        return f\"    # Error: Observed variable '{var_name}' needs data source\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "generate_rxinfer_model_definition",
        "type": "function",
        "start_line": 108,
        "end_line": 116,
        "code": "def generate_rxinfer_model_definition(model_name: str, model_args: List[str], body_lines: List[str]) -> str:\n    \"\"\"Wraps model body lines with RxInfer's @model function syntax.\"\"\"\n    args_str = \", \".join(model_args)\n    body_str = \"\\n\".join(body_lines) # Assuming body_lines are already correctly indented (4 spaces)\n    return (\n        f\"@model function {model_name}({args_str})\\n\"\n        f\"{body_str}\\n\"\n        f\"end\"\n    )",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "generate_rxinfer_constraints_definition",
        "type": "function",
        "start_line": 118,
        "end_line": 132,
        "code": "def generate_rxinfer_constraints_definition(constraints_name: Optional[str], body_lines: List[str]) -> str:\n    \"\"\"Wraps constraints body lines with RxInfer's @constraints syntax.\"\"\"\n    body_str = \"\\n\".join([f\"    {line}\" for line in body_lines]) # Ensure 4-space indent for lines\n    if constraints_name:\n        return (\n            f\"@constraints function {constraints_name}()\\n\"\n            f\"{body_str}\\n\"\n            f\"end\"\n        )\n    else:\n        return (\n            f\"@constraints begin\\n\"\n            f\"{body_str}\\n\"\n            f\"end\"\n        )",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "generate_rxinfer_meta_definition",
        "type": "function",
        "start_line": 134,
        "end_line": 148,
        "code": "def generate_rxinfer_meta_definition(meta_name: Optional[str], body_lines: List[str]) -> str:\n    \"\"\"Wraps meta configuration lines with RxInfer's @meta syntax.\"\"\"\n    body_str = \"\\n\".join([f\"    {line}\" for line in body_lines]) # Ensure 4-space indent\n    if meta_name:\n        return (\n            f\"@meta function {meta_name}()\\n\"\n            f\"{body_str}\\n\"\n            f\"end\"\n        )\n    else:\n        return (\n            f\"@meta begin\\n\"\n            f\"{body_str}\\n\"\n            f\"end\"\n        )",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "GnnToRxInferConverter",
        "type": "class",
        "start_line": 152,
        "end_line": 644,
        "code": "class GnnToRxInferConverter:\n    \"\"\"\n    Converts a parsed GNN specification into components of an RxInfer.jl script.\n    Assumes GNN spec provides nodes, their types (random, observed, constant),\n    distributions, parameters, and dependencies.\n    \"\"\"\n    def __init__(self, gnn_spec: Dict[str, Any]):\n        self.gnn_spec = gnn_spec\n        self.model_name = gnn_spec.get(\"name\", \"GNNModel\")\n        # Model arguments are primarily defined by \"arguments\" in GNN spec.\n        # The node processing logic might add to this if not using model_logic.\n        self.model_args = list(gnn_spec.get(\"arguments\", []))\n        self.julia_model_lines: List[str] = []\n        self.julia_constraints_lines: List[str] = []\n        self.julia_meta_lines: List[str] = []\n        self._dependencies_map: Dict[str, List[str]] = {}\n        self._processed_nodes: set[str] = set()\n        self.nodes_map: Dict[str, Dict[str, Any]] = {}\n        # self.model_return_values is not strictly needed if return is part of model_logic lines\n        # self.model_return_values: List[str] = gnn_spec.get(\"returns\", [])\n\n    def _build_dependencies_map(self):\n        \"\"\"Builds a map of node dependencies from the GNN specification.\"\"\"\n        self.nodes_map = {node[\"id\"]: node for node in self.gnn_spec.get(\"nodes\", [])}\n        for node_id, node_data in self.nodes_map.items():\n            self._dependencies_map[node_id] = node_data.get(\"dependencies\", [])\n\n    def _resolve_processing_order(self) -> List[Dict[str, Any]]:\n        \"\"\"Resolves node processing order based on dependencies (topological sort).\"\"\"\n        ordered_nodes_ids: List[str] = []\n        \n        # Ensure nodes_map is built if not already\n        if not self.nodes_map:\n            self.nodes_map = {node[\"id\"]: node for node in self.gnn_spec.get(\"nodes\", [])}\n            for node_id, node_data in self.nodes_map.items():\n                self._dependencies_map[node_id] = node_data.get(\"dependencies\", [])\n\n        nodes_to_visit = list(self.nodes_map.keys())\n        temp_mark = set()  # For detecting cycles in current DFS path\n        perm_mark = set()  # For nodes whose processing is complete\n\n        def visit(node_id):\n            if node_id in perm_mark:\n                return\n            if node_id in temp_mark:\n                # Check if the cycle involves only existing nodes before raising error\n                is_valid_node = node_id in self.nodes_map\n                if is_valid_node:\n                    # Attempt to get more info about the cycle for better debugging\n                    cycle_path = list(temp_mark)\n                    logger.error(f\"Cyclic dependency detected involving node '{node_id}'. Path: {cycle_path}\")\n                    raise ValueError(f\"Cyclic dependency detected involving node '{node_id}'. Path: {cycle_path}\")\n                # If node_id is not in self.nodes_map, it might be an undefined dependency\n                logger.warning(f\"Node '{node_id}' involved in a potential cycle is not defined. Check dependencies.\")\n                # Decide if to raise error or try to continue by ignoring this problematic node_id\n                # For now, we raise to highlight the issue.\n                raise ValueError(f\"Undefined node '{node_id}' found in dependency graph, possibly causing a cycle.\")\n\n            temp_mark.add(node_id)\n            for dep_id in self._dependencies_map.get(node_id, []):\n                if dep_id in self.nodes_map:  # Ensure dependency exists as a defined node\n                    visit(dep_id)\n                elif dep_id in self.model_args: # Dependency might be a model argument\n                    pass # Model arguments don't have further dependencies to visit here\n                else:\n                    # This case means a dependency is listed but isn't a defined node or model arg\n                    logger.warning(f\"Node '{node_id}' has an undefined dependency: '{dep_id}'. It will be ignored in ordering.\")\n            \n            temp_mark.remove(node_id)\n            perm_mark.add(node_id)\n            ordered_nodes_ids.append(node_id) # Add after all dependencies are processed\n\n        for node_id_to_visit in nodes_to_visit:\n            if node_id_to_visit not in perm_mark:\n                visit(node_id_to_visit)\n        \n        # Return full node dicts in the order they should be declared\n        # The `ordered_nodes_ids` is a topological sort (dependencies first).\n        return [self.nodes_map[id_] for id_ in ordered_nodes_ids if id_ in self.nodes_map]\n\n    def _parse_param_value(self, value: Any) -> str:\n        \"\"\"Helper to parse parameter values, including matrix strings.\"\"\"\n        if isinstance(value, str):\n            # Check if it's a GNN-style matrix string\n            if value.startswith(\"{\") and value.endswith(\"}\"):\n                return _parse_active_inference_matrix_str(value)\n            # Check if it's an identifier (another variable/argument) or needs quotes\n            # Allow existing Julia arrays/tuples or expressions that might be complex\n            if value.isidentifier() or \\\n               (value.startswith(\"[\") and value.endswith(\"]\")) or \\\n               (value.startswith(\"(\") and value.endswith(\")\")) or \\\n               any(op in value for op in [\"+:\", \"-:\", \"*:\", \"/:\", \".*\", \".+\", \".-\", \".:\", \"[\", \"]\"]) : # crude check for expressions\n                return value\n            # It's likely a string literal that needs quoting for Julia\n            return f'\"{value.replace(\"\\\"\", \"\\\\\\\"\")}\"' # Escape double quotes for Julia string\n        elif isinstance(value, bool):\n            return str(value).lower()\n        # Numbers, etc., can be directly converted to string\n        return str(value)\n\n    def _format_params_for_distribution(self, params: Dict[str, Any]) -> str:\n        \"\"\"Formats parameters for a distribution call, parsing values as needed.\"\"\"\n        if not params:\n            return \"\"\n        formatted_params = []\n        for k, v_raw in params.items():\n            v_parsed = self._parse_param_value(v_raw)\n            formatted_params.append(f\"{k} = {v_parsed}\")\n        return \", \".join(formatted_params)\n\n    # Update generate_julia_variable_declaration to use _format_params_for_distribution\n    def _generate_julia_variable_declaration(\n        self,\n        var_name: str, # Can be s[t] or observations[t]\n        distribution: str,\n        params: Dict[str, Any],\n        is_observed: bool,\n        is_vectorized: bool = False,\n        observed_data_name: Optional[str] = None, # If var_name is different from data source name\n        base_indent: str = \"    \"\n    ) -> str:\n        operator = \". ~\" if is_vectorized else \"~\"\n        # Use the new params formatter\n        params_str = self._format_params_for_distribution(params)\n\n        # If var_name itself is the observed data (e.g. observations[t]), observed_data_name should be var_name\n        target_name_for_observed = observed_data_name if observed_data_name else var_name\n\n        if is_observed:\n            return f\"{base_indent}{target_name_for_observed} {operator} {distribution}({params_str})\"\n        else: # RV declaration\n            return f\"{base_indent}{var_name} {operator} {distribution}({params_str})\"\n\n    def _handle_rv_vector_declaration(self, item: Dict[str, Any], base_indent: str) -> str:\n        name = item[\"name\"]\n        size_var = item[\"size_var\"]\n        # Default type of elements in RxInfer RandomVariable vectors\n        element_type = item.get(\"element_type\", \"RandomVariable\") \n        return f\"{base_indent}{name} = Vector{{{element_type}}}(undef, {size_var})\"\n\n    def _handle_assignment(self, item: Dict[str, Any], base_indent: str) -> str:\n        lhs = item[\"variable\"] # e.g., \"s[1]\", \"s[t]\", \"observations[t]\"\n        dist = item[\"distribution\"]\n        params = item.get(\"params\", {})\n        is_observed = item.get(\"is_observed_data\", False)\n        is_vectorized = item.get(\"is_vectorized\", False)\n        \n        # When is_observed_data is true, lhs (e.g. \"observations[t]\") is the data placeholder\n        return self._generate_julia_variable_declaration(\n            var_name=lhs,\n            distribution=dist,\n            params=params,\n            is_observed=is_observed,\n            is_vectorized=is_vectorized,\n            observed_data_name=lhs if is_observed else None, # if observed, var_name is the data name\n            base_indent=base_indent\n        )\n\n    def _handle_loop(self, item: Dict[str, Any], base_indent: str) -> List[str]:\n        loop_var = item[\"variable\"]\n        range_start = item[\"range_start\"]\n        range_end = item[\"range_end\"] # This could be a variable like 'T'\n        body_items = item[\"body\"]\n        \n        loop_lines = [f\"{base_indent}for {loop_var} in {range_start}:{range_end}\"]\n        # Process body with increased indentation\n        loop_lines.extend(self._process_model_logic_block(body_items, base_indent + \"    \"))\n        loop_lines.append(f\"{base_indent}end\")\n        return loop_lines\n\n    def _handle_return_statement(self, item: Dict[str, Any], base_indent: str) -> str:\n        values_to_return = item.get(\"values\", [])\n        if not values_to_return:\n            return f\"{base_indent}# No return values specified\"\n        return f\"{base_indent}return {', '.join(values_to_return)}\"\n        \n    def _handle_raw_julia(self, item: Dict[str, Any], base_indent: str) -> str:\n        raw_code = item.get(\"code\", \"\")\n        # Ensure the raw code is indented correctly if it's multi-line\n        lines = raw_code.splitlines() # Use splitlines() for better handling of newlines\n        if not lines:\n            return f\"{base_indent}# Raw Julia item was empty\"\n        indented_lines = [f\"{base_indent}{lines[0].strip()}\"] # Indent first line\n        indented_lines.extend([f\"{base_indent}{line.strip()}\" for line in lines[1:]]) # Indent subsequent lines\n        return \"\\n\".join(indented_lines)\n\n    def _process_model_logic_block(self, logic_block: List[Dict[str, Any]], base_indent: str) -> List[str]:\n        processed_lines: List[str] = []\n        for item in logic_block:\n            item_type = item.get(\"item_type\")\n            if item_type == \"rv_vector_declaration\":\n                processed_lines.append(self._handle_rv_vector_declaration(item, base_indent))\n            elif item_type == \"assignment\":\n                processed_lines.append(self._handle_assignment(item, base_indent))\n            elif item_type == \"loop\":\n                processed_lines.extend(self._handle_loop(item, base_indent))\n            elif item_type == \"return_statement\":\n                processed_lines.append(self._handle_return_statement(item, base_indent))\n            elif item_type == \"raw_julia\":\n                processed_lines.append(self._handle_raw_julia(item, base_indent))\n            else:\n                logger.warning(f\"Unknown model_logic item_type: '{item_type}'. Skipping.\")\n        return processed_lines\n\n    def convert_node_to_julia(self, node: Dict[str, Any]):\n        \"\"\"Translates a single GNN node into Julia code for the @model block (fallback).\"\"\"\n        node_id = node[\"id\"]\n        node_type = node.get(\"type\", \"random_variable\")\n        act_inf_role = node.get(\"act_inf_role\")\n        initial_value_raw = node.get(\"initial_value\") # From GNN InitialParameterization\n        julia_value_str = None\n        if initial_value_raw and isinstance(initial_value_raw, str):\n            julia_value_str = _parse_active_inference_matrix_str(initial_value_raw)\n\n        if node_id in self._processed_nodes:\n            return\n\n        # This method should only add to self.model_args if they are not already defined\n        # by the main \"arguments\" field of the GNN spec.\n        # And it should primarily add to self.julia_model_lines.\n\n        if act_inf_role == \"Prior\" and node_type == \"constant\":\n            if node_id not in self.model_args: self.model_args.append(node_id)\n            logger.debug(f\"Node '{node_id}' (Prior) registered as model argument/data for fallback.\")\n\n        elif act_inf_role == \"LikelihoodMatrix\" and node_type == \"constant\":\n            if node_id not in self.model_args: self.model_args.append(node_id)\n            logger.debug(f\"Node '{node_id}' (LikelihoodMatrix) registered as model argument/data for fallback.\")\n        \n        elif act_inf_role == \"HiddenState\" and node_type == \"random_variable\": # Simplified, no vector handling\n            dist = node.get(\"distribution\", \"Categorical\") \n            params = node.get(\"params\", {})\n            # Infer params from dependencies logic for fallback:\n            if not params and node.get(\"dependencies\"):\n                prior_dep = next((dep for dep in node.get(\"dependencies\", []) if self.nodes_map.get(dep,{}).get(\"act_inf_role\") == \"Prior\"), None)\n                if prior_dep: params = {\"p\": prior_dep}\n            \n            self.julia_model_lines.append(\n                self._generate_julia_variable_declaration(node_id, dist, params, is_observed=False)\n            )\n        \n        elif act_inf_role == \"Observation\" and node_type == \"observed_data\":\n            dist = node.get(\"distribution\", \"Categorical\")\n            params = node.get(\"params\", {})\n            if node_id not in self.model_args: self.model_args.append(node_id)\n            self.julia_model_lines.append(\n                self._generate_julia_variable_declaration(\n                    var_name=node_id, \n                    distribution=dist, params=params, \n                    is_observed=True, \n                    is_vectorized=node.get(\"is_vectorized\", False),\n                    observed_data_name=node_id\n                )\n            )\n        \n        elif node_type == \"random_variable\": # General RV, not specific ActInf role\n            dist = node.get(\"distribution\", \"Distributions.Normal\") # Default if missing\n            params = node.get(\"params\", {})\n            resolved_params = {k: (self._parse_param_value(v) if isinstance(v, str) else v) for k, v in params.items()}\n            self.julia_model_lines.append(\n                self._generate_julia_variable_declaration(node_id, dist, resolved_params, is_observed=False)\n            )\n        elif node_type == \"constant\": \n            if julia_value_str:\n                self.julia_model_lines.append(f\"    {node_id} = {julia_value_str}\")\n            elif node_id not in self.model_args: \n                self.model_args.append(node_id) # Assume passed as argument\n                logger.debug(f\"General constant '{node_id}' added as model argument for fallback.\")\n\n        elif node_type == \"submodel_call\": # Fallback, less common without model_logic\n            submodel_name = node[\"submodel_name\"]\n            instance_params = node.get(\"params\", {})\n            output_var = node_id\n            param_str = self._format_params_for_distribution(instance_params)\n            self.julia_model_lines.append(f\"    {output_var} ~ {submodel_name}({param_str})\")\n        else:\n            logger.warning(f\"Unsupported GNN node type: '{node_type}' for node '{node_id}' in fallback processing.\")\n        self._processed_nodes.add(node_id)\n\n    def convert_gnn_structure(self):\n        \"\"\"Iterates GNN nodes or uses model_logic, populating Julia code lines.\"\"\"\n        self.julia_model_lines = [] # Reset for each conversion\n\n        # Prioritize model_logic if present\n        if \"model_logic\" in self.gnn_spec and self.gnn_spec[\"model_logic\"]:\n            logger.info(\"Processing GNN specification using 'model_logic' section.\")\n            self.julia_model_lines = self._process_model_logic_block(self.gnn_spec[\"model_logic\"], base_indent=\"    \")\n            # Ensure model_args from GNN spec are respected, model_logic should use them.\n            # No need to auto-add args from nodes if model_logic is used.\n        else:\n            logger.info(\"No 'model_logic' found or it's empty. Falling back to node-based processing.\")\n            self._build_dependencies_map() # Builds nodes_map and _dependencies_map\n            if not self.nodes_map:\n                logger.warning(\"No nodes found in GNN specification for node-based processing.\")\n            else:\n                ordered_nodes = self._resolve_processing_order()\n                if not ordered_nodes:\n                    logger.warning(\"Node order resolution yielded no nodes. Model body might be empty.\")\n                for node in ordered_nodes:\n                    self.convert_node_to_julia(node)\n        \n        # Process constraints and meta, these append to their respective lists\n        gnn_constraints = self.gnn_spec.get(\"constraints\")\n        if gnn_constraints:\n            if isinstance(gnn_constraints, list):\n                for constr in gnn_constraints:\n                    if constr.get(\"type\") == \"mean_field\" and \"factors\" in constr:\n                        for group in constr[\"factors\"]:\n                            self.julia_constraints_lines.append(f\"q({', '.join(group)}) = {''.join([f'q({factor})' for factor in group])}\")\n                    elif constr.get(\"type\") == \"form\" and \"variable\" in constr:\n                        form_type = constr.get(\"form_type\", \"PointMass\") + \"FormConstraint\"\n                        self.julia_constraints_lines.append(f\"q({constr['variable']}) :: {form_type}()\")\n            elif isinstance(gnn_constraints, dict) and \"raw_lines\" in gnn_constraints:\n                self.julia_constraints_lines.extend(gnn_constraints[\"raw_lines\"])\n\n        gnn_meta = self.gnn_spec.get(\"meta\")\n        if gnn_meta:\n            if isinstance(gnn_meta, list):\n                for meta_item in gnn_meta:\n                    node_ref = meta_item.get(\"node_id\", meta_item.get(\"factor_ref\"))\n                    # Use _format_params for consistency in settings string\n                    settings_str = _format_params(meta_item.get(\"settings\", {}))\n                    if node_ref and settings_str:\n                        self.julia_meta_lines.append(f\"{node_ref} -> _ where {{ {settings_str} }}\")\n            elif isinstance(gnn_meta, dict) and \"raw_lines\" in gnn_meta:\n                self.julia_meta_lines.extend(gnn_meta[\"raw_lines\"])\n\n    def generate_inference_script(self, data_bindings: Dict[str, str], iterations: int = 50, free_energy: bool = False) -> str:\n        \"\"\"Generates Julia code for running inference.\"\"\"\n        model_call_args_bindings = [] # For (param = value) in model call\n        data_tuple_entries = []       # For data = (obs = my_obs_data, ...)\n        \n        # self.model_args should be set from gnn_spec[\"arguments\"] primarily\n        for arg_name in self.model_args: # Iterate over declared model arguments\n            if arg_name in data_bindings:\n                val_str = str(data_bindings[arg_name])\n                # Assume val_str is a valid Julia expression or variable name for the binding\n                model_call_args_bindings.append(f\"{arg_name} = {val_str}\")\n                \n                # Check if this arg_name corresponds to an observed_data node or is used for data\n                # This heuristic might need refinement: check if arg_name is used as observed data in model_logic or nodes.\n                # For now, if it's in data_bindings, assume it *could* be data for the tuple.\n                # A more robust way is to identify \"observed_data\" nodes/vars from GNN spec.\n                is_data_var = False\n                if \"model_logic\" in self.gnn_spec and self.gnn_spec[\"model_logic\"]:\n                    for item in self.gnn_spec[\"model_logic\"]:\n                        if item.get(\"item_type\") == \"assignment\" and item.get(\"is_observed_data\", False) and item.get(\"variable\",\"\").startswith(arg_name): # e.g. obs[t] for arg obs\n                            is_data_var = True\n                            break\n                        if item.get(\"item_type\") == \"loop\": # Check inside loops\n                            for sub_item in item.get(\"body\",[]):\n                                 if sub_item.get(\"item_type\") == \"assignment\" and sub_item.get(\"is_observed_data\", False) and sub_item.get(\"variable\",\"\").startswith(arg_name):\n                                     is_data_var = True; break\n                            if is_data_var: break\n                else: # Fallback: check nodes\n                    node_def = self.nodes_map.get(arg_name)\n                    if node_def and node_def.get(\"type\") == \"observed_data\":\n                        is_data_var = True\n                \n                if is_data_var:\n                    data_tuple_entries.append(f\"{arg_name} = {val_str}\")\n            else:\n                # If a model argument is not in data_bindings, it's an unbound parameter.\n                # RxInfer might require all arguments to be bound or have defaults in the model itself (not handled here).\n                logger.warning(f\"Model argument '{arg_name}' not found in data_bindings for inference. It will be omitted from the `data` tuple and assumed to be passed directly if needed, or be a model constant.\")\n                # It will still be part of model_call_args_bindings if it was meant to be a constant value not in data tuple.\n                # This part is tricky: should non-data args also be in data_bindings?\n                # For RxInfer: model_call_args_bindings are for args like `model = MyModel(N=10, k=0.5)`\n                # data_tuple_entries are for `data = (y = y_data, x = x_data)`\n                # Let's assume if not in data_bindings, it's not for the `data` tuple for now.\n                # If it's a parameter like `transition_matrix` that is NOT data, it should still be in data_bindings.\n\n        model_signature_for_call = self.model_name\n        # Parameters passed directly to the model function call\n        model_direct_params_str = \", \".join(model_call_args_bindings)\n        if model_direct_params_str:\n             model_signature_for_call += f\"({model_direct_params_str})\"\n        # else: # If no params, call as MyModel() or just MyModel if it's a submodel ref.\n        #    model_signature_for_call += \"()\" # RxInfer usually needs () if it's a function\n\n        data_arg_str = f\"data = ({', '.join(data_tuple_entries)}),\" if data_tuple_entries else \"\"\n        \n        # Determine if constraints/meta functions are named or anonymous\n        constraints_name_from_spec = self.gnn_spec.get(\"constraints\",{}).get(\"name\")\n        meta_name_from_spec = self.gnn_spec.get(\"meta\",{}).get(\"name\")\n\n        constraints_arg_str = \"\"\n        if self.julia_constraints_lines:\n            constraints_func_name = constraints_name_from_spec if constraints_name_from_spec else f\"{self.model_name}Constraints\"\n            if self.gnn_spec.get(\"constraints\",{}).get(\"is_anonymous\"): # Check if anonymous\n                 constraints_arg_str = f\"constraints = @constraints begin\\\\n{self.julia_constraints_lines[0]}\\\\nend,\" # Simplified for one line\n            else:\n                 constraints_arg_str = f\"constraints = {constraints_func_name}(),\"\n\n        meta_arg_str = \"\"\n        if self.julia_meta_lines:\n            meta_func_name = meta_name_from_spec if meta_name_from_spec else f\"{self.model_name}Meta\"\n            if self.gnn_spec.get(\"meta\",{}).get(\"is_anonymous\"):\n                meta_arg_str = f\"meta = @meta begin\\\\n{self.julia_meta_lines[0]}\\\\nend,\" # Simplified for one line\n            else:\n                meta_arg_str = f\"meta = {meta_func_name}(),\"\n\n        inference_params_list = [\n            f\"model = {model_signature_for_call}\",\n            data_arg_str,\n            constraints_arg_str,\n            meta_arg_str,\n            f\"iterations = {iterations}\",\n        ]\n        if free_energy:\n            inference_params_list.append(\"free_energy = true\")\n        \n        # Filter out empty strings and join with newline and indent\n        inference_params_str = \"\\n    \".join(filter(None, [p.strip(\",\") for p in inference_params_list if p])).strip()\n\n        print_posteriors_lines = []\n        for node in self.gnn_spec.get(\"nodes\", []):\n            if node.get(\"type\") == \"random_variable\" and node.get(\"report_posterior\", False):\n                node_id = node['id']\n                # Julia symbol for dictionary key: :node_id\n                julia_println = f'println(\"Posterior for {node_id}: \", result.posteriors[:{node_id}])'\n                print_posteriors_lines.append(julia_println)\n        \n        if not print_posteriors_lines and any(n.get(\"type\") == \"random_variable\" for n in self.nodes_map.values()):\n            first_rv = next((n['id'] for n_id, n in self.nodes_map.items() if n.get(\"type\") == \"random_variable\"), None)\n            if first_rv:\n                julia_println_default = f'println(\"Posterior for {first_rv} (example): \", result.posteriors[:{first_rv}])'\n                print_posteriors_lines.append(julia_println_default)\n\n        print_posteriors_str = \"\\n\".join(print_posteriors_lines)\n        if free_energy:\n            vfe_line = 'println(\"Variational Free Energy: \", result.free_energy)'\n            if print_posteriors_str:\n                print_posteriors_str += f\"\\n{vfe_line}\"\n            else:\n                print_posteriors_str = vfe_line\n\n        data_vars_comment = ', '.join(data_bindings.values()) if data_bindings else \"your_data_variables\"\n        return (\n            f\"# --- Inference ---\\n\"\n            f\"# Note: Ensure that data variables (e.g., {data_vars_comment})\\n\"\n            f\"# are defined and loaded in the Julia environment before this script section.\\n\"\n            f\"# Example:\\n\"\n            f\"# using CSV, DataFrames\\n\"\n            f\"# my_data_table = CSV.read(\\\"path/to/your/data.csv\\\", DataFrame)\\n\"\n            f\"# y_observed_data = my_data_table.y_column\\n\"\n            f\"# X_matrix_data = Matrix(my_data_table[!, [:x1_column, :x2_column]])\\n\\n\"\n            f\"result = infer(\\n    {inference_params_str}\\n)\\\n\\n\"\n            f\"{print_posteriors_str}\"\n        )\n\n    def get_full_julia_script(\n        self, \n        include_inference: bool = True, \n        data_bindings: Optional[Dict[str, str]] = None, \n        iterations: int = 50,\n        free_energy: bool = False\n    ) -> str:\n        \"\"\"Generates the complete RxInfer.jl Julia script content.\"\"\"\n        self.convert_gnn_structure()\n        imports = [\"using RxInfer\"]\n        if self.gnn_spec.get(\"julia_imports\"):\n            imports.extend(self.gnn_spec[\"julia_imports\"])\n        imports_str = \"\\n\".join(imports) + \"\\n\"\n\n        model_definition = generate_rxinfer_model_definition(self.model_name, self.model_args, self.julia_model_lines)\n        \n        constraints_definition = \"\"\n        if self.julia_constraints_lines:\n            constraints_name = self.gnn_spec.get(\"constraints\",{}).get(\"name\") # Get potential custom name\n            if not constraints_name and not self.gnn_spec.get(\"constraints\",{}).get(\"is_anonymous\"):\n                constraints_name = f\"{self.model_name}Constraints\" # Default name if not anonymous and no custom name\n            constraints_definition = generate_rxinfer_constraints_definition(constraints_name, self.julia_constraints_lines)\n            \n        meta_definition = \"\"\n        if self.julia_meta_lines:\n            meta_name = self.gnn_spec.get(\"meta\",{}).get(\"name\") # Get potential custom name\n            if not meta_name and not self.gnn_spec.get(\"meta\",{}).get(\"is_anonymous\"):\n                meta_name = f\"{self.model_name}Meta\" # Default name if not anonymous and no custom name\n            meta_definition = generate_rxinfer_meta_definition(meta_name, self.julia_meta_lines)\n\n        script_parts = [imports_str, model_definition]\n        if constraints_definition:\n            script_parts.append(constraints_definition)\n        if meta_definition:\n            script_parts.append(meta_definition)\n        \n        if include_inference:\n            inference_code = self.generate_inference_script(data_bindings or {}, iterations, free_energy)\n            script_parts.append(f\"\\n{inference_code}\")\n            \n        return \"\\n\\n\".join(filter(None, script_parts))",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 158,
        "end_line": 171,
        "code": "def __init__(self, gnn_spec: Dict[str, Any]):\n        self.gnn_spec = gnn_spec\n        self.model_name = gnn_spec.get(\"name\", \"GNNModel\")\n        # Model arguments are primarily defined by \"arguments\" in GNN spec.\n        # The node processing logic might add to this if not using model_logic.\n        self.model_args = list(gnn_spec.get(\"arguments\", []))\n        self.julia_model_lines: List[str] = []\n        self.julia_constraints_lines: List[str] = []\n        self.julia_meta_lines: List[str] = []\n        self._dependencies_map: Dict[str, List[str]] = {}\n        self._processed_nodes: set[str] = set()\n        self.nodes_map: Dict[str, Dict[str, Any]] = {}\n        # self.model_return_values is not strictly needed if return is part of model_logic lines\n        # self.model_return_values: List[str] = gnn_spec.get(\"returns\", [])",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_build_dependencies_map",
        "type": "method",
        "start_line": 173,
        "end_line": 177,
        "code": "def _build_dependencies_map(self):\n        \"\"\"Builds a map of node dependencies from the GNN specification.\"\"\"\n        self.nodes_map = {node[\"id\"]: node for node in self.gnn_spec.get(\"nodes\", [])}\n        for node_id, node_data in self.nodes_map.items():\n            self._dependencies_map[node_id] = node_data.get(\"dependencies\", [])",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_resolve_processing_order",
        "type": "method",
        "start_line": 179,
        "end_line": 230,
        "code": "def _resolve_processing_order(self) -> List[Dict[str, Any]]:\n        \"\"\"Resolves node processing order based on dependencies (topological sort).\"\"\"\n        ordered_nodes_ids: List[str] = []\n        \n        # Ensure nodes_map is built if not already\n        if not self.nodes_map:\n            self.nodes_map = {node[\"id\"]: node for node in self.gnn_spec.get(\"nodes\", [])}\n            for node_id, node_data in self.nodes_map.items():\n                self._dependencies_map[node_id] = node_data.get(\"dependencies\", [])\n\n        nodes_to_visit = list(self.nodes_map.keys())\n        temp_mark = set()  # For detecting cycles in current DFS path\n        perm_mark = set()  # For nodes whose processing is complete\n\n        def visit(node_id):\n            if node_id in perm_mark:\n                return\n            if node_id in temp_mark:\n                # Check if the cycle involves only existing nodes before raising error\n                is_valid_node = node_id in self.nodes_map\n                if is_valid_node:\n                    # Attempt to get more info about the cycle for better debugging\n                    cycle_path = list(temp_mark)\n                    logger.error(f\"Cyclic dependency detected involving node '{node_id}'. Path: {cycle_path}\")\n                    raise ValueError(f\"Cyclic dependency detected involving node '{node_id}'. Path: {cycle_path}\")\n                # If node_id is not in self.nodes_map, it might be an undefined dependency\n                logger.warning(f\"Node '{node_id}' involved in a potential cycle is not defined. Check dependencies.\")\n                # Decide if to raise error or try to continue by ignoring this problematic node_id\n                # For now, we raise to highlight the issue.\n                raise ValueError(f\"Undefined node '{node_id}' found in dependency graph, possibly causing a cycle.\")\n\n            temp_mark.add(node_id)\n            for dep_id in self._dependencies_map.get(node_id, []):\n                if dep_id in self.nodes_map:  # Ensure dependency exists as a defined node\n                    visit(dep_id)\n                elif dep_id in self.model_args: # Dependency might be a model argument\n                    pass # Model arguments don't have further dependencies to visit here\n                else:\n                    # This case means a dependency is listed but isn't a defined node or model arg\n                    logger.warning(f\"Node '{node_id}' has an undefined dependency: '{dep_id}'. It will be ignored in ordering.\")\n            \n            temp_mark.remove(node_id)\n            perm_mark.add(node_id)\n            ordered_nodes_ids.append(node_id) # Add after all dependencies are processed\n\n        for node_id_to_visit in nodes_to_visit:\n            if node_id_to_visit not in perm_mark:\n                visit(node_id_to_visit)\n        \n        # Return full node dicts in the order they should be declared\n        # The `ordered_nodes_ids` is a topological sort (dependencies first).\n        return [self.nodes_map[id_] for id_ in ordered_nodes_ids if id_ in self.nodes_map]",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_parse_param_value",
        "type": "method",
        "start_line": 232,
        "end_line": 250,
        "code": "def _parse_param_value(self, value: Any) -> str:\n        \"\"\"Helper to parse parameter values, including matrix strings.\"\"\"\n        if isinstance(value, str):\n            # Check if it's a GNN-style matrix string\n            if value.startswith(\"{\") and value.endswith(\"}\"):\n                return _parse_active_inference_matrix_str(value)\n            # Check if it's an identifier (another variable/argument) or needs quotes\n            # Allow existing Julia arrays/tuples or expressions that might be complex\n            if value.isidentifier() or \\\n               (value.startswith(\"[\") and value.endswith(\"]\")) or \\\n               (value.startswith(\"(\") and value.endswith(\")\")) or \\\n               any(op in value for op in [\"+:\", \"-:\", \"*:\", \"/:\", \".*\", \".+\", \".-\", \".:\", \"[\", \"]\"]) : # crude check for expressions\n                return value\n            # It's likely a string literal that needs quoting for Julia\n            return f'\"{value.replace(\"\\\"\", \"\\\\\\\"\")}\"' # Escape double quotes for Julia string\n        elif isinstance(value, bool):\n            return str(value).lower()\n        # Numbers, etc., can be directly converted to string\n        return str(value)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_format_params_for_distribution",
        "type": "method",
        "start_line": 252,
        "end_line": 260,
        "code": "def _format_params_for_distribution(self, params: Dict[str, Any]) -> str:\n        \"\"\"Formats parameters for a distribution call, parsing values as needed.\"\"\"\n        if not params:\n            return \"\"\n        formatted_params = []\n        for k, v_raw in params.items():\n            v_parsed = self._parse_param_value(v_raw)\n            formatted_params.append(f\"{k} = {v_parsed}\")\n        return \", \".join(formatted_params)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_generate_julia_variable_declaration",
        "type": "method",
        "start_line": 263,
        "end_line": 283,
        "code": "def _generate_julia_variable_declaration(\n        self,\n        var_name: str, # Can be s[t] or observations[t]\n        distribution: str,\n        params: Dict[str, Any],\n        is_observed: bool,\n        is_vectorized: bool = False,\n        observed_data_name: Optional[str] = None, # If var_name is different from data source name\n        base_indent: str = \"    \"\n    ) -> str:\n        operator = \". ~\" if is_vectorized else \"~\"\n        # Use the new params formatter\n        params_str = self._format_params_for_distribution(params)\n\n        # If var_name itself is the observed data (e.g. observations[t]), observed_data_name should be var_name\n        target_name_for_observed = observed_data_name if observed_data_name else var_name\n\n        if is_observed:\n            return f\"{base_indent}{target_name_for_observed} {operator} {distribution}({params_str})\"\n        else: # RV declaration\n            return f\"{base_indent}{var_name} {operator} {distribution}({params_str})\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_handle_rv_vector_declaration",
        "type": "method",
        "start_line": 285,
        "end_line": 290,
        "code": "def _handle_rv_vector_declaration(self, item: Dict[str, Any], base_indent: str) -> str:\n        name = item[\"name\"]\n        size_var = item[\"size_var\"]\n        # Default type of elements in RxInfer RandomVariable vectors\n        element_type = item.get(\"element_type\", \"RandomVariable\") \n        return f\"{base_indent}{name} = Vector{{{element_type}}}(undef, {size_var})\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_handle_assignment",
        "type": "method",
        "start_line": 292,
        "end_line": 308,
        "code": "def _handle_assignment(self, item: Dict[str, Any], base_indent: str) -> str:\n        lhs = item[\"variable\"] # e.g., \"s[1]\", \"s[t]\", \"observations[t]\"\n        dist = item[\"distribution\"]\n        params = item.get(\"params\", {})\n        is_observed = item.get(\"is_observed_data\", False)\n        is_vectorized = item.get(\"is_vectorized\", False)\n        \n        # When is_observed_data is true, lhs (e.g. \"observations[t]\") is the data placeholder\n        return self._generate_julia_variable_declaration(\n            var_name=lhs,\n            distribution=dist,\n            params=params,\n            is_observed=is_observed,\n            is_vectorized=is_vectorized,\n            observed_data_name=lhs if is_observed else None, # if observed, var_name is the data name\n            base_indent=base_indent\n        )",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_handle_loop",
        "type": "method",
        "start_line": 310,
        "end_line": 320,
        "code": "def _handle_loop(self, item: Dict[str, Any], base_indent: str) -> List[str]:\n        loop_var = item[\"variable\"]\n        range_start = item[\"range_start\"]\n        range_end = item[\"range_end\"] # This could be a variable like 'T'\n        body_items = item[\"body\"]\n        \n        loop_lines = [f\"{base_indent}for {loop_var} in {range_start}:{range_end}\"]\n        # Process body with increased indentation\n        loop_lines.extend(self._process_model_logic_block(body_items, base_indent + \"    \"))\n        loop_lines.append(f\"{base_indent}end\")\n        return loop_lines",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_handle_return_statement",
        "type": "method",
        "start_line": 322,
        "end_line": 326,
        "code": "def _handle_return_statement(self, item: Dict[str, Any], base_indent: str) -> str:\n        values_to_return = item.get(\"values\", [])\n        if not values_to_return:\n            return f\"{base_indent}# No return values specified\"\n        return f\"{base_indent}return {', '.join(values_to_return)}\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_handle_raw_julia",
        "type": "method",
        "start_line": 328,
        "end_line": 336,
        "code": "def _handle_raw_julia(self, item: Dict[str, Any], base_indent: str) -> str:\n        raw_code = item.get(\"code\", \"\")\n        # Ensure the raw code is indented correctly if it's multi-line\n        lines = raw_code.splitlines() # Use splitlines() for better handling of newlines\n        if not lines:\n            return f\"{base_indent}# Raw Julia item was empty\"\n        indented_lines = [f\"{base_indent}{lines[0].strip()}\"] # Indent first line\n        indented_lines.extend([f\"{base_indent}{line.strip()}\" for line in lines[1:]]) # Indent subsequent lines\n        return \"\\n\".join(indented_lines)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "_process_model_logic_block",
        "type": "method",
        "start_line": 338,
        "end_line": 354,
        "code": "def _process_model_logic_block(self, logic_block: List[Dict[str, Any]], base_indent: str) -> List[str]:\n        processed_lines: List[str] = []\n        for item in logic_block:\n            item_type = item.get(\"item_type\")\n            if item_type == \"rv_vector_declaration\":\n                processed_lines.append(self._handle_rv_vector_declaration(item, base_indent))\n            elif item_type == \"assignment\":\n                processed_lines.append(self._handle_assignment(item, base_indent))\n            elif item_type == \"loop\":\n                processed_lines.extend(self._handle_loop(item, base_indent))\n            elif item_type == \"return_statement\":\n                processed_lines.append(self._handle_return_statement(item, base_indent))\n            elif item_type == \"raw_julia\":\n                processed_lines.append(self._handle_raw_julia(item, base_indent))\n            else:\n                logger.warning(f\"Unknown model_logic item_type: '{item_type}'. Skipping.\")\n        return processed_lines",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "convert_node_to_julia",
        "type": "method",
        "start_line": 356,
        "end_line": 429,
        "code": "def convert_node_to_julia(self, node: Dict[str, Any]):\n        \"\"\"Translates a single GNN node into Julia code for the @model block (fallback).\"\"\"\n        node_id = node[\"id\"]\n        node_type = node.get(\"type\", \"random_variable\")\n        act_inf_role = node.get(\"act_inf_role\")\n        initial_value_raw = node.get(\"initial_value\") # From GNN InitialParameterization\n        julia_value_str = None\n        if initial_value_raw and isinstance(initial_value_raw, str):\n            julia_value_str = _parse_active_inference_matrix_str(initial_value_raw)\n\n        if node_id in self._processed_nodes:\n            return\n\n        # This method should only add to self.model_args if they are not already defined\n        # by the main \"arguments\" field of the GNN spec.\n        # And it should primarily add to self.julia_model_lines.\n\n        if act_inf_role == \"Prior\" and node_type == \"constant\":\n            if node_id not in self.model_args: self.model_args.append(node_id)\n            logger.debug(f\"Node '{node_id}' (Prior) registered as model argument/data for fallback.\")\n\n        elif act_inf_role == \"LikelihoodMatrix\" and node_type == \"constant\":\n            if node_id not in self.model_args: self.model_args.append(node_id)\n            logger.debug(f\"Node '{node_id}' (LikelihoodMatrix) registered as model argument/data for fallback.\")\n        \n        elif act_inf_role == \"HiddenState\" and node_type == \"random_variable\": # Simplified, no vector handling\n            dist = node.get(\"distribution\", \"Categorical\") \n            params = node.get(\"params\", {})\n            # Infer params from dependencies logic for fallback:\n            if not params and node.get(\"dependencies\"):\n                prior_dep = next((dep for dep in node.get(\"dependencies\", []) if self.nodes_map.get(dep,{}).get(\"act_inf_role\") == \"Prior\"), None)\n                if prior_dep: params = {\"p\": prior_dep}\n            \n            self.julia_model_lines.append(\n                self._generate_julia_variable_declaration(node_id, dist, params, is_observed=False)\n            )\n        \n        elif act_inf_role == \"Observation\" and node_type == \"observed_data\":\n            dist = node.get(\"distribution\", \"Categorical\")\n            params = node.get(\"params\", {})\n            if node_id not in self.model_args: self.model_args.append(node_id)\n            self.julia_model_lines.append(\n                self._generate_julia_variable_declaration(\n                    var_name=node_id, \n                    distribution=dist, params=params, \n                    is_observed=True, \n                    is_vectorized=node.get(\"is_vectorized\", False),\n                    observed_data_name=node_id\n                )\n            )\n        \n        elif node_type == \"random_variable\": # General RV, not specific ActInf role\n            dist = node.get(\"distribution\", \"Distributions.Normal\") # Default if missing\n            params = node.get(\"params\", {})\n            resolved_params = {k: (self._parse_param_value(v) if isinstance(v, str) else v) for k, v in params.items()}\n            self.julia_model_lines.append(\n                self._generate_julia_variable_declaration(node_id, dist, resolved_params, is_observed=False)\n            )\n        elif node_type == \"constant\": \n            if julia_value_str:\n                self.julia_model_lines.append(f\"    {node_id} = {julia_value_str}\")\n            elif node_id not in self.model_args: \n                self.model_args.append(node_id) # Assume passed as argument\n                logger.debug(f\"General constant '{node_id}' added as model argument for fallback.\")\n\n        elif node_type == \"submodel_call\": # Fallback, less common without model_logic\n            submodel_name = node[\"submodel_name\"]\n            instance_params = node.get(\"params\", {})\n            output_var = node_id\n            param_str = self._format_params_for_distribution(instance_params)\n            self.julia_model_lines.append(f\"    {output_var} ~ {submodel_name}({param_str})\")\n        else:\n            logger.warning(f\"Unsupported GNN node type: '{node_type}' for node '{node_id}' in fallback processing.\")\n        self._processed_nodes.add(node_id)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "convert_gnn_structure",
        "type": "method",
        "start_line": 431,
        "end_line": 477,
        "code": "def convert_gnn_structure(self):\n        \"\"\"Iterates GNN nodes or uses model_logic, populating Julia code lines.\"\"\"\n        self.julia_model_lines = [] # Reset for each conversion\n\n        # Prioritize model_logic if present\n        if \"model_logic\" in self.gnn_spec and self.gnn_spec[\"model_logic\"]:\n            logger.info(\"Processing GNN specification using 'model_logic' section.\")\n            self.julia_model_lines = self._process_model_logic_block(self.gnn_spec[\"model_logic\"], base_indent=\"    \")\n            # Ensure model_args from GNN spec are respected, model_logic should use them.\n            # No need to auto-add args from nodes if model_logic is used.\n        else:\n            logger.info(\"No 'model_logic' found or it's empty. Falling back to node-based processing.\")\n            self._build_dependencies_map() # Builds nodes_map and _dependencies_map\n            if not self.nodes_map:\n                logger.warning(\"No nodes found in GNN specification for node-based processing.\")\n            else:\n                ordered_nodes = self._resolve_processing_order()\n                if not ordered_nodes:\n                    logger.warning(\"Node order resolution yielded no nodes. Model body might be empty.\")\n                for node in ordered_nodes:\n                    self.convert_node_to_julia(node)\n        \n        # Process constraints and meta, these append to their respective lists\n        gnn_constraints = self.gnn_spec.get(\"constraints\")\n        if gnn_constraints:\n            if isinstance(gnn_constraints, list):\n                for constr in gnn_constraints:\n                    if constr.get(\"type\") == \"mean_field\" and \"factors\" in constr:\n                        for group in constr[\"factors\"]:\n                            self.julia_constraints_lines.append(f\"q({', '.join(group)}) = {''.join([f'q({factor})' for factor in group])}\")\n                    elif constr.get(\"type\") == \"form\" and \"variable\" in constr:\n                        form_type = constr.get(\"form_type\", \"PointMass\") + \"FormConstraint\"\n                        self.julia_constraints_lines.append(f\"q({constr['variable']}) :: {form_type}()\")\n            elif isinstance(gnn_constraints, dict) and \"raw_lines\" in gnn_constraints:\n                self.julia_constraints_lines.extend(gnn_constraints[\"raw_lines\"])\n\n        gnn_meta = self.gnn_spec.get(\"meta\")\n        if gnn_meta:\n            if isinstance(gnn_meta, list):\n                for meta_item in gnn_meta:\n                    node_ref = meta_item.get(\"node_id\", meta_item.get(\"factor_ref\"))\n                    # Use _format_params for consistency in settings string\n                    settings_str = _format_params(meta_item.get(\"settings\", {}))\n                    if node_ref and settings_str:\n                        self.julia_meta_lines.append(f\"{node_ref} -> _ where {{ {settings_str} }}\")\n            elif isinstance(gnn_meta, dict) and \"raw_lines\" in gnn_meta:\n                self.julia_meta_lines.extend(gnn_meta[\"raw_lines\"])",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "generate_inference_script",
        "type": "method",
        "start_line": 479,
        "end_line": 602,
        "code": "def generate_inference_script(self, data_bindings: Dict[str, str], iterations: int = 50, free_energy: bool = False) -> str:\n        \"\"\"Generates Julia code for running inference.\"\"\"\n        model_call_args_bindings = [] # For (param = value) in model call\n        data_tuple_entries = []       # For data = (obs = my_obs_data, ...)\n        \n        # self.model_args should be set from gnn_spec[\"arguments\"] primarily\n        for arg_name in self.model_args: # Iterate over declared model arguments\n            if arg_name in data_bindings:\n                val_str = str(data_bindings[arg_name])\n                # Assume val_str is a valid Julia expression or variable name for the binding\n                model_call_args_bindings.append(f\"{arg_name} = {val_str}\")\n                \n                # Check if this arg_name corresponds to an observed_data node or is used for data\n                # This heuristic might need refinement: check if arg_name is used as observed data in model_logic or nodes.\n                # For now, if it's in data_bindings, assume it *could* be data for the tuple.\n                # A more robust way is to identify \"observed_data\" nodes/vars from GNN spec.\n                is_data_var = False\n                if \"model_logic\" in self.gnn_spec and self.gnn_spec[\"model_logic\"]:\n                    for item in self.gnn_spec[\"model_logic\"]:\n                        if item.get(\"item_type\") == \"assignment\" and item.get(\"is_observed_data\", False) and item.get(\"variable\",\"\").startswith(arg_name): # e.g. obs[t] for arg obs\n                            is_data_var = True\n                            break\n                        if item.get(\"item_type\") == \"loop\": # Check inside loops\n                            for sub_item in item.get(\"body\",[]):\n                                 if sub_item.get(\"item_type\") == \"assignment\" and sub_item.get(\"is_observed_data\", False) and sub_item.get(\"variable\",\"\").startswith(arg_name):\n                                     is_data_var = True; break\n                            if is_data_var: break\n                else: # Fallback: check nodes\n                    node_def = self.nodes_map.get(arg_name)\n                    if node_def and node_def.get(\"type\") == \"observed_data\":\n                        is_data_var = True\n                \n                if is_data_var:\n                    data_tuple_entries.append(f\"{arg_name} = {val_str}\")\n            else:\n                # If a model argument is not in data_bindings, it's an unbound parameter.\n                # RxInfer might require all arguments to be bound or have defaults in the model itself (not handled here).\n                logger.warning(f\"Model argument '{arg_name}' not found in data_bindings for inference. It will be omitted from the `data` tuple and assumed to be passed directly if needed, or be a model constant.\")\n                # It will still be part of model_call_args_bindings if it was meant to be a constant value not in data tuple.\n                # This part is tricky: should non-data args also be in data_bindings?\n                # For RxInfer: model_call_args_bindings are for args like `model = MyModel(N=10, k=0.5)`\n                # data_tuple_entries are for `data = (y = y_data, x = x_data)`\n                # Let's assume if not in data_bindings, it's not for the `data` tuple for now.\n                # If it's a parameter like `transition_matrix` that is NOT data, it should still be in data_bindings.\n\n        model_signature_for_call = self.model_name\n        # Parameters passed directly to the model function call\n        model_direct_params_str = \", \".join(model_call_args_bindings)\n        if model_direct_params_str:\n             model_signature_for_call += f\"({model_direct_params_str})\"\n        # else: # If no params, call as MyModel() or just MyModel if it's a submodel ref.\n        #    model_signature_for_call += \"()\" # RxInfer usually needs () if it's a function\n\n        data_arg_str = f\"data = ({', '.join(data_tuple_entries)}),\" if data_tuple_entries else \"\"\n        \n        # Determine if constraints/meta functions are named or anonymous\n        constraints_name_from_spec = self.gnn_spec.get(\"constraints\",{}).get(\"name\")\n        meta_name_from_spec = self.gnn_spec.get(\"meta\",{}).get(\"name\")\n\n        constraints_arg_str = \"\"\n        if self.julia_constraints_lines:\n            constraints_func_name = constraints_name_from_spec if constraints_name_from_spec else f\"{self.model_name}Constraints\"\n            if self.gnn_spec.get(\"constraints\",{}).get(\"is_anonymous\"): # Check if anonymous\n                 constraints_arg_str = f\"constraints = @constraints begin\\\\n{self.julia_constraints_lines[0]}\\\\nend,\" # Simplified for one line\n            else:\n                 constraints_arg_str = f\"constraints = {constraints_func_name}(),\"\n\n        meta_arg_str = \"\"\n        if self.julia_meta_lines:\n            meta_func_name = meta_name_from_spec if meta_name_from_spec else f\"{self.model_name}Meta\"\n            if self.gnn_spec.get(\"meta\",{}).get(\"is_anonymous\"):\n                meta_arg_str = f\"meta = @meta begin\\\\n{self.julia_meta_lines[0]}\\\\nend,\" # Simplified for one line\n            else:\n                meta_arg_str = f\"meta = {meta_func_name}(),\"\n\n        inference_params_list = [\n            f\"model = {model_signature_for_call}\",\n            data_arg_str,\n            constraints_arg_str,\n            meta_arg_str,\n            f\"iterations = {iterations}\",\n        ]\n        if free_energy:\n            inference_params_list.append(\"free_energy = true\")\n        \n        # Filter out empty strings and join with newline and indent\n        inference_params_str = \"\\n    \".join(filter(None, [p.strip(\",\") for p in inference_params_list if p])).strip()\n\n        print_posteriors_lines = []\n        for node in self.gnn_spec.get(\"nodes\", []):\n            if node.get(\"type\") == \"random_variable\" and node.get(\"report_posterior\", False):\n                node_id = node['id']\n                # Julia symbol for dictionary key: :node_id\n                julia_println = f'println(\"Posterior for {node_id}: \", result.posteriors[:{node_id}])'\n                print_posteriors_lines.append(julia_println)\n        \n        if not print_posteriors_lines and any(n.get(\"type\") == \"random_variable\" for n in self.nodes_map.values()):\n            first_rv = next((n['id'] for n_id, n in self.nodes_map.items() if n.get(\"type\") == \"random_variable\"), None)\n            if first_rv:\n                julia_println_default = f'println(\"Posterior for {first_rv} (example): \", result.posteriors[:{first_rv}])'\n                print_posteriors_lines.append(julia_println_default)\n\n        print_posteriors_str = \"\\n\".join(print_posteriors_lines)\n        if free_energy:\n            vfe_line = 'println(\"Variational Free Energy: \", result.free_energy)'\n            if print_posteriors_str:\n                print_posteriors_str += f\"\\n{vfe_line}\"\n            else:\n                print_posteriors_str = vfe_line\n\n        data_vars_comment = ', '.join(data_bindings.values()) if data_bindings else \"your_data_variables\"\n        return (\n            f\"# --- Inference ---\\n\"\n            f\"# Note: Ensure that data variables (e.g., {data_vars_comment})\\n\"\n            f\"# are defined and loaded in the Julia environment before this script section.\\n\"\n            f\"# Example:\\n\"\n            f\"# using CSV, DataFrames\\n\"\n            f\"# my_data_table = CSV.read(\\\"path/to/your/data.csv\\\", DataFrame)\\n\"\n            f\"# y_observed_data = my_data_table.y_column\\n\"\n            f\"# X_matrix_data = Matrix(my_data_table[!, [:x1_column, :x2_column]])\\n\\n\"\n            f\"result = infer(\\n    {inference_params_str}\\n)\\\n\\n\"\n            f\"{print_posteriors_str}\"\n        )",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "get_full_julia_script",
        "type": "method",
        "start_line": 604,
        "end_line": 644,
        "code": "def get_full_julia_script(\n        self, \n        include_inference: bool = True, \n        data_bindings: Optional[Dict[str, str]] = None, \n        iterations: int = 50,\n        free_energy: bool = False\n    ) -> str:\n        \"\"\"Generates the complete RxInfer.jl Julia script content.\"\"\"\n        self.convert_gnn_structure()\n        imports = [\"using RxInfer\"]\n        if self.gnn_spec.get(\"julia_imports\"):\n            imports.extend(self.gnn_spec[\"julia_imports\"])\n        imports_str = \"\\n\".join(imports) + \"\\n\"\n\n        model_definition = generate_rxinfer_model_definition(self.model_name, self.model_args, self.julia_model_lines)\n        \n        constraints_definition = \"\"\n        if self.julia_constraints_lines:\n            constraints_name = self.gnn_spec.get(\"constraints\",{}).get(\"name\") # Get potential custom name\n            if not constraints_name and not self.gnn_spec.get(\"constraints\",{}).get(\"is_anonymous\"):\n                constraints_name = f\"{self.model_name}Constraints\" # Default name if not anonymous and no custom name\n            constraints_definition = generate_rxinfer_constraints_definition(constraints_name, self.julia_constraints_lines)\n            \n        meta_definition = \"\"\n        if self.julia_meta_lines:\n            meta_name = self.gnn_spec.get(\"meta\",{}).get(\"name\") # Get potential custom name\n            if not meta_name and not self.gnn_spec.get(\"meta\",{}).get(\"is_anonymous\"):\n                meta_name = f\"{self.model_name}Meta\" # Default name if not anonymous and no custom name\n            meta_definition = generate_rxinfer_meta_definition(meta_name, self.julia_meta_lines)\n\n        script_parts = [imports_str, model_definition]\n        if constraints_definition:\n            script_parts.append(constraints_definition)\n        if meta_definition:\n            script_parts.append(meta_definition)\n        \n        if include_inference:\n            inference_code = self.generate_inference_script(data_bindings or {}, iterations, free_energy)\n            script_parts.append(f\"\\n{inference_code}\")\n            \n        return \"\\n\\n\".join(filter(None, script_parts))",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "render_gnn_to_rxinfer_jl",
        "type": "function",
        "start_line": 648,
        "end_line": 672,
        "code": "def render_gnn_to_rxinfer_jl(\n    gnn_spec: Dict[str, Any],\n    output_script_path: Path,\n    options: Optional[Dict[str, Any]] = None\n) -> Tuple[bool, str, List[str]]:\n    \"\"\"Renders GNN to RxInfer.jl script.\"\"\"\n    options = options or {}\n    logger.info(f\"Rendering GNN spec to RxInfer.jl script '{output_script_path}'.\")\n    try:\n        converter = GnnToRxInferConverter(gnn_spec)\n        \n        julia_script_content = converter.get_full_julia_script(\n            include_inference=options.get(\"include_inference_script\", True),\n            data_bindings=options.get(\"data_bindings\", {}),\n            iterations=options.get(\"inference_iterations\", 50),\n            free_energy=options.get(\"calculate_free_energy\", False)\n        )\n        output_script_path.parent.mkdir(parents=True, exist_ok=True)\n        with open(output_script_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(julia_script_content)\n        logger.info(f\"Successfully wrote RxInfer.jl script to {output_script_path}\")\n        return True, f\"Successfully rendered to RxInfer.jl: {output_script_path.name}\", [output_script_path.as_uri()]\n    except Exception as e:\n        logger.error(f\"Error rendering GNN to RxInfer.jl: {e}\", exc_info=True)\n        return False, f\"Error rendering to RxInfer.jl: {str(e)}\", []",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      },
      {
        "name": "placeholder_gnn_parser",
        "type": "function",
        "start_line": 675,
        "end_line": 694,
        "code": "def placeholder_gnn_parser(gnn_file_path: Path) -> Optional[Dict[str, Any]]:\n    \"\"\"Placeholder GNN parser. Loads from JSON.\"\"\"\n    logger.warning(f\"Using placeholder GNN parser for '{gnn_file_path.name}'.\")\n    if not gnn_file_path.exists():\n        logger.error(f\"GNN file not found: {gnn_file_path}\")\n        return {\n            \"name\": \"DefaultPlaceholderModel\",\n            \"nodes\": [{\"id\": \"theta\", \"type\": \"random_variable\", \"distribution\": \"Normal\", \n                      \"params\": {\"mean\":0, \"variance\":1}, \"report_posterior\": True}],\n            \"arguments\": []}\n    try:\n        import json\n        with open(gnn_file_path, 'r', encoding='utf-8') as f:\n            return json.load(f)\n    except ImportError:\n        logger.error(\"json module not found for placeholder GNN parser.\")\n        return None\n    except Exception as e:\n        logger.error(f\"Error parsing GNN file {gnn_file_path} with placeholder: {e}\")\n        return None",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/rxinfer.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/render.py": [
      {
        "name": "render_gnn_spec",
        "type": "function",
        "start_line": 47,
        "end_line": 80,
        "code": "def render_gnn_spec(\n    gnn_spec: dict, \n    output_script_path: Path, \n    target_format: str,\n    render_options: Optional[dict] = None\n) -> Tuple[bool, str, List[str]]:\n    \"\"\"\n    Renders a GNN specification to the specified target format.\n\n    Args:\n        gnn_spec: The parsed GNN specification as a Python dictionary.\n        output_script_path: Path to save the rendered script.\n        target_format: The target rendering format (\"pymdp\" or \"rxinfer\").\n        render_options: Optional dictionary of options for the specific renderer.\n\n    Returns:\n        A tuple: (success: bool, message: str, artifact_uris: List[str])\n    \"\"\"\n    render_options = render_options or {}\n\n    if target_format.lower() == \"pymdp\":\n        logger.info(f\"Rendering GNN spec to PyMDP format at {output_script_path}...\")\n        # Note: render_gnn_to_pymdp will be refactored to take gnn_spec (dict) directly\n        # and output_script_path. The gnn_parser argument will be removed from it.\n        # For now, we pass a dummy parser, but this part of render_gnn_to_pymdp will be unused.\n        return render_gnn_to_pymdp(gnn_spec, output_script_path, options=render_options)\n    elif target_format.lower() == \"rxinfer\":\n        logger.info(f\"Rendering GNN spec to RxInfer.jl format at {output_script_path}...\")\n        # Note: render_gnn_to_rxinfer_jl will be refactored similarly.\n        return render_gnn_to_rxinfer_jl(gnn_spec, output_script_path, options=render_options)\n    else:\n        msg = f\"Unsupported target format: {target_format}. Supported formats: pymdp, rxinfer.\"\n        logger.error(msg)\n        return False, msg, []",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/render.py"
      },
      {
        "name": "main",
        "type": "function",
        "start_line": 82,
        "end_line": 167,
        "code": "def main(cli_args: Optional[List[str]] = None):\n    parser = argparse.ArgumentParser(description=\"Render GNN specifications to executable formats.\")\n    parser.add_argument(\"gnn_spec_file\", type=Path, help=\"Path to the GNN specification file (JSON format).\")\n    parser.add_argument(\"output_dir\", type=Path, help=\"Directory to save the rendered output script.\")\n    parser.add_argument(\"target_format\", type=str.lower, choices=[\"pymdp\", \"rxinfer\"], \n                        help=\"Target format for rendering (pymdp or rxinfer).\")\n    parser.add_argument(\"--output_filename\", type=str, default=None, \n                        help=\"Optional custom name for the output file (extension will be added automatically).\")\n    # Add other generic options if needed, e.g., verbosity for this script's logger\n    parser.add_argument(\"--verbose\", action=\"store_true\", help=\"Enable verbose logging for the renderer.\")\n\n    args = parser.parse_args(cli_args)\n\n    # Set logger level based on verbose flag, effective if main() is called directly\n    # or if standalone and setup_standalone_logging hasn't already set this specific logger.\n    if args.verbose:\n        logger.setLevel(logging.DEBUG)\n        logger.debug(\"Verbose logging enabled for render.py.\")\n    else:\n        # If not verbose, and not configured by a parent, it might default to WARNING or INFO.\n        # Ensure it's at least INFO if no parent logger set it higher or if standalone.\n        if logger.level == logging.NOTSET or logger.level > logging.INFO: # check if unconfigured or too high\n            logger.setLevel(logging.INFO)\n\n    logger.info(f\"Starting GNN rendering process for {args.gnn_spec_file} to {args.target_format}\")\n\n    if not args.gnn_spec_file.is_file():\n        logger.error(f\"GNN specification file not found: {args.gnn_spec_file}\")\n        return 1\n\n    try:\n        with open(args.gnn_spec_file, 'r', encoding='utf-8') as f:\n            gnn_spec = json.load(f)\n        logger.debug(f\"src/render/render.py: Loaded gnn_spec from JSON ({args.gnn_spec_file}): {{gnn_spec}}\")\n        logger.info(f\"Successfully loaded GNN specification from {args.gnn_spec_file}\")\n    except json.JSONDecodeError as e:\n        logger.error(f\"Error decoding JSON from GNN specification file {args.gnn_spec_file}: {e}\")\n        return 1\n    except Exception as e:\n        logger.error(f\"Failed to read GNN specification file {args.gnn_spec_file}: {e}\")\n        return 1\n\n    args.output_dir.mkdir(parents=True, exist_ok=True)\n    logger.info(f\"Ensured output directory exists: {args.output_dir}\")\n\n    # Determine output filename\n    if args.output_filename:\n        base_filename = args.output_filename\n        # Remove existing extension if user provided one, to avoid doubling up\n        base_filename = Path(base_filename).stem \n    else:\n        base_filename = args.gnn_spec_file.stem\n        if base_filename.endswith('.gnn'): # e.g., my_model.gnn.json -> my_model\n            base_filename = Path(base_filename).stem\n\n    file_extension = \".py\" if args.target_format == \"pymdp\" else \".jl\"\n    output_script_name = f\"{base_filename}_rendered{file_extension}\"\n    output_script_path = args.output_dir / output_script_name\n\n    # Placeholder for render_options; could be extended via more CLI args or a config file\n    render_options = {}\n    if args.target_format == \"pymdp\":\n        render_options[\"include_example_usage\"] = True # Default for PyMDP\n    elif args.target_format == \"rxinfer\":\n        render_options[\"include_inference_script\"] = True # Default for RxInfer\n        render_options[\"data_bindings\"] = {} # Example, user might need to specify this\n        render_options[\"inference_iterations\"] = 50\n        render_options[\"calculate_free_energy\"] = False\n\n    logger.info(f\"Output will be saved to: {output_script_path}\")\n\n    success, message, artifacts = render_gnn_spec(\n        gnn_spec,\n        output_script_path,\n        args.target_format,\n        render_options\n    )\n\n    if success:\n        logger.info(f\"Rendering successful: {message}\")\n        if artifacts:\n            logger.info(f\"Generated artifacts: {artifacts}\")\n        return 0\n    else:\n        logger.error(f\"Rendering failed: {message}\")\n        return 1",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/render.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py": [
      {
        "name": "GnnToPyMdpConverter",
        "type": "class",
        "start_line": 54,
        "end_line": 1152,
        "code": "class GnnToPyMdpConverter:\n    \"\"\"Converts a GNN specification dictionary to a PyMDP compatible Python script.\"\"\"\n\n    def __init__(self, gnn_spec: Dict[str, Any]):\n        self.gnn_spec = gnn_spec\n        raw_model_name = self.gnn_spec.get(\"name\", self.gnn_spec.get(\"ModelName\", \"pymdp_agent_model\"))\n        # Sanitize the model name to be a valid Python variable name\n        # Replace spaces and hyphens with underscores\n        temp_name = raw_model_name.replace(\" \", \"_\").replace(\"-\", \"_\")\n        # Remove other invalid characters (keep alphanumeric and underscores)\n        temp_name = re.sub(r'[^0-9a-zA-Z_]', '', temp_name)\n        # Ensure it doesn't start with a number\n        if temp_name and temp_name[0].isdigit():\n            temp_name = \"_\" + temp_name\n        # Ensure it's not empty, default if it becomes empty after sanitization\n        self.model_name = temp_name if temp_name else \"pymdp_agent_model\"\n        \n        self.script_parts: Dict[str, List[str]] = {\n            \"imports\": [\n                \"import numpy as np\",\n                \"from pymdp.agent import Agent\",\n                \"from pymdp import utils\", # Added\n                \"from pymdp import maths\", # Added, for softmax etc.\n                \"import copy\", # Added for A_gp, B_gp\n                \"import sys\", # for sys.modules\n                \"import inspect\", # for inspect.signature\n                \"import traceback\" # for traceback.format_exc()\n            ],\n            \"preamble_vars\": [], # For obs_names, state_names etc.\n            \"comments\": [f\"# --- GNN Model: {self.model_name} ---\"],\n            \"matrix_definitions\": [],\n            \"agent_instantiation\": [],\n            \"example_usage\": []\n        }\n        self.conversion_log: List[str] = [] # Log messages for summary\n\n        # Extracted and processed GNN data\n        self.obs_names: List[str] = []\n        self.state_names: List[str] = []\n        self.action_names_per_control_factor: Dict[int, List[str]] = {} # factor_idx -> list of action names\n\n        self.num_obs: List[int] = [] # num_outcomes per modality\n        self.num_states: List[int] = [] # num_states per factor\n        self.num_actions_per_control_factor: Dict[int, int] = {} # factor_idx -> num_actions\n\n        self.num_modalities: int = 0\n        self.num_factors: int = 0\n        self.control_factor_indices: List[int] = [] # List of hidden state factor indices that are controllable\n\n        self.A_spec: Optional[Union[Dict, List[Dict]]] = None # Can be complex structure\n        self.B_spec: Optional[Union[Dict, List[Dict]]] = None\n        self.C_spec: Optional[Union[Dict, List[Dict]]] = None\n        self.D_spec: Optional[Union[Dict, List[Dict]]] = None\n        self.E_spec: Optional[Dict] = None # For expected future utilities / policies\n\n        self.agent_hyperparams: Dict[str, Any] = {}\n        self.simulation_params: Dict[str, Any] = {}\n        \n        self._extract_gnn_data() # Populate the above fields\n\n\n    def _add_log(self, message: str, level: str = \"INFO\"): \n        \"\"\"Adds a message to the internal conversion log and also logs it via the module logger.\"\"\"\n        level_upper = level.upper()\n        self.conversion_log.append(f\"{level_upper}: {message}\")\n        \n        log_level_map = {\n            \"DEBUG\": logging.DEBUG,\n            \"INFO\": logging.INFO,\n            \"WARNING\": logging.WARNING,\n            \"ERROR\": logging.ERROR,\n            \"CRITICAL\": logging.CRITICAL\n        }\n        actual_log_level = log_level_map.get(level_upper, logging.INFO)\n        \n        # For errors caught and logged, include exception info if it's a genuine error message\n        # This is a heuristic; specific calls might pass exc_info directly if appropriate\n        if actual_log_level >= logging.ERROR and sys.exc_info()[0] is not None:\n             logger.log(actual_log_level, message, exc_info=True)\n        else:\n             logger.log(actual_log_level, message)\n\n    def _parse_string_to_literal(self, data_str: Any, context_msg: str) -> Optional[Any]:\n        \"\"\"Attempts to parse a string representation of a Python literal (e.g., list, tuple, dict).\"\"\"\n        if not isinstance(data_str, str):\n            if data_str is None or isinstance(data_str, (list, dict, tuple, int, float, bool, np.ndarray)): # Added np.ndarray\n                 return data_str\n            # This log call will use the updated _add_log which also logs to the module logger\n            self._add_log(f\"{context_msg}: Expected string for ast.literal_eval or a known pre-parsed type (list, dict, tuple, int, float, bool, np.ndarray), but got {type(data_str)}. Value: \\'{str(data_str)[:100]}...\\'. Returning None as parsing is not applicable.\", \"ERROR\")\n            return None\n\n        if not data_str.strip():\n            self._add_log(f\"{context_msg}: Received empty string data. Cannot parse. Returning None.\", \"WARNING\")\n            return None\n        \n        # Add a check for potentially very large strings to avoid performance issues with ast.literal_eval\n        # This limit is arbitrary and can be adjusted.\n        MAX_STRING_LEN_FOR_AST_EVAL = 1_000_000 # 1MB of string data\n        if len(data_str) > MAX_STRING_LEN_FOR_AST_EVAL:\n            self._add_log(f\"{context_msg}: Input string data is very long (len: {len(data_str)} characters). Parsing with ast.literal_eval might be slow or consume significant memory. Consider optimizing GNN spec to provide parsed data directly if possible.\", \"WARNING\")\n\n        try:\n            return ast.literal_eval(data_str)\n        except (ValueError, SyntaxError, TypeError) as e:\n            # The _add_log method will now also log this to the standard logger with ERROR level\n            # and exc_info=True if an exception is active.\n            # No need to call logger.error(..., exc_info=True) directly here if _add_log handles it.\n            error_message_detail = f\"ast.literal_eval failed. String \\'{data_str[:100]}...\\'. {e}\"\n            if \"array(\" in data_str:\n                 self._add_log(f\"{context_msg}: {error_message_detail} Appears to contain 'array(...)'. This construct is not supported by ast.literal_eval. The GNN spec should provide lists/numbers directly or use a format that can be parsed to basic Python types.\", \"ERROR\")\n            else:\n                self._add_log(f\"{context_msg}: {error_message_detail}\", \"ERROR\")\n            return None\n\n    def _extract_gnn_data(self):\n        \"\"\"Parses the raw gnn_spec and populates structured attributes.\"\"\"\n        self._add_log(\"Starting GNN data extraction.\")\n        # Ensure ast is imported if not already at module level\n        import ast\n\n        # Prioritize top-level keys from gnn_spec (populated by the exporter)\n        direct_num_obs = self.gnn_spec.get(\"num_obs_modalities\")\n        direct_obs_names = self.gnn_spec.get(\"obs_modality_names\") # New potential key\n\n        direct_num_states = self.gnn_spec.get(\"num_hidden_states_factors\")\n        direct_state_names = self.gnn_spec.get(\"hidden_state_factor_names\") # New potential key\n\n        # Attempt to parse stringified lists for direct_num_obs\n        if isinstance(direct_num_obs, str) and direct_num_obs.startswith('[') and direct_num_obs.endswith(']'):\n            try:\n                parsed_val = ast.literal_eval(direct_num_obs)\n                if isinstance(parsed_val, list) and all(isinstance(n, int) for n in parsed_val):\n                    direct_num_obs = parsed_val\n                    self._add_log(f\"Successfully parsed stringified direct_num_obs: {direct_num_obs}\", \"DEBUG\")\n            except (ValueError, SyntaxError, TypeError):\n                self._add_log(f\"Failed to parse stringified direct_num_obs: {direct_num_obs}\", \"WARNING\")\n        \n        # Attempt to parse stringified lists for direct_num_states\n        if isinstance(direct_num_states, str) and direct_num_states.startswith('[') and direct_num_states.endswith(']'):\n            try:\n                parsed_val = ast.literal_eval(direct_num_states)\n                if isinstance(parsed_val, list) and all(isinstance(n, int) for n in parsed_val):\n                    direct_num_states = parsed_val\n                    self._add_log(f\"Successfully parsed stringified direct_num_states: {direct_num_states}\", \"DEBUG\")\n            except (ValueError, SyntaxError, TypeError):\n                self._add_log(f\"Failed to parse stringified direct_num_states: {direct_num_states}\", \"WARNING\")\n\n        direct_num_control_dims = self.gnn_spec.get(\"num_control_factors\") # This should be a list of action dimensions for each factor\n        direct_control_action_names = self.gnn_spec.get(\"control_action_names_per_factor\") # Dict: factor_idx -> list of names\n\n        ss_block = self.gnn_spec.get(\"StateSpaceBlock\", {})\n        model_params_spec = self.gnn_spec.get(\"ModelParameters\", {})\n\n        # Observation Modalities Dimensions & Names\n        processed_obs_directly = False\n        if isinstance(direct_num_obs, list) and all(isinstance(n, int) for n in direct_num_obs):\n            self.num_obs = direct_num_obs\n            self.num_modalities = len(self.num_obs)\n            self._add_log(f\"Observation dimensions (num_obs) derived directly from gnn_spec.num_obs_modalities: {self.num_obs}\", \"INFO\")\n            if isinstance(direct_obs_names, list) and len(direct_obs_names) == self.num_modalities:\n                self.obs_names = direct_obs_names\n                self._add_log(f\"Observation names derived directly from gnn_spec.obs_modality_names: {self.obs_names}\", \"INFO\")\n            else:\n                self.obs_names = [f\"modality_{i}\" for i in range(self.num_modalities)]\n                self._add_log(f\"Observation names generated as defaults (gnn_spec.obs_modality_names not found or mismatched).\", \"INFO\")\n            processed_obs_directly = True\n\n        if not processed_obs_directly:\n            num_obs_from_model_params = model_params_spec.get(\"num_obs_modalities\")\n            if isinstance(num_obs_from_model_params, list) and all(isinstance(n, int) for n in num_obs_from_model_params):\n                self.num_obs = num_obs_from_model_params\n                self.num_modalities = len(self.num_obs)\n                self._add_log(f\"Observation dimensions (num_obs) derived from ModelParameters: {self.num_obs}\", \"INFO\")\n                obs_modalities_spec = ss_block.get(\"ObservationModalities\", [])\n                if obs_modalities_spec and len(obs_modalities_spec) == self.num_modalities:\n                    self.obs_names = [mod.get(\"modality_name\", f\"modality_{i}\") for i, mod in enumerate(obs_modalities_spec)]\n                else:\n                    self.obs_names = [f\"modality_{i}\" for i in range(self.num_modalities)]\n            else:\n                obs_modalities_spec = ss_block.get(\"ObservationModalities\", [])\n                if not obs_modalities_spec:\n                    self._add_log(\"No 'ObservationModalities' in StateSpaceBlock and no 'num_obs_modalities' in ModelParameters or gnn_spec.\", \"WARNING\")\n                for i, mod_spec in enumerate(obs_modalities_spec):\n                    name = mod_spec.get(\"modality_name\", f\"modality_{i}\")\n                    num_outcomes = mod_spec.get(\"num_outcomes\")\n                    if num_outcomes is None:\n                        self._add_log(f\"Modality '{name}' missing 'num_outcomes'. Skipping.\", \"ERROR\")\n                        continue\n                    self.obs_names.append(name)\n                    self.num_obs.append(int(num_outcomes))\n                self.num_modalities = len(self.num_obs)\n\n        self.script_parts[\"preamble_vars\"].append(f\"obs_names = {self.obs_names if self.num_modalities > 0 else []}\")\n        self.script_parts[\"preamble_vars\"].append(f\"num_obs = {self.num_obs if self.num_modalities > 0 else []}\")\n        self.script_parts[\"preamble_vars\"].append(f\"num_modalities = {self.num_modalities}\")\n\n        # Hidden State Factors Dimensions & Names\n        processed_states_directly = False\n        if isinstance(direct_num_states, list) and all(isinstance(n, int) for n in direct_num_states):\n            self.num_states = direct_num_states\n            self.num_factors = len(self.num_states)\n            self._add_log(f\"Hidden state dimensions (num_states) derived directly from gnn_spec.num_hidden_states_factors: {self.num_states}\", \"INFO\")\n            if isinstance(direct_state_names, list) and len(direct_state_names) == self.num_factors:\n                self.state_names = direct_state_names\n                self._add_log(f\"Hidden state names derived directly from gnn_spec.hidden_state_factor_names: {self.state_names}\", \"INFO\")\n            else:\n                self.state_names = [f\"factor_{i}\" for i in range(self.num_factors)]\n                self._add_log(f\"Hidden state names generated as defaults (gnn_spec.hidden_state_factor_names not found or mismatched).\", \"INFO\")\n            processed_states_directly = True\n\n        if not processed_states_directly:\n            num_states_from_model_params = model_params_spec.get(\"num_hidden_states_factors\")\n            if isinstance(num_states_from_model_params, list) and all(isinstance(n, int) for n in num_states_from_model_params):\n                self.num_states = num_states_from_model_params\n                self.num_factors = len(self.num_states)\n                self._add_log(f\"Hidden state dimensions (num_states) derived from ModelParameters: {self.num_states}\", \"INFO\")\n                hidden_factors_spec_mp_fallback = ss_block.get(\"HiddenStateFactors\", [])\n                if hidden_factors_spec_mp_fallback and len(hidden_factors_spec_mp_fallback) == self.num_factors:\n                    self.state_names = [fac.get(\"factor_name\", f\"factor_{i}\") for i, fac in enumerate(hidden_factors_spec_mp_fallback)]\n                else:\n                    self.state_names = [f\"factor_{i}\" for i in range(self.num_factors)]\n            else:\n                hidden_factors_spec = ss_block.get(\"HiddenStateFactors\", [])\n                if not hidden_factors_spec:\n                    self._add_log(\"No 'HiddenStateFactors' in StateSpaceBlock and no 'num_hidden_states_factors' in ModelParameters or gnn_spec.\", \"WARNING\")\n                for i, fac_spec in enumerate(hidden_factors_spec):\n                    name = fac_spec.get(\"factor_name\", f\"factor_{i}\")\n                    num_states_val = fac_spec.get(\"num_states\")\n                    if num_states_val is None:\n                        self._add_log(f\"Factor '{name}' missing 'num_states'. Skipping.\", \"ERROR\")\n                        continue\n                    self.state_names.append(name)\n                    self.num_states.append(int(num_states_val))\n                self.num_factors = len(self.num_states)\n            \n        # Controllable factors and actions - try direct gnn_spec keys first\n        processed_control_directly = False\n        if isinstance(direct_num_control_dims, list) and self.num_factors > 0 and len(direct_num_control_dims) == self.num_factors:\n            self._add_log(f\"Control dimensions derived directly from gnn_spec.num_control_factors: {direct_num_control_dims}\", \"INFO\")\n            for f_idx, num_actions_for_factor_val in enumerate(direct_num_control_dims):\n                num_actions_for_factor = int(num_actions_for_factor_val)\n                if num_actions_for_factor > 1: # Assumes >1 action means controllable\n                    self.control_factor_indices.append(f_idx)\n                    self.num_actions_per_control_factor[f_idx] = num_actions_for_factor\n                    # Get action names if provided directly\n                    if isinstance(direct_control_action_names, dict) and f_idx in direct_control_action_names and \\\n                       isinstance(direct_control_action_names[f_idx], list) and len(direct_control_action_names[f_idx]) == num_actions_for_factor:\n                        self.action_names_per_control_factor[f_idx] = direct_control_action_names[f_idx]\n                        self._add_log(f\"Action names for control factor {f_idx} derived directly from gnn_spec.control_action_names_per_factor.\", \"INFO\")\n                    else:\n                        factor_name_for_action = self.state_names[f_idx] if f_idx < len(self.state_names) else f\"factor_{f_idx}\"\n                        self.action_names_per_control_factor[f_idx] = [f\"{factor_name_for_action}_action_{j}\" for j in range(num_actions_for_factor)]\n            processed_control_directly = True\n\n        if not processed_control_directly:\n            num_control_factors_dims_mp = model_params_spec.get(\"num_control_factors\", model_params_spec.get(\"num_control_action_dims\"))\n            if isinstance(num_control_factors_dims_mp, list) and self.num_factors > 0 and len(num_control_factors_dims_mp) == self.num_factors:\n                self._add_log(f\"Control dimensions derived from ModelParameters.num_control_factors/dims: {num_control_factors_dims_mp}\", \"INFO\")\n                for f_idx, num_actions_for_factor_val in enumerate(num_control_factors_dims_mp):\n                    num_actions_for_factor = int(num_actions_for_factor_val)\n                    if num_actions_for_factor > 1:\n                        self.control_factor_indices.append(f_idx)\n                        self.num_actions_per_control_factor[f_idx] = num_actions_for_factor\n                        hsf_block = ss_block.get(\"HiddenStateFactors\", [])\n                        factor_name_for_action = self.state_names[f_idx] if f_idx < len(self.state_names) else f\"factor_{f_idx}\"\n                        action_names_from_hsf = None\n                        if f_idx < len(hsf_block) and hsf_block[f_idx].get(\"factor_name\") == factor_name_for_action:\n                            action_names_from_hsf = hsf_block[f_idx].get(\"action_names\")\n                        \n                        if action_names_from_hsf and len(action_names_from_hsf) == num_actions_for_factor:\n                           self.action_names_per_control_factor[f_idx] = action_names_from_hsf\n                        else:\n                           self.action_names_per_control_factor[f_idx] = [f\"{factor_name_for_action}_action_{j}\" for j in range(num_actions_for_factor)]\n            else:\n                hidden_factors_spec_ctrl = ss_block.get(\"HiddenStateFactors\", [])\n                if self.num_factors > 0 and len(hidden_factors_spec_ctrl) == self.num_factors:\n                    for i, fac_spec in enumerate(hidden_factors_spec_ctrl):\n                        if fac_spec.get(\"controllable\", False):\n                            self.control_factor_indices.append(i)\n                            num_actions = fac_spec.get(\"num_actions\")\n                            factor_name_for_action = self.state_names[i] if i < len(self.state_names) else f\"factor_{i}\"\n                            if num_actions is None:\n                                self._add_log(f\"Controllable factor '{factor_name_for_action}' missing 'num_actions'. Defaulting to num_states ({self.num_states[i]}).\", \"WARNING\")\n                                num_actions = int(self.num_states[i])\n                            self.num_actions_per_control_factor[i] = int(num_actions)\n                            action_names = fac_spec.get(\"action_names\")\n                            if action_names and len(action_names) == num_actions:\n                                self.action_names_per_control_factor[i] = action_names\n                            else:\n                                self.action_names_per_control_factor[i] = [f\"{factor_name_for_action}_action_{j}\" for j in range(num_actions)]\n                else:\n                     self._add_log(f\"Could not definitively determine control structure from gnn_spec, ModelParameters or StateSpaceBlock. control_fac_idx might be empty.\", \"WARNING\")\n\n        self.script_parts[\"preamble_vars\"].append(f\"state_names = {self.state_names if self.num_factors > 0 else []}\")\n        self.script_parts[\"preamble_vars\"].append(f\"num_states = {self.num_states if self.num_factors > 0 else []}\")\n        self.script_parts[\"preamble_vars\"].append(f\"num_factors = {self.num_factors}\")\n        self.script_parts[\"preamble_vars\"].append(f\"control_fac_idx = {self.control_factor_indices if self.control_factor_indices else []}\")\n\n        num_controls_list = []\n        if self.num_factors > 0:\n            for f_idx in range(self.num_factors):\n                if f_idx in self.control_factor_indices:\n                    # Default to num_states for that factor if num_actions not specified\n                    num_actions_for_factor = self.num_actions_per_control_factor.get(f_idx, self.num_states[f_idx])\n                    num_controls_list.append(num_actions_for_factor)\n                else:\n                    num_controls_list.append(1) # PyMDP convention for uncontrollable factors\n        self.script_parts[\"preamble_vars\"].append(f\"num_controls = {num_controls_list}\")\n        \n        # InitialParameterization (or specific matrix blocks)\n        # This needs to be adapted based on how the GNN spec is structured for matrices.\n        # Assuming a structure like: gnn_spec.get(\"LikelihoodMatrixA\", {})\n        param_block = self.gnn_spec.get(\"InitialParameterization\", self.gnn_spec.get(\"MatrixParameters\", {})) # Backward compatibility\n        \n        # A_spec (Likelihoods)\n        a_matrix_generic_spec = param_block.get(\"A_Matrix\", param_block.get(\"A\"))\n        if a_matrix_generic_spec:\n            self.A_spec = a_matrix_generic_spec\n            self._add_log(\"A_spec: Loaded from generic 'A_Matrix' or 'A' key.\", \"DEBUG\")\n        else:\n            temp_A_list = []\n            found_A_m_keys = False\n            for mod_idx in range(self.num_modalities):\n                mod_a_data = param_block.get(f\"A_m{mod_idx}\")\n                if mod_a_data is not None:\n                    temp_A_list.append({\"array\": mod_a_data}) # Wrap data in dict\n                    found_A_m_keys = True\n                else:\n                    # If a specific A_m<idx> is missing, but others might exist,\n                    # we add a None placeholder. convert_A_matrix should handle it\n                    # (e.g. by defaulting that modality or logging an error).\n                    temp_A_list.append(None) \n            if found_A_m_keys:\n                self.A_spec = temp_A_list\n                self._add_log(f\"A_spec: Constructed from individual 'A_m<idx>' keys. Found specs: {[s is not None for s in temp_A_list]}\", \"DEBUG\")\n            else:\n                self.A_spec = None # No generic A_Matrix and no A_m<idx> keys found\n                self._add_log(\"A_spec: No 'A_Matrix' or 'A_m<idx>' keys found in InitialParameterization.\", \"INFO\")\n\n        # B_spec (Transitions)\n        b_matrix_generic_spec = param_block.get(\"B_Matrix\", param_block.get(\"B\"))\n        if b_matrix_generic_spec:\n            self.B_spec = b_matrix_generic_spec\n            self._add_log(\"B_spec: Loaded from generic 'B_Matrix' or 'B' key.\", \"DEBUG\")\n        else:\n            temp_B_list = []\n            found_B_f_keys = False\n            for f_idx in range(self.num_factors):\n                fac_b_data = param_block.get(f\"B_f{f_idx}\")\n                if fac_b_data is not None:\n                    temp_B_list.append({\"array\": fac_b_data})\n                    found_B_f_keys = True\n                else:\n                    temp_B_list.append(None)\n            if found_B_f_keys:\n                self.B_spec = temp_B_list\n                self._add_log(f\"B_spec: Constructed from individual 'B_f<idx>' keys. Found specs: {[s is not None for s in temp_B_list]}\", \"DEBUG\")\n            else:\n                self.B_spec = None\n                self._add_log(\"B_spec: No 'B_Matrix' or 'B_f<idx>' keys found in InitialParameterization.\", \"INFO\")\n\n        # C_spec (Preferences over outcomes)\n        c_vector_generic_spec = param_block.get(\"C_Vector\", param_block.get(\"C\"))\n        if c_vector_generic_spec:\n            self.C_spec = c_vector_generic_spec\n            self._add_log(\"C_spec: Loaded from generic 'C_Vector' or 'C' key.\", \"DEBUG\")\n        else:\n            temp_C_list = []\n            found_C_m_keys = False\n            for mod_idx in range(self.num_modalities):\n                mod_c_data = param_block.get(f\"C_m{mod_idx}\")\n                if mod_c_data is not None:\n                    temp_C_list.append({\"array\": mod_c_data})\n                    found_C_m_keys = True\n                else:\n                    temp_C_list.append(None)\n            if found_C_m_keys:\n                self.C_spec = temp_C_list\n                self._add_log(f\"C_spec: Constructed from individual 'C_m<idx>' keys. Found specs: {[s is not None for s in temp_C_list]}\", \"DEBUG\")\n            else:\n                self.C_spec = None\n                self._add_log(\"C_spec: No 'C_Vector' or 'C_m<idx>' keys found in InitialParameterization.\", \"INFO\")\n\n        # D_spec (Initial hidden states)\n        d_vector_generic_spec = param_block.get(\"D_Vector\", param_block.get(\"D\"))\n        if d_vector_generic_spec:\n            self.D_spec = d_vector_generic_spec\n            self._add_log(\"D_spec: Loaded from generic 'D_Vector' or 'D' key.\", \"DEBUG\")\n        else:\n            temp_D_list = []\n            found_D_f_keys = False\n            for f_idx in range(self.num_factors):\n                fac_d_data = param_block.get(f\"D_f{f_idx}\")\n                if fac_d_data is not None:\n                    temp_D_list.append({\"array\": fac_d_data})\n                    found_D_f_keys = True\n                else:\n                    temp_D_list.append(None)\n            if found_D_f_keys:\n                self.D_spec = temp_D_list\n                self._add_log(f\"D_spec: Constructed from individual 'D_f<idx>' keys. Found specs: {[s is not None for s in temp_D_list]}\", \"DEBUG\")\n            else:\n                self.D_spec = None\n                self._add_log(\"D_spec: No 'D_Vector' or 'D_f<idx>' keys found in InitialParameterization.\", \"INFO\")\n        \n        # E_spec (Prior preferences over policies) - usually a single spec\n        self.E_spec = param_block.get(\"E_Vector\", param_block.get(\"E\"))\n        if self.E_spec:\n            self._add_log(\"E_spec: Loaded from 'E_Vector' or 'E' key.\", \"DEBUG\")\n        else:\n            self._add_log(\"E_spec: No 'E_Vector' or 'E' key found.\", \"INFO\")\n\n\n        self.agent_hyperparams = self.gnn_spec.get(\"AgentHyperparameters\", {})\n        self.simulation_params = self.gnn_spec.get(\"SimulationParameters\", {})\n\n        self._add_log(\"Finished GNN data extraction.\")\n\n\n    def _get_matrix_data(self, base_name: str, factor_idx: Optional[int] = None, modality_idx: Optional[int] = None) -> Any:\n        \"\"\"DEPRECATED: Use direct spec attributes like self.A_spec instead.\"\"\"\n        # This method is kept for now if old parts of convert_X_matrix still use it,\n        # but the goal is to use the structured self.A_spec, self.B_spec etc.\n        param_block = self.gnn_spec.get(\"InitialParameterization\", self.gnn_spec.get(\"MatrixParameters\", {}))\n\n        if factor_idx is not None:\n            matrix_key = f\"{base_name}_f{factor_idx}\"\n        elif modality_idx is not None:\n            matrix_key = f\"{base_name}_m{modality_idx}\"\n        else:\n            matrix_key = base_name\n        \n        data = param_block.get(matrix_key)\n        if data is None:\n            self._add_log(f\"Matrix {matrix_key} not found in GNN InitialParameterization/MatrixParameters.\", \"WARNING\")\n        return data\n\n    def convert_A_matrix(self) -> str:\n        \"\"\"Converts GNN's A matrix (likelihood) to PyMDP format.\"\"\"\n        if not self.num_modalities:\n            self._add_log(\"A_matrix: No observation modalities defined. 'A' will be None.\", \"INFO\")\n            self.script_parts[\"matrix_definitions\"].append(\"A = None\")\n            return \"# A matrix set to None due to no observation modalities.\"\n\n        if not self.num_factors: # A multi-factor likelihood depends on states\n            self._add_log(\"A_matrix: No hidden state factors defined. Cannot form A. 'A' will be None.\", \"INFO\")\n            self.script_parts[\"matrix_definitions\"].append(\"A = None\")\n            return \"# A matrix set to None due to no hidden state factors.\"\n\n        init_code = f\"A = utils.obj_array({self.num_modalities})\"\n        self.script_parts[\"matrix_definitions\"].append(init_code)\n\n        # Default to uniform if no A_spec\n        for mod_idx in range(self.num_modalities):\n            shape_A_mod = tuple([self.num_obs[mod_idx]] + self.num_states)\n            self.script_parts[\"matrix_definitions\"].append(f\"A[{mod_idx}] = utils.norm_dist(np.ones({shape_A_mod})) # Defaulted to uniform\")\n\n        if self.A_spec:\n            if isinstance(self.A_spec, list): # List of specs per modality\n                for mod_idx, mod_a_spec in enumerate(self.A_spec):\n                    if mod_a_spec is None: # Modality spec might be missing\n                        self._add_log(f\"A_matrix (modality {mod_idx}): Spec is None. Using default uniform A[{mod_idx}].\", \"INFO\")\n                        continue\n\n                    array_data_input = mod_a_spec.get(\"array\")\n                    rule = mod_a_spec.get(\"rule\")\n                    context_msg = f\"A_matrix (modality {self.obs_names[mod_idx] if mod_idx < len(self.obs_names) else mod_idx})\"\n\n                    if array_data_input is not None:\n                        parsed_array_data = self._parse_string_to_literal(array_data_input, context_msg)\n                        if parsed_array_data is not None:\n                            try:\n                                np_array = np.array(parsed_array_data)\n                                expected_shape = tuple([self.num_obs[mod_idx]] + self.num_states)\n                                if np_array.shape == expected_shape:\n                                    assign_str = f\"utils.norm_dist({_numpy_array_to_string(np_array, indent=4)})\"\n                                    self.script_parts[\"matrix_definitions\"].append(f\"A[{mod_idx}] = {assign_str}\")\n                                else:\n                                    self._add_log(f\"{context_msg}: Shape mismatch. Expected {expected_shape}, got {np_array.shape}. Using default uniform A[{mod_idx}].\", \"ERROR\")\n                            except Exception as e:\n                                self._add_log(f\"{context_msg}: Error processing parsed array data to NumPy: {e}. Using default uniform A[{mod_idx}].\", \"ERROR\")\n                        else:\n                            self._add_log(f\"{context_msg}: Failed to parse array data string. Using default uniform A[{mod_idx}].\", \"INFO\")\n                    elif rule:\n                        self._add_log(f\"{context_msg}: Rule '{rule}' not fully implemented yet. Using default uniform A[{mod_idx}].\", \"WARNING\")\n                    else:\n                        self._add_log(f\"{context_msg}: No 'array' or 'rule' found. Using default uniform A[{mod_idx}].\", \"INFO\")\n            # Handling for A_spec as single dict if num_modalities == 1\n            elif isinstance(self.A_spec, dict) and self.num_modalities == 1:\n                mod_idx = 0\n                array_data_input = self.A_spec.get(\"array\")\n                rule = self.A_spec.get(\"rule\")\n                context_msg = f\"A_matrix (modality {mod_idx})\"\n                if array_data_input is not None:\n                    parsed_array_data = self._parse_string_to_literal(array_data_input, context_msg)\n                    if parsed_array_data is not None:\n                        try:\n                            np_array = np.array(parsed_array_data)\n                            expected_shape = tuple([self.num_obs[mod_idx]] + self.num_states)\n                            if np_array.shape == expected_shape:\n                                assign_str = f\"utils.norm_dist({_numpy_array_to_string(np_array, indent=4)})\"\n                                self.script_parts[\"matrix_definitions\"].append(f\"A[{mod_idx}] = {assign_str}\")\n                            else:\n                                self._add_log(f\"{context_msg}: Shape mismatch. Expected {expected_shape}, got {np_array.shape}. Using default uniform A[{mod_idx}].\", \"ERROR\")\n                        except Exception as e:\n                            self._add_log(f\"{context_msg}: Error processing parsed array data to NumPy: {e}. Using default uniform A[{mod_idx}].\", \"ERROR\")\n                    else:\n                        self._add_log(f\"{context_msg}: Failed to parse array data string. Using default uniform A[{mod_idx}].\", \"INFO\")\n                elif rule:\n                    self._add_log(f\"{context_msg}: Rule '{rule}' not fully implemented. Using default uniform A[{mod_idx}].\", \"WARNING\")\n                else:\n                    self._add_log(f\"{context_msg}: No 'array' or 'rule'. Using default uniform A[{mod_idx}].\", \"INFO\")\n            else:\n                self._add_log(\"A_matrix: A_spec format not recognized for multiple modalities. All A modalities will be default uniform.\", \"WARNING\")\n        else: # No A_spec\n            self._add_log(\"A_matrix: No A_spec provided in GNN. All modalities of A defaulted to uniform.\", \"INFO\")\n            return \"# A matrix modalities remain default initialized (uniform).\"\n        \n        return \"# A matrix construction based on GNN spec.\"\n\n\n    def convert_B_matrix(self) -> str:\n        \"\"\"Converts GNN's B matrix (transition) to PyMDP format.\"\"\"\n        if not self.num_factors:\n            self._add_log(\"B_matrix: No hidden state factors defined. 'B' will be None.\", \"INFO\")\n            self.script_parts[\"matrix_definitions\"].append(\"B = None\")\n            return \"# B matrix set to None due to no hidden state factors.\"\n\n        init_code = f\"B = utils.obj_array(num_factors)\"\n        self.script_parts[\"matrix_definitions\"].append(init_code)\n\n        # Default initialization for all B slices first\n        for f_idx in range(self.num_factors):\n            num_states_f = self.num_states[f_idx]\n            log_msg_prefix_f = f\"B_matrix (factor {self.state_names[f_idx] if f_idx < len(self.state_names) else f_idx})\"\n            if f_idx in self.control_factor_indices:\n                num_actions_f = self.num_actions_per_control_factor.get(f_idx, num_states_f) # Default actions = num_states for that factor\n                # PyMDP default for controllable B: tile identity matrices for each action\n                self.script_parts[\"matrix_definitions\"].append(f\"B[{f_idx}] = np.tile(np.eye({num_states_f}), ({num_actions_f}, 1, 1)).transpose(1, 2, 0) # Default for controllable\")\n                self._add_log(f\"{log_msg_prefix_f}: Initialized with default structure for controllable factor (repeated identity matrices).\", \"DEBUG\")\n            else: # Uncontrolled\n                self.script_parts[\"matrix_definitions\"].append(f\"B[{f_idx}] = np.eye({num_states_f})[:, :, np.newaxis] # Default for uncontrolled (identity)\")\n                self._add_log(f\"{log_msg_prefix_f}: Initialized with default identity matrix for uncontrolled factor.\", \"DEBUG\")\n\n        if not self.B_spec:\n            self._add_log(\"B_matrix: No B_spec provided in GNN. B slices will use default initializations (identities).\", \"INFO\")\n            return \"# B matrix slices remain default initialized.\"\n\n        def get_b_assignment_string(spec_value_input, num_states_val, is_controlled_val, num_actions_val, factor_idx_for_log, indent_level=4) -> Optional[str]:\n            np_array = None\n            context_msg_b_assign = f\"B_matrix (factor {self.state_names[factor_idx_for_log] if factor_idx_for_log < len(self.state_names) else factor_idx_for_log}) internal assignment\"\n            \n            parsed_spec_value = self._parse_string_to_literal(spec_value_input, context_msg_b_assign)\n\n            if parsed_spec_value is None:\n                self._add_log(f\"{context_msg_b_assign}: Parsed spec value from string is None. Cannot create NumPy array.\", \"ERROR\")\n                return None\n            try:\n                np_array = np.array(parsed_spec_value)\n            except Exception as e:\n                self._add_log(f\"{context_msg_b_assign}: Error converting parsed data to NumPy array: {e}. Value was: '{str(parsed_spec_value)[:100]}...'\", \"ERROR\")\n                return None\n\n            expected_shape_controlled = (num_states_val, num_states_val, num_actions_val)\n            expected_shape_uncontrolled_2d = (num_states_val, num_states_val)\n            expected_shape_uncontrolled_3d = (num_states_val, num_states_val, 1)\n\n            assign_str_val = _numpy_array_to_string(np_array, indent=indent_level)\n\n            if is_controlled_val:\n                if np_array.shape == expected_shape_controlled:\n                    return f\"utils.norm_dist({assign_str_val})\"\n                else:\n                    self._add_log(f\"{context_msg_b_assign}: Shape mismatch for controlled factor. Expected {expected_shape_controlled}, got {np_array.shape}. Not assigning.\", \"ERROR\")\n                    return None\n            else: # Uncontrolled\n                if np_array.shape == expected_shape_uncontrolled_2d:\n                    return f\"utils.norm_dist({assign_str_val})[:, :, np.newaxis]\"\n                elif np_array.shape == expected_shape_uncontrolled_3d:\n                    return f\"utils.norm_dist({assign_str_val})\"\n                else:\n                    self._add_log(f\"{context_msg_b_assign}: Shape mismatch for uncontrolled factor. Expected {expected_shape_uncontrolled_2d} or {expected_shape_uncontrolled_3d}, got {np_array.shape}. Not assigning.\", \"ERROR\")\n                    return None\n        \n        if isinstance(self.B_spec, list):\n            for f_idx, fac_b_spec in enumerate(self.B_spec):\n                if fac_b_spec is None: \n                    self._add_log(f\"B_matrix (factor {f_idx}): Spec is None. Using default B[{f_idx}].\", \"INFO\")\n                    continue\n                \n                array_data_input = fac_b_spec.get(\"array\")\n                rule = fac_b_spec.get(\"rule\")\n                is_controlled = f_idx in self.control_factor_indices\n                num_actions = self.num_actions_per_control_factor.get(f_idx, 1) if is_controlled else 1\n                context_msg_b = f\"B_matrix (factor {self.state_names[f_idx] if f_idx < len(self.state_names) else f_idx})\"\n\n                if array_data_input is not None:\n                    assign_str = get_b_assignment_string(array_data_input, self.num_states[f_idx], is_controlled, num_actions, f_idx)\n                    if assign_str:\n                        self.script_parts[\"matrix_definitions\"].append(f\"B[{f_idx}] = {assign_str}\")\n                    else:\n                        self._add_log(f\"{context_msg_b}: Failed to get assignment string from array data. Using default B[{f_idx}].\", \"WARNING\")\n                elif rule:\n                    self._add_log(f\"{context_msg_b}: Rule '{rule}' for B not fully implemented. Using default B[{f_idx}].\", \"WARNING\")\n                else:\n                    self._add_log(f\"{context_msg_b}: No 'array' or 'rule' found. Using default B[{f_idx}].\", \"INFO\")\n\n        elif isinstance(self.B_spec, dict) and self.num_factors == 1:\n            f_idx = 0\n            array_data_input = self.B_spec.get(\"array\")\n            rule = self.B_spec.get(\"rule\")\n            is_controlled = f_idx in self.control_factor_indices\n            num_actions = self.num_actions_per_control_factor.get(f_idx, 1) if is_controlled else 1\n            context_msg_b = f\"B_matrix (factor {self.state_names[f_idx] if f_idx < len(self.state_names) else f_idx})\"\n\n            if array_data_input is not None:\n                assign_str = get_b_assignment_string(array_data_input, self.num_states[f_idx], is_controlled, num_actions, f_idx)\n                if assign_str:\n                    self.script_parts[\"matrix_definitions\"].append(f\"B[{f_idx}] = {assign_str}\")\n                else:\n                    self._add_log(f\"{context_msg_b}: Failed to get assignment string from array data for single factor. Using default B[{f_idx}].\", \"WARNING\")\n            elif rule:\n                self._add_log(f\"{context_msg_b}: Rule '{rule}' for B (single factor) not fully implemented. Using default B[{f_idx}].\", \"WARNING\")\n            else:\n                self._add_log(f\"{context_msg_b}: No 'array' or 'rule' for B (single factor). Using default B[{f_idx}].\", \"INFO\")\n        else:\n            self._add_log(\"B_matrix: B_spec format not recognized. B factors will be default initialized.\", \"WARNING\")\n            \n        return \"# B matrix construction based on GNN spec.\"\n\n    def convert_C_vector(self) -> str:\n        \"\"\"Converts GNN's C vector (preferences) to PyMDP format.\"\"\"\n        if not self.num_modalities:\n            self._add_log(\"C_vector: No observation modalities defined. 'C' will be None.\", \"INFO\") # C is optional\n            # Directly append the definition to script_parts\n            self.script_parts[\"matrix_definitions\"].append(generate_pymdp_matrix_definition(\"C\", None)) \n            return \"# C matrix set to None due to no observation modalities.\" # Return value is for logging/info\n\n        # Initialize C = utils.obj_array_zeros(num_obs)\n        init_code = f\"C = utils.obj_array_zeros(num_obs)\" # num_obs is list of outcome counts per modality\n        self.script_parts[\"matrix_definitions\"].append(init_code)\n\n        if self.C_spec:\n            if isinstance(self.C_spec, list): # List of specs per modality\n                for mod_idx, mod_c_spec in enumerate(self.C_spec):\n                    if mod_c_spec is None: continue # Allow sparse C definition\n                    \n                    array_data_input = mod_c_spec.get(\"array\") # Expects 1D array of length num_obs[mod_idx]\n                    if array_data_input:\n                        try:\n                            np_array = np.array(array_data_input)\n                            expected_shape = (self.num_obs[mod_idx],)\n                            if np_array.shape == expected_shape:\n                                self.script_parts[\"matrix_definitions\"].append(f\"C[{mod_idx}] = {_numpy_array_to_string(np_array, indent=4)}\")\n                            else:\n                                self._add_log(f\"C_vector (modality {mod_idx}): Shape mismatch. Expected {expected_shape}, got {np_array.shape}.\", \"ERROR\")\n                        except Exception as e:\n                             self._add_log(f\"C_vector (modality {mod_idx}): Error processing array data: {e}.\", \"ERROR\")\n                    else:\n                         self._add_log(f\"C_vector (modality {mod_idx}): No 'array' found in spec. C[{mod_idx}] will be zeros.\", \"INFO\")\n            # Add handling for C_spec as single dict if num_modalities == 1\n            else:\n                self._add_log(\"C_vector: C_spec format not recognized for detailed construction. C will be zeros.\", \"WARNING\")\n        else:\n            self._add_log(\"C_vector: No C_spec. C will be initialized to zeros by obj_array_zeros.\", \"INFO\")\n        \n        return \"# C vector definition appended to script parts\"\n        \n    def convert_D_vector(self) -> str:\n        \"\"\"Converts GNN's D vector (initial beliefs about hidden states) to PyMDP format.\"\"\"\n        if not self.num_factors:\n            self._add_log(\"D_vector: No hidden state factors defined. 'D' will be None.\", \"INFO\")\n            self.script_parts[\"matrix_definitions\"].append(\"D = None\")\n            return \"# D vector set to None due to no hidden state factors.\"\n\n        init_code = f\"D = utils.obj_array({self.num_factors})\"\n        self.script_parts[\"matrix_definitions\"].append(init_code)\n        \n        # Default to uniform if no D_spec\n        for f_idx in range(self.num_factors):\n            self.script_parts[\"matrix_definitions\"].append(f\"D[{f_idx}] = utils.norm_dist(np.ones({self.num_states[f_idx]})) # Default: uniform D for factor {f_idx}\")\n\n        if self.D_spec:\n            if isinstance(self.D_spec, list): \n                for f_idx, fac_d_spec in enumerate(self.D_spec):\n                    if fac_d_spec is None: \n                        self._add_log(f\"D_vector (factor {f_idx}): Spec is None. Using default uniform D[{f_idx}].\", \"INFO\")\n                        continue\n\n                    array_data_input = fac_d_spec.get(\"array\")\n                    rule = fac_d_spec.get(\"rule\")\n                    context_msg = f\"D_vector (factor {self.state_names[f_idx] if f_idx < len(self.state_names) else f_idx})\"\n\n                    if array_data_input is not None:\n                        parsed_array_data = self._parse_string_to_literal(array_data_input, context_msg)\n                        if parsed_array_data is not None:\n                            try:\n                                np_array = np.array(parsed_array_data)\n                                expected_shape = (self.num_states[f_idx],)\n                                if np_array.shape == expected_shape:\n                                    if np.isclose(np.sum(np_array), 1.0) and np.all(np_array >= 0):\n                                         assign_str = _numpy_array_to_string(np_array, indent=4)\n                                    else: \n                                         assign_str = f\"utils.norm_dist({_numpy_array_to_string(np_array, indent=4)})\"\n                                    self.script_parts[\"matrix_definitions\"].append(f\"D[{f_idx}] = {assign_str}\")\n                                else:\n                                    self._add_log(f\"{context_msg}: Shape mismatch. Expected {expected_shape}, got {np_array.shape}. Using default uniform.\", \"ERROR\")\n                            except Exception as e:\n                                 self._add_log(f\"{context_msg}: Error processing parsed array data to NumPy: {e}. Using default uniform.\", \"ERROR\")\n                        else:\n                            self._add_log(f\"{context_msg}: Failed to parse array data string. Using default uniform D[{f_idx}].\", \"INFO\")\n                    elif rule:\n                        self._add_log(f\"{context_msg}: Rule '{rule}' for D not implemented. Using default uniform D[{f_idx}].\", \"WARNING\")\n                    else:\n                        self._add_log(f\"{context_msg}: No 'array' or 'rule' found. Using default uniform D[{f_idx}].\", \"INFO\")\n            elif isinstance(self.D_spec, dict) and self.num_factors == 1:\n                f_idx = 0\n                array_data_input = self.D_spec.get(\"array\")\n                rule = self.D_spec.get(\"rule\")\n                context_msg = f\"D_vector (factor {f_idx})\"\n                if array_data_input is not None:\n                    parsed_array_data = self._parse_string_to_literal(array_data_input, context_msg)\n                    if parsed_array_data is not None:\n                        try:\n                            np_array = np.array(parsed_array_data)\n                            expected_shape = (self.num_states[f_idx],)\n                            if np_array.shape == expected_shape:\n                                if np.isclose(np.sum(np_array), 1.0) and np.all(np_array >= 0):\n                                     assign_str = _numpy_array_to_string(np_array, indent=4)\n                                else: \n                                     assign_str = f\"utils.norm_dist({_numpy_array_to_string(np_array, indent=4)})\"\n                                self.script_parts[\"matrix_definitions\"].append(f\"D[{f_idx}] = {assign_str}\")\n                            else:\n                                self._add_log(f\"{context_msg}: Shape mismatch for single factor D. Expected {expected_shape}, got {np_array.shape}. Using default uniform.\", \"ERROR\")\n                        except Exception as e:\n                            self._add_log(f\"{context_msg}: Error processing parsed array data for single factor D: {e}. Using default uniform.\", \"ERROR\")\n                    else:\n                         self._add_log(f\"{context_msg}: Failed to parse array data string for single factor D. Using default uniform D[{f_idx}].\", \"INFO\")\n                elif rule:\n                    self._add_log(f\"{context_msg}: Rule '{rule}' for D (single factor) not implemented. Using default uniform D[{f_idx}].\", \"WARNING\")\n                else:\n                    self._add_log(f\"{context_msg}: No 'array' or 'rule' for D (single factor). Using default uniform D[{f_idx}].\", \"INFO\")\n            else: # This 'else' aligns with 'if isinstance(self.D_spec, list)' and 'elif isinstance(self.D_spec, dict)'\n                 self._add_log(\"D_vector: D_spec format not recognized. D factors will be default uniform.\", \"WARNING\")\n        else: # This 'else' aligns with 'if self.D_spec:'\n            self._add_log(\"D_vector: No D_spec. All factors of D defaulted to uniform.\", \"INFO\")\n            return \"# D vector factors remain default initialized (uniform).\"\n        \n        return \"# D vector construction based on GNN spec.\"\n\n    def convert_E_vector(self) -> str:\n        \"\"\"Converts GNN's E vector (prior preferences for policies) to PyMDP format.\"\"\"\n        # E is optional. It's a flat vector (num_policies) or not used if policy_len=1\n        if self.E_spec:\n            array_data = self.E_spec.get(\"array\")\n            if array_data:\n                try:\n                    np_array = np.array(array_data)\n                    # Shape depends on policy_len and num_control_states, complex to validate here without policy_len\n                    # For now, just generate the assignment\n                    self.script_parts[\"matrix_definitions\"].append(generate_pymdp_matrix_definition(\"E\", np_array))\n                    self._add_log(\"E_vector: Defined from GNN spec.\", \"INFO\")\n                except Exception as e:\n                    self._add_log(f\"E_vector: Error processing array data: {e}. 'E' will be None.\", \"ERROR\")\n                    self.script_parts[\"matrix_definitions\"].append(\"E = None\")\n            else:\n                self.script_parts[\"matrix_definitions\"].append(\"E = None\") # No array in E_spec\n        else:\n            self.script_parts[\"matrix_definitions\"].append(\"E = None\") # E is often None by default\n        return \"# E vector definition appended to script parts\"\n\n\n    def extract_agent_hyperparameters(self) -> Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]], Optional[Dict[str,Any]]]:\n        \"\"\"Extracts control, learning, and algorithm parameters from GNN spec for Agent.\"\"\"\n        # This method needs to be updated if GNN spec for these changes\n        self._add_log(\"AgentHyperparameters: Extracting learning and algorithm parameter dicts.\")\n        \n        # These are generic dictionaries for other parameters not explicitly handled by Agent constructor args\n        # control_params_dict = self.agent_hyperparams.get(\"control_parameters\", {}) # Potentially unused or for other control aspects\n        learning_params_dict = self.agent_hyperparams.get(\"learning_parameters\", {})\n        algorithm_params_dict = self.agent_hyperparams.get(\"algorithm_parameters\", {})\n        \n        # Return None for control_params_dict if it's not meant for direct Agent constructor args here.\n        # Or ensure it only contains parameters that pymdp.Agent would accept via **kwargs if that's supported.\n        # For now, assume it's not directly used for fixed Agent constructor args.\n        return None, learning_params_dict, algorithm_params_dict\n\n    def generate_agent_instantiation_code(self, action_names: Optional[Dict[int,List[str]]] = None, qs_initial: Optional[Any] = None) -> str: # Added args\n        model_matrix_params = {\"A\": \"A\", \"B\": \"B\", \"C\": \"C\"} # A and B are always included\n        \n        # Add D if there are factors, otherwise Agent handles D=None if not provided and factors exist\n        if self.num_factors > 0: \n            model_matrix_params[\"D\"] = \"D\"\n        \n        # E is added only if explicitly provided and non-empty in the spec\n        if self.E_spec and self.E_spec.get(\"array\") is not None and len(self.E_spec.get(\"array\")) > 0 :\n             model_matrix_params[\"E\"] = \"E\"\n\n        _unused_control_dict, learning_params, algorithm_params = self.extract_agent_hyperparameters()\n        \n        policy_len = self.agent_hyperparams.get(\"policy_len\")\n        control_fac_idx_to_pass = self.control_factor_indices if self.control_factor_indices else None\n        \n        use_utility = self.agent_hyperparams.get(\"use_utility\")\n        use_states_info_gain = self.agent_hyperparams.get(\"use_states_info_gain\")\n        use_param_info_gain = self.agent_hyperparams.get(\"use_param_info_gain\")\n        action_selection = self.agent_hyperparams.get(\"action_selection\")\n\n        # qs_initial can be a string like \"np.array(...)\" or None (if not specified)\n        # The generate_pymdp_agent_instantiation function handles this.\n        # If qs_initial is actual data (list of arrays), it should be formatted by the caller or handled in generate_...\n        # For now, assume if qs_initial (the variable) is passed, it's a string name of a var or direct data.\n\n        return generate_pymdp_agent_instantiation(\n            self.model_name, \n            model_params=model_matrix_params,\n            control_fac_idx_list=control_fac_idx_to_pass,\n            policy_len=policy_len,\n            use_utility=use_utility,\n            use_states_info_gain=use_states_info_gain,\n            use_param_info_gain=use_param_info_gain,\n            action_selection=action_selection,\n            action_names=action_names, # Pass parsed action_names\n            qs_initial=qs_initial,     # Pass parsed qs_initial\n            learning_params=learning_params,\n            algorithm_params=algorithm_params\n        )\n\n    def generate_example_usage_code(self) -> List[str]:\n        \"\"\"Generates a runnable example usage block based on the GNN spec and user's example.\"\"\"\n        usage_lines = [\"\", \"# --- Example Usage ---\", \"if __name__ == '__main__':\"]\n        indent = \"    \"\n\n        sim_T = self.simulation_params.get(\"timesteps\", 5)\n        init_o_raw = self.simulation_params.get(\"initial_observations\")\n        init_s_raw = self.simulation_params.get(\"initial_true_states\")\n        use_gp_copy = self.simulation_params.get(\"use_generative_process_copy\", True)\n\n        print_obs = self.simulation_params.get(\"print_observations\", True)\n        print_beliefs = self.simulation_params.get(\"print_belief_states\", True)\n        print_actions = self.simulation_params.get(\"print_actions\", True)\n        print_states = self.simulation_params.get(\"print_true_states\", True)\n        \n        usage_lines.append(f\"{indent}# Initialize agent (already done above)\")\n        usage_lines.append(f\"{indent}agent = {self.model_name}\")\n        usage_lines.append(f\"{indent}print(f\\\"Agent '{self.model_name}' initialized with {{agent.num_factors if hasattr(agent, 'num_factors') else 'N/A'}} factors and {{agent.num_modalities if hasattr(agent, 'num_modalities') else 'N/A'}} modalities.\\\")\")\n\n        # Initial observation\n        if init_o_raw and isinstance(init_o_raw, list) and len(init_o_raw) == self.num_modalities:\n            usage_lines.append(f\"{indent}o_current = {init_o_raw} # Initial observation from GNN spec\")\n        else: # Default initial observation (e.g., first outcome for each modality or a placeholder)\n            default_o = [0] * self.num_modalities if self.num_modalities > 0 else []\n            usage_lines.append(f\"{indent}o_current = {default_o} # Example initial observation (e.g. first outcome for each modality)\")\n            if not init_o_raw and self.num_modalities > 0 : self._add_log(\"Simulation: No 'initial_observations' in GNN, using default.\", \"INFO\")\n        \n        # Initial true state (for simulation purposes, not agent's belief D)\n        if init_s_raw and isinstance(init_s_raw, list) and len(init_s_raw) == self.num_factors:\n             usage_lines.append(f\"{indent}s_current = {init_s_raw} # Initial true states from GNN spec\")\n        else:\n            default_s = [0] * self.num_factors if self.num_factors > 0 else [] # Example: first state for each factor\n            usage_lines.append(f\"{indent}s_current = {default_s} # Example initial true states for simulation\")\n            if not init_s_raw and self.num_factors > 0: self._add_log(\"Simulation: No 'initial_true_states' in GNN, using default.\", \"INFO\")\n\n        usage_lines.append(f\"{indent}T = {sim_T} # Number of timesteps\")\n\n        if use_gp_copy:\n            usage_lines.append(f\"{indent}A_gen_process = copy.deepcopy(A)\")\n            usage_lines.append(f\"{indent}B_gen_process = copy.deepcopy(B)\")\n        else:\n            usage_lines.append(f\"{indent}A_gen_process = A\")\n            usage_lines.append(f\"{indent}B_gen_process = B\")\n        \n        usage_lines.append(\"\")\n        usage_lines.append(f\"{indent}for t_step in range(T):\")\n        inner_indent = indent * 2\n\n        if print_obs:\n            usage_lines.append(f\"{inner_indent}print(f\\\"\\\\n--- Timestep {{t_step + 1}} ---\\\")\")\n            usage_lines.append(f\"{inner_indent}if o_current is not None:\")\n            usage_lines.append(f\"{inner_indent}{indent}for g_idx, o_val in enumerate(o_current):\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}print(f\\\"Observation ({{obs_names[g_idx] if obs_names else f'Modality {{g_idx}}'}}): {{o_val}}\\\")\")\n        \n        usage_lines.append(f\"{inner_indent}# Infer states\")\n        usage_lines.append(f\"{inner_indent}qs_current = agent.infer_states(o_current)\")\n        if print_beliefs:\n            usage_lines.append(f\"{inner_indent}if qs_current is not None:\")\n            usage_lines.append(f\"{inner_indent}{indent}for f_idx, q_val in enumerate(qs_current):\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}print(f\\\"Beliefs about {{state_names[f_idx] if state_names else f'Factor {{f_idx}}'}}: {{q_val}}\\\")\")\n\n        usage_lines.append(\"\")\n        usage_lines.append(f\"{inner_indent}# Infer policies and sample action\")\n        usage_lines.append(f\"{inner_indent}q_pi_current, efe_current = agent.infer_policies()\")\n        usage_lines.append(f\"{inner_indent}if hasattr(agent, 'q_pi') and agent.q_pi is not None:\") # Check if q_pi is available\n        usage_lines.append(f\"{inner_indent}{indent}print(f\\\"Posterior over policies (q_pi): {{agent.q_pi}}\\\")\")\n        usage_lines.append(f\"{inner_indent}if efe_current is not None:\")\n        usage_lines.append(f\"{inner_indent}{indent}print(f\\\"Expected Free Energy (EFE): {{efe_current}}\\\")\")\n        usage_lines.append(f\"{inner_indent}action_agent = agent.sample_action()\")\n        \n        # Map agent action (control_factor list) to environment action (all factors list)\n        usage_lines.append(f\"{inner_indent}# Map agent's action (on control factors) to full environment action vector\")\n        usage_lines.append(f\"{inner_indent}action_env = np.zeros(num_factors, dtype=int)\")\n        usage_lines.append(f\"{inner_indent}if control_fac_idx and action_agent is not None:\")\n        usage_lines.append(f\"{inner_indent}{indent}for i, cf_idx in enumerate(control_fac_idx):\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}action_env[cf_idx] = int(action_agent[i])\")\n\n\n        if print_actions:\n            usage_lines.append(f\"{inner_indent}# Construct action names for printing\")\n            usage_lines.append(f\"{inner_indent}action_names_str_list = []\")\n            usage_lines.append(f\"{inner_indent}if control_fac_idx and action_agent is not None:\")\n            usage_lines.append(f\"{inner_indent}{indent}for i, cf_idx in enumerate(control_fac_idx):\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}factor_action_name_list = agent.action_names.get(cf_idx, []) if hasattr(agent, 'action_names') and isinstance(agent.action_names, dict) else []\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}action_idx_on_factor = int(action_agent[i])\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}if factor_action_name_list and action_idx_on_factor < len(factor_action_name_list):\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}{indent}action_names_str_list.append(f\\\"{{state_names[cf_idx] if state_names else f'Factor {{cf_idx}}'}}: {{factor_action_name_list[action_idx_on_factor]}} (idx {{action_idx_on_factor}})\\\")\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}else:\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}{indent}action_names_str_list.append(f\\\"{{state_names[cf_idx] if state_names else f'Factor {{cf_idx}}'}}: Action idx {{action_idx_on_factor}}\\\")\")\n            usage_lines.append(f\"{inner_indent}print(f\\\"Action taken: {{', '.join(action_names_str_list) if action_names_str_list else 'No controllable actions or names not found'}}\\\")\")\n            usage_lines.append(f\"{inner_indent}# Raw sampled action_agent: {{action_agent}}\")\n            usage_lines.append(f\"{inner_indent}# Mapped action_env for B matrix: {{action_env}}\")\n\n        usage_lines.append(\"\")\n        usage_lines.append(f\"{inner_indent}# Update true states of the environment based on action\")\n        usage_lines.append(f\"{inner_indent}s_next = np.zeros(num_factors, dtype=int)\")\n        usage_lines.append(f\"{inner_indent}if s_current is not None and B_gen_process is not None:\")\n        usage_lines.append(f\"{inner_indent}{indent}for f_idx in range(num_factors):\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}# B_gen_process[f_idx] shape: (num_states[f_idx], num_states[f_idx], num_actions_for_this_factor_or_1)\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}action_for_factor = action_env[f_idx] if f_idx in control_fac_idx else 0\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}s_next[f_idx] = utils.sample(B_gen_process[f_idx][:, s_current[f_idx], action_for_factor])\")\n        usage_lines.append(f\"{inner_indent}s_current = s_next.tolist()\")\n\n        if print_states:\n            usage_lines.append(f\"{inner_indent}if s_current is not None:\")\n            usage_lines.append(f\"{inner_indent}{indent}for f_idx, s_val in enumerate(s_current):\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}print(f\\\"New true state ({{state_names[f_idx] if state_names else f'Factor {{f_idx}}'}}): {{s_val}}\\\")\")\n\n\n        usage_lines.append(\"\")\n        usage_lines.append(f\"{inner_indent}# Generate next observation based on new true states\")\n        usage_lines.append(f\"{inner_indent}o_next = np.zeros(num_modalities, dtype=int)\")\n        usage_lines.append(f\"{inner_indent}if s_current is not None and A_gen_process is not None:\")\n        usage_lines.append(f\"{inner_indent}{indent}for g_idx in range(num_modalities):\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}# A_gen_process[g_idx] shape: (num_obs[g_idx], num_states[0], num_states[1], ...)\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}# Construct index for A matrix: (outcome_idx, s_f0, s_f1, ...)\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}prob_vector = A_gen_process[g_idx][:, \" + \", \".join([f\"s_current[{sf_i}]\" for sf_i in range(self.num_factors)]) + \"]\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}o_next[g_idx] = utils.sample(prob_vector)\")\n        usage_lines.append(f\"{inner_indent}o_current = o_next.tolist()\")\n        \n        usage_lines.append(\"\")\n        usage_lines.append(f\"{indent}print(f\\\"\\\\nSimulation finished after {{T}} timesteps.\\\")\")\n\n        return usage_lines\n\n\n    def get_full_python_script(self, include_example_usage: bool = True) -> str:\n        \"\"\"Assembles all parts into a single Python script string.\"\"\"\n        \n        # Pre-computation / matrix generation calls\n        self.convert_A_matrix()\n        self.convert_B_matrix()\n        self.convert_C_vector()\n        self.convert_D_vector()\n        self.convert_E_vector()\n\n        # Agent instantiation\n        self.script_parts[\"agent_instantiation\"].append(self.generate_agent_instantiation_code())\n        \n        if include_example_usage:\n            self.script_parts[\"example_usage\"] = self.generate_example_usage_code()\n        else:\n            self.script_parts[\"example_usage\"] = [\"# Example usage block skipped as per options.\"]\n\n        script_content = []\n        script_content.extend(self.script_parts[\"imports\"])\n        script_content.append(\"\")\n        \n        summary_header = [\"# --- GNN to PyMDP Conversion Summary ---\"]\n        summary_lines = [f\"# {log_entry}\" for log_entry in self.conversion_log]\n        summary_footer = [\"# --- End of GNN to PyMDP Conversion Summary ---\"]\n        script_content.extend(summary_header)\n        script_content.extend(summary_lines)\n        script_content.extend(summary_footer)\n        script_content.append(\"\")\n        script_content.append(\"\")\n\n        script_content.extend(self.script_parts[\"comments\"])\n        script_content.append(\"\")\n\n        script_content.extend(self.script_parts[\"preamble_vars\"])\n        script_content.append(\"\")\n\n        script_content.append(\"# --- Matrix Definitions ---\")\n        script_content.extend(self.script_parts[\"matrix_definitions\"])\n        script_content.append(\"\")\n        \n        script_content.append(\"# --- Agent Instantiation ---\")\n        script_content.extend(self.script_parts[\"agent_instantiation\"])\n        script_content.append(\"\")\n\n        # Define agent_params_for_debug dictionary for the debug block\n        # It should capture the actual arguments intended for the Agent constructor\n        agent_params_lines = [\"agent_params_for_debug = {\"]\n        # Collect args from how generate_agent_instantiation_code structures them\n        # Based on model_matrix_params and other specific args in generate_agent_instantiation_code:\n        agent_params_lines.append(\"    'A': A if 'A' in globals() else None,\")\n        agent_params_lines.append(\"    'B': B if 'B' in globals() else None,\")\n        agent_params_lines.append(\"    'C': C if 'C' in globals() else None,\")\n        if self.num_factors > 0: # D is only passed if there are factors\n             agent_params_lines.append(\"    'D': D if 'D' in globals() else None,\")\n        if self.E_spec and self.E_spec.get(\"array\") is not None:\n             agent_params_lines.append(\"    'E': E if 'E' in globals() else None,\")\n\n        # Add other specific Agent constructor parameters that generate_agent_instantiation_code handles\n        # These should ideally be sourced from the same place generate_agent_instantiation_code gets them (self.agent_hyperparams)\n        # or directly from the variables defined in the preamble.\n        agent_params_lines.append(\"    'control_fac_idx': (control_fac_idx if control_fac_idx else None) if 'control_fac_idx' in globals() else None,\")\n        if self.agent_hyperparams.get(\"policy_len\") is not None:\n             agent_params_lines.append(f\"    'policy_len': {self.agent_hyperparams['policy_len']},\")\n        if self.agent_hyperparams.get(\"use_utility\") is not None:\n             agent_params_lines.append(f\"    'use_utility': {self.agent_hyperparams['use_utility']},\")\n        if self.agent_hyperparams.get(\"use_states_info_gain\") is not None:\n            agent_params_lines.append(f\"    'use_states_info_gain': {self.agent_hyperparams['use_states_info_gain']},\")\n        if self.agent_hyperparams.get(\"use_param_info_gain\") is not None:\n            agent_params_lines.append(f\"    'use_param_info_gain': {self.agent_hyperparams['use_param_info_gain']},\")\n        if self.agent_hyperparams.get(\"action_selection\") is not None:\n            agent_params_lines.append(f\"    'action_selection': '{self.agent_hyperparams['action_selection']}',\")\n        \n        # Learning and algorithm params are passed as dicts\n        _, learning_params_dict, algorithm_params_dict = self.extract_agent_hyperparameters()\n        if learning_params_dict:\n            agent_params_lines.append(f\"    'learning_params': {learning_params_dict},\")\n        if algorithm_params_dict:\n            agent_params_lines.append(f\"    'algorithm_params': {algorithm_params_dict},\")\n\n        if agent_params_lines[-1].endswith(','): # Remove trailing comma if any\n            agent_params_lines[-1] = agent_params_lines[-1][:-1]\n        agent_params_lines.append(\"}\")\n        script_content.extend(agent_params_lines)\n        script_content.append(\"\")\n\n        script_content.extend(self.script_parts[\"example_usage\"]) # This should come after agent_params_for_debug definition\n        \n        # Prepare string representations for the debug_block f-strings\n        # These are string versions of the GNN spec sections or derived values\n        # that the debug block intends to print.\n        \n        # Action names as passed to the agent\n        # self.action_names_per_control_factor is the dict like {factor_idx: [name1, name2]}\n        action_names_val = self.action_names_per_control_factor\n        action_names_dict_str = str(action_names_val) # Creates a string like \"{0: ['action_0', 'action_1']}\"\n\n        # qs_initial from agent_hyperparams\n        qs_initial_val = self.agent_hyperparams.get(\"qs_initial\")\n        qs_initial_str = str(qs_initial_val) # String representation, e.g., 'None' or list as string\n\n        # The full agent_hyperparams dictionary from the GNN spec\n        agent_hyperparams_dict_str = str(self.agent_hyperparams)\n\n        # Add runtime debug block\n        # The temp_agent instantiation should use agent_params_for_debug\n        debug_block = [\n            \"print('--- PyMDP Runtime Debug ---')\",\n            \"try:\",\n            \"    import pymdp\",\n            \"    try:\",\n            \"        print(f'AGENT_SCRIPT: Imported pymdp version: {pymdp.__version__}')\",\n            \"    except AttributeError:\",\n            \"        print('AGENT_SCRIPT: pymdp.__version__ attribute not found.')\",\n            \"    print(f'AGENT_SCRIPT: pymdp module location: {pymdp.__file__}')\",\n            \"    from pymdp.agent import Agent\",\n            \"    print(f'AGENT_SCRIPT: Imported Agent: {Agent}')\",\n            \"    print(f'AGENT_SCRIPT: Agent module location: {inspect.getfile(Agent)}')\",\n            \"    print('AGENT_SCRIPT: Checking for required variables in global scope:')\",\n            \"    # Check defined parameters for the main agent\",\n            \"    print(f\\\"  AGENT_SCRIPT: A = {{A if 'A' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f\\\"  AGENT_SCRIPT: B = {{B if 'B' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f\\\"  AGENT_SCRIPT: C = {{C if 'C' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f\\\"  AGENT_SCRIPT: D = {{D if 'D' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f\\\"  AGENT_SCRIPT: E = {{E if 'E' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f\\\"  AGENT_SCRIPT: control_fac_idx = {{control_fac_idx if 'control_fac_idx' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f'  AGENT_SCRIPT: action_names = {action_names_dict_str if action_names_dict_str != \\\"{{}}\\\" else \\\"Not Defined\\\"}')\",\n            \"    print(f'  AGENT_SCRIPT: qs_initial = {qs_initial_str if qs_initial_str != \\\"None\\\" else \\\"Not Defined\\\"}')\",\n            \"    print(f'  AGENT_SCRIPT: agent_hyperparams = {agent_hyperparams_dict_str}')\",\n            \"    print('AGENT_SCRIPT: Attempting to instantiate agent with defined parameters for debug...')\",\n            \"    # Filter out None hyperparams from agent_params_for_debug if it was originally None\",\n            \"    # The ** unpacking handles empty dicts correctly if agent_hyperparams_dict_str was \\\"{}\\\"\",\n            \"    debug_params_copy = {k: v for k, v in agent_params_for_debug.items() if not (isinstance(v, str) and v == 'None')}\",\n            \"    temp_agent = Agent(**debug_params_copy)\",\n            \"    print(f'AGENT_SCRIPT: Debug agent successfully instantiated: {temp_agent}')\",\n            \"except Exception as e_debug:\",\n            \"    print(f'AGENT_SCRIPT: Error during PyMDP runtime debug: {e_debug}')\", \n            \"    print(f\\\"AGENT_SCRIPT: Traceback:\\\\n{traceback.format_exc()}\\\")\", # Keep f\\\" for this multi-line\n            \"print('--- End PyMDP Runtime Debug ---')\",\n        ]\n        script_content.extend(debug_block)\n\n        script_content.append(f\"# --- GNN Model: {self.model_name} ---\\\\n\")\n\n        return \"\\n\".join(script_content)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "__init__",
        "type": "method",
        "start_line": 57,
        "end_line": 112,
        "code": "def __init__(self, gnn_spec: Dict[str, Any]):\n        self.gnn_spec = gnn_spec\n        raw_model_name = self.gnn_spec.get(\"name\", self.gnn_spec.get(\"ModelName\", \"pymdp_agent_model\"))\n        # Sanitize the model name to be a valid Python variable name\n        # Replace spaces and hyphens with underscores\n        temp_name = raw_model_name.replace(\" \", \"_\").replace(\"-\", \"_\")\n        # Remove other invalid characters (keep alphanumeric and underscores)\n        temp_name = re.sub(r'[^0-9a-zA-Z_]', '', temp_name)\n        # Ensure it doesn't start with a number\n        if temp_name and temp_name[0].isdigit():\n            temp_name = \"_\" + temp_name\n        # Ensure it's not empty, default if it becomes empty after sanitization\n        self.model_name = temp_name if temp_name else \"pymdp_agent_model\"\n        \n        self.script_parts: Dict[str, List[str]] = {\n            \"imports\": [\n                \"import numpy as np\",\n                \"from pymdp.agent import Agent\",\n                \"from pymdp import utils\", # Added\n                \"from pymdp import maths\", # Added, for softmax etc.\n                \"import copy\", # Added for A_gp, B_gp\n                \"import sys\", # for sys.modules\n                \"import inspect\", # for inspect.signature\n                \"import traceback\" # for traceback.format_exc()\n            ],\n            \"preamble_vars\": [], # For obs_names, state_names etc.\n            \"comments\": [f\"# --- GNN Model: {self.model_name} ---\"],\n            \"matrix_definitions\": [],\n            \"agent_instantiation\": [],\n            \"example_usage\": []\n        }\n        self.conversion_log: List[str] = [] # Log messages for summary\n\n        # Extracted and processed GNN data\n        self.obs_names: List[str] = []\n        self.state_names: List[str] = []\n        self.action_names_per_control_factor: Dict[int, List[str]] = {} # factor_idx -> list of action names\n\n        self.num_obs: List[int] = [] # num_outcomes per modality\n        self.num_states: List[int] = [] # num_states per factor\n        self.num_actions_per_control_factor: Dict[int, int] = {} # factor_idx -> num_actions\n\n        self.num_modalities: int = 0\n        self.num_factors: int = 0\n        self.control_factor_indices: List[int] = [] # List of hidden state factor indices that are controllable\n\n        self.A_spec: Optional[Union[Dict, List[Dict]]] = None # Can be complex structure\n        self.B_spec: Optional[Union[Dict, List[Dict]]] = None\n        self.C_spec: Optional[Union[Dict, List[Dict]]] = None\n        self.D_spec: Optional[Union[Dict, List[Dict]]] = None\n        self.E_spec: Optional[Dict] = None # For expected future utilities / policies\n\n        self.agent_hyperparams: Dict[str, Any] = {}\n        self.simulation_params: Dict[str, Any] = {}\n        \n        self._extract_gnn_data() # Populate the above fields",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "_add_log",
        "type": "method",
        "start_line": 115,
        "end_line": 134,
        "code": "def _add_log(self, message: str, level: str = \"INFO\"): \n        \"\"\"Adds a message to the internal conversion log and also logs it via the module logger.\"\"\"\n        level_upper = level.upper()\n        self.conversion_log.append(f\"{level_upper}: {message}\")\n        \n        log_level_map = {\n            \"DEBUG\": logging.DEBUG,\n            \"INFO\": logging.INFO,\n            \"WARNING\": logging.WARNING,\n            \"ERROR\": logging.ERROR,\n            \"CRITICAL\": logging.CRITICAL\n        }\n        actual_log_level = log_level_map.get(level_upper, logging.INFO)\n        \n        # For errors caught and logged, include exception info if it's a genuine error message\n        # This is a heuristic; specific calls might pass exc_info directly if appropriate\n        if actual_log_level >= logging.ERROR and sys.exc_info()[0] is not None:\n             logger.log(actual_log_level, message, exc_info=True)\n        else:\n             logger.log(actual_log_level, message)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "_parse_string_to_literal",
        "type": "method",
        "start_line": 136,
        "end_line": 166,
        "code": "def _parse_string_to_literal(self, data_str: Any, context_msg: str) -> Optional[Any]:\n        \"\"\"Attempts to parse a string representation of a Python literal (e.g., list, tuple, dict).\"\"\"\n        if not isinstance(data_str, str):\n            if data_str is None or isinstance(data_str, (list, dict, tuple, int, float, bool, np.ndarray)): # Added np.ndarray\n                 return data_str\n            # This log call will use the updated _add_log which also logs to the module logger\n            self._add_log(f\"{context_msg}: Expected string for ast.literal_eval or a known pre-parsed type (list, dict, tuple, int, float, bool, np.ndarray), but got {type(data_str)}. Value: \\'{str(data_str)[:100]}...\\'. Returning None as parsing is not applicable.\", \"ERROR\")\n            return None\n\n        if not data_str.strip():\n            self._add_log(f\"{context_msg}: Received empty string data. Cannot parse. Returning None.\", \"WARNING\")\n            return None\n        \n        # Add a check for potentially very large strings to avoid performance issues with ast.literal_eval\n        # This limit is arbitrary and can be adjusted.\n        MAX_STRING_LEN_FOR_AST_EVAL = 1_000_000 # 1MB of string data\n        if len(data_str) > MAX_STRING_LEN_FOR_AST_EVAL:\n            self._add_log(f\"{context_msg}: Input string data is very long (len: {len(data_str)} characters). Parsing with ast.literal_eval might be slow or consume significant memory. Consider optimizing GNN spec to provide parsed data directly if possible.\", \"WARNING\")\n\n        try:\n            return ast.literal_eval(data_str)\n        except (ValueError, SyntaxError, TypeError) as e:\n            # The _add_log method will now also log this to the standard logger with ERROR level\n            # and exc_info=True if an exception is active.\n            # No need to call logger.error(..., exc_info=True) directly here if _add_log handles it.\n            error_message_detail = f\"ast.literal_eval failed. String \\'{data_str[:100]}...\\'. {e}\"\n            if \"array(\" in data_str:\n                 self._add_log(f\"{context_msg}: {error_message_detail} Appears to contain 'array(...)'. This construct is not supported by ast.literal_eval. The GNN spec should provide lists/numbers directly or use a format that can be parsed to basic Python types.\", \"ERROR\")\n            else:\n                self._add_log(f\"{context_msg}: {error_message_detail}\", \"ERROR\")\n            return None",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "_extract_gnn_data",
        "type": "method",
        "start_line": 168,
        "end_line": 470,
        "code": "def _extract_gnn_data(self):\n        \"\"\"Parses the raw gnn_spec and populates structured attributes.\"\"\"\n        self._add_log(\"Starting GNN data extraction.\")\n        # Ensure ast is imported if not already at module level\n        import ast\n\n        # Prioritize top-level keys from gnn_spec (populated by the exporter)\n        direct_num_obs = self.gnn_spec.get(\"num_obs_modalities\")\n        direct_obs_names = self.gnn_spec.get(\"obs_modality_names\") # New potential key\n\n        direct_num_states = self.gnn_spec.get(\"num_hidden_states_factors\")\n        direct_state_names = self.gnn_spec.get(\"hidden_state_factor_names\") # New potential key\n\n        # Attempt to parse stringified lists for direct_num_obs\n        if isinstance(direct_num_obs, str) and direct_num_obs.startswith('[') and direct_num_obs.endswith(']'):\n            try:\n                parsed_val = ast.literal_eval(direct_num_obs)\n                if isinstance(parsed_val, list) and all(isinstance(n, int) for n in parsed_val):\n                    direct_num_obs = parsed_val\n                    self._add_log(f\"Successfully parsed stringified direct_num_obs: {direct_num_obs}\", \"DEBUG\")\n            except (ValueError, SyntaxError, TypeError):\n                self._add_log(f\"Failed to parse stringified direct_num_obs: {direct_num_obs}\", \"WARNING\")\n        \n        # Attempt to parse stringified lists for direct_num_states\n        if isinstance(direct_num_states, str) and direct_num_states.startswith('[') and direct_num_states.endswith(']'):\n            try:\n                parsed_val = ast.literal_eval(direct_num_states)\n                if isinstance(parsed_val, list) and all(isinstance(n, int) for n in parsed_val):\n                    direct_num_states = parsed_val\n                    self._add_log(f\"Successfully parsed stringified direct_num_states: {direct_num_states}\", \"DEBUG\")\n            except (ValueError, SyntaxError, TypeError):\n                self._add_log(f\"Failed to parse stringified direct_num_states: {direct_num_states}\", \"WARNING\")\n\n        direct_num_control_dims = self.gnn_spec.get(\"num_control_factors\") # This should be a list of action dimensions for each factor\n        direct_control_action_names = self.gnn_spec.get(\"control_action_names_per_factor\") # Dict: factor_idx -> list of names\n\n        ss_block = self.gnn_spec.get(\"StateSpaceBlock\", {})\n        model_params_spec = self.gnn_spec.get(\"ModelParameters\", {})\n\n        # Observation Modalities Dimensions & Names\n        processed_obs_directly = False\n        if isinstance(direct_num_obs, list) and all(isinstance(n, int) for n in direct_num_obs):\n            self.num_obs = direct_num_obs\n            self.num_modalities = len(self.num_obs)\n            self._add_log(f\"Observation dimensions (num_obs) derived directly from gnn_spec.num_obs_modalities: {self.num_obs}\", \"INFO\")\n            if isinstance(direct_obs_names, list) and len(direct_obs_names) == self.num_modalities:\n                self.obs_names = direct_obs_names\n                self._add_log(f\"Observation names derived directly from gnn_spec.obs_modality_names: {self.obs_names}\", \"INFO\")\n            else:\n                self.obs_names = [f\"modality_{i}\" for i in range(self.num_modalities)]\n                self._add_log(f\"Observation names generated as defaults (gnn_spec.obs_modality_names not found or mismatched).\", \"INFO\")\n            processed_obs_directly = True\n\n        if not processed_obs_directly:\n            num_obs_from_model_params = model_params_spec.get(\"num_obs_modalities\")\n            if isinstance(num_obs_from_model_params, list) and all(isinstance(n, int) for n in num_obs_from_model_params):\n                self.num_obs = num_obs_from_model_params\n                self.num_modalities = len(self.num_obs)\n                self._add_log(f\"Observation dimensions (num_obs) derived from ModelParameters: {self.num_obs}\", \"INFO\")\n                obs_modalities_spec = ss_block.get(\"ObservationModalities\", [])\n                if obs_modalities_spec and len(obs_modalities_spec) == self.num_modalities:\n                    self.obs_names = [mod.get(\"modality_name\", f\"modality_{i}\") for i, mod in enumerate(obs_modalities_spec)]\n                else:\n                    self.obs_names = [f\"modality_{i}\" for i in range(self.num_modalities)]\n            else:\n                obs_modalities_spec = ss_block.get(\"ObservationModalities\", [])\n                if not obs_modalities_spec:\n                    self._add_log(\"No 'ObservationModalities' in StateSpaceBlock and no 'num_obs_modalities' in ModelParameters or gnn_spec.\", \"WARNING\")\n                for i, mod_spec in enumerate(obs_modalities_spec):\n                    name = mod_spec.get(\"modality_name\", f\"modality_{i}\")\n                    num_outcomes = mod_spec.get(\"num_outcomes\")\n                    if num_outcomes is None:\n                        self._add_log(f\"Modality '{name}' missing 'num_outcomes'. Skipping.\", \"ERROR\")\n                        continue\n                    self.obs_names.append(name)\n                    self.num_obs.append(int(num_outcomes))\n                self.num_modalities = len(self.num_obs)\n\n        self.script_parts[\"preamble_vars\"].append(f\"obs_names = {self.obs_names if self.num_modalities > 0 else []}\")\n        self.script_parts[\"preamble_vars\"].append(f\"num_obs = {self.num_obs if self.num_modalities > 0 else []}\")\n        self.script_parts[\"preamble_vars\"].append(f\"num_modalities = {self.num_modalities}\")\n\n        # Hidden State Factors Dimensions & Names\n        processed_states_directly = False\n        if isinstance(direct_num_states, list) and all(isinstance(n, int) for n in direct_num_states):\n            self.num_states = direct_num_states\n            self.num_factors = len(self.num_states)\n            self._add_log(f\"Hidden state dimensions (num_states) derived directly from gnn_spec.num_hidden_states_factors: {self.num_states}\", \"INFO\")\n            if isinstance(direct_state_names, list) and len(direct_state_names) == self.num_factors:\n                self.state_names = direct_state_names\n                self._add_log(f\"Hidden state names derived directly from gnn_spec.hidden_state_factor_names: {self.state_names}\", \"INFO\")\n            else:\n                self.state_names = [f\"factor_{i}\" for i in range(self.num_factors)]\n                self._add_log(f\"Hidden state names generated as defaults (gnn_spec.hidden_state_factor_names not found or mismatched).\", \"INFO\")\n            processed_states_directly = True\n\n        if not processed_states_directly:\n            num_states_from_model_params = model_params_spec.get(\"num_hidden_states_factors\")\n            if isinstance(num_states_from_model_params, list) and all(isinstance(n, int) for n in num_states_from_model_params):\n                self.num_states = num_states_from_model_params\n                self.num_factors = len(self.num_states)\n                self._add_log(f\"Hidden state dimensions (num_states) derived from ModelParameters: {self.num_states}\", \"INFO\")\n                hidden_factors_spec_mp_fallback = ss_block.get(\"HiddenStateFactors\", [])\n                if hidden_factors_spec_mp_fallback and len(hidden_factors_spec_mp_fallback) == self.num_factors:\n                    self.state_names = [fac.get(\"factor_name\", f\"factor_{i}\") for i, fac in enumerate(hidden_factors_spec_mp_fallback)]\n                else:\n                    self.state_names = [f\"factor_{i}\" for i in range(self.num_factors)]\n            else:\n                hidden_factors_spec = ss_block.get(\"HiddenStateFactors\", [])\n                if not hidden_factors_spec:\n                    self._add_log(\"No 'HiddenStateFactors' in StateSpaceBlock and no 'num_hidden_states_factors' in ModelParameters or gnn_spec.\", \"WARNING\")\n                for i, fac_spec in enumerate(hidden_factors_spec):\n                    name = fac_spec.get(\"factor_name\", f\"factor_{i}\")\n                    num_states_val = fac_spec.get(\"num_states\")\n                    if num_states_val is None:\n                        self._add_log(f\"Factor '{name}' missing 'num_states'. Skipping.\", \"ERROR\")\n                        continue\n                    self.state_names.append(name)\n                    self.num_states.append(int(num_states_val))\n                self.num_factors = len(self.num_states)\n            \n        # Controllable factors and actions - try direct gnn_spec keys first\n        processed_control_directly = False\n        if isinstance(direct_num_control_dims, list) and self.num_factors > 0 and len(direct_num_control_dims) == self.num_factors:\n            self._add_log(f\"Control dimensions derived directly from gnn_spec.num_control_factors: {direct_num_control_dims}\", \"INFO\")\n            for f_idx, num_actions_for_factor_val in enumerate(direct_num_control_dims):\n                num_actions_for_factor = int(num_actions_for_factor_val)\n                if num_actions_for_factor > 1: # Assumes >1 action means controllable\n                    self.control_factor_indices.append(f_idx)\n                    self.num_actions_per_control_factor[f_idx] = num_actions_for_factor\n                    # Get action names if provided directly\n                    if isinstance(direct_control_action_names, dict) and f_idx in direct_control_action_names and \\\n                       isinstance(direct_control_action_names[f_idx], list) and len(direct_control_action_names[f_idx]) == num_actions_for_factor:\n                        self.action_names_per_control_factor[f_idx] = direct_control_action_names[f_idx]\n                        self._add_log(f\"Action names for control factor {f_idx} derived directly from gnn_spec.control_action_names_per_factor.\", \"INFO\")\n                    else:\n                        factor_name_for_action = self.state_names[f_idx] if f_idx < len(self.state_names) else f\"factor_{f_idx}\"\n                        self.action_names_per_control_factor[f_idx] = [f\"{factor_name_for_action}_action_{j}\" for j in range(num_actions_for_factor)]\n            processed_control_directly = True\n\n        if not processed_control_directly:\n            num_control_factors_dims_mp = model_params_spec.get(\"num_control_factors\", model_params_spec.get(\"num_control_action_dims\"))\n            if isinstance(num_control_factors_dims_mp, list) and self.num_factors > 0 and len(num_control_factors_dims_mp) == self.num_factors:\n                self._add_log(f\"Control dimensions derived from ModelParameters.num_control_factors/dims: {num_control_factors_dims_mp}\", \"INFO\")\n                for f_idx, num_actions_for_factor_val in enumerate(num_control_factors_dims_mp):\n                    num_actions_for_factor = int(num_actions_for_factor_val)\n                    if num_actions_for_factor > 1:\n                        self.control_factor_indices.append(f_idx)\n                        self.num_actions_per_control_factor[f_idx] = num_actions_for_factor\n                        hsf_block = ss_block.get(\"HiddenStateFactors\", [])\n                        factor_name_for_action = self.state_names[f_idx] if f_idx < len(self.state_names) else f\"factor_{f_idx}\"\n                        action_names_from_hsf = None\n                        if f_idx < len(hsf_block) and hsf_block[f_idx].get(\"factor_name\") == factor_name_for_action:\n                            action_names_from_hsf = hsf_block[f_idx].get(\"action_names\")\n                        \n                        if action_names_from_hsf and len(action_names_from_hsf) == num_actions_for_factor:\n                           self.action_names_per_control_factor[f_idx] = action_names_from_hsf\n                        else:\n                           self.action_names_per_control_factor[f_idx] = [f\"{factor_name_for_action}_action_{j}\" for j in range(num_actions_for_factor)]\n            else:\n                hidden_factors_spec_ctrl = ss_block.get(\"HiddenStateFactors\", [])\n                if self.num_factors > 0 and len(hidden_factors_spec_ctrl) == self.num_factors:\n                    for i, fac_spec in enumerate(hidden_factors_spec_ctrl):\n                        if fac_spec.get(\"controllable\", False):\n                            self.control_factor_indices.append(i)\n                            num_actions = fac_spec.get(\"num_actions\")\n                            factor_name_for_action = self.state_names[i] if i < len(self.state_names) else f\"factor_{i}\"\n                            if num_actions is None:\n                                self._add_log(f\"Controllable factor '{factor_name_for_action}' missing 'num_actions'. Defaulting to num_states ({self.num_states[i]}).\", \"WARNING\")\n                                num_actions = int(self.num_states[i])\n                            self.num_actions_per_control_factor[i] = int(num_actions)\n                            action_names = fac_spec.get(\"action_names\")\n                            if action_names and len(action_names) == num_actions:\n                                self.action_names_per_control_factor[i] = action_names\n                            else:\n                                self.action_names_per_control_factor[i] = [f\"{factor_name_for_action}_action_{j}\" for j in range(num_actions)]\n                else:\n                     self._add_log(f\"Could not definitively determine control structure from gnn_spec, ModelParameters or StateSpaceBlock. control_fac_idx might be empty.\", \"WARNING\")\n\n        self.script_parts[\"preamble_vars\"].append(f\"state_names = {self.state_names if self.num_factors > 0 else []}\")\n        self.script_parts[\"preamble_vars\"].append(f\"num_states = {self.num_states if self.num_factors > 0 else []}\")\n        self.script_parts[\"preamble_vars\"].append(f\"num_factors = {self.num_factors}\")\n        self.script_parts[\"preamble_vars\"].append(f\"control_fac_idx = {self.control_factor_indices if self.control_factor_indices else []}\")\n\n        num_controls_list = []\n        if self.num_factors > 0:\n            for f_idx in range(self.num_factors):\n                if f_idx in self.control_factor_indices:\n                    # Default to num_states for that factor if num_actions not specified\n                    num_actions_for_factor = self.num_actions_per_control_factor.get(f_idx, self.num_states[f_idx])\n                    num_controls_list.append(num_actions_for_factor)\n                else:\n                    num_controls_list.append(1) # PyMDP convention for uncontrollable factors\n        self.script_parts[\"preamble_vars\"].append(f\"num_controls = {num_controls_list}\")\n        \n        # InitialParameterization (or specific matrix blocks)\n        # This needs to be adapted based on how the GNN spec is structured for matrices.\n        # Assuming a structure like: gnn_spec.get(\"LikelihoodMatrixA\", {})\n        param_block = self.gnn_spec.get(\"InitialParameterization\", self.gnn_spec.get(\"MatrixParameters\", {})) # Backward compatibility\n        \n        # A_spec (Likelihoods)\n        a_matrix_generic_spec = param_block.get(\"A_Matrix\", param_block.get(\"A\"))\n        if a_matrix_generic_spec:\n            self.A_spec = a_matrix_generic_spec\n            self._add_log(\"A_spec: Loaded from generic 'A_Matrix' or 'A' key.\", \"DEBUG\")\n        else:\n            temp_A_list = []\n            found_A_m_keys = False\n            for mod_idx in range(self.num_modalities):\n                mod_a_data = param_block.get(f\"A_m{mod_idx}\")\n                if mod_a_data is not None:\n                    temp_A_list.append({\"array\": mod_a_data}) # Wrap data in dict\n                    found_A_m_keys = True\n                else:\n                    # If a specific A_m<idx> is missing, but others might exist,\n                    # we add a None placeholder. convert_A_matrix should handle it\n                    # (e.g. by defaulting that modality or logging an error).\n                    temp_A_list.append(None) \n            if found_A_m_keys:\n                self.A_spec = temp_A_list\n                self._add_log(f\"A_spec: Constructed from individual 'A_m<idx>' keys. Found specs: {[s is not None for s in temp_A_list]}\", \"DEBUG\")\n            else:\n                self.A_spec = None # No generic A_Matrix and no A_m<idx> keys found\n                self._add_log(\"A_spec: No 'A_Matrix' or 'A_m<idx>' keys found in InitialParameterization.\", \"INFO\")\n\n        # B_spec (Transitions)\n        b_matrix_generic_spec = param_block.get(\"B_Matrix\", param_block.get(\"B\"))\n        if b_matrix_generic_spec:\n            self.B_spec = b_matrix_generic_spec\n            self._add_log(\"B_spec: Loaded from generic 'B_Matrix' or 'B' key.\", \"DEBUG\")\n        else:\n            temp_B_list = []\n            found_B_f_keys = False\n            for f_idx in range(self.num_factors):\n                fac_b_data = param_block.get(f\"B_f{f_idx}\")\n                if fac_b_data is not None:\n                    temp_B_list.append({\"array\": fac_b_data})\n                    found_B_f_keys = True\n                else:\n                    temp_B_list.append(None)\n            if found_B_f_keys:\n                self.B_spec = temp_B_list\n                self._add_log(f\"B_spec: Constructed from individual 'B_f<idx>' keys. Found specs: {[s is not None for s in temp_B_list]}\", \"DEBUG\")\n            else:\n                self.B_spec = None\n                self._add_log(\"B_spec: No 'B_Matrix' or 'B_f<idx>' keys found in InitialParameterization.\", \"INFO\")\n\n        # C_spec (Preferences over outcomes)\n        c_vector_generic_spec = param_block.get(\"C_Vector\", param_block.get(\"C\"))\n        if c_vector_generic_spec:\n            self.C_spec = c_vector_generic_spec\n            self._add_log(\"C_spec: Loaded from generic 'C_Vector' or 'C' key.\", \"DEBUG\")\n        else:\n            temp_C_list = []\n            found_C_m_keys = False\n            for mod_idx in range(self.num_modalities):\n                mod_c_data = param_block.get(f\"C_m{mod_idx}\")\n                if mod_c_data is not None:\n                    temp_C_list.append({\"array\": mod_c_data})\n                    found_C_m_keys = True\n                else:\n                    temp_C_list.append(None)\n            if found_C_m_keys:\n                self.C_spec = temp_C_list\n                self._add_log(f\"C_spec: Constructed from individual 'C_m<idx>' keys. Found specs: {[s is not None for s in temp_C_list]}\", \"DEBUG\")\n            else:\n                self.C_spec = None\n                self._add_log(\"C_spec: No 'C_Vector' or 'C_m<idx>' keys found in InitialParameterization.\", \"INFO\")\n\n        # D_spec (Initial hidden states)\n        d_vector_generic_spec = param_block.get(\"D_Vector\", param_block.get(\"D\"))\n        if d_vector_generic_spec:\n            self.D_spec = d_vector_generic_spec\n            self._add_log(\"D_spec: Loaded from generic 'D_Vector' or 'D' key.\", \"DEBUG\")\n        else:\n            temp_D_list = []\n            found_D_f_keys = False\n            for f_idx in range(self.num_factors):\n                fac_d_data = param_block.get(f\"D_f{f_idx}\")\n                if fac_d_data is not None:\n                    temp_D_list.append({\"array\": fac_d_data})\n                    found_D_f_keys = True\n                else:\n                    temp_D_list.append(None)\n            if found_D_f_keys:\n                self.D_spec = temp_D_list\n                self._add_log(f\"D_spec: Constructed from individual 'D_f<idx>' keys. Found specs: {[s is not None for s in temp_D_list]}\", \"DEBUG\")\n            else:\n                self.D_spec = None\n                self._add_log(\"D_spec: No 'D_Vector' or 'D_f<idx>' keys found in InitialParameterization.\", \"INFO\")\n        \n        # E_spec (Prior preferences over policies) - usually a single spec\n        self.E_spec = param_block.get(\"E_Vector\", param_block.get(\"E\"))\n        if self.E_spec:\n            self._add_log(\"E_spec: Loaded from 'E_Vector' or 'E' key.\", \"DEBUG\")\n        else:\n            self._add_log(\"E_spec: No 'E_Vector' or 'E' key found.\", \"INFO\")\n\n\n        self.agent_hyperparams = self.gnn_spec.get(\"AgentHyperparameters\", {})\n        self.simulation_params = self.gnn_spec.get(\"SimulationParameters\", {})\n\n        self._add_log(\"Finished GNN data extraction.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "_get_matrix_data",
        "type": "method",
        "start_line": 473,
        "end_line": 489,
        "code": "def _get_matrix_data(self, base_name: str, factor_idx: Optional[int] = None, modality_idx: Optional[int] = None) -> Any:\n        \"\"\"DEPRECATED: Use direct spec attributes like self.A_spec instead.\"\"\"\n        # This method is kept for now if old parts of convert_X_matrix still use it,\n        # but the goal is to use the structured self.A_spec, self.B_spec etc.\n        param_block = self.gnn_spec.get(\"InitialParameterization\", self.gnn_spec.get(\"MatrixParameters\", {}))\n\n        if factor_idx is not None:\n            matrix_key = f\"{base_name}_f{factor_idx}\"\n        elif modality_idx is not None:\n            matrix_key = f\"{base_name}_m{modality_idx}\"\n        else:\n            matrix_key = base_name\n        \n        data = param_block.get(matrix_key)\n        if data is None:\n            self._add_log(f\"Matrix {matrix_key} not found in GNN InitialParameterization/MatrixParameters.\", \"WARNING\")\n        return data",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "convert_A_matrix",
        "type": "method",
        "start_line": 491,
        "end_line": 572,
        "code": "def convert_A_matrix(self) -> str:\n        \"\"\"Converts GNN's A matrix (likelihood) to PyMDP format.\"\"\"\n        if not self.num_modalities:\n            self._add_log(\"A_matrix: No observation modalities defined. 'A' will be None.\", \"INFO\")\n            self.script_parts[\"matrix_definitions\"].append(\"A = None\")\n            return \"# A matrix set to None due to no observation modalities.\"\n\n        if not self.num_factors: # A multi-factor likelihood depends on states\n            self._add_log(\"A_matrix: No hidden state factors defined. Cannot form A. 'A' will be None.\", \"INFO\")\n            self.script_parts[\"matrix_definitions\"].append(\"A = None\")\n            return \"# A matrix set to None due to no hidden state factors.\"\n\n        init_code = f\"A = utils.obj_array({self.num_modalities})\"\n        self.script_parts[\"matrix_definitions\"].append(init_code)\n\n        # Default to uniform if no A_spec\n        for mod_idx in range(self.num_modalities):\n            shape_A_mod = tuple([self.num_obs[mod_idx]] + self.num_states)\n            self.script_parts[\"matrix_definitions\"].append(f\"A[{mod_idx}] = utils.norm_dist(np.ones({shape_A_mod})) # Defaulted to uniform\")\n\n        if self.A_spec:\n            if isinstance(self.A_spec, list): # List of specs per modality\n                for mod_idx, mod_a_spec in enumerate(self.A_spec):\n                    if mod_a_spec is None: # Modality spec might be missing\n                        self._add_log(f\"A_matrix (modality {mod_idx}): Spec is None. Using default uniform A[{mod_idx}].\", \"INFO\")\n                        continue\n\n                    array_data_input = mod_a_spec.get(\"array\")\n                    rule = mod_a_spec.get(\"rule\")\n                    context_msg = f\"A_matrix (modality {self.obs_names[mod_idx] if mod_idx < len(self.obs_names) else mod_idx})\"\n\n                    if array_data_input is not None:\n                        parsed_array_data = self._parse_string_to_literal(array_data_input, context_msg)\n                        if parsed_array_data is not None:\n                            try:\n                                np_array = np.array(parsed_array_data)\n                                expected_shape = tuple([self.num_obs[mod_idx]] + self.num_states)\n                                if np_array.shape == expected_shape:\n                                    assign_str = f\"utils.norm_dist({_numpy_array_to_string(np_array, indent=4)})\"\n                                    self.script_parts[\"matrix_definitions\"].append(f\"A[{mod_idx}] = {assign_str}\")\n                                else:\n                                    self._add_log(f\"{context_msg}: Shape mismatch. Expected {expected_shape}, got {np_array.shape}. Using default uniform A[{mod_idx}].\", \"ERROR\")\n                            except Exception as e:\n                                self._add_log(f\"{context_msg}: Error processing parsed array data to NumPy: {e}. Using default uniform A[{mod_idx}].\", \"ERROR\")\n                        else:\n                            self._add_log(f\"{context_msg}: Failed to parse array data string. Using default uniform A[{mod_idx}].\", \"INFO\")\n                    elif rule:\n                        self._add_log(f\"{context_msg}: Rule '{rule}' not fully implemented yet. Using default uniform A[{mod_idx}].\", \"WARNING\")\n                    else:\n                        self._add_log(f\"{context_msg}: No 'array' or 'rule' found. Using default uniform A[{mod_idx}].\", \"INFO\")\n            # Handling for A_spec as single dict if num_modalities == 1\n            elif isinstance(self.A_spec, dict) and self.num_modalities == 1:\n                mod_idx = 0\n                array_data_input = self.A_spec.get(\"array\")\n                rule = self.A_spec.get(\"rule\")\n                context_msg = f\"A_matrix (modality {mod_idx})\"\n                if array_data_input is not None:\n                    parsed_array_data = self._parse_string_to_literal(array_data_input, context_msg)\n                    if parsed_array_data is not None:\n                        try:\n                            np_array = np.array(parsed_array_data)\n                            expected_shape = tuple([self.num_obs[mod_idx]] + self.num_states)\n                            if np_array.shape == expected_shape:\n                                assign_str = f\"utils.norm_dist({_numpy_array_to_string(np_array, indent=4)})\"\n                                self.script_parts[\"matrix_definitions\"].append(f\"A[{mod_idx}] = {assign_str}\")\n                            else:\n                                self._add_log(f\"{context_msg}: Shape mismatch. Expected {expected_shape}, got {np_array.shape}. Using default uniform A[{mod_idx}].\", \"ERROR\")\n                        except Exception as e:\n                            self._add_log(f\"{context_msg}: Error processing parsed array data to NumPy: {e}. Using default uniform A[{mod_idx}].\", \"ERROR\")\n                    else:\n                        self._add_log(f\"{context_msg}: Failed to parse array data string. Using default uniform A[{mod_idx}].\", \"INFO\")\n                elif rule:\n                    self._add_log(f\"{context_msg}: Rule '{rule}' not fully implemented. Using default uniform A[{mod_idx}].\", \"WARNING\")\n                else:\n                    self._add_log(f\"{context_msg}: No 'array' or 'rule'. Using default uniform A[{mod_idx}].\", \"INFO\")\n            else:\n                self._add_log(\"A_matrix: A_spec format not recognized for multiple modalities. All A modalities will be default uniform.\", \"WARNING\")\n        else: # No A_spec\n            self._add_log(\"A_matrix: No A_spec provided in GNN. All modalities of A defaulted to uniform.\", \"INFO\")\n            return \"# A matrix modalities remain default initialized (uniform).\"\n        \n        return \"# A matrix construction based on GNN spec.\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "convert_B_matrix",
        "type": "method",
        "start_line": 575,
        "end_line": 682,
        "code": "def convert_B_matrix(self) -> str:\n        \"\"\"Converts GNN's B matrix (transition) to PyMDP format.\"\"\"\n        if not self.num_factors:\n            self._add_log(\"B_matrix: No hidden state factors defined. 'B' will be None.\", \"INFO\")\n            self.script_parts[\"matrix_definitions\"].append(\"B = None\")\n            return \"# B matrix set to None due to no hidden state factors.\"\n\n        init_code = f\"B = utils.obj_array(num_factors)\"\n        self.script_parts[\"matrix_definitions\"].append(init_code)\n\n        # Default initialization for all B slices first\n        for f_idx in range(self.num_factors):\n            num_states_f = self.num_states[f_idx]\n            log_msg_prefix_f = f\"B_matrix (factor {self.state_names[f_idx] if f_idx < len(self.state_names) else f_idx})\"\n            if f_idx in self.control_factor_indices:\n                num_actions_f = self.num_actions_per_control_factor.get(f_idx, num_states_f) # Default actions = num_states for that factor\n                # PyMDP default for controllable B: tile identity matrices for each action\n                self.script_parts[\"matrix_definitions\"].append(f\"B[{f_idx}] = np.tile(np.eye({num_states_f}), ({num_actions_f}, 1, 1)).transpose(1, 2, 0) # Default for controllable\")\n                self._add_log(f\"{log_msg_prefix_f}: Initialized with default structure for controllable factor (repeated identity matrices).\", \"DEBUG\")\n            else: # Uncontrolled\n                self.script_parts[\"matrix_definitions\"].append(f\"B[{f_idx}] = np.eye({num_states_f})[:, :, np.newaxis] # Default for uncontrolled (identity)\")\n                self._add_log(f\"{log_msg_prefix_f}: Initialized with default identity matrix for uncontrolled factor.\", \"DEBUG\")\n\n        if not self.B_spec:\n            self._add_log(\"B_matrix: No B_spec provided in GNN. B slices will use default initializations (identities).\", \"INFO\")\n            return \"# B matrix slices remain default initialized.\"\n\n        def get_b_assignment_string(spec_value_input, num_states_val, is_controlled_val, num_actions_val, factor_idx_for_log, indent_level=4) -> Optional[str]:\n            np_array = None\n            context_msg_b_assign = f\"B_matrix (factor {self.state_names[factor_idx_for_log] if factor_idx_for_log < len(self.state_names) else factor_idx_for_log}) internal assignment\"\n            \n            parsed_spec_value = self._parse_string_to_literal(spec_value_input, context_msg_b_assign)\n\n            if parsed_spec_value is None:\n                self._add_log(f\"{context_msg_b_assign}: Parsed spec value from string is None. Cannot create NumPy array.\", \"ERROR\")\n                return None\n            try:\n                np_array = np.array(parsed_spec_value)\n            except Exception as e:\n                self._add_log(f\"{context_msg_b_assign}: Error converting parsed data to NumPy array: {e}. Value was: '{str(parsed_spec_value)[:100]}...'\", \"ERROR\")\n                return None\n\n            expected_shape_controlled = (num_states_val, num_states_val, num_actions_val)\n            expected_shape_uncontrolled_2d = (num_states_val, num_states_val)\n            expected_shape_uncontrolled_3d = (num_states_val, num_states_val, 1)\n\n            assign_str_val = _numpy_array_to_string(np_array, indent=indent_level)\n\n            if is_controlled_val:\n                if np_array.shape == expected_shape_controlled:\n                    return f\"utils.norm_dist({assign_str_val})\"\n                else:\n                    self._add_log(f\"{context_msg_b_assign}: Shape mismatch for controlled factor. Expected {expected_shape_controlled}, got {np_array.shape}. Not assigning.\", \"ERROR\")\n                    return None\n            else: # Uncontrolled\n                if np_array.shape == expected_shape_uncontrolled_2d:\n                    return f\"utils.norm_dist({assign_str_val})[:, :, np.newaxis]\"\n                elif np_array.shape == expected_shape_uncontrolled_3d:\n                    return f\"utils.norm_dist({assign_str_val})\"\n                else:\n                    self._add_log(f\"{context_msg_b_assign}: Shape mismatch for uncontrolled factor. Expected {expected_shape_uncontrolled_2d} or {expected_shape_uncontrolled_3d}, got {np_array.shape}. Not assigning.\", \"ERROR\")\n                    return None\n        \n        if isinstance(self.B_spec, list):\n            for f_idx, fac_b_spec in enumerate(self.B_spec):\n                if fac_b_spec is None: \n                    self._add_log(f\"B_matrix (factor {f_idx}): Spec is None. Using default B[{f_idx}].\", \"INFO\")\n                    continue\n                \n                array_data_input = fac_b_spec.get(\"array\")\n                rule = fac_b_spec.get(\"rule\")\n                is_controlled = f_idx in self.control_factor_indices\n                num_actions = self.num_actions_per_control_factor.get(f_idx, 1) if is_controlled else 1\n                context_msg_b = f\"B_matrix (factor {self.state_names[f_idx] if f_idx < len(self.state_names) else f_idx})\"\n\n                if array_data_input is not None:\n                    assign_str = get_b_assignment_string(array_data_input, self.num_states[f_idx], is_controlled, num_actions, f_idx)\n                    if assign_str:\n                        self.script_parts[\"matrix_definitions\"].append(f\"B[{f_idx}] = {assign_str}\")\n                    else:\n                        self._add_log(f\"{context_msg_b}: Failed to get assignment string from array data. Using default B[{f_idx}].\", \"WARNING\")\n                elif rule:\n                    self._add_log(f\"{context_msg_b}: Rule '{rule}' for B not fully implemented. Using default B[{f_idx}].\", \"WARNING\")\n                else:\n                    self._add_log(f\"{context_msg_b}: No 'array' or 'rule' found. Using default B[{f_idx}].\", \"INFO\")\n\n        elif isinstance(self.B_spec, dict) and self.num_factors == 1:\n            f_idx = 0\n            array_data_input = self.B_spec.get(\"array\")\n            rule = self.B_spec.get(\"rule\")\n            is_controlled = f_idx in self.control_factor_indices\n            num_actions = self.num_actions_per_control_factor.get(f_idx, 1) if is_controlled else 1\n            context_msg_b = f\"B_matrix (factor {self.state_names[f_idx] if f_idx < len(self.state_names) else f_idx})\"\n\n            if array_data_input is not None:\n                assign_str = get_b_assignment_string(array_data_input, self.num_states[f_idx], is_controlled, num_actions, f_idx)\n                if assign_str:\n                    self.script_parts[\"matrix_definitions\"].append(f\"B[{f_idx}] = {assign_str}\")\n                else:\n                    self._add_log(f\"{context_msg_b}: Failed to get assignment string from array data for single factor. Using default B[{f_idx}].\", \"WARNING\")\n            elif rule:\n                self._add_log(f\"{context_msg_b}: Rule '{rule}' for B (single factor) not fully implemented. Using default B[{f_idx}].\", \"WARNING\")\n            else:\n                self._add_log(f\"{context_msg_b}: No 'array' or 'rule' for B (single factor). Using default B[{f_idx}].\", \"INFO\")\n        else:\n            self._add_log(\"B_matrix: B_spec format not recognized. B factors will be default initialized.\", \"WARNING\")\n            \n        return \"# B matrix construction based on GNN spec.\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "convert_C_vector",
        "type": "method",
        "start_line": 684,
        "end_line": 720,
        "code": "def convert_C_vector(self) -> str:\n        \"\"\"Converts GNN's C vector (preferences) to PyMDP format.\"\"\"\n        if not self.num_modalities:\n            self._add_log(\"C_vector: No observation modalities defined. 'C' will be None.\", \"INFO\") # C is optional\n            # Directly append the definition to script_parts\n            self.script_parts[\"matrix_definitions\"].append(generate_pymdp_matrix_definition(\"C\", None)) \n            return \"# C matrix set to None due to no observation modalities.\" # Return value is for logging/info\n\n        # Initialize C = utils.obj_array_zeros(num_obs)\n        init_code = f\"C = utils.obj_array_zeros(num_obs)\" # num_obs is list of outcome counts per modality\n        self.script_parts[\"matrix_definitions\"].append(init_code)\n\n        if self.C_spec:\n            if isinstance(self.C_spec, list): # List of specs per modality\n                for mod_idx, mod_c_spec in enumerate(self.C_spec):\n                    if mod_c_spec is None: continue # Allow sparse C definition\n                    \n                    array_data_input = mod_c_spec.get(\"array\") # Expects 1D array of length num_obs[mod_idx]\n                    if array_data_input:\n                        try:\n                            np_array = np.array(array_data_input)\n                            expected_shape = (self.num_obs[mod_idx],)\n                            if np_array.shape == expected_shape:\n                                self.script_parts[\"matrix_definitions\"].append(f\"C[{mod_idx}] = {_numpy_array_to_string(np_array, indent=4)}\")\n                            else:\n                                self._add_log(f\"C_vector (modality {mod_idx}): Shape mismatch. Expected {expected_shape}, got {np_array.shape}.\", \"ERROR\")\n                        except Exception as e:\n                             self._add_log(f\"C_vector (modality {mod_idx}): Error processing array data: {e}.\", \"ERROR\")\n                    else:\n                         self._add_log(f\"C_vector (modality {mod_idx}): No 'array' found in spec. C[{mod_idx}] will be zeros.\", \"INFO\")\n            # Add handling for C_spec as single dict if num_modalities == 1\n            else:\n                self._add_log(\"C_vector: C_spec format not recognized for detailed construction. C will be zeros.\", \"WARNING\")\n        else:\n            self._add_log(\"C_vector: No C_spec. C will be initialized to zeros by obj_array_zeros.\", \"INFO\")\n        \n        return \"# C vector definition appended to script parts\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "convert_D_vector",
        "type": "method",
        "start_line": 722,
        "end_line": 802,
        "code": "def convert_D_vector(self) -> str:\n        \"\"\"Converts GNN's D vector (initial beliefs about hidden states) to PyMDP format.\"\"\"\n        if not self.num_factors:\n            self._add_log(\"D_vector: No hidden state factors defined. 'D' will be None.\", \"INFO\")\n            self.script_parts[\"matrix_definitions\"].append(\"D = None\")\n            return \"# D vector set to None due to no hidden state factors.\"\n\n        init_code = f\"D = utils.obj_array({self.num_factors})\"\n        self.script_parts[\"matrix_definitions\"].append(init_code)\n        \n        # Default to uniform if no D_spec\n        for f_idx in range(self.num_factors):\n            self.script_parts[\"matrix_definitions\"].append(f\"D[{f_idx}] = utils.norm_dist(np.ones({self.num_states[f_idx]})) # Default: uniform D for factor {f_idx}\")\n\n        if self.D_spec:\n            if isinstance(self.D_spec, list): \n                for f_idx, fac_d_spec in enumerate(self.D_spec):\n                    if fac_d_spec is None: \n                        self._add_log(f\"D_vector (factor {f_idx}): Spec is None. Using default uniform D[{f_idx}].\", \"INFO\")\n                        continue\n\n                    array_data_input = fac_d_spec.get(\"array\")\n                    rule = fac_d_spec.get(\"rule\")\n                    context_msg = f\"D_vector (factor {self.state_names[f_idx] if f_idx < len(self.state_names) else f_idx})\"\n\n                    if array_data_input is not None:\n                        parsed_array_data = self._parse_string_to_literal(array_data_input, context_msg)\n                        if parsed_array_data is not None:\n                            try:\n                                np_array = np.array(parsed_array_data)\n                                expected_shape = (self.num_states[f_idx],)\n                                if np_array.shape == expected_shape:\n                                    if np.isclose(np.sum(np_array), 1.0) and np.all(np_array >= 0):\n                                         assign_str = _numpy_array_to_string(np_array, indent=4)\n                                    else: \n                                         assign_str = f\"utils.norm_dist({_numpy_array_to_string(np_array, indent=4)})\"\n                                    self.script_parts[\"matrix_definitions\"].append(f\"D[{f_idx}] = {assign_str}\")\n                                else:\n                                    self._add_log(f\"{context_msg}: Shape mismatch. Expected {expected_shape}, got {np_array.shape}. Using default uniform.\", \"ERROR\")\n                            except Exception as e:\n                                 self._add_log(f\"{context_msg}: Error processing parsed array data to NumPy: {e}. Using default uniform.\", \"ERROR\")\n                        else:\n                            self._add_log(f\"{context_msg}: Failed to parse array data string. Using default uniform D[{f_idx}].\", \"INFO\")\n                    elif rule:\n                        self._add_log(f\"{context_msg}: Rule '{rule}' for D not implemented. Using default uniform D[{f_idx}].\", \"WARNING\")\n                    else:\n                        self._add_log(f\"{context_msg}: No 'array' or 'rule' found. Using default uniform D[{f_idx}].\", \"INFO\")\n            elif isinstance(self.D_spec, dict) and self.num_factors == 1:\n                f_idx = 0\n                array_data_input = self.D_spec.get(\"array\")\n                rule = self.D_spec.get(\"rule\")\n                context_msg = f\"D_vector (factor {f_idx})\"\n                if array_data_input is not None:\n                    parsed_array_data = self._parse_string_to_literal(array_data_input, context_msg)\n                    if parsed_array_data is not None:\n                        try:\n                            np_array = np.array(parsed_array_data)\n                            expected_shape = (self.num_states[f_idx],)\n                            if np_array.shape == expected_shape:\n                                if np.isclose(np.sum(np_array), 1.0) and np.all(np_array >= 0):\n                                     assign_str = _numpy_array_to_string(np_array, indent=4)\n                                else: \n                                     assign_str = f\"utils.norm_dist({_numpy_array_to_string(np_array, indent=4)})\"\n                                self.script_parts[\"matrix_definitions\"].append(f\"D[{f_idx}] = {assign_str}\")\n                            else:\n                                self._add_log(f\"{context_msg}: Shape mismatch for single factor D. Expected {expected_shape}, got {np_array.shape}. Using default uniform.\", \"ERROR\")\n                        except Exception as e:\n                            self._add_log(f\"{context_msg}: Error processing parsed array data for single factor D: {e}. Using default uniform.\", \"ERROR\")\n                    else:\n                         self._add_log(f\"{context_msg}: Failed to parse array data string for single factor D. Using default uniform D[{f_idx}].\", \"INFO\")\n                elif rule:\n                    self._add_log(f\"{context_msg}: Rule '{rule}' for D (single factor) not implemented. Using default uniform D[{f_idx}].\", \"WARNING\")\n                else:\n                    self._add_log(f\"{context_msg}: No 'array' or 'rule' for D (single factor). Using default uniform D[{f_idx}].\", \"INFO\")\n            else: # This 'else' aligns with 'if isinstance(self.D_spec, list)' and 'elif isinstance(self.D_spec, dict)'\n                 self._add_log(\"D_vector: D_spec format not recognized. D factors will be default uniform.\", \"WARNING\")\n        else: # This 'else' aligns with 'if self.D_spec:'\n            self._add_log(\"D_vector: No D_spec. All factors of D defaulted to uniform.\", \"INFO\")\n            return \"# D vector factors remain default initialized (uniform).\"\n        \n        return \"# D vector construction based on GNN spec.\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "convert_E_vector",
        "type": "method",
        "start_line": 804,
        "end_line": 823,
        "code": "def convert_E_vector(self) -> str:\n        \"\"\"Converts GNN's E vector (prior preferences for policies) to PyMDP format.\"\"\"\n        # E is optional. It's a flat vector (num_policies) or not used if policy_len=1\n        if self.E_spec:\n            array_data = self.E_spec.get(\"array\")\n            if array_data:\n                try:\n                    np_array = np.array(array_data)\n                    # Shape depends on policy_len and num_control_states, complex to validate here without policy_len\n                    # For now, just generate the assignment\n                    self.script_parts[\"matrix_definitions\"].append(generate_pymdp_matrix_definition(\"E\", np_array))\n                    self._add_log(\"E_vector: Defined from GNN spec.\", \"INFO\")\n                except Exception as e:\n                    self._add_log(f\"E_vector: Error processing array data: {e}. 'E' will be None.\", \"ERROR\")\n                    self.script_parts[\"matrix_definitions\"].append(\"E = None\")\n            else:\n                self.script_parts[\"matrix_definitions\"].append(\"E = None\") # No array in E_spec\n        else:\n            self.script_parts[\"matrix_definitions\"].append(\"E = None\") # E is often None by default\n        return \"# E vector definition appended to script parts\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "extract_agent_hyperparameters",
        "type": "method",
        "start_line": 826,
        "end_line": 839,
        "code": "def extract_agent_hyperparameters(self) -> Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]], Optional[Dict[str,Any]]]:\n        \"\"\"Extracts control, learning, and algorithm parameters from GNN spec for Agent.\"\"\"\n        # This method needs to be updated if GNN spec for these changes\n        self._add_log(\"AgentHyperparameters: Extracting learning and algorithm parameter dicts.\")\n        \n        # These are generic dictionaries for other parameters not explicitly handled by Agent constructor args\n        # control_params_dict = self.agent_hyperparams.get(\"control_parameters\", {}) # Potentially unused or for other control aspects\n        learning_params_dict = self.agent_hyperparams.get(\"learning_parameters\", {})\n        algorithm_params_dict = self.agent_hyperparams.get(\"algorithm_parameters\", {})\n        \n        # Return None for control_params_dict if it's not meant for direct Agent constructor args here.\n        # Or ensure it only contains parameters that pymdp.Agent would accept via **kwargs if that's supported.\n        # For now, assume it's not directly used for fixed Agent constructor args.\n        return None, learning_params_dict, algorithm_params_dict",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "generate_agent_instantiation_code",
        "type": "method",
        "start_line": 841,
        "end_line": 880,
        "code": "def generate_agent_instantiation_code(self, action_names: Optional[Dict[int,List[str]]] = None, qs_initial: Optional[Any] = None) -> str: # Added args\n        model_matrix_params = {\"A\": \"A\", \"B\": \"B\", \"C\": \"C\"} # A and B are always included\n        \n        # Add D if there are factors, otherwise Agent handles D=None if not provided and factors exist\n        if self.num_factors > 0: \n            model_matrix_params[\"D\"] = \"D\"\n        \n        # E is added only if explicitly provided and non-empty in the spec\n        if self.E_spec and self.E_spec.get(\"array\") is not None and len(self.E_spec.get(\"array\")) > 0 :\n             model_matrix_params[\"E\"] = \"E\"\n\n        _unused_control_dict, learning_params, algorithm_params = self.extract_agent_hyperparameters()\n        \n        policy_len = self.agent_hyperparams.get(\"policy_len\")\n        control_fac_idx_to_pass = self.control_factor_indices if self.control_factor_indices else None\n        \n        use_utility = self.agent_hyperparams.get(\"use_utility\")\n        use_states_info_gain = self.agent_hyperparams.get(\"use_states_info_gain\")\n        use_param_info_gain = self.agent_hyperparams.get(\"use_param_info_gain\")\n        action_selection = self.agent_hyperparams.get(\"action_selection\")\n\n        # qs_initial can be a string like \"np.array(...)\" or None (if not specified)\n        # The generate_pymdp_agent_instantiation function handles this.\n        # If qs_initial is actual data (list of arrays), it should be formatted by the caller or handled in generate_...\n        # For now, assume if qs_initial (the variable) is passed, it's a string name of a var or direct data.\n\n        return generate_pymdp_agent_instantiation(\n            self.model_name, \n            model_params=model_matrix_params,\n            control_fac_idx_list=control_fac_idx_to_pass,\n            policy_len=policy_len,\n            use_utility=use_utility,\n            use_states_info_gain=use_states_info_gain,\n            use_param_info_gain=use_param_info_gain,\n            action_selection=action_selection,\n            action_names=action_names, # Pass parsed action_names\n            qs_initial=qs_initial,     # Pass parsed qs_initial\n            learning_params=learning_params,\n            algorithm_params=algorithm_params\n        )",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "generate_example_usage_code",
        "type": "method",
        "start_line": 882,
        "end_line": 1005,
        "code": "def generate_example_usage_code(self) -> List[str]:\n        \"\"\"Generates a runnable example usage block based on the GNN spec and user's example.\"\"\"\n        usage_lines = [\"\", \"# --- Example Usage ---\", \"if __name__ == '__main__':\"]\n        indent = \"    \"\n\n        sim_T = self.simulation_params.get(\"timesteps\", 5)\n        init_o_raw = self.simulation_params.get(\"initial_observations\")\n        init_s_raw = self.simulation_params.get(\"initial_true_states\")\n        use_gp_copy = self.simulation_params.get(\"use_generative_process_copy\", True)\n\n        print_obs = self.simulation_params.get(\"print_observations\", True)\n        print_beliefs = self.simulation_params.get(\"print_belief_states\", True)\n        print_actions = self.simulation_params.get(\"print_actions\", True)\n        print_states = self.simulation_params.get(\"print_true_states\", True)\n        \n        usage_lines.append(f\"{indent}# Initialize agent (already done above)\")\n        usage_lines.append(f\"{indent}agent = {self.model_name}\")\n        usage_lines.append(f\"{indent}print(f\\\"Agent '{self.model_name}' initialized with {{agent.num_factors if hasattr(agent, 'num_factors') else 'N/A'}} factors and {{agent.num_modalities if hasattr(agent, 'num_modalities') else 'N/A'}} modalities.\\\")\")\n\n        # Initial observation\n        if init_o_raw and isinstance(init_o_raw, list) and len(init_o_raw) == self.num_modalities:\n            usage_lines.append(f\"{indent}o_current = {init_o_raw} # Initial observation from GNN spec\")\n        else: # Default initial observation (e.g., first outcome for each modality or a placeholder)\n            default_o = [0] * self.num_modalities if self.num_modalities > 0 else []\n            usage_lines.append(f\"{indent}o_current = {default_o} # Example initial observation (e.g. first outcome for each modality)\")\n            if not init_o_raw and self.num_modalities > 0 : self._add_log(\"Simulation: No 'initial_observations' in GNN, using default.\", \"INFO\")\n        \n        # Initial true state (for simulation purposes, not agent's belief D)\n        if init_s_raw and isinstance(init_s_raw, list) and len(init_s_raw) == self.num_factors:\n             usage_lines.append(f\"{indent}s_current = {init_s_raw} # Initial true states from GNN spec\")\n        else:\n            default_s = [0] * self.num_factors if self.num_factors > 0 else [] # Example: first state for each factor\n            usage_lines.append(f\"{indent}s_current = {default_s} # Example initial true states for simulation\")\n            if not init_s_raw and self.num_factors > 0: self._add_log(\"Simulation: No 'initial_true_states' in GNN, using default.\", \"INFO\")\n\n        usage_lines.append(f\"{indent}T = {sim_T} # Number of timesteps\")\n\n        if use_gp_copy:\n            usage_lines.append(f\"{indent}A_gen_process = copy.deepcopy(A)\")\n            usage_lines.append(f\"{indent}B_gen_process = copy.deepcopy(B)\")\n        else:\n            usage_lines.append(f\"{indent}A_gen_process = A\")\n            usage_lines.append(f\"{indent}B_gen_process = B\")\n        \n        usage_lines.append(\"\")\n        usage_lines.append(f\"{indent}for t_step in range(T):\")\n        inner_indent = indent * 2\n\n        if print_obs:\n            usage_lines.append(f\"{inner_indent}print(f\\\"\\\\n--- Timestep {{t_step + 1}} ---\\\")\")\n            usage_lines.append(f\"{inner_indent}if o_current is not None:\")\n            usage_lines.append(f\"{inner_indent}{indent}for g_idx, o_val in enumerate(o_current):\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}print(f\\\"Observation ({{obs_names[g_idx] if obs_names else f'Modality {{g_idx}}'}}): {{o_val}}\\\")\")\n        \n        usage_lines.append(f\"{inner_indent}# Infer states\")\n        usage_lines.append(f\"{inner_indent}qs_current = agent.infer_states(o_current)\")\n        if print_beliefs:\n            usage_lines.append(f\"{inner_indent}if qs_current is not None:\")\n            usage_lines.append(f\"{inner_indent}{indent}for f_idx, q_val in enumerate(qs_current):\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}print(f\\\"Beliefs about {{state_names[f_idx] if state_names else f'Factor {{f_idx}}'}}: {{q_val}}\\\")\")\n\n        usage_lines.append(\"\")\n        usage_lines.append(f\"{inner_indent}# Infer policies and sample action\")\n        usage_lines.append(f\"{inner_indent}q_pi_current, efe_current = agent.infer_policies()\")\n        usage_lines.append(f\"{inner_indent}if hasattr(agent, 'q_pi') and agent.q_pi is not None:\") # Check if q_pi is available\n        usage_lines.append(f\"{inner_indent}{indent}print(f\\\"Posterior over policies (q_pi): {{agent.q_pi}}\\\")\")\n        usage_lines.append(f\"{inner_indent}if efe_current is not None:\")\n        usage_lines.append(f\"{inner_indent}{indent}print(f\\\"Expected Free Energy (EFE): {{efe_current}}\\\")\")\n        usage_lines.append(f\"{inner_indent}action_agent = agent.sample_action()\")\n        \n        # Map agent action (control_factor list) to environment action (all factors list)\n        usage_lines.append(f\"{inner_indent}# Map agent's action (on control factors) to full environment action vector\")\n        usage_lines.append(f\"{inner_indent}action_env = np.zeros(num_factors, dtype=int)\")\n        usage_lines.append(f\"{inner_indent}if control_fac_idx and action_agent is not None:\")\n        usage_lines.append(f\"{inner_indent}{indent}for i, cf_idx in enumerate(control_fac_idx):\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}action_env[cf_idx] = int(action_agent[i])\")\n\n\n        if print_actions:\n            usage_lines.append(f\"{inner_indent}# Construct action names for printing\")\n            usage_lines.append(f\"{inner_indent}action_names_str_list = []\")\n            usage_lines.append(f\"{inner_indent}if control_fac_idx and action_agent is not None:\")\n            usage_lines.append(f\"{inner_indent}{indent}for i, cf_idx in enumerate(control_fac_idx):\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}factor_action_name_list = agent.action_names.get(cf_idx, []) if hasattr(agent, 'action_names') and isinstance(agent.action_names, dict) else []\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}action_idx_on_factor = int(action_agent[i])\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}if factor_action_name_list and action_idx_on_factor < len(factor_action_name_list):\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}{indent}action_names_str_list.append(f\\\"{{state_names[cf_idx] if state_names else f'Factor {{cf_idx}}'}}: {{factor_action_name_list[action_idx_on_factor]}} (idx {{action_idx_on_factor}})\\\")\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}else:\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}{indent}action_names_str_list.append(f\\\"{{state_names[cf_idx] if state_names else f'Factor {{cf_idx}}'}}: Action idx {{action_idx_on_factor}}\\\")\")\n            usage_lines.append(f\"{inner_indent}print(f\\\"Action taken: {{', '.join(action_names_str_list) if action_names_str_list else 'No controllable actions or names not found'}}\\\")\")\n            usage_lines.append(f\"{inner_indent}# Raw sampled action_agent: {{action_agent}}\")\n            usage_lines.append(f\"{inner_indent}# Mapped action_env for B matrix: {{action_env}}\")\n\n        usage_lines.append(\"\")\n        usage_lines.append(f\"{inner_indent}# Update true states of the environment based on action\")\n        usage_lines.append(f\"{inner_indent}s_next = np.zeros(num_factors, dtype=int)\")\n        usage_lines.append(f\"{inner_indent}if s_current is not None and B_gen_process is not None:\")\n        usage_lines.append(f\"{inner_indent}{indent}for f_idx in range(num_factors):\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}# B_gen_process[f_idx] shape: (num_states[f_idx], num_states[f_idx], num_actions_for_this_factor_or_1)\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}action_for_factor = action_env[f_idx] if f_idx in control_fac_idx else 0\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}s_next[f_idx] = utils.sample(B_gen_process[f_idx][:, s_current[f_idx], action_for_factor])\")\n        usage_lines.append(f\"{inner_indent}s_current = s_next.tolist()\")\n\n        if print_states:\n            usage_lines.append(f\"{inner_indent}if s_current is not None:\")\n            usage_lines.append(f\"{inner_indent}{indent}for f_idx, s_val in enumerate(s_current):\")\n            usage_lines.append(f\"{inner_indent}{indent}{indent}print(f\\\"New true state ({{state_names[f_idx] if state_names else f'Factor {{f_idx}}'}}): {{s_val}}\\\")\")\n\n\n        usage_lines.append(\"\")\n        usage_lines.append(f\"{inner_indent}# Generate next observation based on new true states\")\n        usage_lines.append(f\"{inner_indent}o_next = np.zeros(num_modalities, dtype=int)\")\n        usage_lines.append(f\"{inner_indent}if s_current is not None and A_gen_process is not None:\")\n        usage_lines.append(f\"{inner_indent}{indent}for g_idx in range(num_modalities):\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}# A_gen_process[g_idx] shape: (num_obs[g_idx], num_states[0], num_states[1], ...)\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}# Construct index for A matrix: (outcome_idx, s_f0, s_f1, ...)\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}prob_vector = A_gen_process[g_idx][:, \" + \", \".join([f\"s_current[{sf_i}]\" for sf_i in range(self.num_factors)]) + \"]\")\n        usage_lines.append(f\"{inner_indent}{indent}{indent}o_next[g_idx] = utils.sample(prob_vector)\")\n        usage_lines.append(f\"{inner_indent}o_current = o_next.tolist()\")\n        \n        usage_lines.append(\"\")\n        usage_lines.append(f\"{indent}print(f\\\"\\\\nSimulation finished after {{T}} timesteps.\\\")\")\n\n        return usage_lines",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "get_full_python_script",
        "type": "method",
        "start_line": 1008,
        "end_line": 1152,
        "code": "def get_full_python_script(self, include_example_usage: bool = True) -> str:\n        \"\"\"Assembles all parts into a single Python script string.\"\"\"\n        \n        # Pre-computation / matrix generation calls\n        self.convert_A_matrix()\n        self.convert_B_matrix()\n        self.convert_C_vector()\n        self.convert_D_vector()\n        self.convert_E_vector()\n\n        # Agent instantiation\n        self.script_parts[\"agent_instantiation\"].append(self.generate_agent_instantiation_code())\n        \n        if include_example_usage:\n            self.script_parts[\"example_usage\"] = self.generate_example_usage_code()\n        else:\n            self.script_parts[\"example_usage\"] = [\"# Example usage block skipped as per options.\"]\n\n        script_content = []\n        script_content.extend(self.script_parts[\"imports\"])\n        script_content.append(\"\")\n        \n        summary_header = [\"# --- GNN to PyMDP Conversion Summary ---\"]\n        summary_lines = [f\"# {log_entry}\" for log_entry in self.conversion_log]\n        summary_footer = [\"# --- End of GNN to PyMDP Conversion Summary ---\"]\n        script_content.extend(summary_header)\n        script_content.extend(summary_lines)\n        script_content.extend(summary_footer)\n        script_content.append(\"\")\n        script_content.append(\"\")\n\n        script_content.extend(self.script_parts[\"comments\"])\n        script_content.append(\"\")\n\n        script_content.extend(self.script_parts[\"preamble_vars\"])\n        script_content.append(\"\")\n\n        script_content.append(\"# --- Matrix Definitions ---\")\n        script_content.extend(self.script_parts[\"matrix_definitions\"])\n        script_content.append(\"\")\n        \n        script_content.append(\"# --- Agent Instantiation ---\")\n        script_content.extend(self.script_parts[\"agent_instantiation\"])\n        script_content.append(\"\")\n\n        # Define agent_params_for_debug dictionary for the debug block\n        # It should capture the actual arguments intended for the Agent constructor\n        agent_params_lines = [\"agent_params_for_debug = {\"]\n        # Collect args from how generate_agent_instantiation_code structures them\n        # Based on model_matrix_params and other specific args in generate_agent_instantiation_code:\n        agent_params_lines.append(\"    'A': A if 'A' in globals() else None,\")\n        agent_params_lines.append(\"    'B': B if 'B' in globals() else None,\")\n        agent_params_lines.append(\"    'C': C if 'C' in globals() else None,\")\n        if self.num_factors > 0: # D is only passed if there are factors\n             agent_params_lines.append(\"    'D': D if 'D' in globals() else None,\")\n        if self.E_spec and self.E_spec.get(\"array\") is not None:\n             agent_params_lines.append(\"    'E': E if 'E' in globals() else None,\")\n\n        # Add other specific Agent constructor parameters that generate_agent_instantiation_code handles\n        # These should ideally be sourced from the same place generate_agent_instantiation_code gets them (self.agent_hyperparams)\n        # or directly from the variables defined in the preamble.\n        agent_params_lines.append(\"    'control_fac_idx': (control_fac_idx if control_fac_idx else None) if 'control_fac_idx' in globals() else None,\")\n        if self.agent_hyperparams.get(\"policy_len\") is not None:\n             agent_params_lines.append(f\"    'policy_len': {self.agent_hyperparams['policy_len']},\")\n        if self.agent_hyperparams.get(\"use_utility\") is not None:\n             agent_params_lines.append(f\"    'use_utility': {self.agent_hyperparams['use_utility']},\")\n        if self.agent_hyperparams.get(\"use_states_info_gain\") is not None:\n            agent_params_lines.append(f\"    'use_states_info_gain': {self.agent_hyperparams['use_states_info_gain']},\")\n        if self.agent_hyperparams.get(\"use_param_info_gain\") is not None:\n            agent_params_lines.append(f\"    'use_param_info_gain': {self.agent_hyperparams['use_param_info_gain']},\")\n        if self.agent_hyperparams.get(\"action_selection\") is not None:\n            agent_params_lines.append(f\"    'action_selection': '{self.agent_hyperparams['action_selection']}',\")\n        \n        # Learning and algorithm params are passed as dicts\n        _, learning_params_dict, algorithm_params_dict = self.extract_agent_hyperparameters()\n        if learning_params_dict:\n            agent_params_lines.append(f\"    'learning_params': {learning_params_dict},\")\n        if algorithm_params_dict:\n            agent_params_lines.append(f\"    'algorithm_params': {algorithm_params_dict},\")\n\n        if agent_params_lines[-1].endswith(','): # Remove trailing comma if any\n            agent_params_lines[-1] = agent_params_lines[-1][:-1]\n        agent_params_lines.append(\"}\")\n        script_content.extend(agent_params_lines)\n        script_content.append(\"\")\n\n        script_content.extend(self.script_parts[\"example_usage\"]) # This should come after agent_params_for_debug definition\n        \n        # Prepare string representations for the debug_block f-strings\n        # These are string versions of the GNN spec sections or derived values\n        # that the debug block intends to print.\n        \n        # Action names as passed to the agent\n        # self.action_names_per_control_factor is the dict like {factor_idx: [name1, name2]}\n        action_names_val = self.action_names_per_control_factor\n        action_names_dict_str = str(action_names_val) # Creates a string like \"{0: ['action_0', 'action_1']}\"\n\n        # qs_initial from agent_hyperparams\n        qs_initial_val = self.agent_hyperparams.get(\"qs_initial\")\n        qs_initial_str = str(qs_initial_val) # String representation, e.g., 'None' or list as string\n\n        # The full agent_hyperparams dictionary from the GNN spec\n        agent_hyperparams_dict_str = str(self.agent_hyperparams)\n\n        # Add runtime debug block\n        # The temp_agent instantiation should use agent_params_for_debug\n        debug_block = [\n            \"print('--- PyMDP Runtime Debug ---')\",\n            \"try:\",\n            \"    import pymdp\",\n            \"    try:\",\n            \"        print(f'AGENT_SCRIPT: Imported pymdp version: {pymdp.__version__}')\",\n            \"    except AttributeError:\",\n            \"        print('AGENT_SCRIPT: pymdp.__version__ attribute not found.')\",\n            \"    print(f'AGENT_SCRIPT: pymdp module location: {pymdp.__file__}')\",\n            \"    from pymdp.agent import Agent\",\n            \"    print(f'AGENT_SCRIPT: Imported Agent: {Agent}')\",\n            \"    print(f'AGENT_SCRIPT: Agent module location: {inspect.getfile(Agent)}')\",\n            \"    print('AGENT_SCRIPT: Checking for required variables in global scope:')\",\n            \"    # Check defined parameters for the main agent\",\n            \"    print(f\\\"  AGENT_SCRIPT: A = {{A if 'A' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f\\\"  AGENT_SCRIPT: B = {{B if 'B' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f\\\"  AGENT_SCRIPT: C = {{C if 'C' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f\\\"  AGENT_SCRIPT: D = {{D if 'D' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f\\\"  AGENT_SCRIPT: E = {{E if 'E' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f\\\"  AGENT_SCRIPT: control_fac_idx = {{control_fac_idx if 'control_fac_idx' in globals() else 'Not Defined'}}\\\")\",\n            \"    print(f'  AGENT_SCRIPT: action_names = {action_names_dict_str if action_names_dict_str != \\\"{{}}\\\" else \\\"Not Defined\\\"}')\",\n            \"    print(f'  AGENT_SCRIPT: qs_initial = {qs_initial_str if qs_initial_str != \\\"None\\\" else \\\"Not Defined\\\"}')\",\n            \"    print(f'  AGENT_SCRIPT: agent_hyperparams = {agent_hyperparams_dict_str}')\",\n            \"    print('AGENT_SCRIPT: Attempting to instantiate agent with defined parameters for debug...')\",\n            \"    # Filter out None hyperparams from agent_params_for_debug if it was originally None\",\n            \"    # The ** unpacking handles empty dicts correctly if agent_hyperparams_dict_str was \\\"{}\\\"\",\n            \"    debug_params_copy = {k: v for k, v in agent_params_for_debug.items() if not (isinstance(v, str) and v == 'None')}\",\n            \"    temp_agent = Agent(**debug_params_copy)\",\n            \"    print(f'AGENT_SCRIPT: Debug agent successfully instantiated: {temp_agent}')\",\n            \"except Exception as e_debug:\",\n            \"    print(f'AGENT_SCRIPT: Error during PyMDP runtime debug: {e_debug}')\", \n            \"    print(f\\\"AGENT_SCRIPT: Traceback:\\\\n{traceback.format_exc()}\\\")\", # Keep f\\\" for this multi-line\n            \"print('--- End PyMDP Runtime Debug ---')\",\n        ]\n        script_content.extend(debug_block)\n\n        script_content.append(f\"# --- GNN Model: {self.model_name} ---\\\\n\")\n\n        return \"\\n\".join(script_content)",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "render_gnn_to_pymdp",
        "type": "function",
        "start_line": 1154,
        "end_line": 1206,
        "code": "def render_gnn_to_pymdp(\n    gnn_spec: Dict[str, Any],\n    output_script_path: Path,\n    options: Optional[Dict[str, Any]] = None # e.g. {\"include_example_usage\": True}\n) -> Tuple[bool, str, List[str]]:\n    \"\"\"\n    Main function to render a GNN specification to a PyMDP Python script.\n\n    Args:\n        gnn_spec: The GNN specification as a Python dictionary.\n        output_script_path: The path where the generated Python script will be saved.\n        options: Dictionary of rendering options. \n                 Currently supports \"include_example_usage\" (bool, default True).\n\n    Returns:\n        A tuple (success: bool, message: str, artifact_uris: List[str]).\n        `artifact_uris` will contain a file URI to the generated script on success.\n    \"\"\"\n    # If the rendering process itself seems to hang, investigate large string parsing (see _parse_string_to_literal)\n    # or complex GNN structures leading to extensive processing.\n    # If the *generated script* hangs when executed, it's likely due to PyMDP agent computations\n    # (e.g., large state spaces, long policy horizons). In that case, profile the generated script\n    # (e.g., using cProfile or line_profiler) to identify bottlenecks within PyMDP or the simulation loop.\n    options = options or {}\n    include_example_usage = options.get(\"include_example_usage\", True)\n\n    try:\n        logger.info(f\"Initializing GNN to PyMDP converter for model: {gnn_spec.get('ModelName', 'UnknownModel')}\")\n        converter = GnnToPyMdpConverter(gnn_spec)\n        \n        logger.info(\"Generating PyMDP Python script content...\")\n        python_script_content = converter.get_full_python_script(\n            include_example_usage=include_example_usage\n        )\n        \n        logger.info(f\"Writing PyMDP script to: {output_script_path}\")\n        with open(output_script_path, \"w\", encoding='utf-8') as f:\n            f.write(python_script_content)\n        \n        success_msg = f\"Successfully wrote PyMDP script: {output_script_path.name}\"\n        logger.info(success_msg)\n        \n        # Include conversion log in the final message for clarity, perhaps capped\n        log_summary = \"\\n\".join(converter.conversion_log[:20]) # First 20 log messages\n        if len(converter.conversion_log) > 20:\n            log_summary += \"\\n... (log truncated)\"\n            \n        return True, f\"{success_msg}\\nConversion Log Summary:\\n{log_summary}\", [output_script_path.as_uri()]\n\n    except Exception as e:\n        error_msg = f\"Failed to render GNN to PyMDP: {e}\"\n        logger.exception(error_msg) # Log full traceback\n        return False, error_msg, []",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      },
      {
        "name": "placeholder_gnn_parser_pymdp",
        "type": "function",
        "start_line": 1210,
        "end_line": 1230,
        "code": "def placeholder_gnn_parser_pymdp(gnn_file_path: Path) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Placeholder function to parse a GNN Markdown file into a dictionary.\n    This would ideally live in a dedicated GNN parsing module.\n    \"\"\"\n    logger.warning(f\"Using placeholder GNN parser for {gnn_file_path}. This is for testing/dev only.\")\n    if not gnn_file_path.is_file():\n        logger.error(f\"GNN file not found: {gnn_file_path}\")\n        return None\n    try:\n        # This is a HACK: assumes GNN file is JSON for placeholder\n        with open(gnn_file_path, 'r') as f:\n            # A real parser would handle Markdown structure (StateSpaceBlock, Connections, etc.)\n            # and convert to the structured dict `GnnToPyMdpConverter` expects.\n            # For this placeholder, we assume it's a JSON that directly matches the expected dict structure.\n            # This will likely fail for actual .md GNN files.\n            data = json.load(f) \n        return data\n    except Exception as e:\n        logger.error(f\"Error in placeholder GNN parser for {gnn_file_path}: {e}\")\n        return None",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/pymdp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/render/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/llm_operations.py": [
      {
        "name": "load_api_key",
        "type": "function",
        "start_line": 7,
        "end_line": 16,
        "code": "def load_api_key():\n    \"\"\"Loads the OpenAI API key from the .env file.\"\"\"\n    load_dotenv()\n    api_key = os.getenv(\"OPENAI_API_KEY\")\n    if not api_key:\n        logger.error(\"OPENAI_API_KEY not found in .env file or environment variables.\")\n        raise ValueError(\"OPENAI_API_KEY not found.\")\n    openai.api_key = api_key\n    logger.info(\"OpenAI API key loaded successfully.\")\n    return api_key",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/llm_operations.py"
      },
      {
        "name": "construct_prompt",
        "type": "function",
        "start_line": 18,
        "end_line": 39,
        "code": "def construct_prompt(contexts: list[str], task_description: str) -> str:\n    \"\"\"\n    Constructs a prompt for the LLM by concatenating various context strings\n    and a specific task description.\n\n    Args:\n        contexts (list[str]): A list of strings, where each string is a piece of context\n                              (e.g., GNN file content, user query, previous responses).\n        task_description (str): A string describing the specific task for the LLM.\n\n    Returns:\n        str: The fully constructed prompt.\n    \"\"\"\n    full_context = \"\\n\\n---\\n\\n\".join(contexts)\n    prompt = f\"\"\"{full_context}\n\n---\\n\nBased on the context above, please perform the following task:\n{task_description}\n\"\"\"\n    logger.debug(f\"Constructed prompt: {prompt[:500]}...\") # Log a preview\n    return prompt",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/llm_operations.py"
      },
      {
        "name": "get_llm_response",
        "type": "function",
        "start_line": 41,
        "end_line": 83,
        "code": "def get_llm_response(prompt: str, model: str = \"gpt-4o-mini\", max_tokens: int = 8000, temperature: float = 0.7, request_timeout: float = 30.0) -> str:\n    \"\"\"\n    Sends a prompt to the specified OpenAI model and returns the response.\n\n    Args:\n        prompt (str): The prompt to send to the LLM.\n        model (str): The OpenAI model to use (e.g., \"gpt-3.5-turbo\", \"gpt-4\").\n        max_tokens (int): The maximum number of tokens to generate.\n        temperature (float): Controls randomness (0.0 to 2.0). Lower values are more deterministic.\n        request_timeout (float): Timeout in seconds for the API request.\n\n    Returns:\n        str: The LLM's response or an error message.\n    \"\"\"\n    try:\n        logger.info(f\"Sending prompt to OpenAI model: {model} (Timeout: {request_timeout}s)\")\n        # Using the new client syntax for OpenAI API version >= 1.0\n        client = openai.OpenAI() \n        response = client.chat.completions.create(\n            model=model,\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant specializing in analyzing and summarizing technical documents, particularly GNN (Generalized Notation Notation) files.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            max_tokens=max_tokens,\n            temperature=temperature,\n            n=1,\n            stop=None,\n            timeout=request_timeout\n        )\n        llm_response = response.choices[0].message.content.strip()\n        logger.info(f\"Received response from LLM. Length: {len(llm_response)} chars.\")\n        logger.debug(f\"LLM Response preview: {llm_response[:500]}...\")\n        return llm_response\n    except openai.APITimeoutError as e:\n        logger.error(f\"OpenAI API Timeout Error after {request_timeout}s: {e}\", exc_info=True)\n        return f\"Error: OpenAI API Timeout Error after {request_timeout}s - {e}\"\n    except openai.APIError as e:\n        logger.error(f\"OpenAI API Error: {e}\", exc_info=True)\n        return f\"Error: OpenAI API Error - {e}\"\n    except Exception as e:\n        logger.error(f\"An unexpected error occurred while getting LLM response: {e}\", exc_info=True)\n        return f\"Error: An unexpected error occurred - {e}\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/llm_operations.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/mcp.py": [
      {
        "name": "initialize_llm_module",
        "type": "function",
        "start_line": 29,
        "end_line": 67,
        "code": "def initialize_llm_module(mcp_instance_ref):\n    \"\"\"\n    Initializes the LLM module, loads API key, and updates MCP status.\n    This should be called by the MCP main system after it has initialized mcp_instance.\n    \"\"\"\n    global llm_operations, MCPTool, MCPSDKNotFoundError # Allow modification of global placeholders\n\n    # Import MCPTool and MCPSDKNotFoundError directly from src.mcp.mcp\n    try:\n        from src.mcp.mcp import MCPTool as RealMCPTool, MCPSDKNotFoundError as RealMCPSDKNotFoundError\n        MCPTool = RealMCPTool\n        MCPSDKNotFoundError = RealMCPSDKNotFoundError\n        logger.info(\"Successfully imported MCPTool and MCPSDKNotFoundError from src.mcp.mcp in initialize_llm_module.\")\n    except ImportError:\n        logger.warning(\"Could not import MCPTool or MCPSDKNotFoundError from src.mcp.mcp in initialize_llm_module. Tool registration might fail.\")\n        # Keep them as None or a dummy type if not found\n        if MCPTool is None: MCPTool = type('MCPTool', (object,), {}) # Dummy class\n        if MCPSDKNotFoundError is None: MCPSDKNotFoundError = type('MCPSDKNotFoundError', (Exception,), {}) # Dummy exception\n\n    if not llm_operations:\n        logger.error(\"LLM operations module not loaded. LLM tools cannot be initialized or registered.\")\n        if mcp_instance_ref and hasattr(mcp_instance_ref, 'sdk_status'):\n            mcp_instance_ref.sdk_status = False\n            mcp_instance_ref.sdk_status_message = \"LLM operations module not loaded.\"\n        return False\n\n    try:\n        llm_operations.load_api_key()\n        logger.info(\"LLM API Key loaded successfully.\")\n        if mcp_instance_ref and hasattr(mcp_instance_ref, 'sdk_status'):\n            mcp_instance_ref.sdk_status = True # Assuming successful load means SDK is ready\n            mcp_instance_ref.sdk_status_message = \"LLM SDK ready (API Key loaded).\"\n        return True\n    except ValueError as e:\n        logger.error(f\"MCP for LLM: OpenAI API Key not loaded: {e}. LLM tools will not function.\")\n        if mcp_instance_ref and hasattr(mcp_instance_ref, 'sdk_status'):\n            mcp_instance_ref.sdk_status = False # Indicate SDK (LLM part) is not ready\n            mcp_instance_ref.sdk_status_message = f\"OpenAI API Key not loaded: {e}. LLM tools will not function.\"\n        return False",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/mcp.py"
      },
      {
        "name": "summarize_gnn_file_content",
        "type": "function",
        "start_line": 71,
        "end_line": 101,
        "code": "def summarize_gnn_file_content(file_path_str: str, user_prompt_suffix: Optional[str] = None) -> str:\n    \"\"\"\n    Reads a GNN file, sends its content to an LLM, and returns a summary.\n    An optional user prompt suffix can be added to guide the summary.\n    \"\"\"\n    if not llm_operations:\n        error_msg = \"Error: LLM operations module not loaded.\"\n        logger.error(f\"summarize_gnn_file_content: {error_msg}\")\n        return error_msg\n\n    file_path = Path(file_path_str)\n    if not file_path.is_file():\n        error_msg = f\"File not found at {file_path_str}\"\n        logger.error(f\"summarize_gnn_file_content: {error_msg}\")\n        return f\"Error: {error_msg}\"\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            gnn_content = f.read()\n        \n        contexts = [f\"GNN File Content ({file_path.name}):\\n{gnn_content}\"]\n        task = \"Provide a concise summary of the GNN model described in the content above, highlighting its key components (ModelName, primary states/observations, and main connections).\"\n        if user_prompt_suffix:\n            task += f\" {user_prompt_suffix}\"\n            \n        prompt = llm_operations.construct_prompt(contexts, task)\n        summary = llm_operations.get_llm_response(prompt)\n        return summary\n    except Exception as e:\n        logger.error(f\"Error summarizing GNN file {file_path_str}: {e}\", exc_info=True)\n        return f\"Error processing file {file_path_str}: {e}\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/mcp.py"
      },
      {
        "name": "explain_gnn_file_content",
        "type": "function",
        "start_line": 103,
        "end_line": 134,
        "code": "def explain_gnn_file_content(file_path_str: str, aspect_to_explain: Optional[str] = None) -> str:\n    \"\"\"\n    Reads a GNN file, sends its content to an LLM, and returns an explanation.\n    If aspect_to_explain is provided, the explanation focuses on that part.\n    \"\"\"\n    if not llm_operations:\n        error_msg = \"Error: LLM operations module not loaded.\"\n        logger.error(f\"explain_gnn_file_content: {error_msg}\")\n        return error_msg\n\n    file_path = Path(file_path_str)\n    if not file_path.is_file():\n        error_msg = f\"File not found at {file_path_str}\"\n        logger.error(f\"explain_gnn_file_content: {error_msg}\")\n        return f\"Error: {error_msg}\"\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            gnn_content = f.read()\n\n        contexts = [f\"GNN File Content ({file_path.name}):\\n{gnn_content}\"]\n        if aspect_to_explain:\n            task = f\"Explain the following aspect of the GNN model: '{aspect_to_explain}'. Provide a clear and simple explanation suitable for someone familiar with GNNs but perhaps not this specific model.\"\n        else:\n            task = \"Provide a general explanation of the GNN model described above. Cover its potential purpose, the nature of its state space, and how its components might interact.\"\n        \n        prompt = llm_operations.construct_prompt(contexts, task)\n        explanation = llm_operations.get_llm_response(prompt)\n        return explanation\n    except Exception as e:\n        logger.error(f\"Error explaining GNN file {file_path_str}: {e}\", exc_info=True)\n        return f\"Error processing file {file_path_str}: {e}\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/mcp.py"
      },
      {
        "name": "generate_professional_summary_from_gnn",
        "type": "function",
        "start_line": 136,
        "end_line": 168,
        "code": "def generate_professional_summary_from_gnn(file_path_str: str, experiment_details: Optional[str] = None, target_audience: str = \"fellow researchers\") -> str:\n    \"\"\"\n    Generates a professional summary of a GNN model and its experimental context.\n    Useful for reports or presentations.\n    \"\"\"\n    if not llm_operations:\n        error_msg = \"Error: LLM operations module not loaded.\"\n        logger.error(f\"generate_professional_summary_from_gnn: {error_msg}\")\n        return error_msg\n\n    file_path = Path(file_path_str)\n    if not file_path.is_file():\n        error_msg = f\"File not found at {file_path_str}\"\n        logger.error(f\"generate_professional_summary_from_gnn: {error_msg}\")\n        return f\"Error: {error_msg}\"\n\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            gnn_content = f.read()\n        \n        contexts = [f\"GNN Model Specification ({file_path.name}):\\n{gnn_content}\"]\n        if experiment_details:\n            contexts.append(f\"Experimental Context/Results:\\n{experiment_details}\")\n        \n        task = f\"Generate a professional, publication-quality summary of the GNN model and its experimental context. The summary should be targeted at {target_audience}. It should be well-structured, highlight key findings or model characteristics, and be suitable for inclusion in a research paper or technical report.\"\n        \n        prompt = llm_operations.construct_prompt(contexts, task)\n        # Potentially use a more capable model or higher token limit for professional summaries\n        prof_summary = llm_operations.get_llm_response(prompt, model=\"gpt-4o-mini\")\n        return prof_summary\n    except Exception as e:\n        logger.error(f\"Error generating professional summary for {file_path_str}: {e}\", exc_info=True)\n        return f\"Error processing file {file_path_str}: {e}\"",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/mcp.py"
      },
      {
        "name": "register_tools",
        "type": "function",
        "start_line": 173,
        "end_line": 268,
        "code": "def register_tools(mcp_instance_ref):\n    global MCPTool # Use the MCPTool that initialize_llm_module is responsible for setting\n\n    if not mcp_instance_ref:\n        logger.warning(\"MCP instance not available. LLM tools not registered.\")\n        return\n    \n    if MCPTool is None: # This means initialize_llm_module failed to set it (even to a dummy)\n        logger.error(\"MCPTool is None after initialize_llm_module was expected to set it. LLM tools registration aborted.\")\n        return\n\n    # At this point, MCPTool is either the real MCPTool class from src.mcp.mcp\n    # or the dummy class type('MCPTool', (object,), {}) if the import failed in initialize_llm_module.\n    # We proceed with the assumption that MCPTool is callable and usable for instantiation.\n    # If it's the dummy and incompatible with instantiation or registration,\n    # the try-except block below during tool creation/registration will catch it.\n\n    tool_definitions = [\n        {\n            \"name\": \"llm.summarize_gnn_file\",\n            \"description\": \"Reads a GNN specification file and uses an LLM to generate a concise summary of its content. Optionally, a user prompt suffix can refine the summary focus.\",\n            \"func\": summarize_gnn_file_content,\n            \"arg_descriptions\": {\n                \"file_path_str\": \"The absolute or relative path to the GNN file (.md, .gnn.md, .json).\",\n                \"user_prompt_suffix\": \"(Optional) Additional instructions or focus points for the summary.\"\n            }\n        },\n        {\n            \"name\": \"llm.explain_gnn_file\",\n            \"description\": \"Reads a GNN specification file and uses an LLM to generate an explanation of its content. Can focus on a specific aspect if provided.\",\n            \"func\": explain_gnn_file_content,\n            \"arg_descriptions\": {\n                \"file_path_str\": \"The absolute or relative path to the GNN file.\",\n                \"aspect_to_explain\": \"(Optional) A specific part or concept within the GNN to focus the explanation on.\"\n            }\n        },\n        {\n            \"name\": \"llm.generate_professional_summary\",\n            \"description\": \"Reads a GNN file and optional experiment details, then uses an LLM to generate a professional summary suitable for reports or papers.\",\n            \"func\": generate_professional_summary_from_gnn,\n            \"arg_descriptions\": {\n                \"file_path_str\": \"The absolute or relative path to the GNN file.\",\n                \"experiment_details\": \"(Optional) Text describing the experiments conducted with the model, including setup, results, or observations.\",\n                \"target_audience\": \"(Optional) The intended audience for the summary (e.g., 'fellow researchers', 'project managers'). Default: 'fellow researchers'.\"\n            }\n        }\n    ]\n\n    for tool_def in tool_definitions:\n        try:\n            properties = {}\n            required_params = []\n            \n            sig = inspect.signature(tool_def[\"func\"])\n            for param_name, param in sig.parameters.items():\n                desc = tool_def[\"arg_descriptions\"].get(param_name, \"\")\n                param_type_str = \"string\"\n                if param.annotation == str:\n                    param_type_str = \"string\"\n                elif param.annotation == int:\n                    param_type_str = \"integer\"\n                elif param.annotation == float:\n                    param_type_str = \"number\"\n                elif param.annotation == bool:\n                    param_type_str = \"boolean\"\n                elif param.annotation == list:\n                    param_type_str = \"array\"\n                elif param.annotation == dict:\n                    param_type_str = \"object\"\n                elif param.annotation == Path:\n                    param_type_str = \"string\"\n                \n                properties[param_name] = {\"type\": param_type_str, \"description\": desc}\n                if param.default == inspect.Parameter.empty and param.kind != inspect.Parameter.VAR_KEYWORD and param.kind != inspect.Parameter.VAR_POSITIONAL:\n                    # Consider a parameter required if it has no default and is not *args or **kwargs\n                    # Further refinement: check if type hint is Optional or includes None\n                    if not (str(param.annotation).startswith(\"Optional[\") or (\"None\" in str(param.annotation))):\n                         required_params.append(param_name)\n            \n            # Attempt to create and register the tool\n            # MCPTool instance is created internally by mcp_instance_ref.register_tool\n            mcp_instance_ref.register_tool(\n                name=tool_def[\"name\"],\n                func=tool_def[\"func\"],\n                schema={\n                    \"type\": \"object\",\n                    \"properties\": properties,\n                    \"required\": required_params\n                },\n                description=tool_def[\"description\"]\n            )\n            logger.info(f\"Registered MCP tool: {tool_def['name']}\")\n        except Exception as e_reg:\n            logger.error(f\"Failed to register MCP tool {tool_def['name']}: {e_reg}\", exc_info=True)\n    \n    logger.info(\"LLM module MCP tools registration process completed.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/mcp.py"
      },
      {
        "name": "ensure_llm_tools_registered",
        "type": "function",
        "start_line": 270,
        "end_line": 294,
        "code": "def ensure_llm_tools_registered(mcp_instance_ref): # Added mcp_instance_ref parameter\n    \"\"\"\n    Ensures that LLM tools are registered with the provided MCP instance.\n    This function can be called from the main LLM processing script (e.g., 11_llm.py)\n    to make sure tools are available before use, especially if MCP initialization\n    is complex or happens in stages.\n    \"\"\"\n    logger.info(\"Attempting to ensure LLM tools are registered with MCP.\")\n    \n    # First, ensure the LLM module itself is initialized (loads API key, attempts to set MCPTool)\n    # Pass the mcp_instance_ref so initialize_llm_module can also access it if needed (e.g. for sdk_status)\n    if not initialize_llm_module(mcp_instance_ref):\n        logger.warning(\"LLM module initialization failed. Tools may not register or function.\")\n        # Even if initialization has issues, try to proceed with registration if MCPTool was set somehow\n\n    # Check API key status via llm_operations if possible\n    if llm_operations and hasattr(llm_operations, 'is_api_key_loaded') and not llm_operations.is_api_key_loaded():\n        logger.warning(\"LLM API key is not loaded. LLM tools will not function correctly even if registered.\")\n    elif not llm_operations:\n        logger.warning(\"llm_operations module not available for API key check.\")\n\n    # Now, attempt to register tools\n    # register_tools itself uses the global MCPTool set by initialize_llm_module\n    register_tools(mcp_instance_ref)\n    logger.info(\"ensure_llm_tools_registered call completed.\")",
        "file": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/mcp.py"
      }
    ],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/llm/__init__.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/output/gnn_rendered_simulators/pymdp/gnn_example_pymdp_agent/gnn_example_pymdp_agent_rendered.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/output/gnn_rendered_simulators/pymdp/gnn_airplane_trading_pomdp/gnn_airplane_trading_pomdp_rendered.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/output/gnn_rendered_simulators/pymdp/gnn_poetic_muse_model/gnn_poetic_muse_model_rendered.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/output/gnn_rendered_simulators/pymdp/gnn_POMDP_example/gnn_POMDP_example_rendered.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/output/gnn_rendered_simulators/pymdp/gnn_active_inference_language_model/gnn_active_inference_language_model_rendered.py": [],
    "/home/trim/Documents/GitHub/GeneralizedNotationNotation/doc/kit/gnn_kit/kit_setup.py": []
  }
}