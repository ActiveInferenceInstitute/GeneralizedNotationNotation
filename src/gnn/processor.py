#!/usr/bin/env python3
"""
GNN processor module for GNN pipeline.
"""

from pathlib import Path
from typing import Dict, Any, List, Union
import logging
import json
import re
from datetime import datetime

from utils.pipeline_template import (
    log_step_start,
    log_step_success,
    log_step_error,
    log_step_warning
)

def process_gnn_directory_lightweight(target_dir: Path, output_dir: Path = None, recursive: bool = False) -> Dict[str, Any]:
    """
    Lightweight GNN directory processing without heavy dependencies.
    
    Args:
        target_dir: Directory containing GNN files
        output_dir: Directory to save results (optional)
        recursive: Whether to process subdirectories
        
    Returns:
        Dictionary with processing results
    """
    try:
        # Discover GNN files
        gnn_files = discover_gnn_files(target_dir, recursive)
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "target_directory": str(target_dir),
            "files_found": len(gnn_files),
            "files_processed": 0,
            "success": True,
            "errors": [],
            "parsed_files": [],
            "validation_results": []
        }
        
        # Process each file
        for file_path in gnn_files:
            try:
                # Parse GNN file
                parsed_result = parse_gnn_file(file_path)
                if parsed_result:
                    results["parsed_files"].append(parsed_result)
                    results["files_processed"] += 1
                
                # Validate GNN structure
                validation_result = validate_gnn_structure(file_path)
                results["validation_results"].append(validation_result)
                
            except Exception as e:
                error_info = {
                    "file": str(file_path),
                    "error": str(e),
                    "error_type": type(e).__name__
                }
                results["errors"].append(error_info)
        
        # Save results if output directory provided
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            results_file = output_dir / "gnn_processing_results.json"
            with open(results_file, 'w') as f:
                json.dump(results, f, indent=2)
        
        return results
        
    except Exception as e:
        return {
            "timestamp": datetime.now().isoformat(),
            "target_directory": str(target_dir),
            "files_found": 0,
            "files_processed": 0,
            "success": False,
            "errors": [{"error": str(e), "error_type": type(e).__name__}],
            "parsed_files": [],
            "validation_results": []
        }

def _extract_sections_lightweight(content: str) -> List[str]:
    """Extract sections from GNN content using lightweight parsing."""
    sections = []
    
    # Look for markdown headers
    header_pattern = r'^#+\s+(.+)$'
    matches = re.finditer(header_pattern, content, re.MULTILINE)
    
    for match in matches:
        section_title = match.group(1).strip()
        sections.append(section_title)
    
    return sections

def _extract_variables_lightweight(content: str) -> List[str]:
    """Extract variables from GNN content using lightweight parsing."""
    variables = []
    
    # Look for variable definitions
    var_patterns = [
        r'(\w+)\s*:\s*(\w+)',  # name: type
        r'(\w+)\s*=\s*([^;\n]+)',  # name = value
        r'(\w+)\s*\[([^\]]+)\]',  # name[dimensions]
    ]
    
    for pattern in var_patterns:
        matches = re.finditer(pattern, content)
        for match in matches:
            var_name = match.group(1)
            if var_name not in variables:
                variables.append(var_name)
    
    return variables

def discover_gnn_files(directory: Union[str, Path], recursive: bool = True) -> List[Path]:
    """
    Discover GNN files in a directory.
    
    Args:
        directory: Directory to search
        recursive: Whether to search subdirectories
        
    Returns:
        List of discovered GNN file paths
    """
    directory = Path(directory)
    gnn_files = []
    
    if not directory.exists():
        return gnn_files
    
    # Define GNN file patterns
    gnn_patterns = ["*.md", "*.gnn", "*.txt"]
    
    for pattern in gnn_patterns:
        if recursive:
            gnn_files.extend(directory.rglob(pattern))
        else:
            gnn_files.extend(directory.glob(pattern))
    
    # Filter out common non-GNN files
    excluded_patterns = [
        "README.md", "CHANGELOG.md", "LICENSE.md",
        "*.template.md", "*.example.md"
    ]
    
    filtered_files = []
    for file_path in gnn_files:
        should_exclude = False
        for pattern in excluded_patterns:
            if pattern.startswith("*"):
                if file_path.name.endswith(pattern[1:]):
                    should_exclude = True
                    break
            else:
                if file_path.name == pattern:
                    should_exclude = True
                    break
        
        if not should_exclude:
            filtered_files.append(file_path)
    
    return filtered_files

def parse_gnn_file(file_path: Union[str, Path]) -> Dict[str, Any]:
    """
    Parse a GNN file and extract basic information.
    
    Args:
        file_path: Path to the GNN file
        
    Returns:
        Dictionary with parsed information
    """
    file_path = Path(file_path)
    
    try:
        with open(file_path, 'r') as f:
            content = f.read()
        
        # Extract basic information
        sections = _extract_sections_lightweight(content)
        variables = _extract_variables_lightweight(content)
        
        # Count lines and characters
        line_count = len(content.splitlines())
        char_count = len(content)
        
        # Basic structure analysis
        structure_info = {
            "has_variables": len(variables) > 0,
            "has_sections": len(sections) > 0,
            "variable_count": len(variables),
            "section_count": len(sections),
            "line_count": line_count,
            "char_count": char_count
        }
        
        return {
            "file_path": str(file_path),
            "file_name": file_path.name,
            "file_size": file_path.stat().st_size,
            "sections": sections,
            "variables": variables,
            "structure_info": structure_info,
            "parse_timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            "file_path": str(file_path),
            "file_name": file_path.name,
            "error": str(e),
            "parse_timestamp": datetime.now().isoformat()
        }

def validate_gnn_structure(file_path: Union[str, Path]) -> Dict[str, Any]:
    """
    Validate the structure of a GNN file.
    
    Args:
        file_path: Path to the GNN file
        
    Returns:
        Dictionary with validation results
    """
    file_path = Path(file_path)
    
    try:
        with open(file_path, 'r') as f:
            content = f.read()
        
        validation_result = {
            "file_path": str(file_path),
            "file_name": file_path.name,
            "valid": True,
            "errors": [],
            "warnings": [],
            "validation_timestamp": datetime.now().isoformat()
        }
        
        # Basic validation checks
        if len(content.strip()) == 0:
            validation_result["valid"] = False
            validation_result["errors"].append("File is empty")
        
        # Check for minimum content
        if len(content) < 10:
            validation_result["warnings"].append("File content is very short")
        
        # Check for basic GNN structure
        sections = _extract_sections_lightweight(content)
        variables = _extract_variables_lightweight(content)
        
        if len(sections) == 0 and len(variables) == 0:
            validation_result["warnings"].append("No clear GNN structure detected")
        
        # Check for common issues
        if content.count('{') != content.count('}'):
            validation_result["warnings"].append("Unmatched braces detected")
        
        if content.count('[') != content.count(']'):
            validation_result["warnings"].append("Unmatched brackets detected")
        
        return validation_result
        
    except Exception as e:
        return {
            "file_path": str(file_path),
            "file_name": file_path.name,
            "valid": False,
            "errors": [str(e)],
            "warnings": [],
            "validation_timestamp": datetime.now().isoformat()
        }

def process_gnn_directory(directory: Union[str, Path], recursive: bool = True, parallel: bool = False) -> Dict[str, Any]:
    """
    Process all GNN files in a directory.
    
    Args:
        directory: Directory to process
        recursive: Whether to process subdirectories
        parallel: Whether to use parallel processing (not implemented in lightweight version)
        
    Returns:
        Dictionary with processing results
    """
    return process_gnn_directory_lightweight(directory, recursive=recursive)

def generate_gnn_report(processing_results: Dict[str, Any], output_path: Union[str, Path] = None) -> str:
    """
    Generate a report from GNN processing results.
    
    Args:
        processing_results: Results from GNN processing
        output_path: Optional path to save the report
        
    Returns:
        Report content as string
    """
    report = f"""
# GNN Processing Report

**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Processing Summary
- **Target Directory**: {processing_results.get('target_directory', 'Unknown')}
- **Files Found**: {processing_results.get('files_found', 0)}
- **Files Processed**: {processing_results.get('files_processed', 0)}
- **Success**: {processing_results.get('success', False)}
- **Errors**: {len(processing_results.get('errors', []))}

## File Analysis
"""
    
    parsed_files = processing_results.get('parsed_files', [])
    if parsed_files:
        report += f"\n### Parsed Files ({len(parsed_files)})\n"
        for file_info in parsed_files:
            report += f"- **{file_info.get('file_name', 'Unknown')}**\n"
            report += f"  - Variables: {file_info.get('structure_info', {}).get('variable_count', 0)}\n"
            report += f"  - Sections: {file_info.get('structure_info', {}).get('section_count', 0)}\n"
            report += f"  - Lines: {file_info.get('structure_info', {}).get('line_count', 0)}\n"
    
    validation_results = processing_results.get('validation_results', [])
    if validation_results:
        valid_count = sum(1 for result in validation_results if result.get('valid', False))
        report += f"\n### Validation Results\n"
        report += f"- Valid Files: {valid_count}/{len(validation_results)}\n"
        
        invalid_files = [r for r in validation_results if not r.get('valid', False)]
        if invalid_files:
            report += f"- Invalid Files: {len(invalid_files)}\n"
            for result in invalid_files[:5]:  # Show first 5
                report += f"  - {result.get('file_name', 'Unknown')}: {', '.join(result.get('errors', []))}\n"
    
    errors = processing_results.get('errors', [])
    if errors:
        report += f"\n### Errors\n"
        for error in errors[:10]:  # Show first 10
            if isinstance(error, dict):
                report += f"- **{error.get('file', 'Unknown')}**: {error.get('error', 'Unknown error')}\n"
            else:
                report += f"- {error}\n"
    
    return report

def get_module_info():
    """Get information about the GNN module."""
    return {
        "name": "GNN Module",
        "version": "1.0.0",
        "description": "GNN file discovery, parsing, and validation",
        "features": [
            "GNN file discovery",
            "Lightweight parsing",
            "Structure validation",
            "Report generation"
        ],
        "supported_formats": ["Markdown", "GNN", "Text"],
        "capabilities": {
            "file_discovery": True,
            "content_parsing": True,
            "structure_validation": True,
            "report_generation": True
        }
    }
