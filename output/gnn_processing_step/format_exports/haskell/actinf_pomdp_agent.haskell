-- GNN Model: Classic Active Inference POMDP Agent v1
-- Generated from GNN markdown

data Variable = Variable
  { name :: String
  , type_ :: String
  , dimensions :: [Int]
  , description :: String
  } deriving (Show, Eq)

data Connection = Connection
  { source :: String
  , target :: String
  , type_ :: String
  , description :: String
  } deriving (Show, Eq)

data Parameter = Parameter
  { name :: String
  , value :: String
  , description :: String
  } deriving (Show, Eq)

data GNNModel = GNNModel
  { modelName :: String
  , version :: String
  , annotation :: String
  , variables :: [Variable]
  , connections :: [Connection]
  , parameters :: [Parameter]
  } deriving (Show, Eq)

model :: GNNModel
model = GNNModel
  { modelName = "Classic Active Inference POMDP Agent v1"
  , version = "1.0"
  , annotation = "This model describes a classic Active Inference agent for a discrete POMDP:
- One observation modality ("state_observation") with 3 possible outcomes.
- One hidden state factor ("location") with 3 possible states.
- The hidden state is fully controllable via 3 discrete actions.
- The agent's preferences are encoded as log-probabilities over observations.
- The agent has an initial policy prior (habit) encoded as log-probabilities over actions."
  , variables = [
      Variable "A" "parameter_matrix" [3, 3] "Likelihood mapping hidden states to observations"
      Variable "B" "parameter_matrix" [3, 3, 3] "State transitions given previous state and action"
      Variable "C" "parameter_matrix" [3] "Log-preferences over observations"
      Variable "D" "parameter_matrix" [3] "Prior over initial hidden states"
      Variable "E" "parameter_matrix" [3] "Initial policy prior (habit) over actions"
      Variable "s" "hidden_state" [3, 1] "Current hidden state distribution"
      Variable "s_prime" "hidden_state" [3, 1] "Next hidden state distribution"
      Variable "o" "observation" [3, 1] "Current observation (integer index)"
      Variable "π" "hidden_state" [3] "Policy (distribution over actions), no planning"
      Variable "u" "action" [1] "Action taken"
      Variable "G" "hidden_state" [] "Expected Free Energy (per policy)"
      Variable "t" "hidden_state" [1] "Discrete time step"
    ]
  , connections = [
      Connection "D" "s" "directed" ""
      Connection "s" "A" "undirected" ""
      Connection "s" "s_prime" "directed" ""
      Connection "A" "o" "undirected" ""
      Connection "s" "B" "undirected" ""
      Connection "C" "G" "directed" ""
      Connection "E" "π" "directed" ""
      Connection "G" "π" "directed" ""
      Connection "π" "u" "directed" ""
      Connection "B" "u" "directed" ""
      Connection "u" "s_prime" "directed" ""
    ]
  , parameters = [
      Parameter "A" "{" ""
      Parameter "B" "{" ""
      Parameter "C" "(0.1, 0.1, 1.0)" ""
      Parameter "D" "(0.33333, 0.33333, 0.33333)" ""
      Parameter "E" "(0.33333, 0.33333, 0.33333)" ""
    ]
  }
