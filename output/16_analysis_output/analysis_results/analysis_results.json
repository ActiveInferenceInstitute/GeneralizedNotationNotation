{
  "timestamp": "2026-01-07T11:31:30.764076",
  "processed_files": 1,
  "success": true,
  "errors": [],
  "statistical_analysis": [
    {
      "file_path": "input/gnn_files/actinf_pomdp_agent.md",
      "file_name": "actinf_pomdp_agent.md",
      "file_size": 4244,
      "line_count": 129,
      "variables": [
        {
          "name": "Example",
          "definition": "Example: Active",
          "line": 1,
          "type": "Active"
        },
        {
          "name": "Version",
          "definition": "Version: 1",
          "line": 2,
          "type": "1"
        },
        {
          "name": "matrix",
          "definition": "matrix: A",
          "line": 23,
          "type": "A"
        },
        {
          "name": "matrix",
          "definition": "matrix: B",
          "line": 26,
          "type": "B"
        },
        {
          "name": "vector",
          "definition": "vector: C",
          "line": 29,
          "type": "C"
        },
        {
          "name": "vector",
          "definition": "vector: D",
          "line": 32,
          "type": "D"
        },
        {
          "name": "vector",
          "definition": "vector: E",
          "line": 35,
          "type": "E"
        },
        {
          "name": "A",
          "definition": "A: 3",
          "line": 68,
          "type": "3"
        },
        {
          "name": "B",
          "definition": "B: 3",
          "line": 75,
          "type": "3"
        },
        {
          "name": "C",
          "definition": "C: 3",
          "line": 82,
          "type": "3"
        },
        {
          "name": "D",
          "definition": "D: 3",
          "line": 85,
          "type": "3"
        },
        {
          "name": "E",
          "definition": "E: 3",
          "line": 88,
          "type": "3"
        },
        {
          "name": "posterior",
          "definition": "posterior: action",
          "line": 95,
          "type": "action"
        },
        {
          "name": "num_hidden_states",
          "definition": "num_hidden_states: 3",
          "line": 120,
          "type": "3"
        },
        {
          "name": "num_obs",
          "definition": "num_obs: 3",
          "line": 121,
          "type": "3"
        },
        {
          "name": "num_actions",
          "definition": "num_actions: 3",
          "line": 122,
          "type": "3"
        },
        {
          "name": "type",
          "definition": "type=float]   # Likelihood mapping hidden states to observations",
          "line": 24,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=float]   # State transitions given previous state and action",
          "line": 27,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=float]       # Log-preferences over observations",
          "line": 30,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=float]       # Prior over initial hidden states",
          "line": 33,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=float]       # Initial policy prior (habit) over actions",
          "line": 36,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=float]     # Current hidden state distribution",
          "line": 39,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=float] # Next hidden state distribution",
          "line": 40,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=float]       # Variational Free Energy for belief updating from observations",
          "line": 41,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=int]     # Current observation (integer index)",
          "line": 44,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=float]       # Policy (distribution over actions), no planning",
          "line": 47,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=int]         # Action taken",
          "line": 48,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=float]       # Expected Free Energy (per policy)",
          "line": 49,
          "type": "unknown"
        },
        {
          "name": "type",
          "definition": "type=int]         # Discrete time step",
          "line": 52,
          "type": "unknown"
        },
        {
          "name": "A",
          "definition": "A={",
          "line": 69,
          "type": "unknown"
        },
        {
          "name": "B",
          "definition": "B={",
          "line": 76,
          "type": "unknown"
        },
        {
          "name": "C",
          "definition": "C={(0.1, 0.1, 1.0)}",
          "line": 83,
          "type": "unknown"
        },
        {
          "name": "D",
          "definition": "D={(0.33333, 0.33333, 0.33333)}",
          "line": 86,
          "type": "unknown"
        },
        {
          "name": "E",
          "definition": "E={(0.33333, 0.33333, 0.33333)}",
          "line": 89,
          "type": "unknown"
        },
        {
          "name": "Energy",
          "definition": "Energy = with infer_policies()",
          "line": 94,
          "type": "unknown"
        },
        {
          "name": "action",
          "definition": "action = sample_action()",
          "line": 95,
          "type": "unknown"
        },
        {
          "name": "Time",
          "definition": "Time=t",
          "line": 99,
          "type": "unknown"
        },
        {
          "name": "ModelTimeHorizon",
          "definition": "ModelTimeHorizon=Unbounded # The agent is defined for an unbounded time horizon",
          "line": 102,
          "type": "unknown"
        },
        {
          "name": "A",
          "definition": "A=LikelihoodMatrix",
          "line": 105,
          "type": "unknown"
        },
        {
          "name": "B",
          "definition": "B=TransitionMatrix",
          "line": 106,
          "type": "unknown"
        },
        {
          "name": "C",
          "definition": "C=LogPreferenceVector",
          "line": 107,
          "type": "unknown"
        },
        {
          "name": "D",
          "definition": "D=PriorOverHiddenStates",
          "line": 108,
          "type": "unknown"
        },
        {
          "name": "E",
          "definition": "E=Habit",
          "line": 109,
          "type": "unknown"
        },
        {
          "name": "F",
          "definition": "F=VariationalFreeEnergy",
          "line": 110,
          "type": "unknown"
        },
        {
          "name": "G",
          "definition": "G=ExpectedFreeEnergy",
          "line": 111,
          "type": "unknown"
        },
        {
          "name": "s",
          "definition": "s=HiddenState",
          "line": 112,
          "type": "unknown"
        },
        {
          "name": "s_prime",
          "definition": "s_prime=NextHiddenState",
          "line": 113,
          "type": "unknown"
        },
        {
          "name": "o",
          "definition": "o=Observation",
          "line": 114,
          "type": "unknown"
        },
        {
          "name": "\u03c0",
          "definition": "\u03c0=PolicyVector # Distribution over actions",
          "line": 115,
          "type": "unknown"
        },
        {
          "name": "u",
          "definition": "u=Action       # Chosen action",
          "line": 116,
          "type": "unknown"
        },
        {
          "name": "t",
          "definition": "t=Time",
          "line": 117,
          "type": "unknown"
        },
        {
          "name": "actions_dim",
          "definition": "actions_dim=3 (controlled by \u03c0)",
          "line": 122,
          "type": "unknown"
        },
        {
          "name": "A",
          "definition": "A[observation_outcomes, hidden_states]",
          "line": 23,
          "type": "unknown"
        },
        {
          "name": "A",
          "definition": "A[3,3,type=float]",
          "line": 24,
          "type": "unknown"
        },
        {
          "name": "B",
          "definition": "B[states_next, states_previous, actions]",
          "line": 26,
          "type": "unknown"
        },
        {
          "name": "B",
          "definition": "B[3,3,3,type=float]",
          "line": 27,
          "type": "unknown"
        },
        {
          "name": "C",
          "definition": "C[observation_outcomes]",
          "line": 29,
          "type": "unknown"
        },
        {
          "name": "C",
          "definition": "C[3,type=float]",
          "line": 30,
          "type": "unknown"
        },
        {
          "name": "D",
          "definition": "D[states]",
          "line": 32,
          "type": "unknown"
        },
        {
          "name": "D",
          "definition": "D[3,type=float]",
          "line": 33,
          "type": "unknown"
        },
        {
          "name": "E",
          "definition": "E[actions]",
          "line": 35,
          "type": "unknown"
        },
        {
          "name": "E",
          "definition": "E[3,type=float]",
          "line": 36,
          "type": "unknown"
        },
        {
          "name": "s",
          "definition": "s[3,1,type=float]",
          "line": 39,
          "type": "unknown"
        },
        {
          "name": "s_prime",
          "definition": "s_prime[3,1,type=float]",
          "line": 40,
          "type": "unknown"
        },
        {
          "name": "F",
          "definition": "F[\u03c0,type=float]",
          "line": 41,
          "type": "unknown"
        },
        {
          "name": "o",
          "definition": "o[3,1,type=int]",
          "line": 44,
          "type": "unknown"
        },
        {
          "name": "\u03c0",
          "definition": "\u03c0[3,type=float]",
          "line": 47,
          "type": "unknown"
        },
        {
          "name": "u",
          "definition": "u[1,type=int]",
          "line": 48,
          "type": "unknown"
        },
        {
          "name": "G",
          "definition": "G[\u03c0,type=float]",
          "line": 49,
          "type": "unknown"
        },
        {
          "name": "t",
          "definition": "t[1,type=int]",
          "line": 52,
          "type": "unknown"
        },
        {
          "name": "s",
          "definition": "s[3]",
          "line": 120,
          "type": "unknown"
        },
        {
          "name": "o",
          "definition": "o[3]",
          "line": 121,
          "type": "unknown"
        }
      ],
      "connections": [],
      "sections": [
        {
          "name": "GNN Example: Active Inference POMDP Agent",
          "line": 1
        },
        {
          "name": "GNN Version: 1.0",
          "line": 2
        },
        {
          "name": "This file is machine-readable and specifies a classic Active Inference agent for a discrete POMDP with one observation modality and one hidden state factor. The model is suitable for rendering into various simulation or inference backends.",
          "line": 3
        },
        {
          "name": "GNNSection",
          "line": 5
        },
        {
          "name": "GNNVersionAndFlags",
          "line": 8
        },
        {
          "name": "ModelName",
          "line": 11
        },
        {
          "name": "ModelAnnotation",
          "line": 14
        },
        {
          "name": "StateSpaceBlock",
          "line": 22
        },
        {
          "name": "Likelihood matrix: A[observation_outcomes, hidden_states]",
          "line": 23
        },
        {
          "name": "Transition matrix: B[states_next, states_previous, actions]",
          "line": 26
        },
        {
          "name": "Preference vector: C[observation_outcomes]",
          "line": 29
        },
        {
          "name": "Prior vector: D[states]",
          "line": 32
        },
        {
          "name": "Habit vector: E[actions]",
          "line": 35
        },
        {
          "name": "Hidden State",
          "line": 38
        },
        {
          "name": "Observation",
          "line": 43
        },
        {
          "name": "Policy and Control",
          "line": 46
        },
        {
          "name": "Time",
          "line": 51
        },
        {
          "name": "Connections",
          "line": 54
        },
        {
          "name": "InitialParameterization",
          "line": 67
        },
        {
          "name": "A: 3 observations x 3 hidden states. Identity mapping (each state deterministically produces a unique observation). Rows are observations, columns are hidden states.",
          "line": 68
        },
        {
          "name": "B: 3 states x 3 previous states x 3 actions. Each action deterministically moves to a state. For each slice, rows are previous states, columns are next states. Each slice is a transition matrix corresponding to a different action selection.",
          "line": 75
        },
        {
          "name": "C: 3 observations. Preference in terms of log-probabilities over observations.",
          "line": 82
        },
        {
          "name": "D: 3 states. Uniform prior over hidden states. Rows are hidden states, columns are prior probabilities.",
          "line": 85
        },
        {
          "name": "E: 3 actions. Uniform habit used as initial policy prior.",
          "line": 88
        },
        {
          "name": "Equations",
          "line": 91
        },
        {
          "name": "Standard Active Inference update equations for POMDPs:",
          "line": 92
        },
        {
          "name": "- State inference using Variational Free Energy with infer_states()",
          "line": 93
        },
        {
          "name": "- Policy inference using Expected Free Energy = with infer_policies()",
          "line": 94
        },
        {
          "name": "- Action selection from policy posterior: action = sample_action()",
          "line": 95
        },
        {
          "name": "- Belief updating using Variational Free Energy with update_beliefs()",
          "line": 96
        },
        {
          "name": "Time",
          "line": 98
        },
        {
          "name": "ActInfOntologyAnnotation",
          "line": 104
        },
        {
          "name": "ModelParameters",
          "line": 119
        },
        {
          "name": "Footer",
          "line": 124
        },
        {
          "name": "Signature",
          "line": 128
        }
      ],
      "variable_statistics": {
        "count": 72,
        "types": {
          "Active": 1,
          "1": 1,
          "A": 1,
          "B": 1,
          "C": 1,
          "D": 1,
          "E": 1,
          "3": 8,
          "action": 1,
          "unknown": 56
        },
        "average_line": 66.22222222222223,
        "line_std": 36.27067311747966
      },
      "connection_statistics": {
        "count": 0,
        "average_line": 0
      },
      "section_statistics": {
        "count": 35,
        "average_line": 58.34285714285714,
        "line_std": 38.630811431249214
      },
      "distributions": {
        "variable_distribution": {
          "mean": 66.22222222222223,
          "std": 36.27067311747966,
          "min": 1,
          "max": 122,
          "median": 50.5
        },
        "connection_distribution": {},
        "complexity_metrics": {
          "total_elements": 72,
          "variable_complexity": 72,
          "connection_complexity": 0,
          "density": 0.0,
          "cyclomatic_complexity": -70
        }
      },
      "correlations": {
        "variable_connection_correlation": 0.0,
        "line_position_correlation": 0.0
      },
      "analysis_timestamp": "2026-01-07T11:31:30.768509"
    }
  ],
  "complexity_metrics": [
    {
      "file_path": "input/gnn_files/actinf_pomdp_agent.md",
      "file_name": "actinf_pomdp_agent.md",
      "cyclomatic_complexity": -70,
      "cognitive_complexity": 36.0,
      "structural_complexity": 21.599999999999998,
      "maintainability_index": 100.0,
      "technical_debt": 5.2,
      "analysis_timestamp": "2026-01-07T11:31:30.770607"
    }
  ],
  "performance_benchmarks": [
    {
      "file_path": "input/gnn_files/actinf_pomdp_agent.md",
      "file_name": "actinf_pomdp_agent.md",
      "parse_time": 4.236,
      "memory_usage": 423.6,
      "complexity_score": 72,
      "estimated_runtime": 0.0,
      "benchmark_timestamp": "2026-01-07T11:31:30.772252"
    }
  ],
  "model_comparisons": [],
  "visualization_files": [
    "output/16_analysis_output/analysis_results/framework_success_rates.png"
  ],
  "post_simulation_analysis": [
    {
      "model_name": "actinf_pomdp_agent",
      "analysis_file": "output/16_analysis_output/analysis_results/actinf_pomdp_agent_post_simulation_analysis.json",
      "framework_count": 5,
      "has_comparison": true
    }
  ],
  "overall_statistics": {},
  "framework_comparison": {
    "timestamp": "2026-01-07T11:31:30.776633",
    "frameworks": {
      "jax": {
        "success_count": 1,
        "total_count": 1,
        "execution_times": [],
        "output_files": [
          "output/12_execute_output/actinf_pomdp_agent/jax/execution_logs/Classic Active Inference POMDP Agent v1_jax.py_execution.log"
        ],
        "implementation_dirs": [
          "output/12_execute_output/actinf_pomdp_agent/jax"
        ],
        "beliefs": [],
        "actions": [],
        "observations": [],
        "free_energy": []
      },
      "discopy": {
        "success_count": 1,
        "total_count": 1,
        "execution_times": [],
        "output_files": [
          "output/12_execute_output/actinf_pomdp_agent/discopy/execution_logs/Classic Active Inference POMDP Agent v1_discopy.py_execution.log"
        ],
        "implementation_dirs": [
          "output/12_execute_output/actinf_pomdp_agent/discopy"
        ],
        "beliefs": [],
        "actions": [],
        "observations": [],
        "free_energy": []
      },
      "pymdp_gen": {
        "success_count": 0,
        "total_count": 1,
        "execution_times": [],
        "output_files": [
          "output/12_execute_output/actinf_pomdp_agent/pymdp_gen/execution_logs/Classic Active Inference POMDP Agent v1_pymdp.py_execution.log"
        ],
        "implementation_dirs": [
          "output/12_execute_output/actinf_pomdp_agent/pymdp_gen"
        ],
        "beliefs": [],
        "actions": [],
        "observations": [],
        "free_energy": []
      },
      "rxinfer": {
        "success_count": 1,
        "total_count": 1,
        "execution_times": [],
        "output_files": [
          "output/12_execute_output/actinf_pomdp_agent/rxinfer/execution_logs/Classic Active Inference POMDP Agent v1_rxinfer.jl_execution.log"
        ],
        "implementation_dirs": [
          "output/12_execute_output/actinf_pomdp_agent/rxinfer"
        ],
        "beliefs": [],
        "actions": [],
        "observations": [],
        "free_energy": []
      },
      "activeinference_jl": {
        "success_count": 1,
        "total_count": 1,
        "execution_times": [],
        "output_files": [
          "output/12_execute_output/actinf_pomdp_agent/activeinference_jl/execution_logs/Classic Active Inference POMDP Agent v1_activeinference.jl_execution.log"
        ],
        "implementation_dirs": [
          "output/12_execute_output/actinf_pomdp_agent/activeinference_jl"
        ],
        "beliefs": [],
        "actions": [],
        "observations": [],
        "free_energy": []
      }
    },
    "comparisons": {
      "success_rates": {
        "jax": 1.0,
        "discopy": 1.0,
        "pymdp_gen": 0.0,
        "rxinfer": 1.0,
        "activeinference_jl": 1.0
      },
      "performance_comparison": {},
      "metric_agreement": {}
    },
    "metrics": {
      "total_frameworks": 5,
      "total_successful": 4,
      "total_executions": 5,
      "overall_success_rate": 0.8
    }
  },
  "framework_comparison_report": "output/16_analysis_output/analysis_results/framework_comparison_report.md"
}