{
  "_HeaderComments": "# GNN Example: Active Inference Language Model (AILM)\n# Format: Markdown representation of a comprehensive Active Inference model for language.\n# Version: 0.1\n# This file is machine-readable and outlines a multi-level agent for linguistic processing.",
  "ModelName": "Active Inference Language Model (AILM) v0.1",
  "GNNSection": "ActiveInferenceLanguageModel",
  "GNNVersionAndFlags": "GNN v1",
  "ModelAnnotation": "This model outlines a comprehensive Active Inference agent for language understanding and generation.\nIt attempts to capture nested and interacting levels of linguistic processing, from phonetics to discourse.\nKey features demonstrated:\n- Hierarchical state representation (phonetic, lexical, syntactic, semantic, discourse, contextual).\n- Multiple observation modalities reflecting both external input and internal states.\n- Control factors for linguistic actions (vocalization, lexical choice, intent formation).\n- Complex interplay of likelihoods, transitions, preferences, and policies.\n- Designed as a \"one-shot\" GNN-based blueprint, not reliant on pre-existing training datasets.\n\nThis AILM is an illustrative example due to the inherent vastness of real-world language.\nState spaces and parameterizations are simplified for GNN demonstration.\nIt aims to test the full GNN pipeline's capacity to handle complex, multi-faceted models.\nThis model implies a dynamic system operating over discrete time steps.",
  "StateSpaceBlock": "# --- Hidden State Factors (s_fX) ---\n# Phonetic & Articulatory Level\ns_f0[10,1,type=int]  # Hidden State Factor 0: PhoneticTarget (e.g., current target phoneme category; 10 categories)\ns_f1[5,1,type=int]   # Hidden State Factor 1: ArticulatoryConfiguration (e.g., abstract vocal tract state; 5 configurations)\n\n# Lexical & Morpho-Syntactic Level\ns_f2[50,1,type=int]  # Hidden State Factor 2: ActiveLexicalConceptID (e.g., current word/morpheme being processed/generated; 50 abstract concepts)\ns_f3[8,1,type=int]   # Hidden State Factor 3: CurrentSyntacticRole (e.g., Subject, Verb, Object, Adjunct; 8 roles)\ns_f4[10,1,type=int]  # Hidden State Factor 4: MorphoSyntacticFeatures (e.g., tense, number, gender markers; 10 feature sets)\n\n# Semantic Level\ns_f5[100,1,type=int] # Hidden State Factor 5: SemanticPropositionID (e.g., core meaning/event being conveyed/understood; 100 abstract propositions)\ns_f6[5,1,type=int]   # Hidden State Factor 6: SemanticValence (e.g., positive, negative, neutral sentiment of proposition; 5 valences)\n\n# Situational & Narrative Context Level\ns_f7[10,1,type=int]  # Hidden State Factor 7: SituationalContextKey (e.g., speaker, hearer, location, formality; 10 keys)\ns_f8[20,1,type=int]  # Hidden State Factor 8: NarrativeFocusID (e.g., current topic/theme in discourse; 20 foci)\ns_f9[5,1,type=int]   # Hidden State Factor 9: PartnerModelState (e.g., inferred understanding/attention of interlocutor; 5 states)\n\n# Agent's Internal Goal & Prediction Level\ns_f10[10,1,type=int] # Hidden State Factor 10: CommunicativeIntentID (agent's high-level goal, e.g., inform, query; 10 intents)\ns_f11[20,1,type=int] # Hidden State Factor 11: PredictedNextLexicalConceptID (anticipation of next word; 20 concepts)\n\n# --- Observation Modalities (o_mX) ---\no_m0[20,1,type=int]  # Observation Modality 0: AuditoryStreamSegment (discretized features of incoming/outgoing sound; 20 categories)\no_m1[5,1,type=int]   # Observation Modality 1: SemanticCoherenceSignal (internal assessment of understanding/expression clarity; 5 levels)\no_m2[5,1,type=int]   # Observation Modality 2: DiscourseProgressSignal (e.g., turn-taking cues, topic shift cues; 5 signals)\no_m3[5,1,type=int]   # Observation Modality 3: PartnerFeedbackCue (e.g., facial expression, backchannel; 5 cues)\n\n# --- Control Factors / Policies (pi_cX) & Chosen Actions (u_cX) ---\npi_c0[5,type=float]  # Policy for Control Factor 0: VocalizationEffort (modulates articulatory precision/energy)\nu_c0[1,type=int]     # Chosen action for VocalizationEffort\n\npi_c1[20,type=float] # Policy for Control Factor 1: LexicalEmphasis (choosing next lexical item to focus/generate from s_f11 related space)\nu_c1[1,type=int]     # Chosen action for LexicalEmphasis\n\npi_c2[10,type=float] # Policy for Control Factor 2: IntentRefinement (adjusting/committing to a communicative intent from s_f10 space)\nu_c2[1,type=int]     # Chosen action for IntentRefinement\n\n# --- Likelihood Mappings (A_mX) ---\n# A_mX[outcomes, s_fA_states, s_fB_states, ..., type=dataType]\nA_m0[20,10,5,type=float] # P(o_m0 | s_f0, s_f1) - AuditoryStream likelihood given PhoneticTarget, ArticulatoryConfig\nA_m1[5,100,5,type=float] # P(o_m1 | s_f5, s_f6) - SemanticCoherence likelihood given SemanticProposition, Valence\nA_m2[5,20,5,type=float]  # P(o_m2 | s_f8, s_f9) - DiscourseProgress likelihood given NarrativeFocus, PartnerModel\nA_m3[5,5,type=float]     # P(o_m3 | s_f9) - PartnerFeedback likelihood given PartnerModel\n\n# --- Transition Dynamics (B_fX) ---\n# B_fX[next_states, prev_states, u_c0_actions, u_c1_actions, ..., type=dataType]\n# Phonetic/Articulatory Level Transitions (influenced by VocalizationEffort u_c0)\nB_f0[10,10,5,type=float] # P(s_f0' | s_f0, u_c0)\nB_f1[5,5,5,type=float]   # P(s_f1' | s_f1, u_c0)\n\n# Lexical/Morpho-Syntactic Level Transitions (influenced by LexicalEmphasis u_c1, and other states)\nB_f2[50,50,10,8,20,type=float] # P(s_f2' | s_f2, s_f0, s_f3, u_c1) - ActiveLexicalConcept influenced by prev lexical, phonetic target, syntactic role, lexical emphasis\nB_f3[8,8,50,type=float]        # P(s_f3' | s_f3, s_f2) - SyntacticRole influenced by prev role, current lexical concept\nB_f4[10,10,50,type=float]      # P(s_f4' | s_f4, s_f2) - MorphoSyntacticFeatures influenced by prev features, current lexical concept\n\n# Semantic Level Transitions (influenced by lexical, syntactic, previous semantic states)\nB_f5[100,100,50,8,type=float]  # P(s_f5' | s_f5, s_f2, s_f3) - SemanticProposition influenced by prev proposition, lexical concept, syntactic role\nB_f6[5,5,100,type=float]       # P(s_f6' | s_f6, s_f5) - SemanticValence influenced by prev valence, current proposition\n\n# Context/Narrative Level Transitions (influenced by semantics, partner model, discourse goals)\nB_f7[10,10,5,type=float]       # P(s_f7' | s_f7, s_f9) - SituationalContext influenced by prev context, partner model\nB_f8[20,20,100,10,type=float]  # P(s_f8' | s_f8, s_f5, s_f10) - NarrativeFocus influenced by prev focus, semantic proposition, communicative intent\nB_f9[5,5,5,type=float]         # P(s_f9' | s_f9, o_m3) - PartnerModel influenced by prev state, partner feedback cues\n\n# Goal/Prediction Level Transitions (influenced by high-level states and IntentRefinement u_c2)\nB_f10[10,10,20,10,type=float]  # P(s_f10' | s_f10, s_f8, u_c2) - CommunicativeIntent influenced by prev intent, narrative focus, intent refinement action\nB_f11[20,20,100,10,type=float] # P(s_f11' | s_f11, s_f5, s_f10) - PredictedLexicalConcept influenced by prev prediction, current semantic proposition, communicative intent\n\n# --- Preferences (C_mX) ---\nC_m0[20,type=float] # Preferences over AuditoryStreamSegments (e.g., prefer clear, expected sounds)\nC_m1[5,type=float]  # Preferences over SemanticCoherenceLevels (e.g., prefer high clarity)\nC_m2[5,type=float]  # Preferences over DiscourseProgressSignals (e.g., prefer smooth turn-taking)\nC_m3[5,type=float]  # Preferences over PartnerFeedbackCues (e.g., prefer positive feedback)\n\n# --- Priors over Initial Hidden States (D_fX) ---\nD_f0[10,type=float]  # Prior for PhoneticTarget\nD_f1[5,type=float]   # Prior for ArticulatoryConfiguration\nD_f2[50,type=float]  # Prior for ActiveLexicalConceptID\nD_f3[8,type=float]   # Prior for CurrentSyntacticRole\nD_f4[10,type=float]  # Prior for MorphoSyntacticFeatures\nD_f5[100,type=float] # Prior for SemanticPropositionID\nD_f6[5,type=float]   # Prior for SemanticValence\nD_f7[10,type=float]  # Prior for SituationalContextKey\nD_f8[20,type=float]  # Prior for NarrativeFocusID\nD_f9[5,type=float]   # Prior for PartnerModelState\nD_f10[10,type=float] # Prior for CommunicativeIntentID\nD_f11[20,type=float] # Prior for PredictedLexicalConceptID\n\n# --- Expected Free Energy (G) ---\n# G would be calculated over policies combining pi_c0, pi_c1, pi_c2.\n# For GNN representation, a single G or G per policy factor might be used.\nG[1,type=float]      # Overall Expected Free Energy of chosen combined policy\n\n# --- Time ---\nt[1,type=int]        # Current time step",
  "Connections": "# Priors to initial states (example for a few factors)\n(D_f0, D_f1, D_f2, D_f3, D_f4, D_f5, D_f6, D_f7, D_f8, D_f9, D_f10, D_f11) -> (s_f0, s_f1, s_f2, s_f3, s_f4, s_f5, s_f6, s_f7, s_f8, s_f9, s_f10, s_f11)\n\n# State factors to Likelihoods (A_mX) to Observations (o_mX)\n(s_f0, s_f1) -> A_m0 -> o_m0\n(s_f5, s_f6) -> A_m1 -> o_m1\n(s_f8, s_f9) -> A_m2 -> o_m2\n(s_f9)       -> A_m3 -> o_m3\n\n# States and Actions (u_cX) to Transitions (B_fX) to Next States (s_fX_next - implied)\n# Phonetic/Articulatory\n(s_f0, u_c0) -> B_f0 -> s_f0_next\n(s_f1, u_c0) -> B_f1 -> s_f1_next\n\n# Lexical/Morpho-Syntactic\n(s_f2, s_f0, s_f3, u_c1) -> B_f2 -> s_f2_next\n(s_f3, s_f2)             -> B_f3 -> s_f3_next\n(s_f4, s_f2)             -> B_f4 -> s_f4_next\n\n# Semantic\n(s_f5, s_f2, s_f3) -> B_f5 -> s_f5_next\n(s_f6, s_f5)       -> B_f6 -> s_f6_next\n\n# Context/Narrative\n(s_f7, s_f9)          -> B_f7 -> s_f7_next\n(s_f8, s_f5, s_f10)   -> B_f8 -> s_f8_next\n(s_f9, o_m3)          -> B_f9 -> s_f9_next # Partner model updated by their feedback\n\n# Goal/Prediction\n(s_f10, s_f8, u_c2) -> B_f10 -> s_f10_next\n(s_f11, s_f5, s_f10) -> B_f11 -> s_f11_next\n\n# Preferences, Expected Future States/Observations to Expected Free Energy (G)\n(C_m0, C_m1, C_m2, C_m3, A_m0, A_m1, A_m2, A_m3, B_f0, B_f1, ..., B_f11, s_f0, ..., s_f11) > G # Highly simplified EFE dependency\n\n# EFE to Policies (pi_cX)\nG > (pi_c0, pi_c1, pi_c2)\n\n# Policies to Chosen Actions (u_cX)\n(pi_c0) -> u_c0\n(pi_c1) -> u_c1\n(pi_c2) -> u_c2",
  "InitialParameterization": "# Due to the vastness, parameterizations are conceptual placeholders.\n# Real values would require extensive research or learning.\n# All B matrices need to be column-stochastic (sum to 1 over next_states for each prev_state/action combo).\n# All A matrices need to be column-stochastic (sum to 1 over outcomes for each state combo).\n\n# Priors (D_fX) - Example: Uniform for most, could be specific for some (e.g. initial intent)\nD_f0={(0.1, ..., 0.1)} # Uniform over 10 phonetic targets\nD_f5={(0.01, ..., 0.01)} # Uniform over 100 semantic propositions\nD_f10={(0.5, 0.1, ..., 0.1)} # e.g., high prior on 'inform' intent initially\n\n# Likelihoods (A_mX) - Example for A_m1 (SemanticCoherence)\n# A_m1[clarity_level, proposition_ID, valence_ID]\nA_m1={ # P(o_m1 | s_f5, s_f6) - Highly schematic\n  # Clarity=0 (Very Low)\n  ( ((0.8, ..., 0.8), ... ), ... ), # High prob of low clarity if prop/valence are 'incoherent' (not defined here)\n  # Clarity=4 (Very High)\n  ( ((0.1, ..., 0.1), ... ), ... ) # High prob of high clarity if prop/valence are 'coherent'\n}\n\n# Transitions (B_fX) - Example for B_f0 (PhoneticTarget)\n# B_f0[next_target, prev_target, vocal_effort_action]\nB_f0={ # P(s_f0' | s_f0, u_c0) - Schematic\n  # next_target = 0\n  ( ((0.9, 0.1, ...), (0.8, 0.2, ...), ... ), ...), # Depending on effort, might stay or shift phoneme\n  # ...\n}\n\n# Preferences (C_mX) - Example for C_m1 (SemanticCoherence)\nC_m1={(-2.0, -1.0, 0.0, 1.0, 2.0)} # Prefer high semantic coherence (0-4 scale)",
  "Equations": "# Standard Active Inference equations apply:\n# 1. State Estimation: Approximate posterior over hidden states q(s_t) based on observations o_t and priors.\n#    q(s_t) ~ \u03c3( ln(A^T o_t) + ln(P(s_t|s_{t-1}, u_{t-1})) )\n# 2. Policy Evaluation: Expected Free Energy G(\u03c0) for each policy \u03c0.\n#    G(\u03c0) = E_q(o_\u03c4, s_\u03c4 | \u03c0) [ ln q(s_\u03c4|o_\u03c4,\u03c0) - ln q(s_\u03c4,o_\u03c4|\u03c0) - ln C(o_\u03c4) ] for \u03c4 > t\n# 3. Action Selection: Softmax over negative EFE to choose actions.\n#    P(u_t|\u03c0) ~ \u03c3(-G(\u03c0))",
  "Time": "Dynamic\nDiscreteTime=t\nModelTimeHorizon=100 # Example: an interaction of 100 time steps",
  "ActInfOntologyAnnotation": "# Hidden States\ns_f0=PhoneticRepresentation\ns_f1=ArticulatoryMotorState\ns_f2=LexicalEntry\ns_f3=SyntacticConstituentRole\ns_f4=MorphoSyntacticMarkerSet\ns_f5=SemanticProposition\ns_f6=AffectiveValence\ns_f7=SituationalModelParameter\ns_f8=NarrativeState_TopicFocus\ns_f9=TheoryOfMind_PartnerState\ns_f10=Goal_CommunicativeIntent\ns_f11=Prediction_NextLexicalUnit\n\n# Observations\no_m0=AuditoryObservation\no_m1=InternalObservation_SemanticClarity\no_m2=InternalObservation_DiscourseFlow\no_m3=SocialObservation_PartnerFeedback\n\n# Control/Policy\npi_c0=Policy_VocalizationControl\nu_c0=Action_VocalizationModulation\npi_c1=Policy_LexicalSelectionProcess\nu_c1=Action_SelectNextLexeme\npi_c2=Policy_IntentManagement\nu_c2=Action_UpdateIntent\n\n# Matrices\nA_m0=LikelihoodMatrix_AuditoryStream\nB_f0=TransitionMatrix_PhoneticTarget\nC_m0=LogPreferenceVector_AuditoryStream\nD_f0=PriorDistribution_PhoneticTarget\n# ... (annotations for all A, B, C, D matrices)\n\n# Other\nG=ExpectedFreeEnergy\nt=TimeStep",
  "ModelParameters": "num_hidden_state_factors: 12 # s_f0 to s_f11\ndimensions_hidden_state_factors: [10, 5, 50, 8, 10, 100, 5, 10, 20, 5, 10, 20]\nnum_observation_modalities: 4 # o_m0 to o_m3\ndimensions_observation_modalities: [20, 5, 5, 5]\nnum_control_factors: 3 # pi_c0 to pi_c2\ndimensions_control_factors_actions: [5, 20, 10] # Number of actions for each control factor",
  "Footer": "Active Inference Language Model (AILM) v0.1 - End of Specification.\nThis GNN file provides a structural blueprint. Parameterization is illustrative and requires substantial further work for a functional model.",
  "Signature": "Creator: GNN Example Contributor (AI)\nDate: Current Date\nStatus: Ambitious conceptual example for testing GNN pipeline with complex, hierarchical Active Inference models."
}