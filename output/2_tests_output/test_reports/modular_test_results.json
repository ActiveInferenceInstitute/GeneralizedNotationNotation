{
  "gnn": {
    "success": true,
    "tests_run": 30,
    "tests_passed": 21,
    "tests_failed": 0,
    "tests_skipped": 9,
    "duration": 5.6778857707977295,
    "resource_usage": {
      "memory_mb": 16.9375,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [30 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_import_available \nsrc/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_validation \nsrc/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_error_handling \nsrc/tests/test_gnn_overall.py::TestGNNReporting::test_generate_report \nsrc/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_memory_usage \nsrc/tests/test_gnn_overall.py::TestGNNCoreProcessor::test_gnn_processor_basic_imports \nsrc/tests/test_gnn_parsing.py::TestGNNDiscovery::test_discovery_imports \nsrc/tests/test_gnn_parsing.py::TestMarkdownParser::test_invalid_parsing \nsrc/tests/test_gnn_processing.py::TestGNNParsersSerializers::test_serialize_to_format \n[gw2] [  3%] PASSED src/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_validation \nsrc/tests/test_gnn_validation.py::TestGNNValidation::test_check_consistency \nsrc/tests/test_gnn_validation.py::TestGNNValidation::test_validation_imports \nsrc/tests/test_gnn_parsing.py::TestGNNDiscovery::test_scan_directory_recursive \n[gw4] [  6%] PASSED src/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_memory_usage \n[gw0] [ 10%] SKIPPED src/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_import_available \n[gw1] [ 13%] PASSED src/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_error_handling \nsrc/tests/test_gnn_parsing.py::TestCoqParser::test_valid_parsing \n[gw11] [ 16%] PASSED src/tests/test_gnn_parsing.py::TestCoqParser::test_valid_parsing \nsrc/tests/test_gnn_parsing.py::TestScalaParser::test_valid_parsing \n[gw5] [ 20%] PASSED src/tests/test_gnn_parsing.py::TestMarkdownParser::test_invalid_parsing \n[gw6] [ 23%] PASSED src/tests/test_gnn_parsing.py::TestGNNDiscovery::test_discovery_imports \n[gw7] [ 26%] SKIPPED src/tests/test_gnn_overall.py::TestGNNReporting::test_generate_report \n[gw8] [ 30%] SKIPPED src/tests/test_gnn_parsing.py::TestGNNDiscovery::test_scan_directory_recursive \n[gw10] [ 33%] SKIPPED src/tests/test_gnn_processing.py::TestGNNParsersSerializers::test_serialize_to_format \n[gw9] [ 36%] PASSED src/tests/test_gnn_parsing.py::TestScalaParser::test_valid_parsing \nsrc/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_format_conversion \n[gw2] [ 40%] PASSED src/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_format_conversion \nsrc/tests/test_gnn_overall.py::TestGNNCoreProcessor::test_core_processor_imports \nsrc/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_performance \n[gw1] [ 43%] PASSED src/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_performance \nsrc/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_file_processing \n[gw0] [ 46%] PASSED src/tests/test_gnn_integration.py::TestGNNIntegration::test_gnn_file_processing \nsrc/tests/test_gnn_parsing.py::TestMarkdownParser::test_empty_string \nsrc/tests/test_gnn_processing.py::TestGNNParsersSerializers::test_serializers_imports \n[gw5] [ 50%] PASSED src/tests/test_gnn_parsing.py::TestMarkdownParser::test_empty_string \n[gw11] [ 53%] PASSED src/tests/test_gnn_processing.py::TestGNNParsersSerializers::test_serializers_imports \nsrc/tests/test_gnn_parsing.py::TestGNNDiscovery::test_discover_gnn_files \n[gw6] [ 56%] SKIPPED src/tests/test_gnn_parsing.py::TestGNNDiscovery::test_discover_gnn_files \nsrc/tests/test_gnn_overall.py::TestGNNReporting::test_create_summary \n[gw7] [ 60%] SKIPPED src/tests/test_gnn_overall.py::TestGNNReporting::test_create_summary \nsrc/tests/test_gnn_parsing.py::TestLeanParser::test_valid_parsing \nsrc/tests/test_gnn_processing.py::TestGNNParsersSerializers::test_deserialize_from_format \nsrc/tests/test_gnn_parsing.py::TestMarkdownParser::test_valid_parsing \n[gw13] [ 63%] SKIPPED src/tests/test_gnn_validation.py::TestGNNValidation::test_check_consistency \n[gw10] [ 66%] SKIPPED src/tests/test_gnn_processing.py::TestGNNParsersSerializers::test_deserialize_from_format \nsrc/tests/test_gnn_validation.py::TestGNNSimpleValidator::test_simple_validator_instantiation \n[gw2] [ 70%] PASSED src/tests/test_gnn_validation.py::TestGNNSimpleValidator::test_simple_validator_instantiation \n[gw3] [ 73%] PASSED src/tests/test_gnn_overall.py::TestGNNCoreProcessor::test_gnn_processor_basic_imports \n[gw8] [ 76%] PASSED src/tests/test_gnn_parsing.py::TestMarkdownParser::test_valid_parsing \n[gw4] [ 80%] PASSED src/tests/test_gnn_overall.py::TestGNNCoreProcessor::test_core_processor_imports \n[gw9] [ 83%] PASSED src/tests/test_gnn_parsing.py::TestLeanParser::test_valid_parsing \n[gw12] [ 86%] PASSED src/tests/test_gnn_validation.py::TestGNNValidation::test_validation_imports \nsrc/tests/test_gnn_overall.py::TestGNNReporting::test_reporting_imports \nsrc/tests/test_gnn_validation.py::TestGNNSimpleValidator::test_simple_validation \nsrc/tests/test_gnn_validation.py::TestGNNValidation::test_validate_gnn_model \n[gw12] [ 90%] SKIPPED src/tests/test_gnn_validation.py::TestGNNValidation::test_validate_gnn_model \n[gw3] [ 93%] PASSED src/tests/test_gnn_overall.py::TestGNNReporting::test_reporting_imports \nsrc/tests/test_gnn_validation.py::TestGNNSimpleValidator::test_simple_validator_imports \n[gw13] [ 96%] PASSED src/tests/test_gnn_validation.py::TestGNNSimpleValidator::test_simple_validator_imports \n[gw4] [100%] PASSED src/tests/test_gnn_validation.py::TestGNNSimpleValidator::test_simple_validation \n\n============================= slowest 10 durations =============================\n0.01s call     src/tests/test_gnn_validation.py::TestGNNValidation::test_validation_imports\n0.01s call     src/tests/test_gnn_overall.py::TestGNNCoreProcessor::test_gnn_processor_basic_imports\n0.01s call     src/tests/test_gnn_overall.py::TestGNNCoreProcessor::test_core_processor_imports\n\n(7 durations < 0.005s hidden.  Use -vv to show these durations.)\n======================== 21 passed, 9 skipped in 3.76s =========================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:27:51,239 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:27:51,239 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 0
  },
  "render": {
    "success": true,
    "tests_run": 7,
    "tests_passed": 6,
    "tests_failed": 0,
    "tests_skipped": 1,
    "duration": 5.129417896270752,
    "resource_usage": {
      "memory_mb": 20.21875,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [14 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_render_integration.py::TestRenderIntegration::test_pymdp_rendering \n[gw1] [  7%] PASSED src/tests/test_render_integration.py::TestRenderIntegration::test_pymdp_rendering \nsrc/tests/test_render_integration.py::TestRenderIntegration::test_render_import_available \nsrc/tests/test_render_overall.py::TestRenderTargets::test_render_to_jax_pomdp \nsrc/tests/test_render_integration.py::TestRenderIntegration::test_rxinfer_rendering \n[gw2] [ 14%] PASSED src/tests/test_render_integration.py::TestRenderIntegration::test_rxinfer_rendering \nsrc/tests/test_render_overall.py::TestRenderTargets::test_render_to_discopy_combined \nsrc/tests/test_render_overall.py::TestRenderTargets::test_render_to_rxinfer_toml \nsrc/tests/test_render_overall.py::TestRenderTargets::test_render_to_activeinference_jl \nsrc/tests/test_render_integration.py::TestRenderIntegration::test_jax_rendering \n[gw4] [ 21%] PASSED src/tests/test_render_integration.py::TestRenderIntegration::test_jax_rendering \nsrc/tests/test_render_integration.py::TestRenderIntegration::test_render_memory_usage \n[gw7] [ 28%] PASSED src/tests/test_render_integration.py::TestRenderIntegration::test_render_memory_usage \nsrc/tests/test_render_overall.py::TestRenderTargets::test_render_to_jax \nsrc/tests/test_render_overall.py::TestRenderTargets::test_render_to_discopy \nsrc/tests/test_render_integration.py::TestRenderIntegration::test_render_performance \n[gw5] [ 35%] PASSED src/tests/test_render_integration.py::TestRenderIntegration::test_render_performance \nsrc/tests/test_render_integration.py::TestRenderIntegration::test_render_error_handling \n[gw3] [ 42%] PASSED src/tests/test_render_integration.py::TestRenderIntegration::test_render_error_handling \n[gw13] [ 50%] ERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_jax_pomdp \n[gw11] [ 57%] ERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_activeinference_jl \n[gw9] [ 64%] ERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_discopy \n[gw10] [ 71%] ERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_discopy_combined \nsrc/tests/test_render_overall.py::TestRenderTargets::test_render_to_pymdp \n[gw6] [ 78%] ERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_pymdp \n[gw8] [ 85%] ERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_rxinfer_toml \n[gw12] [ 92%] ERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_jax \n[gw0] [100%] SKIPPED src/tests/test_render_integration.py::TestRenderIntegration::test_render_import_available \n\n==================================== ERRORS ====================================\n_________ ERROR at setup of TestRenderTargets.test_render_to_jax_pomdp _________\n[gw13] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py, line 105\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_render_to_jax_pomdp(self, tmp_path, sample_gnn_spec, mock_render_module):\nE       fixture 'sample_gnn_spec' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py:105\n____ ERROR at setup of TestRenderTargets.test_render_to_activeinference_jl _____\n[gw11] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py, line 79\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_render_to_activeinference_jl(self, tmp_path, sample_gnn_spec, mock_render_module):\nE       fixture 'sample_gnn_spec' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py:79\n__________ ERROR at setup of TestRenderTargets.test_render_to_discopy __________\n[gw9] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py, line 53\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_render_to_discopy(self, tmp_path, sample_gnn_spec, mock_render_module):\nE       fixture 'sample_gnn_spec' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py:53\n_____ ERROR at setup of TestRenderTargets.test_render_to_discopy_combined ______\n[gw10] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py, line 66\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_render_to_discopy_combined(self, tmp_path, sample_gnn_spec, mock_render_module):\nE       fixture 'sample_gnn_spec' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py:66\n___________ ERROR at setup of TestRenderTargets.test_render_to_pymdp ___________\n[gw6] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py, line 24\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_render_to_pymdp(self, tmp_path, sample_gnn_spec, mock_render_module):\nE       fixture 'sample_gnn_spec' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py:24\n_______ ERROR at setup of TestRenderTargets.test_render_to_rxinfer_toml ________\n[gw8] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py, line 40\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_render_to_rxinfer_toml(self, tmp_path, sample_gnn_spec, mock_render_module):\nE       fixture 'sample_gnn_spec' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py:40\n____________ ERROR at setup of TestRenderTargets.test_render_to_jax ____________\n[gw12] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py, line 92\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_render_to_jax(self, tmp_path, sample_gnn_spec, mock_render_module):\nE       fixture 'sample_gnn_spec' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_render_overall.py:92\n============================= slowest 10 durations =============================\n0.01s call     src/tests/test_render_integration.py::TestRenderIntegration::test_render_import_available\n\n(9 durations < 0.005s hidden.  Use -vv to show these durations.)\n=========================== short test summary info ============================\nERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_jax_pomdp\nERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_activeinference_jl\nERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_discopy\nERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_discopy_combined\nERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_pymdp\nERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_rxinfer_toml\nERROR src/tests/test_render_overall.py::TestRenderTargets::test_render_to_jax\n==================== 6 passed, 1 skipped, 7 errors in 3.39s ====================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:27:56,737 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:27:56,737 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 1
  },
  "mcp": {
    "success": true,
    "tests_run": 26,
    "tests_passed": 17,
    "tests_failed": 0,
    "tests_skipped": 9,
    "duration": 5.186394929885864,
    "resource_usage": {
      "memory_mb": 21.09375,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [32 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_import_available \nsrc/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_response_format \nsrc/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_concurrent_operations \nsrc/tests/test_mcp_overall.py::TestMCPErrorHandling::test_invalid_tool_execution \nsrc/tests/test_mcp_tools.py::TestMCPToolExecution::test_export_tool_execution \nsrc/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_server_instantiation \nsrc/tests/test_mcp_overall.py::TestMCPCoreComprehensive::test_mcp_core_imports \nsrc/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_instance_retrieval \nsrc/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_tools_registration \nsrc/tests/test_mcp_transport.py::TestMCPTransportLayers::test_websocket_server_imports \n[gw1] [  3%] PASSED src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_response_format \nsrc/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_performance \n[gw4] [  6%] PASSED src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_performance \nsrc/tests/test_mcp_overall.py::TestMCPResourceManagement::test_mcp_resource_registration \nsrc/tests/test_mcp_transport.py::TestMCPTransportLayers::test_stdio_server_imports \nsrc/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_transport_layer \n[gw2] [  9%] PASSED src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_transport_layer \nsrc/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_error_handling \n[gw1] [ 12%] PASSED src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_error_handling \nsrc/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_message_format \n[gw10] [ 15%] ERROR src/tests/test_mcp_tools.py::TestMCPToolExecution::test_export_tool_execution \nsrc/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_memory_usage \n[gw2] [ 18%] PASSED src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_message_format \n[gw6] [ 21%] ERROR src/tests/test_mcp_overall.py::TestMCPErrorHandling::test_invalid_tool_execution \n[gw7] [ 25%] ERROR src/tests/test_mcp_overall.py::TestMCPResourceManagement::test_mcp_resource_registration \n[gw4] [ 28%] PASSED src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_memory_usage \n[gw8] [ 31%] PASSED src/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_tools_registration \n[gw12] [ 34%] PASSED src/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_instance_retrieval \nsrc/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_module_imports \n[gw9] [ 37%] PASSED src/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_server_instantiation \nsrc/tests/test_mcp_tools.py::TestMCPToolExecution::test_utils_system_info_execution \n[gw10] [ 40%] ERROR src/tests/test_mcp_tools.py::TestMCPToolExecution::test_utils_system_info_execution \nsrc/tests/test_mcp_transport.py::TestMCPTransportIntegration::test_transport_with_tools \nsrc/tests/test_mcp_transport.py::TestMCPTransportFunctionality::test_transport_cleanup \n[gw11] [ 43%] PASSED src/tests/test_mcp_transport.py::TestMCPTransportLayers::test_stdio_server_imports \nsrc/tests/test_mcp_overall.py::TestMCPErrorHandling::test_tool_execution_with_invalid_parameters \n[gw6] [ 46%] ERROR src/tests/test_mcp_overall.py::TestMCPErrorHandling::test_tool_execution_with_invalid_parameters \n[gw0] [ 50%] SKIPPED src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_import_available \n[gw5] [ 53%] PASSED src/tests/test_mcp_overall.py::TestMCPCoreComprehensive::test_mcp_core_imports \nsrc/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_initialization \n[gw8] [ 56%] PASSED src/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_initialization \nsrc/tests/test_mcp_transport.py::TestMCPTransportFunctionality::test_transport_configuration \nsrc/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_module_info \n[gw13] [ 59%] SKIPPED src/tests/test_mcp_transport.py::TestMCPTransportLayers::test_websocket_server_imports \nsrc/tests/test_mcp_tools.py::TestMCPToolExecution::test_gnn_validate_tool_execution \n[gw9] [ 62%] SKIPPED src/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_module_info \n[gw12] [ 65%] ERROR src/tests/test_mcp_tools.py::TestMCPToolExecution::test_gnn_validate_tool_execution \n[gw1] [ 68%] SKIPPED src/tests/test_mcp_transport.py::TestMCPTransportFunctionality::test_transport_configuration \n[gw2] [ 71%] SKIPPED src/tests/test_mcp_transport.py::TestMCPTransportIntegration::test_transport_with_tools \n[gw7] [ 75%] PASSED src/tests/test_mcp_overall.py::TestMCPModuleComprehensive::test_mcp_module_imports \nsrc/tests/test_mcp_overall.py::TestMCPErrorHandling::test_mcp_error_classes \n[gw5] [ 78%] PASSED src/tests/test_mcp_overall.py::TestMCPErrorHandling::test_mcp_error_classes \nsrc/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_tool_registration \n[gw0] [ 81%] PASSED src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_tool_registration \n[gw4] [ 84%] SKIPPED src/tests/test_mcp_transport.py::TestMCPTransportFunctionality::test_transport_cleanup \nsrc/tests/test_mcp_transport.py::TestMCPTransportLayers::test_tcp_server_imports \n[gw11] [ 87%] SKIPPED src/tests/test_mcp_transport.py::TestMCPTransportLayers::test_tcp_server_imports \nsrc/tests/test_mcp_transport.py::TestMCPTransportIntegration::test_transport_error_handling \nsrc/tests/test_mcp_transport.py::TestMCPTransportFunctionality::test_transport_initialization \n[gw13] [ 90%] SKIPPED src/tests/test_mcp_transport.py::TestMCPTransportFunctionality::test_transport_initialization \n[gw1] [ 93%] SKIPPED src/tests/test_mcp_transport.py::TestMCPTransportIntegration::test_transport_error_handling \n[gw3] [ 96%] PASSED src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_concurrent_operations \nsrc/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_validation \n[gw3] [100%] PASSED src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_validation \n\n==================================== ERRORS ====================================\n______ ERROR at setup of TestMCPToolExecution.test_export_tool_execution _______\n[gw10] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_tools.py, line 46\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_export_tool_execution(self, mock_mcp_tools, comprehensive_test_data):\nE       fixture 'mock_mcp_tools' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_tools.py:46\n______ ERROR at setup of TestMCPErrorHandling.test_invalid_tool_execution ______\n[gw6] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_overall.py, line 65\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_invalid_tool_execution(self, mock_mcp_tools):\nE       fixture 'mock_mcp_tools' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_overall.py:65\n__ ERROR at setup of TestMCPResourceManagement.test_mcp_resource_registration __\n[gw7] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_overall.py, line 103\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_mcp_resource_registration(self, mock_mcp_tools):\nE       fixture 'mock_mcp_tools' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_overall.py:103\n___ ERROR at setup of TestMCPToolExecution.test_utils_system_info_execution ____\n[gw10] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_tools.py, line 68\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_utils_system_info_execution(self, mock_mcp_tools):\nE       fixture 'mock_mcp_tools' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_tools.py:68\n_ ERROR at setup of TestMCPErrorHandling.test_tool_execution_with_invalid_parameters _\n[gw6] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_overall.py, line 79\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_tool_execution_with_invalid_parameters(self, mock_mcp_tools):\nE       fixture 'mock_mcp_tools' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_overall.py:79\n___ ERROR at setup of TestMCPToolExecution.test_gnn_validate_tool_execution ____\n[gw12] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_tools.py, line 24\n      @pytest.mark.unit\n      @pytest.mark.safe_to_fail\n      def test_gnn_validate_tool_execution(self, mock_mcp_tools, comprehensive_test_data):\nE       fixture 'mock_mcp_tools' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_mcp_tools.py:24\n============================= slowest 10 durations =============================\n0.01s call     src/tests/test_mcp_integration.py::TestMCPIntegration::test_mcp_concurrent_operations\n0.01s call     src/tests/test_mcp_overall.py::TestMCPCoreComprehensive::test_mcp_core_imports\n\n(8 durations < 0.005s hidden.  Use -vv to show these durations.)\n=========================== short test summary info ============================\nERROR src/tests/test_mcp_tools.py::TestMCPToolExecution::test_export_tool_execution\nERROR src/tests/test_mcp_overall.py::TestMCPErrorHandling::test_invalid_tool_execution\nERROR src/tests/test_mcp_overall.py::TestMCPResourceManagement::test_mcp_resource_registration\nERROR src/tests/test_mcp_tools.py::TestMCPToolExecution::test_utils_system_info_execution\nERROR src/tests/test_mcp_overall.py::TestMCPErrorHandling::test_tool_execution_with_invalid_parameters\nERROR src/tests/test_mcp_tools.py::TestMCPToolExecution::test_gnn_validate_tool_execution\n=================== 17 passed, 9 skipped, 6 errors in 3.42s ====================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:28:01,892 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:28:01,893 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 1
  },
  "audio": {
    "success": true,
    "tests_run": 37,
    "tests_passed": 27,
    "tests_failed": 0,
    "tests_skipped": 10,
    "duration": 5.682372093200684,
    "resource_usage": {
      "memory_mb": 21.21875,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [37 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_audio_integration.py::TestAudioIntegration::test_audio_backend_integration \nsrc/tests/test_audio_integration.py::TestAudioIntegration::test_audio_file_processing_integration \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_audio_parameter_validation \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_audio_backend_selection \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_audio_quality_metrics \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_pedalboard_audio_generation \n[gw2] [  2%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_pedalboard_audio_generation \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_audio_performance \nsrc/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_audio_module_imports \n[gw5] [  5%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_backend_selection \nsrc/tests/test_audio_overall.py::TestAudioProcessing::test_audio_generation \nsrc/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_audio_module_info \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_audio_import_available \n[gw0] [  8%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_import_available \nsrc/tests/test_audio_overall.py::TestAudioProcessing::test_gnn_to_audio_conversion \n[gw3] [ 10%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_quality_metrics \nsrc/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_sapf_processor_instantiation \n[gw7] [ 13%] SKIPPED src/tests/test_audio_integration.py::TestAudioIntegration::test_audio_backend_integration \n[gw11] [ 16%] PASSED src/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_audio_module_info \nsrc/tests/test_audio_integration.py::TestAudioIntegration::test_audio_module_imports \n[gw6] [ 18%] PASSED src/tests/test_audio_integration.py::TestAudioIntegration::test_audio_module_imports \n[gw1] [ 21%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_parameter_validation \n[gw10] [ 24%] PASSED src/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_sapf_processor_instantiation \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_audio_format_conversion \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_audio_concurrent_generation \n[gw9] [ 27%] PASSED src/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_audio_module_imports \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_audio_file_operations \n[gw8] [ 29%] SKIPPED src/tests/test_audio_integration.py::TestAudioIntegration::test_audio_file_processing_integration \n[gw2] [ 32%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_format_conversion \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_sapf_audio_generation \n[gw0] [ 35%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_sapf_audio_generation \n[gw3] [ 37%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_file_operations \nsrc/tests/test_audio_integration.py::TestAudioIntegration::test_audio_mcp_integration \nsrc/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_audio_generation_options \n[gw11] [ 40%] PASSED src/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_audio_generation_options \n[gw7] [ 43%] PASSED src/tests/test_audio_integration.py::TestAudioIntegration::test_audio_mcp_integration \nsrc/tests/test_audio_integration.py::TestAudioIntegration::test_audio_pipeline_integration \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_audio_error_handling \n[gw1] [ 45%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_error_handling \nsrc/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_pedalboard_processor_instantiation \nsrc/tests/test_audio_integration.py::TestAudioIntegration::test_audio_quality_validation_integration \nsrc/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_audio_generator_instantiation \n[gw10] [ 48%] PASSED src/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_pedalboard_processor_instantiation \n[gw8] [ 51%] SKIPPED src/tests/test_audio_integration.py::TestAudioIntegration::test_audio_quality_validation_integration \n[gw6] [ 54%] SKIPPED src/tests/test_audio_integration.py::TestAudioIntegration::test_audio_pipeline_integration \nsrc/tests/test_audio_overall.py::TestAudioIntegration::test_audio_mcp_integration \n[gw2] [ 56%] PASSED src/tests/test_audio_overall.py::TestAudioIntegration::test_audio_mcp_integration \nsrc/tests/test_audio_sapf.py::TestSAPFCodeValidation::test_validate_sapf_code_invalid \nsrc/tests/test_audio_sapf.py::TestSAPFStandaloneFunctions::test_convert_gnn_to_sapf_function \nsrc/tests/test_audio_overall.py::test_audio_module_performance \n[gw9] [ 59%] PASSED src/tests/test_audio_overall.py::TestAudioModuleComprehensive::test_audio_generator_instantiation \n[gw4] [ 62%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_performance \nsrc/tests/test_audio_sapf.py::TestSAPFCodeValidation::test_validate_sapf_code_valid \n[gw3] [ 64%] SKIPPED src/tests/test_audio_sapf.py::TestSAPFCodeValidation::test_validate_sapf_code_valid \n[gw7] [ 67%] SKIPPED src/tests/test_audio_sapf.py::TestSAPFCodeValidation::test_validate_sapf_code_invalid \n[gw11] [ 70%] SKIPPED src/tests/test_audio_sapf.py::TestSAPFStandaloneFunctions::test_convert_gnn_to_sapf_function \nsrc/tests/test_audio_sapf.py::TestSAPFStandaloneFunctions::test_apply_envelope_function \nsrc/tests/test_audio_sapf.py::TestSAPFStandaloneFunctions::test_generate_oscillator_audio_function \n[gw6] [ 72%] SKIPPED src/tests/test_audio_sapf.py::TestSAPFStandaloneFunctions::test_generate_oscillator_audio_function \nsrc/tests/test_audio_sapf.py::TestSAPFStandaloneFunctions::test_mix_audio_channels_function \n[gw1] [ 75%] SKIPPED src/tests/test_audio_sapf.py::TestSAPFStandaloneFunctions::test_apply_envelope_function \nsrc/tests/test_audio_generation.py::TestAudioGeneration::test_audio_memory_usage \n[gw10] [ 78%] SKIPPED src/tests/test_audio_sapf.py::TestSAPFStandaloneFunctions::test_mix_audio_channels_function \n[gw5] [ 81%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_concurrent_generation \nsrc/tests/test_audio_overall.py::test_audio_module_completeness \n[gw5] [ 83%] PASSED src/tests/test_audio_overall.py::test_audio_module_completeness \n[gw4] [ 86%] PASSED src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_memory_usage \n[gw0] [ 89%] PASSED src/tests/test_audio_overall.py::test_audio_module_performance \n[gw12] [ 91%] PASSED src/tests/test_audio_overall.py::TestAudioProcessing::test_gnn_to_audio_conversion \nsrc/tests/test_audio_overall.py::TestAudioProcessing::test_audio_validation \n[gw13] [ 94%] PASSED src/tests/test_audio_overall.py::TestAudioProcessing::test_audio_generation \n[gw12] [ 97%] PASSED src/tests/test_audio_overall.py::TestAudioProcessing::test_audio_validation \nsrc/tests/test_audio_overall.py::TestAudioIntegration::test_audio_pipeline_integration \n[gw13] [100%] PASSED src/tests/test_audio_overall.py::TestAudioIntegration::test_audio_pipeline_integration \n\n============================= slowest 10 durations =============================\n0.28s call     src/tests/test_audio_overall.py::TestAudioIntegration::test_audio_pipeline_integration\n0.20s call     src/tests/test_audio_overall.py::TestAudioProcessing::test_audio_generation\n0.20s call     src/tests/test_audio_overall.py::TestAudioProcessing::test_gnn_to_audio_conversion\n0.19s call     src/tests/test_audio_overall.py::test_audio_module_performance\n0.06s call     src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_memory_usage\n0.02s call     src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_concurrent_generation\n0.01s call     src/tests/test_audio_generation.py::TestAudioGeneration::test_audio_performance\n\n(3 durations < 0.005s hidden.  Use -vv to show these durations.)\n======================== 27 passed, 10 skipped in 3.91s ========================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:28:07,077 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:28:07,077 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 0
  },
  "visualization": {
    "success": true,
    "tests_run": 26,
    "tests_passed": 17,
    "tests_failed": 0,
    "tests_skipped": 9,
    "duration": 5.78984808921814,
    "resource_usage": {
      "memory_mb": 21.421875,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [29 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_comparison_visualization \nsrc/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_graph_visualizer_instantiation \nsrc/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_visualization_module_info \nsrc/tests/test_visualization_ontology.py::TestOntologyVisualizer::test_create_ontology_table \n[gw8] [  3%] ERROR src/tests/test_visualization_ontology.py::TestOntologyVisualizer::test_create_ontology_table \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_data_creation \n[gw2] [  6%] PASSED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_data_creation \nsrc/tests/test_visualization_overall.py::TestVisualizationFunctionality::test_matrix_visualization \nsrc/tests/test_visualization_overall.py::TestVisualizationIntegration::test_visualization_mcp_integration \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_color_mapping \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_visualization_pipeline_integration \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_heatmap_generation \nsrc/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_visualization_module_imports \n[gw7] [ 10%] PASSED src/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_visualization_module_imports \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_visualizer_import \n[gw11] [ 13%] PASSED src/tests/test_visualization_overall.py::TestVisualizationIntegration::test_visualization_mcp_integration \nsrc/tests/test_visualization_overall.py::TestVisualizationFunctionality::test_ontology_visualization \n[gw12] [ 17%] PASSED src/tests/test_visualization_overall.py::TestVisualizationFunctionality::test_ontology_visualization \n[gw13] [ 20%] PASSED src/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_visualization_module_info \n[gw9] [ 24%] PASSED src/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_graph_visualizer_instantiation \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_export_formats \n[gw6] [ 27%] SKIPPED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_export_formats \n[gw5] [ 31%] SKIPPED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_color_mapping \n[gw0] [ 34%] PASSED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_visualizer_import \n[gw4] [ 37%] SKIPPED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_visualization_pipeline_integration \nsrc/tests/test_visualization_ontology.py::TestOntologyVisualizer::test_visualize_directory \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_visualization_data_preparation \n[gw1] [ 41%] SKIPPED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_comparison_visualization \n[gw8] [ 44%] ERROR src/tests/test_visualization_ontology.py::TestOntologyVisualizer::test_visualize_directory \nsrc/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_matrix_visualizer_instantiation \n[gw3] [ 48%] SKIPPED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_heatmap_generation \nsrc/tests/test_visualization_overall.py::TestVisualizationIntegration::test_visualization_pipeline_integration \n[gw7] [ 51%] PASSED src/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_matrix_visualizer_instantiation \n[gw2] [ 55%] PASSED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_visualization_data_preparation \nsrc/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_ontology_visualizer_instantiation \nsrc/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_visualization_options \nsrc/tests/test_visualization_overall.py::test_visualization_module_completeness \n[gw11] [ 58%] PASSED src/tests/test_visualization_overall.py::test_visualization_module_completeness \n[gw9] [ 62%] PASSED src/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_ontology_visualizer_instantiation \n[gw13] [ 65%] PASSED src/tests/test_visualization_overall.py::TestVisualizationModuleComprehensive::test_visualization_options \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_interactive_visualization \n[gw6] [ 68%] SKIPPED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_interactive_visualization \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_annotation \n[gw5] [ 72%] SKIPPED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_annotation \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_visualizer_instantiation \n[gw0] [ 75%] PASSED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_visualizer_instantiation \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_statistics_visualization \n[gw1] [ 79%] SKIPPED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_statistics_visualization \nsrc/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_3d_visualization \n[gw3] [ 82%] SKIPPED src/tests/test_visualization_matrices.py::TestVisualizationMatrices::test_matrix_3d_visualization \nsrc/tests/test_visualization_overall.py::test_visualization_module_performance \nsrc/tests/test_visualization_ontology.py::TestOntologyVisualizer::test_extract_ontology_mappings \n[gw4] [ 86%] ERROR src/tests/test_visualization_ontology.py::TestOntologyVisualizer::test_extract_ontology_mappings \n[gw10] [ 89%] PASSED src/tests/test_visualization_overall.py::TestVisualizationFunctionality::test_matrix_visualization \nsrc/tests/test_visualization_overall.py::TestVisualizationFunctionality::test_graph_visualization \n[gw8] [ 93%] PASSED src/tests/test_visualization_overall.py::test_visualization_module_performance \n[gw12] [ 96%] PASSED src/tests/test_visualization_overall.py::TestVisualizationIntegration::test_visualization_pipeline_integration \n[gw10] [100%] PASSED src/tests/test_visualization_overall.py::TestVisualizationFunctionality::test_graph_visualization \n\n==================================== ERRORS ====================================\n_____ ERROR at setup of TestOntologyVisualizer.test_create_ontology_table ______\n[gw8] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_visualization_ontology.py, line 59\n      def test_create_ontology_table(self, temp_output_dir):\nE       fixture 'temp_output_dir' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_visualization_ontology.py:59\n______ ERROR at setup of TestOntologyVisualizer.test_visualize_directory _______\n[gw8] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_visualization_ontology.py, line 78\n      def test_visualize_directory(self, test_data_dir, temp_output_dir):\nE       fixture 'test_data_dir' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_visualization_ontology.py:78\n___ ERROR at setup of TestOntologyVisualizer.test_extract_ontology_mappings ____\n[gw4] darwin -- Python 3.11.13 /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\nfile /Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_visualization_ontology.py, line 24\n      def test_extract_ontology_mappings(self, sample_gnn_file):\nE       fixture 'sample_gnn_file' not found\n>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, comprehensive_test_data, cov, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, include_metadata_in_junit_xml, isolated_temp_dir, json_metadata, metadata, mocker, module_mocker, monkeypatch, no_cover, package_mocker, project_root, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_gnn_files, sample_json, sample_markdown, sample_scala, sample_xml, session_mocker, test_config, test_gnn_content, test_ontology_terms, test_temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory, worker_id\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_visualization_ontology.py:24\n============================= slowest 10 durations =============================\n0.50s call     src/tests/test_visualization_overall.py::TestVisualizationIntegration::test_visualization_pipeline_integration\n0.49s call     src/tests/test_visualization_overall.py::TestVisualizationFunctionality::test_matrix_visualization\n0.48s call     src/tests/test_visualization_overall.py::test_visualization_module_performance\n0.02s call     src/tests/test_visualization_overall.py::TestVisualizationFunctionality::test_graph_visualization\n\n(6 durations < 0.005s hidden.  Use -vv to show these durations.)\n=========================== short test summary info ============================\nERROR src/tests/test_visualization_ontology.py::TestOntologyVisualizer::test_create_ontology_table\nERROR src/tests/test_visualization_ontology.py::TestOntologyVisualizer::test_visualize_directory\nERROR src/tests/test_visualization_ontology.py::TestOntologyVisualizer::test_extract_ontology_mappings\n=================== 17 passed, 9 skipped, 3 errors in 3.96s ====================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:28:12,816 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:28:12,816 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 1
  },
  "pipeline": {
    "success": false,
    "error": "Subprocess timeout",
    "tests_run": 0,
    "tests_passed": 0,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 299.9941780567169
  },
  "export": {
    "success": true,
    "tests_run": 12,
    "tests_passed": 12,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 8.728273153305054,
    "resource_usage": {
      "memory_mb": 13.921875,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [12 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_export_overall.py::TestExportFunctionality::test_multi_format_export \nsrc/tests/test_export_overall.py::test_export_module_performance \n[gw8] [  8%] PASSED src/tests/test_export_overall.py::test_export_module_performance \nsrc/tests/test_export_overall.py::TestExportFunctionality::test_export_gnn_model \n[gw6] [ 16%] PASSED src/tests/test_export_overall.py::TestExportFunctionality::test_export_gnn_model \nsrc/tests/test_export_overall.py::TestExportModuleComprehensive::test_export_module_info \n[gw3] [ 25%] PASSED src/tests/test_export_overall.py::TestExportModuleComprehensive::test_export_module_info \nsrc/tests/test_export_overall.py::TestExportFunctionality::test_export_format_validation \nsrc/tests/test_export_overall.py::test_export_module_completeness \n[gw13] [ 33%] PASSED src/tests/test_export_overall.py::test_export_module_completeness \n[gw10] [ 41%] PASSED src/tests/test_export_overall.py::TestExportFunctionality::test_multi_format_export \nsrc/tests/test_export_overall.py::TestExportModuleComprehensive::test_supported_formats \nsrc/tests/test_export_overall.py::TestExportModuleComprehensive::test_multi_format_exporter_instantiation \nsrc/tests/test_export_overall.py::TestExportIntegration::test_export_mcp_integration \n[gw5] [ 50%] PASSED src/tests/test_export_overall.py::TestExportIntegration::test_export_mcp_integration \nsrc/tests/test_export_overall.py::TestExportIntegration::test_export_pipeline_integration \n[gw7] [ 58%] PASSED src/tests/test_export_overall.py::TestExportIntegration::test_export_pipeline_integration \nsrc/tests/test_export_overall.py::TestExportModuleComprehensive::test_exporter_instantiation \n[gw2] [ 66%] PASSED src/tests/test_export_overall.py::TestExportModuleComprehensive::test_exporter_instantiation \nsrc/tests/test_export_overall.py::TestExportModuleComprehensive::test_export_module_imports \n[gw0] [ 75%] PASSED src/tests/test_export_overall.py::TestExportModuleComprehensive::test_multi_format_exporter_instantiation \n[gw1] [ 83%] PASSED src/tests/test_export_overall.py::TestExportModuleComprehensive::test_export_module_imports \n[gw4] [ 91%] PASSED src/tests/test_export_overall.py::TestExportModuleComprehensive::test_supported_formats \n[gw9] [100%] PASSED src/tests/test_export_overall.py::TestExportFunctionality::test_export_format_validation \n\n============================= slowest 10 durations =============================\n0.42s call     src/tests/test_export_overall.py::TestExportFunctionality::test_export_format_validation\n0.38s call     src/tests/test_export_overall.py::TestExportModuleComprehensive::test_supported_formats\n0.04s call     src/tests/test_export_overall.py::TestExportModuleComprehensive::test_multi_format_exporter_instantiation\n0.03s call     src/tests/test_export_overall.py::TestExportModuleComprehensive::test_export_module_imports\n0.01s setup    src/tests/test_export_overall.py::TestExportModuleComprehensive::test_multi_format_exporter_instantiation\n0.01s call     src/tests/test_export_overall.py::TestExportIntegration::test_export_pipeline_integration\n0.01s call     src/tests/test_export_overall.py::TestExportModuleComprehensive::test_exporter_instantiation\n0.01s call     src/tests/test_export_overall.py::test_export_module_performance\n0.01s call     src/tests/test_export_overall.py::TestExportFunctionality::test_multi_format_export\n0.01s call     src/tests/test_export_overall.py::TestExportIntegration::test_export_mcp_integration\n============================== 12 passed in 7.02s ==============================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:33:18,472 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:33:18,472 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 0
  },
  "execute": {
    "success": true,
    "tests_run": 0,
    "tests_passed": 0,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 0,
    "stdout": "",
    "stderr": "",
    "return_code": 0
  },
  "llm": {
    "success": true,
    "tests_run": 12,
    "tests_passed": 12,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 7.637322902679443,
    "resource_usage": {
      "memory_mb": 14.046875,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [12 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_llm_overall.py::TestLLMFunctionality::test_content_analysis \nsrc/tests/test_llm_overall.py::TestLLMIntegration::test_llm_pipeline_integration \nsrc/tests/test_llm_overall.py::TestLLMFunctionality::test_model_analysis \nsrc/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_module_imports \nsrc/tests/test_llm_overall.py::TestLLMFunctionality::test_description_generation \nsrc/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_analyzer_instantiation \nsrc/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_module_info \nsrc/tests/test_llm_overall.py::TestLLMIntegration::test_llm_mcp_integration \nsrc/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_processor_instantiation \n[gw12] [  8%] PASSED src/tests/test_llm_overall.py::TestLLMFunctionality::test_content_analysis \nsrc/tests/test_llm_overall.py::test_llm_module_performance \n[gw7] [ 16%] PASSED src/tests/test_llm_overall.py::test_llm_module_performance \n[gw8] [ 25%] PASSED src/tests/test_llm_overall.py::TestLLMIntegration::test_llm_mcp_integration \n[gw2] [ 33%] PASSED src/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_processor_instantiation \nsrc/tests/test_llm_overall.py::test_llm_module_completeness \n[gw13] [ 41%] PASSED src/tests/test_llm_overall.py::test_llm_module_completeness \n[gw6] [ 50%] PASSED src/tests/test_llm_overall.py::TestLLMFunctionality::test_description_generation \n[gw0] [ 58%] PASSED src/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_analyzer_instantiation \n[gw11] [ 66%] PASSED src/tests/test_llm_overall.py::TestLLMIntegration::test_llm_pipeline_integration \nsrc/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_providers \n[gw1] [ 75%] PASSED src/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_module_imports \n[gw5] [ 83%] PASSED src/tests/test_llm_overall.py::TestLLMFunctionality::test_model_analysis \n[gw4] [ 91%] PASSED src/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_module_info \n[gw3] [100%] PASSED src/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_providers \n\n============================= slowest 10 durations =============================\n0.13s call     src/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_providers\n0.11s call     src/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_module_info\n0.01s call     src/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_module_imports\n0.01s call     src/tests/test_llm_overall.py::TestLLMModuleComprehensive::test_llm_processor_instantiation\n0.01s call     src/tests/test_llm_overall.py::TestLLMIntegration::test_llm_mcp_integration\n0.01s call     src/tests/test_llm_overall.py::TestLLMFunctionality::test_model_analysis\n0.01s call     src/tests/test_llm_overall.py::TestLLMFunctionality::test_description_generation\n0.01s call     src/tests/test_llm_overall.py::test_llm_module_performance\n\n(2 durations < 0.005s hidden.  Use -vv to show these durations.)\n============================== 12 passed in 5.96s ==============================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:33:27,187 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:33:27,187 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 0
  },
  "ontology": {
    "success": true,
    "tests_run": 12,
    "tests_passed": 12,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 7.865242004394531,
    "resource_usage": {
      "memory_mb": 14.21875,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [12 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_ontology_overall.py::test_ontology_module_performance \nsrc/tests/test_ontology_overall.py::TestOntologyFunctionality::test_ontology_validation \nsrc/tests/test_ontology_overall.py::TestOntologyFunctionality::test_term_validation \nsrc/tests/test_ontology_overall.py::test_ontology_module_completeness \nsrc/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_processor_instantiation \nsrc/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_processing_options \nsrc/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_module_imports \nsrc/tests/test_ontology_overall.py::TestOntologyIntegration::test_ontology_mcp_integration \nsrc/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_validator_instantiation \nsrc/tests/test_ontology_overall.py::TestOntologyIntegration::test_ontology_pipeline_integration \nsrc/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_module_info \n[gw9] [  8%] PASSED src/tests/test_ontology_overall.py::test_ontology_module_completeness \n[gw6] [ 16%] PASSED src/tests/test_ontology_overall.py::TestOntologyFunctionality::test_ontology_validation \nsrc/tests/test_ontology_overall.py::TestOntologyFunctionality::test_ontology_processing \n[gw10] [ 25%] PASSED src/tests/test_ontology_overall.py::test_ontology_module_performance \n[gw7] [ 33%] PASSED src/tests/test_ontology_overall.py::TestOntologyIntegration::test_ontology_mcp_integration \n[gw8] [ 41%] PASSED src/tests/test_ontology_overall.py::TestOntologyFunctionality::test_term_validation \n[gw13] [ 50%] PASSED src/tests/test_ontology_overall.py::TestOntologyIntegration::test_ontology_pipeline_integration \n[gw1] [ 58%] PASSED src/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_processor_instantiation \n[gw2] [ 66%] PASSED src/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_validator_instantiation \n[gw4] [ 75%] PASSED src/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_processing_options \n[gw3] [ 83%] PASSED src/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_module_info \n[gw0] [ 91%] PASSED src/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_module_imports \n[gw5] [100%] PASSED src/tests/test_ontology_overall.py::TestOntologyFunctionality::test_ontology_processing \n\n============================= slowest 10 durations =============================\n0.01s call     src/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_module_imports\n0.01s setup    src/tests/test_ontology_overall.py::TestOntologyFunctionality::test_ontology_processing\n0.01s call     src/tests/test_ontology_overall.py::TestOntologyFunctionality::test_ontology_processing\n0.01s call     src/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_module_info\n0.01s call     src/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_validator_instantiation\n0.01s call     src/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_processor_instantiation\n0.01s call     src/tests/test_ontology_overall.py::TestOntologyModuleComprehensive::test_ontology_processing_options\n\n(3 durations < 0.005s hidden.  Use -vv to show these durations.)\n============================== 12 passed in 6.13s ==============================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:33:34,857 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:33:34,857 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 0
  },
  "website": {
    "success": true,
    "tests_run": 12,
    "tests_passed": 12,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 9.015326976776123,
    "resource_usage": {
      "memory_mb": 13.734375,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [12 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_website_overall.py::TestWebsiteModuleComprehensive::test_website_generator_instantiation \nsrc/tests/test_website_overall.py::TestWebsiteModuleComprehensive::test_supported_file_types \nsrc/tests/test_website_overall.py::TestWebsiteModuleComprehensive::test_website_module_imports \n[gw4] [  8%] PASSED src/tests/test_website_overall.py::TestWebsiteModuleComprehensive::test_website_module_imports \nsrc/tests/test_website_overall.py::test_website_module_performance \nsrc/tests/test_website_overall.py::TestWebsiteIntegration::test_website_mcp_integration \n[gw11] [ 16%] PASSED src/tests/test_website_overall.py::TestWebsiteIntegration::test_website_mcp_integration \nsrc/tests/test_website_overall.py::TestWebsiteFunctionality::test_html_rendering \n[gw5] [ 25%] PASSED src/tests/test_website_overall.py::TestWebsiteFunctionality::test_html_rendering \n[gw0] [ 33%] PASSED src/tests/test_website_overall.py::TestWebsiteModuleComprehensive::test_website_generator_instantiation \n[gw1] [ 41%] PASSED src/tests/test_website_overall.py::TestWebsiteModuleComprehensive::test_supported_file_types \nsrc/tests/test_website_overall.py::TestWebsiteModuleComprehensive::test_website_renderer_instantiation \n[gw3] [ 50%] PASSED src/tests/test_website_overall.py::TestWebsiteModuleComprehensive::test_website_renderer_instantiation \nsrc/tests/test_website_overall.py::TestWebsiteFunctionality::test_website_validation \nsrc/tests/test_website_overall.py::TestWebsiteIntegration::test_website_pipeline_integration \n[gw8] [ 58%] PASSED src/tests/test_website_overall.py::TestWebsiteIntegration::test_website_pipeline_integration \nsrc/tests/test_website_overall.py::TestWebsiteModuleComprehensive::test_website_module_info \n[gw2] [ 66%] PASSED src/tests/test_website_overall.py::TestWebsiteModuleComprehensive::test_website_module_info \nsrc/tests/test_website_overall.py::test_website_module_completeness \n[gw10] [ 75%] PASSED src/tests/test_website_overall.py::test_website_module_performance \n[gw7] [ 83%] PASSED src/tests/test_website_overall.py::TestWebsiteFunctionality::test_website_validation \n[gw13] [ 91%] PASSED src/tests/test_website_overall.py::test_website_module_completeness \nsrc/tests/test_website_overall.py::TestWebsiteFunctionality::test_website_generation \n[gw6] [100%] PASSED src/tests/test_website_overall.py::TestWebsiteFunctionality::test_website_generation \n\n============================= slowest 10 durations =============================\n0.01s call     src/tests/test_website_overall.py::test_website_module_performance\n0.01s call     src/tests/test_website_overall.py::test_website_module_completeness\n\n(8 durations < 0.005s hidden.  Use -vv to show these durations.)\n============================== 12 passed in 7.14s ==============================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:33:42,758 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:33:42,759 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 0
  },
  "report": {
    "success": true,
    "tests_run": 12,
    "tests_passed": 12,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 19.489014148712158,
    "resource_usage": {
      "memory_mb": 13.75,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [12 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_report_overall.py::TestReportIntegration::test_report_pipeline_integration \nsrc/tests/test_report_overall.py::test_report_module_performance \nsrc/tests/test_report_overall.py::TestReportFunctionality::test_report_formatting \nsrc/tests/test_report_overall.py::test_report_module_completeness \n[gw13] [  8%] PASSED src/tests/test_report_overall.py::test_report_module_completeness \nsrc/tests/test_report_overall.py::TestReportFunctionality::test_report_validation \n[gw3] [ 16%] PASSED src/tests/test_report_overall.py::TestReportFunctionality::test_report_validation \n[gw12] [ 25%] PASSED src/tests/test_report_overall.py::test_report_module_performance \n[gw6] [ 33%] PASSED src/tests/test_report_overall.py::TestReportIntegration::test_report_pipeline_integration \nsrc/tests/test_report_overall.py::TestReportIntegration::test_report_mcp_integration \n[gw4] [ 41%] PASSED src/tests/test_report_overall.py::TestReportIntegration::test_report_mcp_integration \n[gw11] [ 50%] PASSED src/tests/test_report_overall.py::TestReportFunctionality::test_report_formatting \nsrc/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_formats \nsrc/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_formatter_instantiation \nsrc/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_module_info \nsrc/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_generator_instantiation \nsrc/tests/test_report_overall.py::TestReportFunctionality::test_report_generation \nsrc/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_module_imports \n[gw0] [ 58%] PASSED src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_module_info \n[gw2] [ 66%] PASSED src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_formats \n[gw5] [ 75%] PASSED src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_formatter_instantiation \n[gw1] [ 83%] PASSED src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_module_imports \n[gw7] [ 91%] PASSED src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_generator_instantiation \n[gw8] [100%] PASSED src/tests/test_report_overall.py::TestReportFunctionality::test_report_generation \n\n============================= slowest 10 durations =============================\n0.05s setup    src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_formatter_instantiation\n0.05s setup    src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_generator_instantiation\n0.05s setup    src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_module_imports\n0.05s setup    src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_module_info\n0.05s setup    src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_formats\n0.05s setup    src/tests/test_report_overall.py::TestReportFunctionality::test_report_generation\n0.05s call     src/tests/test_report_overall.py::TestReportFunctionality::test_report_formatting\n0.03s call     src/tests/test_report_overall.py::TestReportFunctionality::test_report_generation\n0.02s call     src/tests/test_report_overall.py::TestReportModuleComprehensive::test_report_generator_instantiation\n0.02s call     src/tests/test_report_overall.py::TestReportIntegration::test_report_mcp_integration\n============================= 12 passed in 17.02s ==============================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:33:52,384 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:33:52,384 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 0
  },
  "environment": {
    "success": true,
    "tests_run": 32,
    "tests_passed": 29,
    "tests_failed": 0,
    "tests_skipped": 3,
    "duration": 10.754935026168823,
    "resource_usage": {
      "memory_mb": 17.78125,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [32 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_virtual_environment_instantiation \nsrc/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_python_version_compatibility \nsrc/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_uv_availability \nsrc/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_optional_packages_graceful_degradation \nsrc/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_file_system_permissions \n[gw2] [  3%] PASSED src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_python_version_compatibility \nsrc/tests/test_environment_integration.py::TestEnvironmentIntegration::test_package_installation_integration \nsrc/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_dependency_version_compatibility \n[gw0] [  6%] PASSED src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_optional_packages_graceful_degradation \nsrc/tests/test_environment_integration.py::TestEnvironmentIntegration::test_pipeline_environment_integration \n[gw3] [  9%] PASSED src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_file_system_permissions \nsrc/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_setup_integration \nsrc/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_essential_packages_available \n[gw5] [ 12%] PASSED src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_dependency_version_compatibility \n[gw2] [ 15%] PASSED src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_essential_packages_available \nsrc/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_monitoring_integration \n[gw13] [ 18%] PASSED src/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_virtual_environment_instantiation \nsrc/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_error_handling_integration \nsrc/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_pytest_availability \n[gw7] [ 21%] PASSED src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_pipeline_environment_integration \nsrc/tests/test_environment_overall.py::TestEnvironmentIntegration::test_environment_pipeline_integration \nsrc/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_dependency_installation_simulation \n[gw0] [ 25%] PASSED src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_pytest_availability \nsrc/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_import_path_resolution \n[gw3] [ 28%] PASSED src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_import_path_resolution \nsrc/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_environment_validation \nsrc/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_environment_module_imports \n[gw4] [ 31%] SKIPPED src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_setup_integration \nsrc/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_environment_module_info \nsrc/tests/test_environment_overall.py::TestEnvironmentIntegration::test_environment_mcp_integration \n[gw13] [ 34%] PASSED src/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_environment_module_info \nsrc/tests/test_environment_integration.py::TestEnvironmentIntegration::test_virtual_environment_integration \nsrc/tests/test_environment_overall.py::test_environment_module_performance \nsrc/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_cleanup_integration \n[gw7] [ 37%] PASSED src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_cleanup_integration \n[gw11] [ 40%] PASSED src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_error_handling_integration \n[gw0] [ 43%] SKIPPED src/tests/test_environment_overall.py::TestEnvironmentIntegration::test_environment_mcp_integration \n[gw10] [ 46%] PASSED src/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_environment_module_imports \nsrc/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_logging_integration \nsrc/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_environment_manager_instantiation \n[gw11] [ 50%] PASSED src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_logging_integration \n[gw1] [ 53%] PASSED src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_uv_availability \nsrc/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_environment_variables \n[gw10] [ 56%] PASSED src/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_environment_manager_instantiation \n[gw1] [ 59%] PASSED src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_environment_variables \n[gw6] [ 62%] PASSED src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_package_installation_integration \nsrc/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_validation_integration \n[gw6] [ 65%] SKIPPED src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_validation_integration \n[gw2] [ 68%] PASSED src/tests/test_environment_overall.py::TestEnvironmentIntegration::test_environment_pipeline_integration \n[gw12] [ 71%] PASSED src/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_environment_validation \nsrc/tests/test_environment_overall.py::TestEnvironmentFunctionality::test_environment_setup \n[gw3] [ 75%] PASSED src/tests/test_environment_overall.py::test_environment_module_performance \n[gw12] [ 78%] PASSED src/tests/test_environment_overall.py::TestEnvironmentFunctionality::test_environment_setup \nsrc/tests/test_environment_overall.py::TestEnvironmentFunctionality::test_dependency_installation \n[gw8] [ 81%] PASSED src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_monitoring_integration \nsrc/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_configuration_integration \n[gw8] [ 84%] PASSED src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_configuration_integration \n[gw5] [ 87%] PASSED src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_dependency_installation_simulation \nsrc/tests/test_environment_overall.py::test_environment_module_completeness \n[gw5] [ 90%] PASSED src/tests/test_environment_overall.py::test_environment_module_completeness \n[gw4] [ 93%] PASSED src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_virtual_environment_integration \n[gw9] [ 96%] PASSED src/tests/test_environment_overall.py::TestEnvironmentFunctionality::test_dependency_installation \nsrc/tests/test_environment_overall.py::TestEnvironmentFunctionality::test_python_version_check \n[gw9] [100%] PASSED src/tests/test_environment_overall.py::TestEnvironmentFunctionality::test_python_version_check \n\n============================= slowest 10 durations =============================\n2.90s call     src/tests/test_environment_overall.py::TestEnvironmentFunctionality::test_dependency_installation\n2.08s call     src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_virtual_environment_integration\n0.21s call     src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_dependency_installation_simulation\n0.11s call     src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_environment_monitoring_integration\n0.07s teardown src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_virtual_environment_integration\n0.06s call     src/tests/test_environment_overall.py::test_environment_module_performance\n0.06s call     src/tests/test_environment_overall.py::TestEnvironmentModuleComprehensive::test_environment_validation\n0.05s call     src/tests/test_environment_overall.py::TestEnvironmentIntegration::test_environment_pipeline_integration\n0.03s call     src/tests/test_environment_integration.py::TestEnvironmentIntegration::test_package_installation_integration\n0.02s call     src/tests/test_environment_dependencies.py::TestEnvironmentDependencies::test_uv_availability\n======================== 29 passed, 3 skipped in 8.69s =========================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:34:11,297 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:34:11,297 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 0
  },
  "type_checker": {
    "success": true,
    "tests_run": 44,
    "tests_passed": 44,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 5.745626926422119,
    "resource_usage": {
      "memory_mb": 18.484375,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [44 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_variable_types_missing_fields \n[gw1] [  2%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_variable_types_missing_fields \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerPerformance::test_large_file_processing \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_analyze_pomdp_structure_invalid \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validate_gnn_files_no_files \n[gw7] [  4%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validate_gnn_files_no_files \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validate_type \n[gw2] [  6%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validate_type \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_analyze_types \n[gw8] [  9%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_analyze_types \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_pomdp_analyzer_with_ontology \n[gw12] [ 11%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_pomdp_analyzer_with_ontology \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_gnn_type_checker_initialization \n[gw3] [ 13%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_gnn_type_checker_initialization \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validate_single_gnn_file_nonexistent \n[gw6] [ 15%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validate_single_gnn_file_nonexistent \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_connections_empty \n[gw4] [ 18%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_connections_empty \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_connections_basic \n[gw1] [ 20%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_connections_basic \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerPipelineIntegration::test_step5_integration \n[gw11] [ 22%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerPipelineIntegration::test_step5_integration \n[gw10] [ 25%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerPerformance::test_large_file_processing \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_estimate_computational_complexity \n[gw5] [ 27%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_estimate_computational_complexity \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerIntegration::test_end_to_end_processing \n[gw9] [ 29%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerIntegration::test_end_to_end_processing \n[gw13] [ 31%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_analyze_pomdp_structure_invalid \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_variable_types_basic \n[gw0] [ 34%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_variable_types_basic \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validation_rules \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_check_type_consistency \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validate_gnn_files_basic \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_pomdp_analyzer_initialization \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validate_single_gnn_file \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_estimate_computational_complexity_high_complexity \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_generate_type_check_summary \n[gw8] [ 36%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_generate_type_check_summary \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerPerformance::test_memory_efficiency \n[gw10] [ 38%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerPerformance::test_memory_efficiency \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_validate_pomdp_model_invalid \n[gw1] [ 40%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_validate_pomdp_model_invalid \n[gw5] [ 43%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_estimate_computational_complexity_high_complexity \n[gw7] [ 45%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validation_rules \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_connections_missing_fields \n[gw4] [ 47%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_connections_missing_fields \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_analyze_pomdp_structure \n[gw12] [ 50%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_analyze_pomdp_structure \n[gw11] [ 52%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_pomdp_analyzer_initialization \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_variable_types_empty \n[gw0] [ 54%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerAnalysisUtils::test_analyze_variable_types_empty \n[gw3] [ 56%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validate_single_gnn_file \n[gw2] [ 59%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_check_type_consistency \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_validate_pomdp_model \nsrc/tests/test_type_checker_overall.py::TestTypeCheckerIntegration::test_error_handling_robustness \n[gw9] [ 61%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerIntegration::test_error_handling_robustness \n[gw13] [ 63%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_validate_pomdp_model \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPIntegration::test_pomdp_analysis_in_main_workflow \n[gw6] [ 65%] PASSED src/tests/test_type_checker_overall.py::TestTypeCheckerProcessor::test_validate_gnn_files_basic \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_gnn_type_checker_pomdp_mode_no_ontology \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPValidationRules::test_required_components_validation \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_estimate_pomdp_complexity \n[gw5] [ 68%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPValidationRules::test_required_components_validation \n[gw8] [ 70%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_gnn_type_checker_pomdp_mode_no_ontology \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPIntegration::test_pomdp_ontology_loading_nonexistent \n[gw10] [ 72%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPIntegration::test_pomdp_ontology_loading_nonexistent \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_get_pomdp_analysis_summary_no_pomdp_mode \n[gw7] [ 75%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPAnalyzer::test_estimate_pomdp_complexity \n[gw4] [ 77%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_get_pomdp_analysis_summary_no_pomdp_mode \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_validate_pomdp_file \n[gw12] [ 79%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_validate_pomdp_file \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPIntegration::test_pomdp_ontology_loading \n[gw11] [ 81%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPIntegration::test_pomdp_ontology_loading \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPPerformance::test_large_pomdp_analysis \n[gw0] [ 84%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPPerformance::test_large_pomdp_analysis \n[gw1] [ 86%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPIntegration::test_pomdp_analysis_in_main_workflow \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_gnn_type_checker_pomdp_mode \n[gw2] [ 88%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_gnn_type_checker_pomdp_mode \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPValidationRules::test_dimension_consistency_validation \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_validate_pomdp_file_not_pomdp_mode \n[gw3] [ 90%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_validate_pomdp_file_not_pomdp_mode \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPValidationRules::test_ontology_compliance_validation \n[gw13] [ 93%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPValidationRules::test_ontology_compliance_validation \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPPerformance::test_pomdp_complexity_estimation \n[gw8] [ 95%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPPerformance::test_pomdp_complexity_estimation \nsrc/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_get_pomdp_analysis_summary \n[gw6] [ 97%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPTypeChecker::test_get_pomdp_analysis_summary \n[gw9] [100%] PASSED src/tests/test_type_checker_pomdp.py::TestPOMDPValidationRules::test_dimension_consistency_validation \n\n============================= slowest 10 durations =============================\n\n(10 durations < 0.005s hidden.  Use -vv to show these durations.)\n============================== 44 passed in 3.68s ==============================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:34:22,360 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:34:22,360 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 0
  },
  "pomdp": {
    "success": false,
    "tests_run": 0,
    "tests_passed": 0,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 5.158376932144165,
    "resource_usage": {
      "memory_mb": 18.5625,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [0 items]\n\nscheduling tests via LoadScheduling\n\n============================ no tests ran in 3.19s =============================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:34:28,044 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:34:28,044 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 5
  },
  "validation": {
    "success": true,
    "tests_run": 21,
    "tests_passed": 21,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 4.911123275756836,
    "resource_usage": {
      "memory_mb": 18.96875,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'xdist': '3.8.0', 'sugar': '1.0.0', 'asyncio': '1.1.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: xdist-3.8.0, sugar-1.0.0, asyncio-1.1.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncreated: 14/14 workers\n14 workers [21 items]\n\nscheduling tests via LoadScheduling\n\nsrc/tests/test_pomdp_validation.py::TestPOMDPDimensionConsistency::test_inconsistent_dimensions \n[gw6] [  4%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPDimensionConsistency::test_inconsistent_dimensions \nsrc/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_valid_pomdp_structure \n[gw2] [  9%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_valid_pomdp_structure \nsrc/tests/test_pomdp_validation.py::TestPOMDPSemanticValidation::test_semantic_consistency \n[gw2] [ 14%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPSemanticValidation::test_semantic_consistency \nsrc/tests/test_pomdp_validation.py::TestPOMDPDimensionConsistency::test_missing_dimension_validation \nsrc/tests/test_pomdp_validation.py::TestPOMDPOntologyCompliance::test_ontology_loading_error_handling \n[gw13] [ 19%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPOntologyCompliance::test_ontology_loading_error_handling \nsrc/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_invalid_pomdp_structure \nsrc/tests/test_pomdp_validation.py::TestPOMDPOntologyCompliance::test_ontology_non_compliant_pomdp \n[gw11] [ 23%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPOntologyCompliance::test_ontology_non_compliant_pomdp \n[gw10] [ 28%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPDimensionConsistency::test_missing_dimension_validation \nsrc/tests/test_pomdp_validation.py::TestPOMDPOntologyCompliance::test_ontology_compliant_pomdp \n[gw9] [ 33%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPOntologyCompliance::test_ontology_compliant_pomdp \nsrc/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_invalid_dimension_syntax \n[gw3] [ 38%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_invalid_dimension_syntax \nsrc/tests/test_pomdp_validation.py::TestPOMDPErrorHandling::test_invalid_input_handling \n[gw3] [ 42%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPErrorHandling::test_invalid_input_handling \nsrc/tests/test_pomdp_validation.py::TestPOMDPOntologyCompliance::test_missing_ontology_file \n[gw12] [ 47%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPOntologyCompliance::test_missing_ontology_file \nsrc/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_pomdp_dimension_extraction \n[gw5] [ 52%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_pomdp_dimension_extraction \nsrc/tests/test_pomdp_validation.py::TestPOMDPErrorHandling::test_large_content_handling \n[gw5] [ 57%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPErrorHandling::test_large_content_handling \nsrc/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_pomdp_component_detection \n[gw4] [ 61%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_pomdp_component_detection \nsrc/tests/test_pomdp_validation.py::TestPOMDPErrorHandling::test_malformed_content_handling \n[gw4] [ 66%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPErrorHandling::test_malformed_content_handling \n[gw1] [ 71%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_invalid_pomdp_structure \nsrc/tests/test_pomdp_validation.py::TestPOMDPSemanticValidation::test_semantic_inconsistency \n[gw1] [ 76%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPSemanticValidation::test_semantic_inconsistency \nsrc/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_pomdp_specific_metrics \n[gw8] [ 80%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_pomdp_specific_metrics \nsrc/tests/test_pomdp_validation.py::TestPOMDPErrorHandling::test_unicode_content_handling \n[gw8] [ 85%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPErrorHandling::test_unicode_content_handling \nsrc/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_missing_required_components \n[gw0] [ 90%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_missing_required_components \nsrc/tests/test_pomdp_validation.py::TestPOMDPSemanticValidation::test_connection_validation \n[gw0] [ 95%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPSemanticValidation::test_connection_validation \nsrc/tests/test_pomdp_validation.py::TestPOMDPDimensionConsistency::test_consistent_dimensions \n[gw7] [100%] PASSED src/tests/test_pomdp_validation.py::TestPOMDPDimensionConsistency::test_consistent_dimensions \n\n============================= slowest 10 durations =============================\n0.01s setup    src/tests/test_pomdp_validation.py::TestPOMDPDimensionConsistency::test_missing_dimension_validation\n0.01s call     src/tests/test_pomdp_validation.py::TestPOMDPStructureValidation::test_invalid_pomdp_structure\n0.01s call     src/tests/test_pomdp_validation.py::TestPOMDPErrorHandling::test_large_content_handling\n\n(7 durations < 0.005s hidden.  Use -vv to show these durations.)\n============================== 21 passed in 2.94s ==============================\n",
    "stderr": "/Users/4d/Documents/GitHub/generalizednotationnotation/.venv/lib/python3.11/site-packages/pytest_benchmark/logger.py:39: PytestBenchmarkWarning: Benchmarks are automatically disabled because xdist plugin is active.Benchmarks cannot be performed reliably in a parallelized environment.\n  warner(PytestBenchmarkWarning(text))\n2025-09-22 16:34:33,217 - src.llm.llm_processor - INFO - Loaded API keys for providers: ['openai']\n2025-09-22 16:34:33,217 - src.llm.llm_operations - INFO - Created new LLM processor\n",
    "return_code": 0
  },
  "model_registry": {
    "success": true,
    "tests_run": 0,
    "tests_passed": 0,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 0,
    "stdout": "",
    "stderr": "",
    "return_code": 0
  },
  "analysis": {
    "success": true,
    "tests_run": 0,
    "tests_passed": 0,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 0,
    "stdout": "",
    "stderr": "",
    "return_code": 0
  },
  "integration": {
    "success": false,
    "tests_run": 11,
    "tests_passed": 0,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 2.255229949951172,
    "resource_usage": {
      "memory_mb": 18.46875,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'sugar': '1.0.0', 'asyncio': '1.1.0', 'xdist': '3.8.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: sugar-1.0.0, asyncio-1.1.0, xdist-3.8.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 11 items / 1 error\n\n==================================== ERRORS ====================================\n__________ ERROR collecting src/tests/test_performance_benchmarks.py ___________\n.venv/lib/python3.11/site-packages/_pytest/python.py:498: in importtestmodule\n    mod = import_path(\n.venv/lib/python3.11/site-packages/_pytest/pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n../../../.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1204: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1176: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1147: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:690: in _load_unlocked\n    ???\n.venv/lib/python3.11/site-packages/_pytest/assertion/rewrite.py:177: in exec_module\n    source_stat, co = _rewrite_test(fn, self.config)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.11/site-packages/_pytest/assertion/rewrite.py:357: in _rewrite_test\n    tree = ast.parse(source, filename=strfn)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n../../../.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/ast.py:50: in parse\n    return compile(source, filename, mode, flags,\nE     File \"/Users/4d/Documents/GitHub/generalizednotationnotation/src/tests/test_performance_benchmarks.py\", line 101\nE       assert type_check_time < 3.0, f\"Type checking took {type_check_time\".2f\"}s, should be < 3.0s\"\nE                                                                            ^\nE   SyntaxError: invalid decimal literal\n=========================== short test summary info ============================\nERROR src/tests/test_performance_benchmarks.py\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n=============================== 1 error in 0.17s ===============================\n",
    "stderr": "",
    "return_code": 2
  },
  "security": {
    "success": true,
    "tests_run": 0,
    "tests_passed": 0,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 0,
    "stdout": "",
    "stderr": "",
    "return_code": 0
  },
  "research": {
    "success": true,
    "tests_run": 0,
    "tests_passed": 0,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 0,
    "stdout": "",
    "stderr": "",
    "return_code": 0
  },
  "ml_integration": {
    "success": true,
    "tests_run": 0,
    "tests_passed": 0,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 0,
    "stdout": "",
    "stderr": "",
    "return_code": 0
  },
  "advanced_visualization": {
    "success": true,
    "tests_run": 0,
    "tests_passed": 0,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 0,
    "stdout": "",
    "stderr": "",
    "return_code": 0
  },
  "comprehensive": {
    "success": true,
    "tests_run": 47,
    "tests_passed": 47,
    "tests_failed": 0,
    "tests_skipped": 0,
    "duration": 1.0556700229644775,
    "resource_usage": {
      "memory_mb": 19.671875,
      "cpu_percent": 0.0,
      "threads": 1
    },
    "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /Users/4d/Documents/GitHub/generalizednotationnotation/.venv/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.13', 'Platform': 'macOS-15.6.1-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'sugar': '1.0.0', 'asyncio': '1.1.0', 'xdist': '3.8.0', 'json-report': '1.5.0', 'timeout': '2.4.0', 'metadata': '3.1.1', 'anyio': '4.10.0', 'cov': '6.2.1', 'mock': '3.14.1', 'benchmark': '5.1.0'}}\nbenchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)\nrootdir: /Users/4d/Documents/GitHub/generalizednotationnotation\nconfigfile: pytest.ini\nplugins: sugar-1.0.0, asyncio-1.1.0, xdist-3.8.0, json-report-1.5.0, timeout-2.4.0, metadata-3.1.1, anyio-4.10.0, cov-6.2.1, mock-3.14.1, benchmark-5.1.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 47 items\n\nsrc/tests/test_comprehensive_api.py::TestGNNModule::test_module_imports PASSED [  2%]\nsrc/tests/test_comprehensive_api.py::TestGNNModule::test_get_module_info PASSED [  4%]\nsrc/tests/test_comprehensive_api.py::TestGNNModule::test_validate_gnn_function PASSED [  6%]\nsrc/tests/test_comprehensive_api.py::TestGNNModule::test_feature_flags PASSED [  8%]\nsrc/tests/test_comprehensive_api.py::TestExportModule::test_module_imports PASSED [ 10%]\nsrc/tests/test_comprehensive_api.py::TestExportModule::test_get_module_info PASSED [ 12%]\nsrc/tests/test_comprehensive_api.py::TestExportModule::test_get_supported_formats PASSED [ 14%]\nsrc/tests/test_comprehensive_api.py::TestExportModule::test_export_gnn_model_invalid_format PASSED [ 17%]\nsrc/tests/test_comprehensive_api.py::TestRenderModule::test_module_imports PASSED [ 19%]\nsrc/tests/test_comprehensive_api.py::TestRenderModule::test_get_module_info PASSED [ 21%]\nsrc/tests/test_comprehensive_api.py::TestRenderModule::test_get_available_renderers PASSED [ 23%]\nsrc/tests/test_comprehensive_api.py::TestRenderModule::test_feature_flags PASSED [ 25%]\nsrc/tests/test_comprehensive_api.py::TestWebsiteModule::test_module_imports PASSED [ 27%]\nsrc/tests/test_comprehensive_api.py::TestWebsiteModule::test_get_module_info PASSED [ 29%]\nsrc/tests/test_comprehensive_api.py::TestWebsiteModule::test_get_supported_file_types PASSED [ 31%]\nsrc/tests/test_comprehensive_api.py::TestWebsiteModule::test_generate_website_from_pipeline_output_nonexistent PASSED [ 34%]\nsrc/tests/test_comprehensive_api.py::TestWebsiteModule::test_validate_website_config PASSED [ 36%]\nsrc/tests/test_comprehensive_api.py::TestSAPFModule::test_module_imports PASSED [ 38%]\nsrc/tests/test_comprehensive_api.py::TestSAPFModule::test_get_module_info PASSED [ 40%]\nsrc/tests/test_comprehensive_api.py::TestSAPFModule::test_get_audio_generation_options PASSED [ 42%]\nsrc/tests/test_comprehensive_api.py::TestSAPFModule::test_process_gnn_to_audio_invalid_input PASSED [ 44%]\nsrc/tests/test_comprehensive_api.py::TestOntologyModule::test_module_imports PASSED [ 46%]\nsrc/tests/test_comprehensive_api.py::TestOntologyModule::test_get_module_info PASSED [ 48%]\nsrc/tests/test_comprehensive_api.py::TestOntologyModule::test_get_ontology_processing_options PASSED [ 51%]\nsrc/tests/test_comprehensive_api.py::TestOntologyModule::test_process_gnn_ontology_nonexistent_file PASSED [ 53%]\nsrc/tests/test_comprehensive_api.py::TestOntologyModule::test_parse_gnn_ontology_section_empty PASSED [ 55%]\nsrc/tests/test_comprehensive_api.py::TestTypeCheckerModule::test_module_imports PASSED [ 57%]\nsrc/tests/test_comprehensive_api.py::TestTypeCheckerModule::test_type_checker_instantiation PASSED [ 59%]\nsrc/tests/test_comprehensive_api.py::TestVisualizationModule::test_module_imports PASSED [ 61%]\nsrc/tests/test_comprehensive_api.py::TestVisualizationModule::test_visualizer_instantiation PASSED [ 63%]\nsrc/tests/test_comprehensive_api.py::TestExecuteModule::test_module_imports PASSED [ 65%]\nsrc/tests/test_comprehensive_api.py::TestExecuteModule::test_executor_instantiation PASSED [ 68%]\nsrc/tests/test_comprehensive_api.py::TestLLMModule::test_module_imports PASSED [ 70%]\nsrc/tests/test_comprehensive_api.py::TestLLMModule::test_llm_processor_instantiation PASSED [ 72%]\nsrc/tests/test_comprehensive_api.py::TestMCPModule::test_module_imports PASSED [ 74%]\nsrc/tests/test_comprehensive_api.py::TestMCPModule::test_mcp_server_instantiation PASSED [ 76%]\nsrc/tests/test_comprehensive_api.py::TestSetupModule::test_module_imports PASSED [ 78%]\nsrc/tests/test_comprehensive_api.py::TestSetupModule::test_setup_functions_exist PASSED [ 80%]\nsrc/tests/test_comprehensive_api.py::TestUtilsModule::test_module_imports PASSED [ 82%]\nsrc/tests/test_comprehensive_api.py::TestUtilsModule::test_utils_classes_instantiation PASSED [ 85%]\nsrc/tests/test_comprehensive_api.py::TestPipelineModule::test_module_imports PASSED [ 87%]\nsrc/tests/test_comprehensive_api.py::TestPipelineModule::test_pipeline_config PASSED [ 89%]\nsrc/tests/test_comprehensive_api.py::TestMCPIntegration::test_mcp_availability_flags PASSED [ 91%]\nsrc/tests/test_comprehensive_api.py::TestMCPIntegration::test_register_tools_functions PASSED [ 93%]\nsrc/tests/test_comprehensive_api.py::TestModuleConsistency::test_version_consistency PASSED [ 95%]\nsrc/tests/test_comprehensive_api.py::TestModuleConsistency::test_feature_flags_consistency PASSED [ 97%]\nsrc/tests/test_comprehensive_api.py::TestModuleConsistency::test_module_info_consistency PASSED [100%]\n\n============================= slowest 10 durations =============================\n0.05s call     src/tests/test_comprehensive_api.py::TestExportModule::test_get_supported_formats\n\n(9 durations < 0.005s hidden.  Use -vv to show these durations.)\n============================== 47 passed in 0.08s ==============================\n",
    "stderr": "",
    "return_code": 0
  }
}