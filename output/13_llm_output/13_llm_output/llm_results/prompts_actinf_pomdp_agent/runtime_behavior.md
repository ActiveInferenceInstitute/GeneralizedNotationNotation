# Runtime Behavior

Prompt:

> Describe what happens when this GNN model runs and how it would behave in different settings or domains.

Response:

Based on the information in the doc:

1. The GNN model has three different models for the state and hidden states distribution, each with its own set of parameters (observation_outcomes, probability_prior) and initial policies (habit).

2. Each policy is represented as a vector of 3 probabilities over actions which are used to update the action selection based on the current observed observation i = i(1/H[i]), where H denotes an unbounded time horizon and is defined for each state transition in the GNN agent model.

3. The habit has one observation per state (two policies). This allows for a flexible policy assignment across states, with no planning constraints allowed to change from one action into another based on actions. However, there are 4 actions available: Actions = [1] - Use explore_actions() method of the model and then use random initialization of initial hypothesis distributions in GNN agent implementation (this is where the parameterizations for input states come from).

4. There's no prior over state distribution parameters but a habit which has one observation per state, corresponding to each policy. It uses the probability generated by the sequence of previous actions to update. 

So far, it looks like there are 3 different GNN models with their own set of parameters and initial policies (observable) for input observations, action selection from policy posterior via habit estimation, and planning on the future observation horizon. There is also no prior over states distribution parameters but a habit which has one observation per state, corresponding to each policy.