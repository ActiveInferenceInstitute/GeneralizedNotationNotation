# IDENTIFY_COMPONENTS

You've covered the core concepts of GNNs in Active Inference POMDP Agents. Now, let's dive into understanding the structure and implications of different activation graphs in this GNN implementation:

1. **State Variables**: The state variables represent which actions are taken (observations) based on a probability distribution over states. Each action corresponds to a discrete transition from one state to another, with corresponding probabilities for each choice. The number of states is the total number of observations. The number of observables determines the agent's decision-making process and can affect its performance during training.

2. **Observation Variables**: These variables capture the probability distribution over actions or other types of beliefs (facts). Each observation is a tuple containing an action, its corresponding probabilities for that observation across different states/actions, and any prior probabilities associated with those actions. The number of observations defines the agent's learning capacity to estimate future outcomes based on current observed data.

3. **Action Variables**: These variables represent the probability distribution over all actions or policy choices made during training. They are defined by a transition matrix from initial observation (state) to final state and can provide information about their behavior, such as their probabilities for subsequent states/actions in each iteration (`next`).

4. **Model Matrices**: The model matrices represent the joint probability distributions over actions/facts across all observations (`β`) or policies/priorities across different action combinations (state) pairs ($x$ and $y$) based on previous observations, prior probabilities, etc. These matrices are used to update beliefs in each state/action pair during training and provide predictions of future outcomes given the current observed data.

5. **Parameters**: The parameters represent each activation graph in the model, which define how the network adapts to different actions-state relationships based on training. They can vary between actions (e.g., `γ`, `α`) or policy interactions (`β`). Specifically:
   - **Preferred actions**: The number of predictions for each action/policy pair at each step and across all transitions ($P(y|x) = P(y; x)$, where $0 < |[i, j]| ≤ |n_actions|$ denotes the number of observations in a particular state). This allows for more informed decisions based on available actions.
   - **Generalized Actions**: A subset that combines the predicted probabilities from different actions/policies pairs at each step across all transitions ($P(y;x) = P(y, x_{ij})$) and represents which actions are executed during training. These can be used to represent more complex interactions between actions (e.g., "look for a particular target").
   - **Prior Actions**: A subset of the generalized actions represented as a combination of predicted probabilities from different actions/policies pairs (`P(y;x) = P(y; x_{i,j}`). These are used to represent predictions in terms of actions that occur together (e.g., "look for both targets").
   - **Generalized Actions with Prior**: A subset that represents each action combined using the prior probabilities from previous actions or policies (`P([x|y]) = P(y; x_{i,j}**`, where $[...]$ denotes a transition matrix). These are used to represent predictions in terms of actions together.
   - **Generalized Actions with Prior**: A subset that represents each action combined using the prior probabilities from previous actions or policies (`P([x|y]) = P(y; x_{i,j}**`), where $[...]$ denotes a transition matrix). These are used to represent predictions in terms of actions together.

In summary, these parameters describe how the network adaptively updates its beliefs based on observations and action combinations across different transitions between states/actions. The choice of which parameters is chosen depends on the specific use case and computational resources available for training a GNN model within a specified learning rate and initial activation distance.