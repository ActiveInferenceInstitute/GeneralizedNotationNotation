{
    "file_path": "/home/trim/Documents/GitHub/GeneralizedNotationNotation/src/gnn/examples/gnn_example_dynamic_perception_policy.md",
    "name": "gnn_example_dynamic_perception_policy",
    "metadata": {},
    "states": [],
    "parameters": {},
    "observations": [],
    "transitions": [],
    "ontology_annotations": {},
    "equations_text": "",
    "time_info": {},
    "footer_text": "",
    "signature": {},
    "raw_sections": {
        "GNNSection": "DynamicPerceptionWithPolicySelection\n\n## ImageFromPaper\nimage.png\n\n## GNNVersionAndFlags\nGNN v1\n\n## ModelName\nDynamic perception with Policy Selection v1\n\n## ModelAnnotation\nThis model relates a single hidden state to a single observable modality. It is a dynamic model because it tracks changes in the hidden state through time. There is Action applied via policy selection (π).\n\n## StateSpaceBlock\nA[2,2,type=float]\nD[2,1,type=float]\nB[2,len(π),2,type=float]\nπ=[2]\nC=[2,1]\nG[len(π),type=float]\ns[2,1,type=float]\ns_prime[2,1,type=float] # Next state (s at t+1)\no[2,1,type=float]\nt[1,type=int]\n\n## Connections\nD-s\ns-A\nA-o\ns-B\nB-s_prime\nC>G\nG>π\n\n## InitialParameterization\nA={(0.7,0.3),(0.4,0.6)}\nD={(0.5),(0.5)}\nC={(0.8),(0.2)}\nB={( ( (0.9,0.1),(0.1,0.9) ), ( (0.1,0.9),(0.9,0.1) ) )} # B[policy_index][state_from][state_to]\n\n## Equations\ns=sigma((1/2)(lnD+ln(B^dagger_{pi,tau}s_{pi,tau+1}))+lnA^T*o_tau) # for tau=1, policy π\ns=sigma((1/2)(ln(B_{pi,tau-1}s_{pi,tau-1})+ln(B^dagger_{pi,tau}s_{pi,tau+1}))+lnA^T*o_tau) # for tau>1, policy π\nG[π]=sum_tau(As_{pi,tau}(ln(A*s_{pi,tau})-lnC_tau)-diag(A^TlnA)*s_{pi,tau})\nπ=sigma(-G)\n\n## Time\nDynamic\nDiscreteTime=s\nModelTimeHorizon=Unbounded\n\n## ActInfOntologyAnnotation\nA=RecognitionMatrix\nB=TransitionMatrix\nC=Preference\nD=Prior\nG=ExpectedFreeEnergy\ns=HiddenState\ns_prime=NextHiddenState\no=Observation\nπ=PolicyVector\nt=Time\n\n## ModelParameters\nnum_hidden_states_factors: [2]\nnum_obs_modalities: [2]\nnum_control_action_dims: [2] # From len(π) which is 2, used in B matrix\n\n## Footer\nDynamic perception with Policy Selection v1\n\n## Signature\nNA"
    },
    "other_sections": {},
    "gnnsection": {
        "A[2,2,type": "float]",
        "D[2,1,type": "float]",
        "B[2,len(π),2,type": "float]",
        "π": "PolicyVector",
        "C": "Preference",
        "G[len(π),type": "float]",
        "s[2,1,type": "float]",
        "s_prime[2,1,type": "float] # Next state (s at t+1)",
        "o[2,1,type": "float]",
        "t[1,type": "int]",
        "A": "RecognitionMatrix",
        "D": "Prior",
        "B": "TransitionMatrix",
        "s": "HiddenState",
        "G[π]": "sum_tau(As_{pi,tau}(ln(A*s_{pi,tau})-lnC_tau)-diag(A^TlnA)*s_{pi,tau})",
        "DiscreteTime": "s",
        "ModelTimeHorizon": "Unbounded",
        "G": "ExpectedFreeEnergy",
        "s_prime": "NextHiddenState",
        "o": "Observation",
        "t": "Time",
        "num_hidden_states_factors": "[2]",
        "num_obs_modalities": "[2]",
        "num_control_action_dims": "[2] # From len(π) which is 2, used in B matrix"
    },
    "num_obs_modalities": [],
    "num_hidden_states_factors": [],
    "num_control_factors": []
}