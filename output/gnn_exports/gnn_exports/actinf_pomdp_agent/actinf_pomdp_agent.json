{
    "file_path": "/Users/4d/Documents/GitHub/GeneralizedNotationNotation/input/gnn_files/actinf_pomdp_agent.md",
    "name": "Classic Active Inference POMDP Agent v1",
    "raw_sections": {
        "GNNSection": "ActInfPOMDP",
        "GNNVersionAndFlags": "GNN v1",
        "ModelName": "Classic Active Inference POMDP Agent v1",
        "ModelAnnotation": "This model describes a classic Active Inference agent for a discrete POMDP:\n- One observation modality (\"state_observation\") with 3 possible outcomes.\n- One hidden state factor (\"location\") with 3 possible states.\n- The hidden state is fully controllable via 3 discrete actions.\n- The agent's preferences are encoded as log-probabilities over observations.\n- The agent has an initial policy prior (habit) encoded as log-probabilities over actions.",
        "StateSpaceBlock": "# Likelihood matrix: A[observation_outcomes, hidden_states]\nA[3,3,type=float]   # Likelihood mapping hidden states to observations\n\n# Transition matrix: B[states_next, states_previous, actions]\nB[3,3,3,type=float]   # State transitions given previous state and action\n\n# Preference vector: C[observation_outcomes]\nC[3,type=float]       # Log-preferences over observations\n\n# Prior vector: D[states]\nD[3,type=float]       # Prior over initial hidden states\n\n# Habit vector: E[actions]\nE[3,type=float]       # Initial policy prior (habit) over actions\n\n# Hidden State\ns[3,1,type=float]     # Current hidden state distribution\ns_prime[3,1,type=float] # Next hidden state distribution\n\n# Observation\no[3,1,type=int]     # Current observation (integer index)\n\n# Policy and Control\nπ[3,type=float]       # Policy (distribution over actions), no planning\nu[1,type=int]         # Action taken\nG[π,type=float]       # Expected Free Energy (per policy)\n\n# Time\nt[1,type=int]         # Discrete time step",
        "Connections": "D>s\ns-A\ns>s_prime\nA-o\ns-B\nC>G\nE>π\nG>π\nπ>u\nB>u\nu>s_prime",
        "InitialParameterization": "# A: 3 observations x 3 hidden states. Identity mapping (each state deterministically produces a unique observation). Rows are observations, columns are hidden states.\nA={\n  (0.9, 0.05, 0.05),\n  (0.05, 0.9, 0.05),\n  (0.05, 0.05, 0.9)\n}\n\n# B: 3 states x 3 previous states x 3 actions. Each action deterministically moves to a state. For each slice, rows are previous states, columns are next states. Each slice is a transition matrix corresponding to a different action selection.\nB={\n  ( (1.0,0.0,0.0), (0.0,1.0,0.0), (0.0,0.0,1.0) ),\n  ( (0.0,1.0,0.0), (1.0,0.0,0.0), (0.0,0.0,1.0) ),\n  ( (0.0,0.0,1.0), (0.0,1.0,0.0), (1.0,0.0,0.0) )\n}\n\n# C: 3 observations. Preference in terms of log-probabilities over observations.\nC={(0.1, 0.1, 1.0)}\n\n# D: 3 states. Uniform prior over hidden states. Rows are hidden states, columns are prior probabilities.\nD={(0.33333, 0.33333, 0.33333)}\n\n# E: 3 actions. Uniform habit used as initial policy prior.\nE={(0.33333, 0.33333, 0.33333)}",
        "Equations": "# Standard Active Inference update equations for POMDPs:\n# - State inference using Variational Free Energy with infer_states()\n# - Policy inference using Expected Free Energy = with infer_policies()\n# - Action selection from policy posterior: action = sample_action()",
        "Time": "Time=t\nDynamic\nDiscrete\nModelTimeHorizon=Unbounded # The agent is defined for an unbounded time horizon; simulation runs may specify a finite horizon.",
        "ActInfOntologyAnnotation": "A=LikelihoodMatrix\nB=TransitionMatrix\nC=LogPreferenceVector\nD=PriorOverHiddenStates\nE=Habit\nF=VariationalFreeEnergy\nG=ExpectedFreeEnergy\ns=HiddenState\ns_prime=NextHiddenState\no=Observation\nπ=PolicyVector # Distribution over actions\nu=Action       # Chosen action\nt=Time",
        "ModelParameters": "num_hidden_states: 3  # s[3]\nnum_obs: 3           # o[3]\nnum_actions: 3       # B actions_dim=3 (controlled by π)",
        "Footer": "Active Inference POMDP Agent v1 - GNN Representation. \nCurrently there is a planning horizon of 1 step (no deep planning), no precision modulation, no hierarchical nesting.",
        "Signature": "Cryptographic signature goes here"
    },
    "statespaceblock": [
        {
            "id": "A",
            "dimensions": "3,3,type=float",
            "original_id": "A"
        },
        {
            "id": "B",
            "dimensions": "3,3,3,type=float",
            "original_id": "B"
        },
        {
            "id": "C",
            "dimensions": "3,type=float",
            "original_id": "C"
        },
        {
            "id": "D",
            "dimensions": "3,type=float",
            "original_id": "D"
        },
        {
            "id": "E",
            "dimensions": "3,type=float",
            "original_id": "E"
        },
        {
            "id": "s",
            "dimensions": "3,1,type=float",
            "original_id": "s"
        },
        {
            "id": "s_prime",
            "dimensions": "3,1,type=float",
            "original_id": "s_prime"
        },
        {
            "id": "o",
            "dimensions": "3,1,type=int",
            "original_id": "o"
        },
        {
            "id": "u",
            "dimensions": "1,type=int",
            "original_id": "u"
        },
        {
            "id": "G",
            "dimensions": "π,type=float",
            "original_id": "G"
        },
        {
            "id": "t",
            "dimensions": "1,type=int",
            "original_id": "t"
        }
    ],
    "connections": [
        {
            "sources": [
                "D"
            ],
            "operator": ">",
            "targets": [
                "s"
            ],
            "attributes": {}
        },
        {
            "sources": [
                "s"
            ],
            "operator": "-",
            "targets": [
                "A"
            ],
            "attributes": {}
        },
        {
            "sources": [
                "s"
            ],
            "operator": ">",
            "targets": [
                "s_prime"
            ],
            "attributes": {}
        },
        {
            "sources": [
                "A"
            ],
            "operator": "-",
            "targets": [
                "o"
            ],
            "attributes": {}
        },
        {
            "sources": [
                "s"
            ],
            "operator": "-",
            "targets": [
                "B"
            ],
            "attributes": {}
        },
        {
            "sources": [
                "C"
            ],
            "operator": ">",
            "targets": [
                "G"
            ],
            "attributes": {}
        },
        {
            "sources": [
                "E"
            ],
            "operator": ">",
            "targets": [
                "π"
            ],
            "attributes": {}
        },
        {
            "sources": [
                "G"
            ],
            "operator": ">",
            "targets": [
                "π"
            ],
            "attributes": {}
        },
        {
            "sources": [
                "π"
            ],
            "operator": ">",
            "targets": [
                "u"
            ],
            "attributes": {}
        },
        {
            "sources": [
                "B"
            ],
            "operator": ">",
            "targets": [
                "u"
            ],
            "attributes": {}
        },
        {
            "sources": [
                "u"
            ],
            "operator": ">",
            "targets": [
                "s_prime"
            ],
            "attributes": {}
        }
    ],
    "initialparameterization": {
        "A": [
            [
                0.9,
                0.05,
                0.05
            ],
            [
                0.05,
                0.9,
                0.05
            ],
            [
                0.05,
                0.05,
                0.9
            ]
        ],
        "B": [
            [
                [
                    1.0,
                    0.0,
                    0.0
                ],
                [
                    0.0,
                    1.0,
                    0.0
                ],
                [
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            [
                [
                    0.0,
                    1.0,
                    0.0
                ],
                [
                    1.0,
                    0.0,
                    0.0
                ],
                [
                    0.0,
                    0.0,
                    1.0
                ]
            ],
            [
                [
                    0.0,
                    0.0,
                    1.0
                ],
                [
                    0.0,
                    1.0,
                    0.0
                ],
                [
                    1.0,
                    0.0,
                    0.0
                ]
            ]
        ],
        "C": [
            0.1,
            0.1,
            1.0
        ],
        "D": [
            0.33333,
            0.33333,
            0.33333
        ],
        "E": [
            0.33333,
            0.33333,
            0.33333
        ]
    }
}