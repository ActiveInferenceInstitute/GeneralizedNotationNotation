GNN Model Summary: Multifactor PyMDP Agent v1
Source File: gnn/examples/gnn_example_pymdp_agent.md

Metadata:
  description: This model represents a PyMDP agent with multiple observation modalities and hidden state factors.
- Observation modalities: "state_observation" (3 outcomes), "reward" (3 outcomes), "decision_proprioceptive" (3 outcomes)
- Hidden state factors: "reward_level" (2 states), "decision_state" (3 states)
- Control: "decision_state" factor is controllable with 3 possible actions.
The parameterization is derived from a PyMDP Python script example.

States (20):
  - ID: A_m0 (dimensions=3,2,3,type=float, original_id=A_m0)
  - ID: A_m1 (dimensions=3,2,3,type=float, original_id=A_m1)
  - ID: A_m2 (dimensions=3,2,3,type=float, original_id=A_m2)
  - ID: B_f0 (dimensions=2,2,1,type=float, original_id=B_f0)
  - ID: B_f1 (dimensions=3,3,3,type=float, original_id=B_f1)
  - ID: C_m0 (dimensions=3,type=float, original_id=C_m0)
  - ID: C_m1 (dimensions=3,type=float, original_id=C_m1)
  - ID: C_m2 (dimensions=3,type=float, original_id=C_m2)
  - ID: D_f0 (dimensions=2,type=float, original_id=D_f0)
  - ID: D_f1 (dimensions=3,type=float, original_id=D_f1)
  - ID: s_f0 (dimensions=2,1,type=float, original_id=s_f0)
  - ID: s_f1 (dimensions=3,1,type=float, original_id=s_f1)
  - ID: s_prime_f0 (dimensions=2,1,type=float, original_id=s_prime_f0)
  - ID: s_prime_f1 (dimensions=3,1,type=float, original_id=s_prime_f1)
  - ID: o_m0 (dimensions=3,1,type=float, original_id=o_m0)
  - ID: o_m1 (dimensions=3,1,type=float, original_id=o_m1)
  - ID: o_m2 (dimensions=3,1,type=float, original_id=o_m2)
  - ID: u_f1 (dimensions=1,type=int, original_id=u_f1)
  - ID: G (dimensions=1,type=float, original_id=G)
  - ID: t (dimensions=1,type=int, original_id=t)

Initial Parameters (24):
  A_m0: {
  ( (0.33333,0.33333,0.8), (0.33333,0.33333,0.2) ),  # obs: 0; (vals for s_f1 over s_f0=0), (vals for s_f1 over s_f0=1)
  ( (0.33333,0.33333,0.0), (0.33333,0.33333,0.0) ),  # obs: 1
  ( (0.33333,0.33333,0.2), (0.33333,0.33333,0.8) )   # obs: 2
  A_m1: {
  ( (0.0,0.731,0.0), (0.0,0.269,0.0) ),  # obs: 0
  ( (0.0,0.269,0.0), (0.0,0.731,0.0) ),  # obs: 1
  ( (1.0,0.0,1.0), (1.0,0.0,1.0) )      # obs: 2
  A_m2: {
  ( (1.0,0.0,0.0), (1.0,0.0,0.0) ),  # obs: 0
  ( (0.0,1.0,0.0), (0.0,1.0,0.0) ),  # obs: 1
  ( (0.0,0.0,1.0), (0.0,0.0,1.0) )   # obs: 2
  B_f0: {
  ( (1.0),(0.0) ), # s_next: 0; (vals for s_prev over action=0)
  ( (0.0),(1.0) )  # s_next: 1
  B_f1: {
  ( (1.0,1.0,1.0), (0.0,0.0,0.0), (0.0,0.0,0.0) ), # s_next: 0; (vals for actions over s_prev=0), (vals for actions over s_prev=1), ...
  ( (0.0,0.0,0.0), (1.0,1.0,1.0), (0.0,0.0,0.0) ), # s_next: 1
  ( (0.0,0.0,0.0), (0.0,0.0,0.0), (1.0,1.0,1.0) )  # s_next: 2
  C_m0: [0.0, 0.0, 0.0]
  C_m1: [1.0, -2.0, 0.0]
  C_m2: [0.0, 0.0, 0.0]
  D_f0: [0.5, 0.5]
  D_f1: [0.33333, 0.33333, 0.33333]

General Parameters (0):

Observations (0):

Transitions (0):

Ontology Annotations (20):
  A_m0 = LikelihoodMatrixModality0
  A_m1 = LikelihoodMatrixModality1
  A_m2 = LikelihoodMatrixModality2
  B_f0 = TransitionMatrixFactor0
  B_f1 = TransitionMatrixFactor1
  C_m0 = LogPreferenceVectorModality0
  C_m1 = LogPreferenceVectorModality1
  C_m2 = LogPreferenceVectorModality2
  D_f0 = PriorOverHiddenStatesFactor0
  D_f1 = PriorOverHiddenStatesFactor1
  s_f0 = HiddenStateFactor0
  s_f1 = HiddenStateFactor1
  s_prime_f0 = NextHiddenStateFactor0
  s_prime_f1 = NextHiddenStateFactor1
  o_m0 = ObservationModality0
  o_m1 = ObservationModality1
  o_m2 = ObservationModality2
  Ï€_f1 = PolicyVectorFactor1 # Distribution over actions for factor 1
  u_f1 = ActionFactor1       # Chosen action for factor 1
  G = ExpectedFreeEnergy

