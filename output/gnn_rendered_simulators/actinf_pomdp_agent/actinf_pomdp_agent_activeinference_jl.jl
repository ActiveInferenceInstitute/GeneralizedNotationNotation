# ActiveInference.jl Simulation
# Generated from GNN Model: Classic Active Inference POMDP Agent v1
# Generated: 2025-07-28 07:42:31

using ActiveInference
using LinearAlgebra
using Random
using Plots
using Statistics

# Set random seed for reproducibility
Random.seed!(42)

# Model parameters extracted from GNN specification
const NUM_STATES = 3
const NUM_OBSERVATIONS = 3
const NUM_ACTIONS = 3
const TIME_STEPS = 20

println("ðŸ”¬ ActiveInference.jl Simulation")
println("ðŸ“Š State Space: $NUM_STATES states, $NUM_OBSERVATIONS observations, $NUM_ACTIONS actions")

# Initialize model matrices from GNN specification
function initialize_matrices()
    println("\nðŸ—ï¸  Initializing model matrices...")
    
    # A matrix: Observation model P(o|s)
    # Create identity-like mapping with some noise for realism
    A = Matrix{Float64}(I, NUM_OBSERVATIONS, NUM_STATES)
    if NUM_OBSERVATIONS != NUM_STATES
        # If dimensions don't match, create appropriate mapping
        A = rand(NUM_OBSERVATIONS, NUM_STATES)
        A = A ./ sum(A, dims=1)  # Normalize columns
    else
        # Add small noise to diagonal
        A += 0.1 * rand(NUM_OBSERVATIONS, NUM_STATES)
        A = A ./ sum(A, dims=1)  # Normalize columns
    end
    
    # B matrix: Transition model P(s'|s,a)
    B = zeros(NUM_STATES, NUM_STATES, NUM_ACTIONS)
    for action in 1:NUM_ACTIONS
        # Create different transition patterns for each action
        if action == 1
            # Action 1: Stay in same state (identity + noise)
            B[:, :, action] = Matrix{Float64}(I, NUM_STATES, NUM_STATES)
            B[:, :, action] += 0.1 * rand(NUM_STATES, NUM_STATES)
        else
            # Other actions: Move to next state (cyclical)
            for s in 1:NUM_STATES
                next_state = (s % NUM_STATES) + 1
                B[next_state, s, action] = 0.8
                B[s, s, action] = 0.2  # Some probability of staying
            end
        end
        # Normalize columns for each action
        B[:, :, action] = B[:, :, action] ./ sum(B[:, :, action], dims=1)
    end
    
    # C vector: Preferences over observations
    C = zeros(NUM_OBSERVATIONS)
    C[end] = 2.0  # Prefer last observation state
    if NUM_OBSERVATIONS > 1
        C[1] = -1.0  # Avoid first observation state
    end
    
    # D vector: Prior beliefs over initial states
    D = ones(NUM_STATES) / NUM_STATES  # Uniform prior
    
    println("âœ“ Matrices initialized successfully")
    println("  - A matrix shape: $(size(A))")
    println("  - B matrix shape: $(size(B))")
    println("  - C vector length: $(length(C))")
    println("  - D vector length: $(length(D))")
    
    return A, B, C, D
end

# Initialize the matrices
A, B, C, D = initialize_matrices()

# Create agent
function create_agent(A, B, C, D)
    println("\nðŸ¤– Creating Active Inference agent...")
    
    try
        # Create agent with initialized matrices
        agent = Agent(
            A = A,
            B = B, 
            C = C,
            D = D,
            planning_horizon = 3,
            action_selection = "deterministic"
        )
        
        println("âœ“ Agent created successfully")
        return agent
        
    catch e
        println("âŒ Failed to create agent: $e")
        
        # Fallback: create agent with different parameters
        println("ðŸ”„ Trying fallback agent creation...")
        agent = Agent(A, B, C, D)
        println("âœ“ Fallback agent created")
        return agent
    end
end

# Environment simulation
mutable struct SimpleEnvironment
    state::Int
    num_states::Int
    A::Matrix{Float64}
    B::Array{Float64, 3}
    
    function SimpleEnvironment(initial_state::Int, A::Matrix, B::Array)
        new(initial_state, size(A, 2), A, B)
    end
end

function step!(env::SimpleEnvironment, action::Int)
    # Sample next state according to transition model
    transition_probs = env.B[:, env.state, action]
    next_state = sample_from_categorical(transition_probs)
    env.state = next_state
    
    # Generate observation according to observation model
    obs_probs = env.A[:, env.state]
    observation = sample_from_categorical(obs_probs)
    
    return observation
end

function sample_from_categorical(probs::Vector)
    cumsum_probs = cumsum(probs)
    rand_val = rand()
    return findfirst(x -> x >= rand_val, cumsum_probs)
end

# Run simulation
function run_simulation()
    println("\nðŸš€ Starting Active Inference simulation...")
    
    # Create agent
    agent = create_agent(A, B, C, D)
    
    # Create environment
    initial_state = 1
    env = SimpleEnvironment(initial_state, A, B)
    
    # Storage for results
    observations = Int[]
    actions = Int[]
    states = Int[]
    beliefs = Vector{Vector{Float64}}()
    
    println("\nðŸ“ˆ Running simulation for $TIME_STEPS steps...")
    
    for t in 1:TIME_STEPS
        # Current state and observation
        push!(states, env.state)
        
        # Generate observation
        observation = step!(env, 1)  # Default action for first step
        push!(observations, observation)
        
        # Agent inference
        try
            # Infer states given observation
            qs = infer_states(agent, [observation])
            push!(beliefs, qs[1])  # Store belief over first state factor
            
            # Infer policies and select action
            q_pi = infer_policies(agent)
            action = sample_action(agent, q_pi)
            push!(actions, action[1])  # Take first action component
            
            # Update environment with selected action
            if t < TIME_STEPS
                step!(env, action[1])
            end
            
            # Print progress
            if t % 5 == 0 || t <= 5
                belief_max = argmax(qs[1])
                println("  Step $t: obs=$observation, action=$(action[1]), state=$(env.state), belief_peak=$belief_max")
            end
            
        catch e
            println("âš ï¸  Error at step $t: $e")
            # Fallback: random action
            random_action = rand(1:NUM_ACTIONS)
            push!(actions, random_action)
            push!(beliefs, ones(NUM_STATES) / NUM_STATES)
        end
    end
    
    println("âœ… Simulation completed!")
    
    return (
        observations = observations,
        actions = actions,
        states = states,
        beliefs = beliefs
    )
end

# Visualization function
function plot_results(results)
    println("\nðŸ“Š Creating visualizations...")
    
    try
        observations, actions, states, beliefs = results.observations, results.actions, results.states, results.beliefs
        
        # Convert beliefs to matrix for plotting
        belief_matrix = hcat(beliefs...)'
        
        # Create plots
        p1 = plot(1:length(observations), observations,
                 title="Observations Over Time",
                 xlabel="Time Step", ylabel="Observation",
                 marker=:circle, linewidth=2, label="Observations")
        
        p2 = plot(1:length(actions), actions,
                 title="Actions Over Time", 
                 xlabel="Time Step", ylabel="Action",
                 marker=:square, linewidth=2, label="Actions")
        
        p3 = plot(1:length(states), states,
                 title="True States Over Time",
                 xlabel="Time Step", ylabel="State", 
                 marker=:diamond, linewidth=2, label="States")
        
        p4 = heatmap(1:TIME_STEPS, 1:NUM_STATES, belief_matrix',
                    title="State Beliefs Over Time",
                    xlabel="Time Step", ylabel="State",
                    color=:viridis)
        
        # Combine plots
        combined_plot = plot(p1, p2, p3, p4, layout=(2,2), size=(1000, 800))
        
        # Save plot
        output_file = "activeinference_jl_results.png"
        savefig(combined_plot, output_file)
        println("ðŸ’¾ Saved visualization to: $output_file")
        
        # Print summary statistics
        println("\nðŸ“Š Summary Statistics:")
        println("  - Average state: $(round(mean(states), digits=2))")
        println("  - Most common observation: $(mode(observations))")
        println("  - Most common action: $(mode(actions))")
        println("  - Final state: $(states[end])")
        
    catch e
        println("âš ï¸  Visualization failed: $e")
    end
end

# Main execution function
function main()
    println("="^60)
    println("ActiveInference.jl - GNN Generated Simulation")
    println("Model: Classic Active Inference POMDP Agent v1")
    println("="^60)
    
    try
        # Run the simulation
        results = run_simulation()
        
        # Create visualizations
        plot_results(results)
        
        println("\nðŸŽ‰ ActiveInference.jl simulation completed successfully!")
        
        return 0
        
    catch e
        println("âŒ Simulation failed: $e")
        println("ðŸ” Stack trace:")
        println(sprint(showerror, e, catch_backtrace()))
        return 1
    end
end

# Helper function to handle mode calculation
function mode(arr)
    counts = Dict{eltype(arr), Int}()
    for item in arr
        counts[item] = get(counts, item, 0) + 1
    end
    return argmax(counts)
end

# Run the simulation
if abspath(PROGRAM_FILE) == @__FILE__
    exit(main())
end
