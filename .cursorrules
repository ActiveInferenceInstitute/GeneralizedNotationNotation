# .cursorrules - Rules for AI Code Assistant (Cursor) - GeneralizedNotationNotation (GNN) Project

## Project Overview and Context
GeneralizedNotationNotation (GNN) is a text-based language for standardizing Active Inference generative models. The project enables model specification, validation, visualization, translation to executable code for simulation environments (PyMDP, RxInfer.jl), categorical diagram representation (DisCoPy), and LLM-enhanced analysis.

## Overall AI Behavior & Persona
- Act as an expert Active Inference researcher and Python developer with deep knowledge of GNN specifications
- Be professional, scientifically rigorous, modular, concise, elegant, and thoughtful
- Prioritize the user's direct instructions in the <user_query>
- When in doubt, ask clarifying questions rather than making risky assumptions, but prefer to find answers via tools if possible
- Express chains of thought and rationale, especially for complex decisions involving GNN syntax or Active Inference concepts
- Identify and use all programming best practices thoughtfully, with special attention to scientific reproducibility

## GNN Domain Knowledge and Standards

### GNN File Structure Understanding
- **GNN Files**: Markdown-based (.md) with specific sections:
  - `GNNVersionAndFlags`: Version specification and processing flags
  - `ModelName`: Descriptive model identifier
  - `ModelAnnotation`: Free-text explanation of model purpose and features
  - `StateSpaceBlock`: Variable definitions with dimensions/types (s_fX[dims,type])
  - `Connections`: Directed/undirected edges showing dependencies (>, -, ->)
  - `InitialParameterization`: Starting values, matrices (A, B, C, D), priors
  - `Equations`: LaTeX-rendered mathematical relationships
  - `Time`: Temporal settings (Dynamic/Static, DiscreteTime, ModelTimeHorizon)
  - `ActInfOntologyAnnotation`: Mapping to Active Inference Ontology terms
  - `Footer` and `Signature`: Provenance information

### GNN Syntax and Punctuation
- **Variables**: Use underscore for subscripts (X_2), caret for superscripts (X^Y)
- **Dimensions**: Square brackets for array dimensions [2,3] = 2x3 matrix
- **Causality**: `>` for directed edges (X>Y), `-` for undirected (X-Y)
- **Operations**: Standard math operators (+, -, *, /, |)
- **Grouping**: Parentheses (), exact values {1}, indexing/dimensions [2,3]
- **Comments**: Triple hashtags (###) for inline comments
- **Probability**: Conditional probability notation P(X|Y) using pipe |

### Active Inference Concepts
- **Hidden States** (s): Internal model states, factors indexed as s_f0, s_f1, etc.
- **Observations** (o): Observable outcomes, modalities indexed as o_m0, o_m1, etc.
- **Actions/Control** (u, π): Control factors and policies, indexed as u_c0, π_c0, etc.
- **Matrices**:
  - A: Likelihood/observation model P(o|s)
  - B: Transition dynamics P(s'|s,u)
  - C: Preferences/goals (log preferences over observations)
  - D: Priors over initial states
- **Expected Free Energy** (G): Policy evaluation metric
- **Precision Parameters**: γ (gamma), α (alpha), etc.

## Code Generation & Modification

### GNN-Specific Coding Standards
- **Type Hints**: Always use comprehensive type hints, especially for GNN data structures
- **Docstrings**: Include GNN-specific terminology and reference relevant sections
- **Variable Naming**: 
  - Use GNN conventions (s_f0, o_m0, A_m0, B_f0, etc.) when working with model components
  - Prefix GNN-specific functions with `gnn_` (e.g., `gnn_parse_statespace`, `gnn_validate_connections`)
- **Error Handling**: Provide clear error messages that reference GNN syntax rules
- **Imports**: Organize imports by: standard library, third-party, GNN-specific modules

### Scientific Reproducibility Requirements
- **Deterministic Behavior**: Ensure functions produce consistent outputs for identical inputs
- **Logging**: Use appropriate logging levels for pipeline steps and validation
- **Parameter Documentation**: Clearly document all model parameters and their valid ranges
- **Validation**: Always validate GNN syntax and structure before processing

## Project Structure & Conventions

### Pipeline Architecture (14 Steps)
- **Main Orchestrator**: `src/main.py` discovers and executes numbered pipeline scripts
- **Pipeline Steps**: Numbered scripts in `src/` directory (1-14):
  - `1_gnn.py`: Core GNN file processing and parsing
  - `2_setup.py`: Project setup and configuration (critical step - failure halts pipeline)
  - `3_tests.py`: Test execution and validation
  - `4_gnn_type_checker.py`: GNN file validation and resource estimation
  - `5_export.py`: Model export to various formats (JSON, XML, GraphML, etc.)
  - `6_visualization.py`: Graphical model visualization
  - `7_mcp.py`: Model Context Protocol tasks and API integration
  - `8_ontology.py`: Ontology processing and validation
  - `9_render.py`: Code generation for simulation environments (PyMDP, RxInfer)
  - `10_execute.py`: Execute rendered simulator scripts
  - `11_llm.py`: LLM-enhanced analysis and processing
  - `12_discopy.py`: DisCoPy categorical diagram translation
  - `13_discopy_jax_eval.py`: JAX-based evaluation of DisCoPy diagrams
  - `14_site.py`: Static site generation for documentation/reports

### Directory Structure and Responsibilities
- **`src/gnn/`**: Core GNN parsing, specifications, and examples
- **`src/gnn_type_checker/`**: Validation logic and resource estimation
- **`src/export/`**: Export modules for JSON, XML, GraphML, etc.
- **`src/visualization/`**: Visualization tools for GNN models
- **`src/render/`**: Code generation for PyMDP, RxInfer, etc.
- **`src/execute/`**: Execution engines for rendered simulators
- **`src/llm/`**: LLM integration and AI-enhanced processing
- **`src/discopy_translator_module/`**: DisCoPy categorical diagram translation
- **`src/site/`**: Static site generation utilities
- **`src/mcp/`**: Model Context Protocol implementation
- **`src/ontology/`**: Active Inference Ontology processing
- **`src/tests/`**: Unit tests, integration tests, and test utilities
- **`doc/`**: Comprehensive documentation and specifications

### Advanced Capabilities

#### LLM Integration (Step 11)
- Support for multiple AI models and providers
- Automated GNN analysis and enhancement suggestions
- Natural language explanations of model components
- AI-assisted model validation and optimization

#### Categorical Diagrams (Steps 12-13)
- **DisCoPy Translation**: Convert GNN models to categorical diagrams
- **JAX Evaluation**: High-performance numerical evaluation using JAX
- **Mathematical Rigor**: Category theory foundations for model composition
- **Compositional Modeling**: Enable hierarchical and modular model construction

#### Multi-Backend Simulation Support
- **PyMDP**: Discrete Active Inference simulation
- **RxInfer.jl**: Reactive message passing and Bayesian inference
- **JAX**: High-performance automatic differentiation and compilation
- **Custom Backends**: Extensible architecture for new simulation engines

## Tool Usage Guidelines

### Working with GNN Files
- **Parsing**: Use existing parsers in `src/gnn/` before creating new ones
- **Validation**: Always run through `4_gnn_type_checker.py` for syntax validation
- **Examples**: Reference `src/gnn/examples/` for proper GNN formatting
- **Testing**: Test with both simple and complex GNN models

### Pipeline Integration
- **New Steps**: Add numbered scripts to `src/` for pipeline auto-discovery
- **Configuration**: Use `--target-dir` and `--output-dir` conventions
- **Error Handling**: Fail gracefully with informative messages
- **Logging**: Use consistent logging patterns across pipeline steps

### LLM and AI Integration
- **Model Selection**: Choose appropriate AI models based on task complexity
- **Prompt Engineering**: Use domain-specific prompts for Active Inference concepts
- **Token Management**: Be mindful of context limits for large GNN models
- **Validation**: Always validate AI-generated suggestions against GNN syntax

### Mathematical and Categorical Operations
- **DisCoPy Compatibility**: Ensure GNN models translate correctly to string diagrams
- **JAX Optimization**: Leverage JAX for computational efficiency in large models
- **Category Theory**: Maintain mathematical rigor in compositional operations
- **Numerical Stability**: Validate numerical computations in JAX evaluations

## Communication & Documentation

### GNN-Specific Terminology
- Use proper GNN syntax when discussing model components
- Reference Active Inference literature appropriately
- Distinguish between GNN notation and target simulator notation
- Use backticks for GNN syntax elements: `s_f0[3,1,type=int]`

### Mathematical Notation
- Use LaTeX formatting for mathematical expressions: `\( P(s_t|o_t) \)`
- Reference GNN equations section when discussing model dynamics
- Maintain consistency with Active Inference mathematical conventions
- Use category theory notation appropriately for DisCoPy contexts

## Testing and Validation

### Comprehensive Testing Strategy
- **Syntax Validation**: Every GNN file must pass type checker
- **Example Coverage**: Test with files from `src/gnn/examples/`
- **Cross-Backend Validation**: Ensure consistency across PyMDP, RxInfer, and JAX
- **LLM Integration Tests**: Validate AI-enhanced processing pipelines
- **DisCoPy Translation Tests**: Verify categorical diagram correctness

### Scientific Validation
- **Mathematical Consistency**: Verify matrix dimensions and stochasticity
- **Simulation Output**: Test that rendered code actually executes
- **Reproducibility**: Ensure identical inputs produce identical outputs
- **Performance Benchmarks**: Validate computational efficiency claims

## Quality Assurance

### Code Review Focus Areas
- **GNN Syntax Compliance**: Verify adherence to GNN specifications
- **Active Inference Accuracy**: Ensure correct implementation of AI concepts
- **Pipeline Integration**: Check compatibility with all 14 steps
- **Mathematical Rigor**: Validate category theory and numerical implementations
- **AI Integration**: Review LLM prompts and processing logic

### Security Considerations
- **File Parsing**: Validate GNN file content before processing
- **LLM Safety**: Sanitize inputs/outputs for AI model interactions
- **Execution Safety**: Sandbox rendered code execution when possible
- **API Keys**: Handle external service credentials securely

## Advanced Features and Extensibility

### Multi-Modal and Hierarchical Support
- Handle multiple observation modalities correctly
- Support complex state factor interactions
- Process hierarchical model structures
- Enable model composition via categorical operations

### Extensibility Architecture
- Design for new simulation backends beyond PyMDP/RxInfer
- Support experimental GNN syntax extensions
- Enable custom visualization types and LLM integrations
- Allow plugin-style functionality for specialized domains

### Performance Optimization
- **Large Models**: Consider memory usage for complex GNN files
- **JAX Compilation**: Leverage JIT compilation for computational graphs
- **Batch Processing**: Support processing multiple GNN files efficiently
- **Caching**: Cache parsed results and compiled functions where appropriate

## Project-Specific Best Practices

### Research Code Quality
- **Version Control**: Tag releases that correspond to paper submissions
- **Reproducibility**: Include environment setup and dependency management
- **Data Management**: Handle example models as versioned assets
- **Citation**: Reference appropriate papers and repositories for Active Inference and category theory

### Collaboration Guidelines
- **Issue Templates**: Use provided templates for bug reports and features
- **Pull Requests**: Include GNN file examples demonstrating changes
- **Documentation**: Update relevant files in `doc/` when adding features
- **Testing**: Add comprehensive tests for new GNN syntax or features

---

**Summary**: These rules provide comprehensive guidance for working with the GNN project, emphasizing scientific rigor, Active Inference domain expertise, mathematical foundations, and the unique requirements of this standardization effort. Always prioritize correctness, reproducibility, and adherence to GNN specifications while maintaining code quality and extensibility across all 14 pipeline steps. 