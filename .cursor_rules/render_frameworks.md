# Render Frameworks Guide

> **Environment Note**: Framework-specific code is generated by Step 11 (Render). Use `uv run python src/11_render.py` to generate code for all available frameworks.

## Overview

The GNN pipeline generates executable simulation code for multiple Active Inference frameworks. This guide documents each supported framework, its requirements, and the code generation patterns used.

---

## Supported Frameworks

| Framework | Language | Status | Dependency | Use Case |
|-----------|----------|--------|------------|----------|
| PyMDP | Python | Optional | `uv pip install inferactively-pymdp` | Python Active Inference |
| JAX | Python | Recommended | `uv pip install jax optax` | High-performance ML |
| RxInfer.jl | Julia | Optional | Julia + RxInfer | Probabilistic programming |
| ActiveInference.jl | Julia | Optional | Julia + ActiveInference | Native Julia AI |
| DisCoPy | Python | Optional | `uv pip install discopy` | Categorical diagrams |

---

## PyMDP Framework

### Overview

PyMDP is a Python library for Active Inference simulations. It provides a complete POMDP implementation with belief updating, policy inference, and action selection.

### Requirements

```bash
uv pip install inferactively-pymdp
# Or use UV optional group:
uv sync --extra active-inference
```

### Generated Code Structure

```python
"""
PyMDP Simulation: {model_name}
Generated from GNN specification

Framework: PyMDP (Active Inference in Python)
Model: {model_name}
States: {n_states}, Observations: {n_obs}, Actions: {n_actions}
"""

import numpy as np

# Check PyMDP availability
try:
    from pymdp.agent import Agent
    from pymdp import utils
    PYMDP_AVAILABLE = True
except ImportError:
    PYMDP_AVAILABLE = False
    print("PyMDP not installed. Install with: uv pip install inferactively-pymdp")

# Model Matrices
A = np.array([...])  # Observation likelihood (n_obs x n_states)
B = np.array([...])  # Transition dynamics (n_states x n_states x n_actions)
C = np.array([...])  # Prior preferences (n_obs,)
D = np.array([...])  # Initial state prior (n_states,)

def create_agent():
    """Create PyMDP agent with model matrices."""
    if not PYMDP_AVAILABLE:
        raise ImportError("PyMDP required")
    
    return Agent(
        A=A,
        B=B,
        C=C,
        D=D,
        policy_len=1,
        inference_algo="VANILLA"
    )

def run_simulation(n_timesteps=10):
    """Run Active Inference simulation."""
    agent = create_agent()
    
    # Initialize
    obs = agent.reset()
    
    for t in range(n_timesteps):
        # Infer state and select action
        qs = agent.infer_states(obs)
        action = agent.sample_action()
        
        # Environment step (simplified)
        obs = np.random.choice(len(C), p=A[:, np.argmax(qs)])
        
        print(f"Step {t}: obs={obs}, action={action}")

if __name__ == "__main__":
    if PYMDP_AVAILABLE:
        run_simulation()
    else:
        print("Install PyMDP to run simulation")
```

### Rendering Details

- **Location**: `src/render/pymdp/pymdp_renderer.py`
- **Output**: `output/11_render_output/{model}/pymdp/{model}_pymdp.py`
- **Fallback**: Generates stub with installation instructions if PyMDP unavailable

---

## JAX Framework

### Overview

JAX is a high-performance numerical computing library. The GNN pipeline generates **pure JAX code** that does not require Flax or other neural network libraries.

### Requirements

```bash
uv pip install jax jaxlib optax
# Or use UV optional group:
uv sync --extra active-inference
# Note: Flax is NOT required
```

### Generated Code Structure

```python
"""
JAX Active Inference Model: {model_name}
Generated from GNN specification

Framework: Pure JAX (no Flax dependency)
Model: {model_name}
States: {n_states}, Observations: {n_obs}, Actions: {n_actions}
"""

import jax
import jax.numpy as jnp
from jax import random, jit, vmap
import optax

# Model Configuration
N_STATES = {n_states}
N_OBS = {n_obs}
N_ACTIONS = {n_actions}

# Model Matrices (as JAX arrays)
A_MATRIX = jnp.array([...])  # Observation likelihood
B_MATRIX = jnp.array([...])  # Transition dynamics
C_VECTOR = jnp.array([...])  # Prior preferences
D_VECTOR = jnp.array([...])  # Initial state prior

@jit
def softmax(x, temperature=1.0):
    """Numerically stable softmax."""
    x_scaled = x / temperature
    x_max = jnp.max(x_scaled)
    exp_x = jnp.exp(x_scaled - x_max)
    return exp_x / jnp.sum(exp_x)

@jit
def belief_update(prior, observation, A):
    """Bayesian belief update given observation."""
    likelihood = A[observation, :]
    posterior = prior * likelihood
    return posterior / jnp.sum(posterior)

@jit
def expected_free_energy(qs, A, B, C, action):
    """Compute expected free energy for action."""
    # Predicted next state
    qs_next = B[:, :, action] @ qs
    
    # Predicted observations
    qo = A @ qs_next
    
    # Epistemic value (information gain)
    H_qo = -jnp.sum(qo * jnp.log(qo + 1e-10))
    
    # Pragmatic value (preference satisfaction)
    pragmatic = jnp.sum(qo * C)
    
    return -pragmatic + H_qo

@jit
def select_action(qs, A, B, C, temperature=1.0):
    """Select action based on expected free energy."""
    G = jnp.array([
        expected_free_energy(qs, A, B, C, a)
        for a in range(N_ACTIONS)
    ])
    action_probs = softmax(-G, temperature)
    return action_probs

def run_simulation(key, n_timesteps=10):
    """Run Active Inference simulation with JAX."""
    # Initialize belief
    qs = D_VECTOR.copy()
    
    for t in range(n_timesteps):
        key, subkey = random.split(key)
        
        # Select action
        action_probs = select_action(qs, A_MATRIX, B_MATRIX, C_VECTOR)
        action = random.categorical(subkey, jnp.log(action_probs))
        
        # Simulate observation
        key, subkey = random.split(key)
        obs_probs = A_MATRIX @ qs
        obs = random.categorical(subkey, jnp.log(obs_probs))
        
        # Update beliefs
        qs = belief_update(qs, obs, A_MATRIX)
        
        print(f"Step {t}: obs={obs}, action={action}, belief_entropy={-jnp.sum(qs * jnp.log(qs + 1e-10)):.3f}")

if __name__ == "__main__":
    key = random.PRNGKey(42)
    run_simulation(key)
```

### Key Design Decisions

1. **No Flax Dependency**: Generated code uses pure JAX functional patterns
2. **JIT Compilation**: Core functions are decorated with `@jit` for performance
3. **Explicit State**: No hidden state or classes - pure functional approach
4. **Numerical Stability**: Uses log-space operations where appropriate

### Rendering Details

- **Location**: `src/render/jax/jax_renderer.py`
- **Output**: `output/11_render_output/{model}/jax/{model}_jax.py`
- **Recent Change**: Removed Flax dependency (December 2025)

---

## RxInfer.jl Framework

### Overview

RxInfer.jl is a Julia package for probabilistic programming with reactive message passing. It provides efficient inference for complex probabilistic models.

### Requirements

```bash
# Install Julia from https://julialang.org
# Then in Julia REPL:
using Pkg
Pkg.add("RxInfer")
Pkg.add("Distributions")
```

### Generated Code Structure

```julia
#=
RxInfer.jl Active Inference Model: {model_name}
Generated from GNN specification

Framework: RxInfer.jl (Reactive Message Passing)
Model: {model_name}
States: {n_states}, Observations: {n_obs}, Actions: {n_actions}
=#

using RxInfer
using Distributions
using LinearAlgebra
using Random

# Model Configuration
const N_STATES = {n_states}
const N_OBS = {n_obs}
const N_ACTIONS = {n_actions}

# Model Matrices
const A_MATRIX = [...]  # Observation likelihood
const B_MATRIX = [...]  # Transition dynamics
const C_VECTOR = [...]  # Prior preferences
const D_VECTOR = [...]  # Initial state prior

# Define probabilistic model
@model function active_inference_model(n_timesteps)
    # State sequence
    s = randomvar(n_timesteps)
    o = randomvar(n_timesteps)
    
    # Initial state
    s[1] ~ Categorical(D_VECTOR)
    o[1] ~ Categorical(A_MATRIX[:, s[1]])
    
    # Dynamics
    for t in 2:n_timesteps
        s[t] ~ Categorical(B_MATRIX[:, s[t-1], 1])
        o[t] ~ Categorical(A_MATRIX[:, s[t]])
    end
    
    return s, o
end

function run_inference(observations; n_iterations=10)
    """Run inference given observations."""
    n_timesteps = length(observations)
    
    # Create model
    model = active_inference_model(n_timesteps)
    
    # Run inference
    result = infer(
        model = model,
        data = (o = observations,),
        iterations = n_iterations
    )
    
    return result
end

function main()
    println("RxInfer.jl Active Inference Model: {model_name}")
    
    # Generate sample observations
    observations = rand(1:N_OBS, 10)
    
    # Run inference
    result = run_inference(observations)
    
    println("Inference completed")
    println("State marginals: ", result.posteriors[:s])
end

if abspath(PROGRAM_FILE) == @__FILE__
    main()
end
```

### Setup Script

The pipeline includes a setup script for RxInfer:

```julia
# src/execute/rxinfer/setup_environment.jl
# Run: julia src/execute/rxinfer/setup_environment.jl --verbose
```

### Rendering Details

- **Location**: `src/render/rxinfer/rxinfer_renderer.py`
- **Output**: `output/11_render_output/{model}/rxinfer/{model}_rxinfer.jl`
- **Setup**: `src/execute/rxinfer/setup_environment.jl`

---

## ActiveInference.jl Framework

### Overview

ActiveInference.jl is a native Julia implementation of Active Inference, providing a comprehensive POMDP framework similar to PyMDP.

### Requirements

```bash
# In Julia REPL:
using Pkg
Pkg.add("ActiveInference")
Pkg.add("Distributions")
```

### Generated Code Structure

```julia
#=
ActiveInference.jl Model: {model_name}
Generated from GNN specification

Framework: ActiveInference.jl
Model: {model_name}
States: {n_states}, Observations: {n_obs}, Actions: {n_actions}
=#

using ActiveInference
using Distributions
using LinearAlgebra

# Model Configuration
const N_STATES = {n_states}
const N_OBS = {n_obs}
const N_ACTIONS = {n_actions}

# Model Matrices
A = [...]  # Observation model
B = [...]  # Transition model (n_states x n_states x n_actions)
C = [...]  # Prior preferences
D = [...]  # Initial state prior

function create_agent()
    """Create ActiveInference.jl agent."""
    return Agent(
        A = A,
        B = B,
        C = C,
        D = D
    )
end

function run_simulation(; n_timesteps=10)
    """Run Active Inference simulation."""
    agent = create_agent()
    
    # Initialize
    reset!(agent)
    
    for t in 1:n_timesteps
        # Infer states
        qs = infer_states(agent)
        
        # Select action
        action = sample_action(agent)
        
        # Simulate observation
        obs = rand(1:N_OBS)
        
        # Update agent
        update!(agent, obs, action)
        
        println("Step $t: obs=$obs, action=$action")
    end
end

if abspath(PROGRAM_FILE) == @__FILE__
    run_simulation()
end
```

### Rendering Details

- **Location**: `src/render/activeinference_jl/activeinference_renderer.py`
- **Output**: `output/11_render_output/{model}/activeinference_jl/{model}_activeinference.jl`
- **Setup**: `src/execute/activeinference_jl/setup_environment.jl`

---

## DisCoPy Framework

### Overview

DisCoPy is a Python library for categorical diagrams and compositional semantics. It represents Active Inference models as string diagrams.

### Requirements

```bash
uv pip install discopy
# Or use UV optional group:
uv sync --extra active-inference
```

### Generated Code Structure

```python
"""
DisCoPy Categorical Diagram: {model_name}
Generated from GNN specification

Framework: DisCoPy (Categorical Diagrams)
Model: {model_name}
"""

try:
    from discopy import Ty, Box, Diagram, Drawing
    DISCOPY_AVAILABLE = True
except ImportError:
    DISCOPY_AVAILABLE = False
    print("DisCoPy not installed. Install with: uv pip install discopy")

# Define types
State = Ty('State')
Observation = Ty('Observation')
Action = Ty('Action')
Belief = Ty('Belief')

# Define morphisms (boxes)
if DISCOPY_AVAILABLE:
    # Observation model: State -> Observation
    observe = Box('A', State, Observation)
    
    # Transition model: State @ Action -> State
    transition = Box('B', State @ Action, State)
    
    # Belief update: Belief @ Observation -> Belief
    infer = Box('infer', Belief @ Observation, Belief)
    
    # Policy: Belief -> Action
    policy = Box('Ï€', Belief, Action)
    
    # Compose Active Inference loop
    def create_active_inference_diagram():
        """Create categorical diagram of Active Inference loop."""
        # Start with belief
        diagram = Diagram.id(Belief)
        
        # Policy selection
        diagram = diagram >> policy
        
        # Create visualization
        return diagram
    
    def visualize(output_path=None):
        """Visualize the categorical diagram."""
        diagram = create_active_inference_diagram()
        
        drawing = Drawing.from_diagram(diagram)
        
        if output_path:
            drawing.save(output_path)
        else:
            drawing.draw()

if __name__ == "__main__":
    if DISCOPY_AVAILABLE:
        visualize()
    else:
        print("Install DisCoPy to generate diagrams")
```

### Rendering Details

- **Location**: `src/render/discopy/discopy_renderer.py`
- **Output**: `output/11_render_output/{model}/discopy/{model}_discopy.py`

---

## Framework Selection Guide

### Decision Matrix

| Use Case | Recommended Framework | Reason |
|----------|----------------------|--------|
| Quick prototyping | PyMDP | Easy Python setup |
| High performance | JAX | JIT compilation, GPU support |
| Probabilistic analysis | RxInfer.jl | Message passing inference |
| Julia ecosystem | ActiveInference.jl | Native Julia |
| Theoretical analysis | DisCoPy | Categorical semantics |

### Execution Fallback Order

When executing simulations (Step 12), frameworks are attempted in order:

1. **JAX** - Most likely to succeed (pure Python, no complex deps)
2. **PyMDP** - If installed
3. **ActiveInference.jl** - If Julia available
4. **RxInfer.jl** - If Julia + RxInfer available
5. **DisCoPy** - Visualization only

---

## Common Rendering Patterns

### Matrix Extraction

All frameworks extract the same core matrices from GNN:

```python
def extract_matrices(gnn_model: Dict[str, Any]) -> Dict[str, np.ndarray]:
    """
    Extract POMDP matrices from parsed GNN model.
    
    Returns:
        A: Observation model (n_obs x n_states)
        B: Transition model (n_states x n_states x n_actions)
        C: Preference vector (n_obs,)
        D: Initial state prior (n_states,)
    """
    matrices = {}
    
    # Extract from initialparameterization section
    init_params = gnn_model.get("initialparameterization", {})
    
    matrices["A"] = np.array(init_params.get("A", np.eye(3)))
    matrices["B"] = np.array(init_params.get("B", np.eye(3)))
    matrices["C"] = np.array(init_params.get("C", np.zeros(3)))
    matrices["D"] = np.array(init_params.get("D", np.ones(3) / 3))
    
    return matrices
```

### Documentation Generation

Each framework generates a README:

```markdown
# {Framework} Implementation: {Model Name}

Generated from GNN specification.

## Requirements

{installation_instructions}

## Running

{run_instructions}

## Model Details

- States: {n_states}
- Observations: {n_obs}
- Actions: {n_actions}

## Files

- `{model}_{framework}.{ext}` - Main simulation script
- `README.md` - This documentation
```

---

**Last Updated**: December 2025  
**Status**: Production Standard


